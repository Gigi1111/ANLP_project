{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Summary\n",
    "\n",
    "In this notebook, we train a classifier to distinguish whether a pair of new articles, in the sense of real-world events, falls into one of the categories: similar (0), rather similar (1), rather dissimilar (2), and dissimilar (3). Then, we explore the results of training three different models: a neural network, KerasClassifier, logistic regression, and support vector machine (SVM), on provided evaluation data. We also use grid searh to tune the classifiers' hyperparameters to optimize the performance, and keep logs of those information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first imported the features we extracted in the previous notebooks, and group them into 4 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train/_TRAIN_features_complete_df.csv')\n",
    "test_df = pd.read_csv('eval/_EVAL_features_complete_df.csv')\n",
    "all_df = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'overall' label to 0..3\n",
    "# 0 being most similar and 3 being not similar\n",
    "\n",
    "# Train data\n",
    "for idx,row in train_df.iterrows():\n",
    "    overall = row['overall']\n",
    "    train_df.at[idx,'overall'] = overall-1\n",
    "\n",
    "# Test Data\n",
    "for idx,row in test_df.iterrows():\n",
    "    overall = row['overall']\n",
    "    test_df.at[idx,'overall'] = overall-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check training data label imbalance:\n",
      "overall\n",
      "0    497\n",
      "1    529\n",
      "2    581\n",
      "3    978\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check training data labels\n",
    "print('Check training data label imbalance:')\n",
    "print(train_df.groupby('overall').size(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in the training set, there are almost twice as many entries provided for the dissimilar group, which could likely sway the model to 'guess' 3 more often as the possibility that a pair is dissimilar is much higher. But before balancing out the data, we'd like to explore how the models perform on imbalanced data to see if our assumption stands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Imbalanced Data\n",
    "\n",
    "we first randomly picked some hyperparameters to fit and see how well the Kerasclassifier model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced training data\n",
    "target_column = ['overall']\n",
    "predictors = list(set(list(train_df.drop(['pair_id'], axis=1).columns))-set(target_column))\n",
    "\n",
    "X_train = train_df[predictors].values\n",
    "y_train = train_df[target_column].values\n",
    "X_test = test_df[predictors].values\n",
    "y_test = test_df[target_column].values\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(y_train)\n",
    "dummy_y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2585, 5)\n",
      "(2773, 5)\n",
      "(2585, 4)\n",
      "(2773, 4)\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced training data shape : 2585\n",
    "# Balanced training data shape : 1988\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "print(dummy_y_train.shape); print(dummy_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we create a KerasClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with random hyperparameter\n",
    "hidden_size = 8\n",
    "epoch = 100\n",
    "input_size = X_train.shape[1]\n",
    "output_size = dummy_y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "kfold = 5\n",
    "\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_dim=input_size, activation='relu'))\n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassfier\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# Number of folds\n",
    "kfold = KFold(n_splits=kfold, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the training data itself to cross validate to see how the model perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(s) used: 218.81608629226685\n",
      "Baseline: 58.22% (1.06%)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = cross_val_score(estimator, X_train, dummy_y_train, cv=kfold)\n",
    "\n",
    "print('Time(s) used:',time.time() - start)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even tested using train, the result is not quite ideal (58%), so we can assume that when fed the unseen evaluation data, the result could be even lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 1.0924 - accuracy: 0.5048\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9816 - accuracy: 0.5609\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9815 - accuracy: 0.5602\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9796 - accuracy: 0.5590\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9786 - accuracy: 0.5663\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9749 - accuracy: 0.5594\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9773 - accuracy: 0.5663\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9739 - accuracy: 0.5710\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9764 - accuracy: 0.5621\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9716 - accuracy: 0.5679\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9752 - accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9719 - accuracy: 0.5675\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9707 - accuracy: 0.5733\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9704 - accuracy: 0.5640\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9677 - accuracy: 0.5702\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9671 - accuracy: 0.5756\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9735 - accuracy: 0.5710\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9674 - accuracy: 0.5702\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9653 - accuracy: 0.5749\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9675 - accuracy: 0.5706\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9663 - accuracy: 0.5694\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9648 - accuracy: 0.5741\n",
      "Epoch 23/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9646 - accuracy: 0.5749\n",
      "Epoch 24/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9665 - accuracy: 0.5729\n",
      "Epoch 25/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9616 - accuracy: 0.5826\n",
      "Epoch 26/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9632 - accuracy: 0.5768\n",
      "Epoch 27/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9618 - accuracy: 0.5779\n",
      "Epoch 28/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9601 - accuracy: 0.5741\n",
      "Epoch 29/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9649 - accuracy: 0.5718\n",
      "Epoch 30/100\n",
      "517/517 [==============================] - 2s 3ms/step - loss: 0.9583 - accuracy: 0.5725\n",
      "Epoch 31/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9610 - accuracy: 0.5749\n",
      "Epoch 32/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9584 - accuracy: 0.5791\n",
      "Epoch 33/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9618 - accuracy: 0.5683\n",
      "Epoch 34/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9603 - accuracy: 0.5706\n",
      "Epoch 35/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9618 - accuracy: 0.5768\n",
      "Epoch 36/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9592 - accuracy: 0.5810\n",
      "Epoch 37/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9604 - accuracy: 0.5749\n",
      "Epoch 38/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9590 - accuracy: 0.5810\n",
      "Epoch 39/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9610 - accuracy: 0.5749\n",
      "Epoch 40/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9601 - accuracy: 0.5741\n",
      "Epoch 41/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9582 - accuracy: 0.5749\n",
      "Epoch 42/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9573 - accuracy: 0.5745\n",
      "Epoch 43/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9580 - accuracy: 0.5779\n",
      "Epoch 44/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9606 - accuracy: 0.5729\n",
      "Epoch 45/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9597 - accuracy: 0.5752\n",
      "Epoch 46/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9598 - accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9597 - accuracy: 0.5814\n",
      "Epoch 48/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9598 - accuracy: 0.5694\n",
      "Epoch 49/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9567 - accuracy: 0.5768\n",
      "Epoch 50/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9605 - accuracy: 0.5760\n",
      "Epoch 51/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9580 - accuracy: 0.5725\n",
      "Epoch 52/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9581 - accuracy: 0.5737\n",
      "Epoch 53/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9586 - accuracy: 0.5702\n",
      "Epoch 54/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9563 - accuracy: 0.5803\n",
      "Epoch 55/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9577 - accuracy: 0.5764\n",
      "Epoch 56/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9601 - accuracy: 0.5702\n",
      "Epoch 57/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9609 - accuracy: 0.5663\n",
      "Epoch 58/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9576 - accuracy: 0.5791\n",
      "Epoch 59/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9600 - accuracy: 0.5687\n",
      "Epoch 60/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9566 - accuracy: 0.5752\n",
      "Epoch 61/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9608 - accuracy: 0.5814\n",
      "Epoch 62/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9567 - accuracy: 0.5803\n",
      "Epoch 63/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9576 - accuracy: 0.5787\n",
      "Epoch 64/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9549 - accuracy: 0.5706\n",
      "Epoch 65/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9550 - accuracy: 0.5768\n",
      "Epoch 66/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9562 - accuracy: 0.5737\n",
      "Epoch 67/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9579 - accuracy: 0.5807\n",
      "Epoch 68/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9558 - accuracy: 0.5795\n",
      "Epoch 69/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9577 - accuracy: 0.5683\n",
      "Epoch 70/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9583 - accuracy: 0.5760\n",
      "Epoch 71/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9563 - accuracy: 0.5783\n",
      "Epoch 72/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9568 - accuracy: 0.5799\n",
      "Epoch 73/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9584 - accuracy: 0.5783\n",
      "Epoch 74/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9570 - accuracy: 0.5779\n",
      "Epoch 75/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9566 - accuracy: 0.5737\n",
      "Epoch 76/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9562 - accuracy: 0.5876\n",
      "Epoch 77/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9562 - accuracy: 0.5737\n",
      "Epoch 78/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9557 - accuracy: 0.5760\n",
      "Epoch 79/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9540 - accuracy: 0.5791\n",
      "Epoch 80/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9592 - accuracy: 0.5791\n",
      "Epoch 81/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9577 - accuracy: 0.5772\n",
      "Epoch 82/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9561 - accuracy: 0.5779\n",
      "Epoch 83/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9538 - accuracy: 0.5799\n",
      "Epoch 84/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9567 - accuracy: 0.5714\n",
      "Epoch 85/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9568 - accuracy: 0.5718\n",
      "Epoch 86/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9557 - accuracy: 0.5737\n",
      "Epoch 87/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9582 - accuracy: 0.5756\n",
      "Epoch 88/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9567 - accuracy: 0.5698\n",
      "Epoch 89/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9573 - accuracy: 0.5764\n",
      "Epoch 90/100\n",
      "517/517 [==============================] - 1s 3ms/step - loss: 0.9570 - accuracy: 0.5807\n",
      "Epoch 91/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9570 - accuracy: 0.5745\n",
      "Epoch 92/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9555 - accuracy: 0.5779\n",
      "Epoch 93/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9557 - accuracy: 0.5783\n",
      "Epoch 94/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9582 - accuracy: 0.5721\n",
      "Epoch 95/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.9573 - accuracy: 0.5737\n",
      "Epoch 96/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9537 - accuracy: 0.5725\n",
      "Epoch 97/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9567 - accuracy: 0.5745\n",
      "Epoch 98/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9555 - accuracy: 0.5772\n",
      "Epoch 99/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9571 - accuracy: 0.5632\n",
      "Epoch 100/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.9544 - accuracy: 0.5752\n"
     ]
    }
   ],
   "source": [
    "# Fit train data\n",
    "train_result = estimator.fit(X_train, dummy_y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 52.54237288135594 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.66       736\n",
      "           1       0.36      0.23      0.28       652\n",
      "           2       0.38      0.28      0.32       584\n",
      "           3       0.63      0.69      0.66       801\n",
      "\n",
      "    accuracy                           0.53      2773\n",
      "   macro avg       0.48      0.50      0.48      2773\n",
      "weighted avg       0.50      0.53      0.50      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction and get accuracy\n",
    "y_pred = estimator.predict(X_test)\n",
    "print('Accuracy on test data:',accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsnUlEQVR4nO3dd3wU1drA8d+TTSBAQkLvSAcR6QqKBcECCGJDUFReBRGvqNiuXRTLvXqvoIhdVFCvAgIX9GJBihQLnUhVpBeBUAIJhCSb5/1jhxgUkl3Yzexunq+f+WTm7OzMMwJPzjkz54yoKsYYE41i3A7AGGNCxRKcMSZqWYIzxkQtS3DGmKhlCc4YE7Vi3Q4gP4ktpVIi0e0wgu7MxrXcDiFkPDHidgghEZ1XBZs2bSQ1NfWULs9T9jTVnMN+7auHd3+tql1O5XynIrwSXIlESja+zu0wgu6r2cPdDiFkEuPD6q9Q0MR6orNx06Fd21M+huZkUrJJH7/2zVz6asVTPuEpiM6/ncaY0BFAIqOOawnOGBM4iYwariU4Y0zgrAZnjIlOAjEet4PwiyU4Y0xgBGuiGmOilVgT1RgTxawGZ4yJWlaDM8ZEJ7EanDEmSgl2F9UYE62sBmeMiWYRMsmCJThjTGDsOThjTFSzu6jGmOhkQ7WMMdHMmqjGmKgkNlTLGBPNrAZnjIlaVoMzxkQne9DXGBOtbKiW+5ZPeZr0Q0fw5uaSk5NLp34v0qxhDV56uA8JpUuyecceBj4xhoMZmXQ8uwlDB19BibhYsrJzeHLkf5m76Be3L6FQ6zfv4q6nx+Ztb9mxhyG3dGHpqk2s37wLgAPphymbUIr/jX7ArTADlnkkmyvueIWsrBxyvLn06NSSh27rxpyFa3nq1SnkqlKmVElefaIv9WpVcjtcv239fR93PDWW3XsPIkC/qzow6PqL+PmXrdz/z09JP3SE2tUq8PYz/SibUMrtcAtgNTgARKQL8ArgAd5V1X+G8nx/1mPQK+xNy8jbfuXxG3jilcl8v2QdfXu0566bOvP8m/9jz/50rr/vLX5PTeP0+tX4bOSdnHH540UZ6kmpV7tyXuLyenM559qnuez8M7m114V5+zz3+hQSy8S7FeJJKVkilkmj7iKhdEmyc7x0H/gync85nQdfHM+HL95Go7pVee+zuQx//2tGPXmj2+H6LTY2hmeHXE2LJrU4mJHJRTe/QMd2Tbjn2f/wzD1X0aFNQz6a+gOvfjiDx+7o7na4BYuQPriQpWER8QCvAV2BpsD1ItI0VOfzR4Palfl+yToAZi9YQ4+LWgLw8y9b+T01DYDVv+2gVMk4SsRFVuX2+yW/clqNCtSoWj6vTFWZNms5PTq3djGywIkICaVLApCd4yU7x4sgiAgHMzIBOJBxmKqVktwMM2BVKybRoonvJeCJZeJpVKcqO3bvZ93mXZzbugEAHc9uwuezlrkYpZ8kxr/FZaH8V3w2sE5V1wOIyKdAT2BVCM+ZR1WZNGowqsoHk+czZvJ81qzfQbcLmzPtuxR6dm5NjSrl/vK9Kzq1ZPnaLWRl5xRFmEHz+cyl9OjU6piyhSnrqVAugbo1I6cZd5TXm0vn//sXG7bupv8159OmWR1GPHo919/3JvEl40gsE89Xo+9zO8yTtnn7HlLWbqXNGXVoUq8a075L4fKOLZgyYwnbdu5zO7zCFfcaHFAD2JJve6tTViS63jaCjje9QK97XmfAtedzbqv6DB72Mf2vPZ9ZY//ua/5ke4/5TpN6VXnqrp7c+/ynRRVmUGRl5zBj/kq6dmx5TPnUGUu5IsJqb0d5PDHM/vAhUqYOY8mqTaz+bTtvfTKLT4YPIuXzZ7i+e3ueeHmy22GelPRDR7j5oXf5x33XUDahFKOe7Mvoz+bS8aYXSD90hLi4MO/AF7EanL9EZCAwEIC4hKAdd8duX5MzdV86X8xOofUZdRj10Qyuues1AOrXrsyl552Rt3/1ysl8+OJA7hj6IRu3pQYtjqLw3U9rOKNRDSqVT8wry8nx8vXcFKa+Fbm1HICkxNKc16YhM35Yzcp122jTrA4AV17cit5D3nA3uJOQneOl30Pv0KtLW3p0aglAozpVmTRqMADrNu3km3krXYzQPxLjfvLyRyij3AbUyrdd0yk7hqq+raptVbWtxAbnzlHp+BJ5fTil40vQqX0TVv+2nYrlfAlURHjg1st4f+I8AMomlGLciEE8/doUfkpZH5QYitLnM5b8pZ9t/uJfqF+7MtUqJ7sT1ClI3XeQtIOHADicmcXsBWtpVKcKB9Iz+c25Ozx7wVoa1qnqZpgBU1XueuZjGtWpyp19O+eV7957EIDc3Fz+/d7X3HLNeW6F6BfB92/In8VtoazBLQQaikhdfImtD3BDCM+Xp1KFRD568TYAPLEeJn61iBk/rOb2Ph0ZcO0FAHwxexkff/4jALdddwF1a1Xi7wO68vcBXQG4evAoUvelF0W4p+TQ4SPMW/wLz97f65jyL2Yuo0enyGye7kw9wOBnPiLXq+Sq0rNzSy49rxnDH+nDLY+MJkaEpMTSvPJ4kfx1Cpofl69n3LQFNG1QnfNv+AcAT9x5Bes37+Ldz+YA0L1jS/r2aO9mmIUTZ4kAoqqhO7hIN+BlfI+JvKeqzxW0f0zpylqy8XUhi8ct62cPdzuEkEmMd72XIyRiPZHRBAtUh3ZtWbx40SmlJ0/5ulrq4qF+7Zsx4ZbFqtr2VM53KkL6t1NVpwHTQnkOY0zRC4fmpz+i89eUMSakYmJi/FoKIyIbReRnEVkmIoucsvIiMl1EfnV+lnPKRURGisg6EUkRkUL7YCzBGWMCIwEs/rlIVVvma8o+DMxQ1YbADGcbfIMGGjrLQKDQ2+iW4IwxATk6qiSEd1F7AmOc9THAlfnKx6rPj0CyiFQr6ECW4IwxAQsgwVUUkUX5loF/OpQC34jI4nyfVVHVHc7670AVZz3gwQPReQvMGBNSAdTOUgu5i3qeqm4TkcrAdBFZk/9DVVUROelHPawGZ4wJWLCaqKq6zfm5C5iMbwz7zqNNT+fnLmd3vwYP5GcJzhgTGAGJEb+WAg8jUkZEEo+uA5cCK4CpQD9nt37AFGd9KnCzcze1PZCWryl7XNZENcYE5OhNhiCoAkx2jhUL/EdVvxKRhcB4EekPbAKOPv0/DegGrAMOAbcUdgJLcMaYgAUjwTlTqbU4TvkeoPNxyhW4M5BzWIIzxgQuMgYyWIIzxgRIImeoliU4Y0zALMEZY6KSIH6NMw0HluCMMYGLjAqcJThjTICsD84YE80swRljopYlOGNM1CpsGFa4sARnjAlIuLwxyx+W4IwxAbMEZ4yJWpbgTkLF6pXp9cTf3A4j6Lbvy3Q7hJBJLh3ndgghUTIuMh5kDVR2bpBeExoZ+S28EpwxJjJYDc4YE5VEIMbuohpjopPdRTXGRLEIyW+W4IwxgbManDEmOonV4IwxUUqwmwzGmChmCc4YE52siWqMiVaC3WQwxkQtew7OGBPFIiS/WYIzxgTIhmoZY6KV9cEZY6JahOQ3S3DGmMBFSg0uOmf1M8aElIh/i3/HEo+ILBWRL5ztuiLyk4isE5FxIlLCKS/pbK9zPq9T2LEtwRljAiN/vHimsMVP9wCr822/AIxQ1QbAPqC/U94f2OeUj3D2K5AlOGNMQAQhJsa/pdBjidQELgfedbYF6AR85uwyBrjSWe/pbON83lkKyaKW4IwxAQtiE/Vl4O9ArrNdAdivqjnO9laghrNeA9gC4Hye5ux/QpbgjDEBC6CJWlFEFuVbBuY7Rndgl6ouDlWcdhfVGBOYwAbbp6pq2xN81gG4QkS6AfFAWeAVIFlEYp1aWk1gm7P/NqAWsFVEYoEkYE9BJ7canDEmIEcf9D3Vmwyq+oiq1lTVOkAfYKaq9gVmAdc6u/UDpjjrU51tnM9nqmqB70GMyhpcbIxwZ4c6xMYIMQIpOw7y9drddKhTjgvqV6BimRI8+dVaMrK8ALSuUZaLGlZEgCM5uXyWsoMdB464exEn8PyrE/l+0RrKJZXhw5FDABj96bd8Pn0RyWXLAHD7jZdyTpvGAHw4cTZffLuImJgYhgzoTrtWjdwKvUCPvzSeOT+tonxyAv99+wEA0g4c4v7nP2L7zn1Ur1KOlx67kaTE0ixY/ht3P/UBNaqWA+DiDmdyx42XuBm+396f8B3jp/2EiNCoblVeeKgPT4z4jIXL15NQJh6AFx7qQ9MGNQo5krtC/BzcQ8CnIvIssBQY7ZSPBj4UkXXAXnxJsUAhS3Ai8h5wtI3dLFTnOZ6cXOWN7zeS5VViBAafV5fVu9LZuPcwq3Zu4m8dTjtm/72Hsnl9/kYOZ+fSpHICvVpUZ+TcDUUZst+6dWrNNd3a8+wrE44pv65HB2648vxjyjZs2cm381L4cOQQUvceYMjQ9/jktfvweMKv4n7lpW254YpzefRfn+aVvTt+Ju1bNWBA7068O24mo8fN4r4BlwPQulldXn/mVrfCPSm/705j7OR5fPn+34kvGcfdT4/li5lLAfj77d3pemELlyP0X7DHoqrqbGC2s74eOPs4+2QCvQI5bij/pn8AdAnh8QuU5fXVXD0xgkcAhW0HMtl3OPsv+27cd5jD2b6bOJv2HSI5Pnwrti3PqEvZxNJ+7TtvwWouPq85JeJiqV6lPDWrVWD1r1tDHOHJaXtmPZL+dF2zflhFz4t93Tc9L27LzB9WuhFaUOV4vWQeySbH6+XwkSwqV0hyO6TA+XkHNRwGO4QswanqHHzVSFcIcN+F9Xj6ssb8sjuDzfsP+/W9drXLsWZXemiDC4FJ036g35CRPP/qRA6k+651954Dx/wDqlShLLv3prkVYsD27DtIpQplAahYPpE9+w7mfbZ89SauHjScQY+9y7qNv7sVYkCqVkqi/3UdubDPM5x77dMklonn/LN8XQkjRn9J9wH/5rnXpnAkK6eQI7lL8K//LRyGc7neVhGRgUdvIR9OC14+VGD4d+sZ9s0v1C5XiqqJJQv9Tv0KpTm7djJfrNoVtDiKwlVd2jHujQd4f/hgKpRLZNT709wOKejy/4Np2qAG0z98lElv3scNPTtw99NjCvl2eEg7eIgZ81cy8z+PMX/CUA5nZjFl+mIeGHA5X495iImvDyHt4CHe/nSm26EWqtjX4Pylqm+raltVbVsqqXzQj5+Zk8u61AyaVE4ocL9qZUtyXcvqvLdgC4eyvUGPI5TKJyfi8cQQExPDFZeexepftwC+GtuuPX/U2HbvOUCl8pHTJKpQLpHdew4AvtjLJ/v+DBPKxFO6lO8X1gVnn06O18u+tAzX4vTX94t/pWa18lRITiAu1sOl5zdnycqNVK5QFhGhZIlYrulyFilrNrsdaqFiRPxa3OZ6gguFMiU8xMf6Li02RmhUKYGd6Se+K5pcKpb/O6sWnyzZRmpGVlGFGTSpew/krc/5cSX1TqsCQIezTufbeSlkZeewfedetuxI5fSGNd0KM2Ad2zdlyreLAJjy7SIuOqcp4Lveo08H/LxmM7m5SnJZ//ol3VStSjLLVm3icGYWqsoPS36lfu3K7HKSuKoyfd4KGtWp6nKkBRNnwstgDNUKtfDtTT8FZeNjub5VdV+zBli+/QCrd6ZzXt3yXNSgAoklY7m/Yz3W7Exn/PIdXNqoEqXjPFzdvBoAuaq8PCc876IOfelTlq3cwP4DGVw14J/073MxS1es59cNOxARqlZO5sFBVwJQr3YVOp17Jjfe9TIeTwz33XZFWN5BBXjwHx+zMOU39qdl0Lnvs/ztpksZ0Psi7n/uIyZ9tZDqlZN56bGbAPhm7s+M++IHPJ4Y4kvG8a9H+oZFf09hWp5+Gl0ubM6Vtw/H4/HQtEENenc/hwEPv8PetHRU4fQG1Rl277WFH8xlYZC7/CKFPCd38gcW+QToCFQEdgJDVXV0Qd+p3KCZ9npxfEjicdOtrSOn1hSo5NJxbocQEiXjwvMXwanq1ulcUpYuPqX0lHTa6drhEf/6Pb+8o93iAkYyhNwJa3Ai8iq+vvrjUtW7Czqwql5/CnEZY8JYBFSYgYKbqIuKLApjTMQQfI+KRIITJjhVPaYOKiKlVfVQ6EMyxoS7SOmDK7SjQUTOEZFVwBpnu4WIvB7yyIwx4UmCN+FlqPnTk/oycBnOtCSquhy4IIQxGWPCmBA5z8H59ZiIqm750234yHoS1hgTVGGQu/ziT4LbIiLnAioicfz1BRHGmGImEp47BP+aqIOAO/HNh74daOlsG2OKIX/HoYZDDiy0BqeqqUDfIojFGBMhPOGQvfzgz13UeiLyuYjsFpFdIjJFROoVRXDGmPAUTdMl/QcYD1QDqgMTgE9CGZQxJnz57qL6t7jNnwRXWlU/VNUcZ/kI3xtwjDHFkZ+1t3CowRU0FvXo5GxfisjDwKf4xqb2BqJvRkVjjN/CIHf5paCbDIvxJbSjl3J7vs8UeCRUQRljwls41M78UdBY1LpFGYgxJjIIvpc5RQK/RjKISDOgKfn63lR1bKiCMsaEt8hIb34kOBEZim/iyqb4+t66AvMAS3DGFEMihMU4U3/4cxf1WqAz8Luq3gK0ACLnzSXGmKCLmpEMwGFVzRWRHBEpC+wCaoU4LmNMGIv4mwz5LBKRZOAdfHdW04EfQhmUMSa8RUh+82ss6t+c1TdF5CugrKqmhDYsY0y4EpHIv4sqIq0L+kxVl4QmJGNMuIuGJupLBXymQKcgx0LVhJI8eEH0jePPzI7e+UFTD574hdqRbOehTLdDCIlDWTlBOU6kvFSxoAd9LyrKQIwxkUEITg1OROKBOUBJfLnoM1UdKiJ18Q0NrYCv3/8mVc0SkZL4Hk9rg+8VCr1VdWNB54iURGyMCSNBmk3kCNBJVVvgm0i3i4i0B14ARqhqA2Af0N/Zvz+wzykf4exXcJwndXXGmGJLxDdUy5+lIOqT7mzGOcvR7q/PnPIxwJXOek9nG+fzzlJIVdISnDEmYAHU4CqKyKJ8y8D8xxERj4gsw/d87XTgN2C/qh7tLNyK73UJOD+3ADifp+Frxp6QP0O1BN+U5fVUdZiI1AaqquoCv/5PGGOiTgBdcKmq2vZEH6qqF2jpPGs7GWhyysHl408N7nXgHOB6Z/sg8FowgzDGRI5QvBdVVfcDs/DlmmQROVr5qglsc9a34Yyicj5Pwnlf84n4k+DaqeqdQKYTyD6ghN+RG2OiToyfS0FEpJJTc0NESgGX4Hsl6Sx8Y+AB+gFTnPWpzjbO5zNVVQs6hz9DtbJFxIOv8w8RqQTk+vE9Y0yUCtJzvtWAMU5+iQHGq+oXIrIK+FREngWWAqOd/UcDH4rIOmAv0KewE/iT4EbiaxtXFpHn8GXOxwO+FGNMVAjWUC1nyGer45SvB84+Tnkm0CuQc/gzFvVjEVmMb8okAa5UVXuzvTHFWIQMRfXrLmpt4BDwef4yVd0cysCMMeHp6E2GSOBPE/V//PHymXigLrAWOCOEcRljwliE5De/mqhn5t92Zhn52wl2N8ZEuzB5qbM//HrpTH6qukRE2oUiGGNMZJAIee2MP31w9+XbjAFaA9tDFpExJqwJEBshgzz9qcEl5lvPwdcnNzE04RhjIkE0THiJ8wBeoqo+UETxGGPCnO8uqttR+KegKctjVTVHRDoUZUDGmDAXJq8E9EdBNbgF+PrblonIVGACkHH0Q1WdFOLYjDFhKpqeg4vHN2K/E388D6eAJThjiiEBPFFwk6Gycwd1BX8ktqMKHMFvjIlmQkwUPCbiARLguFdiCc6YYsr30hm3o/BPQQluh6oOK7JIQmjspLlM+PJHVKFXt3b0u/oCRo39mgnTfqJ8UgIAQ27tyoXtTnc50sI9NWICcxaspnxyAp+94XtEcfrcFN78eDobtuzmwxGDOaNRTQCyc7wMe+Uz1qzbjjfXy+Wd2tC/d3i+LO2F1ybxw+K1JCeV4YMRd+eVT5r2A5O/+glPTAzt2zRi0E1d2LFrH/2GvEKt6hUBaNqwFvff3tOt0AuUuieN196eSlpaBiLQuWNrul12Nunph3n5tUnsTt1PpYrJDBl8NQllSgGwcvVGxnw8Ha/XS2JCaZ567GaXr+JPomQkwyldgojUwveKryr4anxvq+orp3LMk/HLhh1M+PJHxr96D3FxHm575F06tmsKQL9rLuDWXh2LOqRT0uPiNvTucS5PvDQur6z+aVV46fGbefbVY7tFv52bQlZ2DhPeuJfDmVlcM2g4XTu2oHqV8kUddqG6XNSKq7q25/lXP8srW7piPfMWrmb0S4MpERfLvrT0vM+qVynP6H8PdiPUgHg8Mdx0/cXUq1ONw4eP8MiTo2nerC6z56bQrGkdruzRgf9+Pp8pX3xP396dycjIZPSYr3j0geupWDGJtAMZhZ/EBZFyk6GgrsLOp3jsHOB+VW0KtAfuFJGmp3jMgK3fvIvmTU6jVHwJYj0ezmpej+nzfi7qMIKmzZn1SEosdUxZvdpVqFOz0l93FiEzM5scr5cjWdnExXooUzq+iCINTIumdUlMOPa6pny9gBuuuoAScb7fw+Wc2nYkKZecSL061QAoVaokNapXZO++gyxaspYLz28OwIXnN2fh4rUAzPthBWe3bUzFikkAJJUt407gBTjaRPVncVtBL37eeyoHVtUdwA5n/aCIrMb3VpxVp3LcQDWsU5WX3/+SfQcyiC8Rx5wFa2jWqCbJZUvz8ZT5TJm+mGaNavL323uQlFi6KEMLuYvPO5PZP67kkr7PkXkkiwcGRtY1btmRys+rNzH6P99SokQsd9zchSYNfM3v33ftY8ADr1GmdEn697mY5k3ruBusH3bt3s+GTb/ToH4N0g5kUC7ZN0goOSkhr6a24/e9eL1enn5+LIczs+h66dlceF5zN8M+rmBMeFkUAh5sfzJEpA6+mTt/Os5nA4GBANVr1gr6ueufVoUBvS9iwMNvUyq+BE3qVycmJoY+Pc7ljr6XIAIjP/iaF9/6nOce6B3087tp5doteGJi+OajxziYfphbH3yDdi0bULNagW9aCxteby4H0g/z+j9uZ826bTw1/FM+ee1+KpRLZNybD5KUWJq1v23j8Rc/5oMRd4dt7RQgMzOL4a9+Rr++l1K6VMljPhORvMHrubm5rN/4O0883JesrByeGPY+DevXoHoY/ZkJkfO+0ZDHKSIJ+MauDlHVA3/+XFXfVtW2qtq2QoXjNLOC4Nqu7Zj4+r18NPxOkhJKUadmRSqWS8TjiSEmJoZe3dqRsjb65u/8cvYyzm3TmLhYD+WTE2jZtA6rft3qdlh+q1QhiQvaNUVEOL1hTWJESDtwiBJxsXk10cb1a1C9Snm2bC/w5Uquysnx8tLIzzjvnGa0O8v3VryksmXYt/8gAPv2H6RsWd/1lC+XSIsz6xFfsgRlE0tzeuPabNqy07XYj0ucpOzH4raQJjgRicOX3D52c+TDnn2+v0jbd+1j+vyf6d6pNbv2/JFrp89fQUOnnySaVK2czMLl6wA4nJlFyprN1KlV2eWo/HfeWaezdMV6ALZsTyU7x0tS2dLsT8vA6/W992j7zr1s+30P1auUczPUE1JV3hz9BTWqV6R71/Z55W1bNeK7uSkAfDc3hbatG/vKWzdm7S9b8HpzOXIkm19/204N525xOBE/F7eFrInqvDB6NLBaVYeH6jz+uGfYWPYfyCA21sMTg6+mbEIpnh01mTW/bUdEqFGlHE8NubbwA4WBh1/4D4tT1rP/QAaX3fQcg268hKTE0rzwxhT2pWVw91Pv07heNV5/dgC9u5/D0BETuGbQS6hCz0va0qhueCbyYSPGsWzlBtIOHuLagS9yS+9OdOvUmhden8z/3TuSuFgPjwy+BhFh+eqNvP/pDDyxMcSIcN/AnpQN077Ftb9sYe78n6ldqzJ/f/wdAK7vdRE9u5/Ly69NYtacZVSskMS9g68BoGaNirQ4sz4PPvY2IkKnC1tSu2Z4/VKKpCnLpZDXCp78gUXOA+YCP/PHawYfVdVpJ/pO85ZtdOq380MSj5sys71uhxAyaYey3Q4hJHYeynQ7hJC4r89lrFu5/JSyU72mzfWZD0/4z/gYN7attbigN9uHWshqcKo6j/CopRpjgkqIsbuoxphoFEl3US3BGWMCFg53SP1hCc4YE7DISG+W4IwxgRKrwRljopQAHktwxphoFRnpzRKcMeYkREgFLmLu9hpjwoTvMRHxaynwOCK1RGSWiKwSkZUico9TXl5EpovIr87Pck65iMhIEVknIiki0rqwWC3BGWMCFqT54E40Z+TDwAxVbQjMcLYBugINnWUg8EZhJ7AEZ4wJkPj9X0FUdYeqLnHWDwJH54zsCYxxdhsDXOms9wTGqs+PQLKIFDi42vrgjDEBCfAuakURWZRv+21Vffsvxzx2zsgqzoS5AL/je+0B+JLflnxf2+qU7eAELMEZYwIT2HTkqYUNtv/znJH5n7FTVRWRk54RxJqoxpiABeudDCeYM3Ln0aan83OXU74NyD/td02n7IQswRljAhaMPrgC5oycCvRz1vsBU/KV3+zcTW0PpOVryh6XNVGNMQHxTXgZlEN1AG4CfhaRZU7Zo8A/gfEi0h/YBFznfDYN6AasAw4BtxR2AktwxpiABWNG30LmjPzLa0vVNzvvnYGcwxKcMSZghTU/w4UlOGNMQILYRA05S3DGmAAVfgMhXFiCM8YEJrDn4FxlCc4YE7AIyW/hleA8MUK5MnFuhxF0h7Ki93FDb25oXjvpto63jyl8pwh0ZMueUz6GTXhpjIlukZHfLMEZYwJnNxmMMVErQlqoluCMMYGLkPxmCc4YcxIiJMNZgjPGBEQkOGNRi4IlOGNMwCIjvVmCM8acjAjJcJbgjDEBsrGoxpgoFiFdcJbgjDGBESzBGWOimDVRjTFRy2pwxpioFSH5zRKcMSZAQsRkOEtwxpiAWR+cMSYq2UtnjDHRzRKcMSZaWRPVGBO17DERY0zUipD8ZgnOGHMSIiTDFZsE5/Xmctmt/6ZqpSQ++vftzF20lmGjppKrSplSJXjl8b7UrVnJ7TADsn7zLu56emze9pYdexhySxeWrtrE+s27ADiQfpiyCaX43+gH3ArTL0+/PIF5C9dQLimB8a/fC8Ar701jzoLVxMV6qFm1PEOH9CIxoRQAv27YwfOjJpNxOBMRYeyIwZQsEZ6vnFw+ZhDph7Lw5uaS482l091jeejGDtzcpQV70g4B8MwHc5i+cD0A9/Zuz42XNcebm8vDb8xg5uINbob/FzbhJSAi8cAcoKRzns9UdWiozleYd8Z/R8M6VTiYkQnAQ/+awAcvDKBRnaq8P3EuIz74hpGP93UrvJNSr3blvMTl9eZyzrVPc9n5Z3Jrrwvz9nnu9Skklol3K0S/9bi4Db27n8uTw8fnlbVr2YA7+11GrMfDyPe/5P0Js7n7lq7keL088dI4ht13HY3qVWf/gQxiPR4Xoy9cj4c+Ye+Bw8eUvTF5EaMmLjimrHHtClx94emcc/toqpZP4L//6E3bAe+QG2bvnw1WehOR94DuwC5VbeaUlQfGAXWAjcB1qrpPRAR4BegGHAL+T1WXFHT8UL6R+AjQSVVbAC2BLiLSPoTnO6Htu/bz7fcr6dvjnLwyESHdSXYHMzKpWrGsG6EFzfdLfuW0GhWoUbV8XpmqMm3Wcnp0bu1iZP5p3aweZRNLHVPWvnWjvMR1ZuNa7EpNA+DHJb/SsE5VGtWrDkBy2TJ4PNHxcu1u5zRk0nerycr2snlnGut37KdN42puh/VX4udSuA+ALn8qexiYoaoNgRnONkBXoKGzDATeKOzgIavBqaoC6c5mnLO48mvoiZcn8cSdPUk/lJlX9tLDfeh7/1vEl4wjoUw80965z43QgubzmUvp0anVMWULU9ZToVxCxDW9j2fq9EVcckELADZvTwURBj8xmn0HMrj0/Bb0u/bCQo7gHlVl0vPXoQofTFvGmC+XA3DbFa3pc/EZLP3ldx5/ZyZp6UeoViGBRWu25313e+pBqlVIdCv0EwjehJeqOkdE6vypuCfQ0VkfA8wGHnLKxzq55UcRSRaRaqq640THD+mvPRHxiMgyYBcwXVV/CuX5jueb+SuoWC6BFk1qHVP+9rjZfPzS7SydMow+l7dj6MjJRR1a0GRl5zBj/kq6dmx5TPnUGUu5IgJqb4UZPW4mHk9M3vV5vbksX7WRZx/ow+gXBjH7h5UsWLbO3SAL0PX+j+k4eAy9Hp/AgB6tObdZTd77YimtbnmL8//2Pjv3pvPsbZ3cDjMgIv4tQEURWZRvGejH4avkS1q/A1Wc9RrAlnz7bXXKTiikNxlU1Qu0FJFkYLKINFPVFfn3cS54IECtWrWDHsPClA18M28FM35YzZGsbNIzMul7/1us27ST1mfUAaBn51Zcf9+bQT93UfnupzWc0agGlcr/8Zs+J8fL13NTmPpWhNdMv13EvAVreOO5AYjzL6ZyhSRanVGX5KQyAHRo25g1v23j7JYN3Az1hHbs8TVkUtMO8cX3v9C6cXW+X7E17/MxXy1n3NPX5u1bo9If3SXVKyayY8/Bog24EAFOeJmqqm1P9lyqqiJy0i2/Ium4UNX9wCz+2tZGVd9W1baq2rZCxeA3pR67owdLpwxj0aShvDmsHx3aNGTMCwM4mJHJb86dxjkL19KoTpVCjhS+Pp+x5C/9bPMX/0L92pWpVjnZnaCC4PvFaxk7cQ7Dn7yZ+PgSeeXntGnIuk2/k5mZRY7Xy5IVG6hXOzz//EqXjCOhVIm89U6t67J6426qlC+Tt0/3cxuxemMqAF/+uI6rLzydEnEealdJon71cixee8IWmGvEz/9O0k4RqQbg/NzllG8D8jfFajplJxTKu6iVgGxV3S8ipYBLgBdCdb5AxMZ6+PfDven/6HvExAhJiaV5+dHr3Q7rpBw6fIR5i3/h2ft7HVP+xcxl9OgUOc3TR1/8hMU/r2f/gQy69XuegX0v4YMJs8nOzuHOx0cD0KxxbR4dfBVlE0rT98rzufm+UYDQoW1jzjuribsXcAKVypXmoyevBsDjiWHirFXMWLyBNx+8nDPrVUFRNu9M496RXwOwZlMq/52zhh/f6k9Obi4PvjY97O6gQshHMkwF+gH/dH5OyVc+WEQ+BdoBaQX1vwGIr78u+ESkOb4OQg++muJ4VR1W0HdatW6rs+cXeTddyB3K8rodQsjsTc9yO4SQaNvvNbdDCIkjC14l98DWU0pPzVu20f/N/N6vfWtXiF9cUBNVRD7Bd0OhIrATGAr8FxgP1AY24XtMZK/zmMgofC3BQ8AtqrqooPOH8i5qCtCq0B2NMZFFgleDU9UTNZ06H2dfBe4M5PjFZiSDMSaYivlIBmNMdLIJL40xUS1ChqJagjPGBM4mvDTGRK/IyG+W4IwxgYuQ/GYJzhgTGAniYyKhZgnOGBMwiZAMZwnOGBOwyEhvluCMMSchQipwluCMMYEK3oSXoWYJzhgTkADng3OVJThjTMAswRljopY1UY0x0cmegzPGRCv/3wjoPktwxpjARUiGswRnjAmY9cEZY6KWTXhpjIleluCMMdHKmqjGmKgUSSMZQvZe1JMhIrvxvQexKFQEUovoXEXJrivyFOW1naaqlU7lACLyFb6Y/ZGqql1O5XynIqwSXFESkUUFvZA2Utl1RZ5ovja3xbgdgDHGhIolOGNM1CrOCe5ttwMIEbuuyBPN1+aqYtsHZ4yJfsW5BmeMiXKW4IwxUavYJTgR6SIia0VknYg87HY8wSIi74nILhFZ4XYswSQitURkloisEpGVInKP2zEFg4jEi8gCEVnuXNfTbscUjYpVH5yIeIBfgEuArcBC4HpVXeVqYEEgIhcA6cBYVW3mdjzBIiLVgGqqukREEoHFwJWR/mcmvheLllHVdBGJA+YB96jqjy6HFlWKWw3ubGCdqq5X1SzgU6CnyzEFharOAfa6HUewqeoOVV3irB8EVgM13I3q1KlPurMZ5yzFp7ZRRIpbgqsBbMm3vZUo+MdSXIhIHaAV8JPLoQSFiHhEZBmwC5iuqlFxXeGkuCU4E6FEJAGYCAxR1QNuxxMMqupV1ZZATeBsEYmaroVwUdwS3DagVr7tmk6ZCWNOH9VE4GNVneR2PMGmqvuBWYBrg9KjVXFLcAuBhiJSV0RKAH2AqS7HZArgdMaPBlar6nC34wkWEakkIsnOeil8N77WuBpUFCpWCU5Vc4DBwNf4OqvHq+pKd6MKDhH5BPgBaCwiW0Wkv9sxBUkH4Cagk4gsc5ZubgcVBNWAWSKSgu8X73RV/cLlmKJOsXpMxBhTvBSrGpwxpnixBGeMiVqW4IwxUcsSnDEmalmCM8ZELUtwEUREvM5jEitEZIKIlD6FY30gItc66++KSNMC9u0oIueexDk2ishf3r50ovI/7ZNe0OfH2f8pEXkg0BhNdLMEF1kOq2pLZ7aQLGBQ/g9F5KTec6uqAwqZnaMjEHCCM8ZtluAi11yggVO7misiU4FVzgDuf4nIQhFJEZHbwTciQERGOXPhfQtUPnogEZktIm2d9S4issSZp2yGM8B9EHCvU3s833kKf6JzjoUi0sH5bgUR+caZ3+xdKPz15yLyXxFZ7Hxn4J8+G+GUzxCRSk5ZfRH5yvnOXBFpEpT/myYq2ZvtI5BTU+sKfOUUtQaaqeoGJ0mkqepZIlISmC8i3+CbhaMx0BSoAqwC3vvTcSsB7wAXOMcqr6p7ReRNIF1V/+3s9x9ghKrOE5Ha+EaGnA4MBeap6jARuRzwZzTFrc45SgELRWSiqu4BygCLVPVeEXnSOfZgfC9oGaSqv4pIO+B1oNNJ/G80xYAluMhSypleB3w1uNH4mo4LVHWDU34p0Pxo/xqQBDQELgA+UVUvsF1EZh7n+O2BOUePpaonml/uYqCpb5goAGWd2T4uAK52vvs/EdnnxzXdLSJXOeu1nFj3ALnAOKf8I2CSc45zgQn5zl3Sj3OYYsoSXGQ57Eyvk8f5h56Rvwi4S1W//tN+wRy/GQO0V9XM48TiNxHpiC9ZnqOqh0RkNhB/gt3VOe/+P/8/MOZErA8u+nwN3OFMMYSINBKRMsAcoLfTR1cNuOg43/0RuEBE6jrfLe+UHwQS8+33DXDX0Q0RaemszgFucMq6AuUKiTUJ2Ocktyb4apBHxQBHa6E34Gv6HgA2iEgv5xwiIi0KOYcpxizBRZ938fWvLRHfC2jewldTnwz86nw2Ft/MI8dQ1d3AQHzNweX80UT8HLjq6E0G4G6grXMTYxV/3M19Gl+CXImvqbq5kFi/AmJFZDXwT3wJ9qgMfJNArsDXxzbMKe8L9HfiW0mUTDlvQsNmEzHGRC2rwRljopYlOGNM1LIEZ4yJWpbgjDFRyxKcMSZqWYIzxkQtS3DGmKj1/63MQVeamHAEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was fitting using one set of chosen hyperparameters, we actually did a lot of manual tuning before hand to select the previous hyperparameters, but the result was too messy so we decided to switch to GridSearch for a much cleaner tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/are-you-using-the-scikit-learn-wrapper-in-your-keras-deep-learning-model-a3005696ff38\n",
    "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for Optimal Hyperparameters (KerasClassifier):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are using GridSearch and a list of the following hyperparameters we narrowed down from the above mentioned previous manual tuning to find the optimal set to fit the model:\n",
    "- activation function\n",
    "- optimizer\n",
    "- number of epochs\n",
    "- batch size\n",
    "- learning rate\n",
    "- neurons (hidden nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_grid(neurons = 5 , activation = 'relu', learning_rate = '0.001', optimizer='adam',):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Activation functions\n",
    "    if activation=='relu':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='relu'))\n",
    "    if activation=='tanh':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='tanh'))\n",
    "    if activation=='sigmoid':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='sigmoid'))\n",
    "        \n",
    "    # Output layer    \n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizers\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    if optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "estimator_grid = KerasClassifier(build_fn=create_model_grid, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hyperparameters to be searched\n",
    "activation_list = ['tanh','relu']\n",
    "optimizer_list = ['rmsprop','adam','sgd']\n",
    "epoch_list = [5,10,20]\n",
    "batch_list = [10,20,50]\n",
    "learning_rate_list = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "neurons_list = [8, 16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearch\n",
    "param_grid = dict(activation = activation_list,\n",
    "                 optimizer = optimizer_list,\n",
    "                 epochs = epoch_list, \n",
    "                  batch_size = batch_list,\n",
    "                 learning_rate = learning_rate_list,\n",
    "                 neurons = neurons_list)\n",
    "\n",
    "# Search with 3 folds (cross_validation)\n",
    "grid = GridSearchCV(estimator = estimator_grid, param_grid = param_grid, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 810 candidates, totalling 2430 fits\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n"
     ]
    }
   ],
   "source": [
    "# Training to get the best hyperparameter combination\n",
    "grid_result = grid.fit(X_train,dummy_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we get the optimal set to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.582978 using {'activation': 'relu', 'batch_size': 10, 'epochs': 10, 'learning_rate': 0.01, 'neurons': 16, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Print Best Result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.57791336, 1.64604147, 1.45817423, 1.6089646 , 1.74048026,\n",
       "        1.34062481, 1.72710673, 1.70706924, 1.77508068, 1.65265258,\n",
       "        1.62461543, 1.37807226, 1.94686715, 1.98011621, 1.7914776 ,\n",
       "        2.09962201, 1.74349348, 1.89903649, 1.6869626 , 1.75769957,\n",
       "        1.52279329, 1.8026154 , 1.76320855, 1.73751521, 2.00724332,\n",
       "        1.80047361, 1.76849802, 1.83514396, 1.94734669, 1.66813151,\n",
       "        1.91164883, 1.70313025, 1.67124669, 1.88278667, 1.44766378,\n",
       "        1.5525353 , 1.97493315, 1.61064974, 1.3959295 , 1.81097968,\n",
       "        1.46403344, 1.55276394, 1.75644445, 1.78262575, 2.78657897,\n",
       "        3.84792662, 3.28486149, 2.65678247, 2.62361972, 2.44247564,\n",
       "        2.1349295 , 2.7340072 , 2.91063245, 2.47981445, 3.06817142,\n",
       "        2.58559696, 2.30333368, 2.70382102, 2.48583738, 2.43422023,\n",
       "        2.60054517, 2.64943894, 2.2989188 , 2.60595353, 2.14786688,\n",
       "        1.95095929, 2.13229926, 2.02607989, 2.11690227, 1.96470483,\n",
       "        2.02963869, 1.87346474, 2.13013705, 1.95788439, 2.15404272,\n",
       "        2.0054969 , 2.28785443, 1.95058934, 2.30075502, 2.42683657,\n",
       "        2.18434501, 2.24996082, 2.30633736, 2.41475813, 2.1355075 ,\n",
       "        2.23808765, 2.34659696, 2.152426  , 2.55505919, 2.12095428,\n",
       "        3.46138334, 3.68287079, 3.18753584, 3.1310304 , 3.36419559,\n",
       "        3.9498837 , 3.53192504, 3.31857872, 3.21217012, 3.49458138,\n",
       "        3.3041904 , 3.21859638, 3.49557646, 3.27185265, 3.23692354,\n",
       "        3.51260408, 3.64646562, 3.6169335 , 3.5067602 , 3.41992044,\n",
       "        2.96980405, 3.36947982, 3.23857617, 3.07137243, 3.37115439,\n",
       "        3.22069995, 3.09925087, 3.40741499, 3.1739045 , 3.13205647,\n",
       "        3.4423298 , 3.13207952, 3.16956703, 3.34658321, 3.20369093,\n",
       "        3.18620531, 3.41012057, 3.12907918, 3.16401235, 3.41892234,\n",
       "        3.12755664, 3.20346506, 3.35327784, 3.20017656, 3.2728316 ,\n",
       "        0.94410491, 0.78589916, 0.7832516 , 0.89183958, 0.88871185,\n",
       "        0.72137403, 0.94484186, 0.99211137, 0.74117247, 0.96082091,\n",
       "        0.80582762, 0.83329964, 0.99287645, 0.89906693, 0.72079857,\n",
       "        0.95139352, 0.85927025, 0.80277316, 0.885216  , 0.86855626,\n",
       "        0.71684432, 1.06012003, 1.03406294, 0.74385142, 0.97036839,\n",
       "        0.79675984, 0.84342821, 0.89914958, 0.90010365, 0.80633243,\n",
       "        1.20266589, 1.17576973, 0.77422373, 0.86796641, 0.87510777,\n",
       "        1.71113118, 1.62663325, 1.12265221, 1.12952971, 1.26110744,\n",
       "        1.06650718, 1.39443294, 1.55194171, 2.21933881, 1.20486275,\n",
       "        2.22820687, 1.79508567, 1.72754669, 2.08538898, 2.09649181,\n",
       "        1.80519136, 2.37730209, 2.17884191, 1.82889016, 2.06709941,\n",
       "        2.33666293, 2.03598324, 1.95835606, 2.2201968 , 1.67260313,\n",
       "        1.92927337, 1.40672429, 1.4668297 , 1.42695204, 1.42911522,\n",
       "        1.35134355, 1.50771459, 1.34190893, 1.3061072 , 1.66794165,\n",
       "        1.40040342, 1.4064517 , 1.47561852, 1.34195352, 1.32573295,\n",
       "        1.52794353, 1.49072949, 1.29118903, 1.63625129, 1.45736289,\n",
       "        1.29257369, 1.89671071, 1.68298928, 1.62795607, 2.37592379,\n",
       "        2.37282944, 2.06962848, 2.92542545, 2.04226033, 2.23132396,\n",
       "        2.72908489, 2.80028033, 2.43251212, 2.9528935 , 2.66006247,\n",
       "        2.6294504 , 2.76540852, 2.57429775, 2.54240505, 2.7532409 ,\n",
       "        2.95048571, 2.59843381, 2.97006162, 2.70582835, 2.47131944,\n",
       "        3.07453624, 3.21881596, 2.95144359, 2.98193463, 2.66936119,\n",
       "        2.64051517, 2.62709562, 2.76650508, 2.33617345, 2.77663406,\n",
       "        1.93330407, 2.09230534, 2.12248421, 2.14930169, 1.82800317,\n",
       "        2.1182669 , 2.15992069, 1.82151834, 2.26008677, 1.9317805 ,\n",
       "        1.98602978, 2.01081379, 2.09908684, 2.12851946, 2.13336539,\n",
       "        2.03104695, 1.82736516, 2.08820303, 1.96432956, 1.7554752 ,\n",
       "        0.92209649, 0.63584749, 0.87926277, 0.93446628, 0.7813971 ,\n",
       "        0.68019772, 0.73306855, 0.66630586, 1.2253116 , 2.1107018 ,\n",
       "        0.85336526, 0.64256827, 0.84305612, 0.8875467 , 0.76536504,\n",
       "        0.84819833, 0.86263092, 1.05790075, 0.9986728 , 0.86442653,\n",
       "        0.82091459, 0.93884611, 0.77757589, 0.70465247, 0.73566779,\n",
       "        0.75374317, 0.56647182, 0.81865581, 0.80950054, 0.57833584,\n",
       "        0.82529632, 1.08425275, 0.6263175 , 0.94481214, 0.70127598,\n",
       "        0.67327356, 0.70941965, 0.71674919, 0.61085844, 0.87117505,\n",
       "        0.64744012, 0.55602908, 0.70828613, 0.62485433, 0.6111602 ,\n",
       "        1.01454425, 0.80337644, 0.70174702, 0.84958744, 0.97816388,\n",
       "        0.72242808, 0.87167907, 0.79279081, 0.95835312, 1.02463905,\n",
       "        0.92579214, 0.7042532 , 0.92880456, 0.77290638, 0.91811792,\n",
       "        0.97133756, 0.82458711, 0.69795235, 0.83476273, 1.01372608,\n",
       "        0.72606794, 0.98479851, 0.77275451, 0.69282023, 1.07742381,\n",
       "        0.94747575, 0.70313533, 0.89687745, 0.76124334, 0.97895694,\n",
       "        0.98591208, 0.9848334 , 0.69807831, 0.94613155, 0.843141  ,\n",
       "        0.78285813, 0.81522242, 0.85162147, 0.67891828, 1.06252662,\n",
       "        0.76281873, 0.77741083, 0.83352526, 0.73502135, 0.81128089,\n",
       "        1.12614544, 1.03806464, 1.05218172, 1.23359903, 1.04099989,\n",
       "        0.93943477, 1.19907037, 1.14282815, 1.04956635, 1.13072268,\n",
       "        1.11628262, 1.08134421, 1.21912392, 1.03724996, 0.93850025,\n",
       "        1.27604397, 1.06915013, 0.96449407, 1.1454072 , 1.1610744 ,\n",
       "        0.96454461, 1.11739159, 1.1198256 , 1.08080975, 1.21683772,\n",
       "        1.05487045, 1.05073222, 1.24471617, 1.13865376, 0.95326503,\n",
       "        1.40162834, 1.4034512 , 1.10968836, 1.12028297, 1.04476897,\n",
       "        1.09120695, 1.21926053, 1.0373702 , 1.03280234, 1.28566106,\n",
       "        1.03127265, 0.96089149, 1.18964338, 1.19231462, 0.95229983,\n",
       "        1.43744659, 1.31975094, 1.11012991, 1.44382548, 1.31120682,\n",
       "        1.22069923, 1.30906518, 1.31619096, 1.22622903, 1.26079981,\n",
       "        1.12365715, 1.03535533, 1.34960381, 1.24621805, 1.05040288,\n",
       "        1.32041184, 1.17241025, 1.14068731, 1.20917829, 1.25195837,\n",
       "        1.07886171, 1.28975781, 1.1468153 , 1.22781563, 1.22153489,\n",
       "        1.23023168, 1.13788303, 1.32136146, 1.1672984 , 1.14483054,\n",
       "        1.37117441, 1.13112267, 1.03821627, 1.36982091, 1.20221869,\n",
       "        1.15350572, 1.20275331, 1.25742698, 1.06507858, 1.2711544 ,\n",
       "        1.3845253 , 1.28508162, 1.26228293, 1.25203236, 1.59716121,\n",
       "        2.40799236, 2.44496004, 1.85823663, 2.21765518, 2.08431713,\n",
       "        1.77279782, 2.20206722, 1.93985335, 1.94503816, 1.92167179,\n",
       "        2.03846145, 1.72663768, 1.88328648, 1.98061673, 1.80633394,\n",
       "        2.0502766 , 1.84946092, 1.72145669, 2.13368678, 1.79914554,\n",
       "        1.88681038, 1.89587951, 1.87199132, 1.83133785, 2.00839663,\n",
       "        1.99797853, 1.79397384, 1.97374018, 1.96806065, 1.72560294,\n",
       "        2.08828553, 1.83163158, 1.84606616, 1.92706148, 1.92364605,\n",
       "        1.83133101, 1.89573336, 1.93228602, 1.71033462, 1.98504798,\n",
       "        1.96581221, 1.80286988, 2.33577998, 2.29740779, 2.04092081,\n",
       "        3.42078646, 3.31706786, 3.15166362, 3.28042452, 3.36691308,\n",
       "        3.13828611, 3.41341726, 3.38205171, 3.24655215, 3.30269265,\n",
       "        3.41241471, 3.14285938, 3.41091919, 3.51528947, 3.39563378,\n",
       "        3.64817007, 3.37565446, 3.20349979, 3.46793501, 3.22459714,\n",
       "        3.14691607, 3.37649957, 3.23625334, 3.15532072, 3.42732771,\n",
       "        3.33616734, 3.32470584, 3.44298967, 3.27958115, 3.20981359,\n",
       "        3.52476939, 3.23299122, 3.54305808, 3.73038546, 3.30627489,\n",
       "        3.41615049, 3.72777613, 3.42536751, 3.040694  , 3.534156  ,\n",
       "        3.27655443, 3.16806157, 3.41135859, 3.4069341 , 3.12633101,\n",
       "        0.9780341 , 0.9426771 , 0.73806993, 0.91099731, 0.79778981,\n",
       "        0.71734651, 1.21854289, 0.88217553, 0.94769557, 0.89971399,\n",
       "        1.03561521, 0.7627279 , 1.07183933, 0.80728785, 0.74470329,\n",
       "        1.19136556, 0.83703224, 0.73451583, 0.88282903, 0.91783174,\n",
       "        0.8332363 , 1.01084693, 0.81003992, 0.82247138, 0.94314551,\n",
       "        1.01083406, 0.76119407, 0.98724373, 0.81051397, 0.81552871,\n",
       "        0.9197336 , 0.81259592, 0.77774906, 0.99397453, 0.93867421,\n",
       "        0.85675677, 0.88660328, 0.92821391, 0.72723961, 1.13092693,\n",
       "        0.83417964, 0.9335196 , 1.12398998, 1.13816961, 0.95167009,\n",
       "        1.29122893, 1.25235931, 1.39850863, 1.55116796, 1.3186814 ,\n",
       "        1.32074277, 1.37636137, 1.3518401 , 1.2880772 , 1.26136923,\n",
       "        1.17163579, 1.22228702, 1.4122436 , 1.26227442, 1.07956862,\n",
       "        1.38271983, 1.20798596, 1.07124352, 1.21451839, 1.28927422,\n",
       "        1.08628432, 1.29843243, 1.15592813, 1.17322477, 1.33831318,\n",
       "        1.14333947, 1.25121586, 1.26246715, 1.28517207, 1.17207233,\n",
       "        1.50090726, 1.1838936 , 1.17733955, 1.43570956, 1.41642872,\n",
       "        1.08414563, 1.32872089, 1.33831859, 1.20309862, 1.32137132,\n",
       "        1.25773589, 1.19802062, 1.2564644 , 1.25426571, 1.20398331,\n",
       "        1.91302919, 1.88601081, 1.94197416, 1.92223318, 2.09117206,\n",
       "        1.77679793, 2.17021505, 1.98428837, 1.84653004, 2.08716242,\n",
       "        1.94490679, 1.87080622, 2.06252996, 1.84564678, 1.88792435,\n",
       "        1.99720764, 2.00443101, 1.8533167 , 1.91490515, 2.09076762,\n",
       "        1.73729118, 2.18297442, 1.85327307, 1.98877199, 2.51596252,\n",
       "        1.95540396, 1.91288145, 1.93822575, 2.0452431 , 1.85829957,\n",
       "        1.99672556, 2.06788468, 1.75954835, 2.18857431, 1.90223916,\n",
       "        1.81052645, 1.9821945 , 1.92123214, 1.88628499, 1.92734838,\n",
       "        2.1013538 , 1.7489682 , 1.9247818 , 1.9973472 , 1.82638685,\n",
       "        0.68118588, 0.80499578, 0.57158136, 0.69092139, 0.61294413,\n",
       "        0.66155728, 0.66907859, 0.65139778, 0.58446821, 0.71554478,\n",
       "        0.74291841, 0.55376903, 0.81227048, 0.71730884, 0.71605945,\n",
       "        0.7145373 , 0.7244095 , 0.55411394, 0.78966157, 0.70001157,\n",
       "        0.7157108 , 0.70391266, 0.71902919, 0.5347956 , 0.67955089,\n",
       "        0.71096309, 0.56533472, 0.81848979, 0.62719369, 0.53476493,\n",
       "        0.68006984, 0.81170257, 0.56659087, 0.8208739 , 0.61757803,\n",
       "        0.65957872, 0.67933591, 0.80334735, 0.56417338, 0.8166488 ,\n",
       "        0.59800188, 0.53664382, 0.799167  , 0.69523247, 0.66960335,\n",
       "        0.84468881, 0.847718  , 0.70822501, 0.97816006, 0.82041883,\n",
       "        0.79122424, 0.83326713, 0.86728239, 0.67524656, 1.0870769 ,\n",
       "        0.76244855, 0.68032559, 0.91224265, 0.74072361, 0.89759096,\n",
       "        0.84155019, 0.73802384, 0.68389988, 0.93343949, 0.84152706,\n",
       "        0.80490216, 0.8300612 , 0.85916646, 0.71766257, 1.00654427,\n",
       "        0.78482405, 0.68895237, 0.93684149, 0.75036605, 0.83225075,\n",
       "        0.91443213, 0.88244597, 0.68405366, 0.96211457, 0.79547819,\n",
       "        0.89546982, 0.85277526, 0.75639518, 0.6714642 , 0.81549446,\n",
       "        0.9359107 , 0.68380221, 0.93477901, 0.74685295, 0.79122678,\n",
       "        1.25583227, 1.17226283, 0.98059813, 1.21634491, 1.21133995,\n",
       "        1.07086492, 1.11732618, 1.05448039, 1.14685456, 1.13571556,\n",
       "        1.21048657, 1.56614677, 1.2792867 , 1.25153923, 1.2521654 ,\n",
       "        1.45723836, 1.33239444, 1.07313315, 1.36736766, 1.08263826,\n",
       "        0.97937751, 1.2063756 , 1.1991291 , 1.06630254, 1.13024664,\n",
       "        1.03758264, 1.04065514, 1.25537157, 1.02519099, 1.06071202,\n",
       "        1.1908501 , 1.15100471, 0.95290542, 1.2002236 , 1.11626649,\n",
       "        0.99437531, 1.21543082, 1.03767347, 1.09737794, 1.03919752,\n",
       "        0.8803188 , 0.85437075, 1.02934909, 0.9752717 , 0.81748796]),\n",
       " 'std_fit_time': array([3.49783044e-02, 1.73046981e-01, 1.60268563e-01, 2.23173270e-02,\n",
       "        3.35943643e-01, 3.47079514e-02, 1.56871624e-01, 2.91910552e-01,\n",
       "        2.67737930e-01, 1.87544699e-02, 1.75339708e-01, 2.30655990e-02,\n",
       "        4.52984871e-02, 1.48286759e-01, 1.87383317e-01, 2.88361307e-01,\n",
       "        1.90417323e-01, 3.74691917e-01, 5.60953927e-02, 3.02444613e-01,\n",
       "        6.38596818e-02, 1.33340871e-01, 2.15186352e-01, 1.13708482e-01,\n",
       "        1.25427672e-01, 1.00614529e-01, 1.55664913e-01, 5.93848302e-02,\n",
       "        1.79494905e-01, 8.02030322e-02, 2.45867837e-02, 7.80619626e-02,\n",
       "        1.60118813e-01, 1.21633610e-01, 4.31497837e-02, 2.62760027e-01,\n",
       "        6.75957818e-02, 1.34938580e-01, 3.16213374e-02, 2.09810411e-01,\n",
       "        2.67854898e-02, 1.72296793e-01, 1.45309240e-01, 4.30010471e-01,\n",
       "        5.76618508e-01, 4.38927332e-01, 4.34749017e-01, 6.21465995e-01,\n",
       "        1.91708293e-01, 3.53031970e-01, 4.64304943e-02, 2.89842530e-01,\n",
       "        3.17731489e-01, 3.09743210e-01, 5.10795033e-01, 1.58006385e-01,\n",
       "        1.20068688e-01, 2.80677576e-01, 1.11594137e-01, 1.74832652e-01,\n",
       "        1.06343289e-01, 2.69538543e-01, 1.24711986e-01, 5.40967265e-02,\n",
       "        3.47103922e-02, 1.00406165e-01, 2.02832730e-01, 1.14312931e-01,\n",
       "        1.39149649e-01, 3.20686274e-02, 7.48415857e-02, 1.01655573e-01,\n",
       "        1.52008750e-01, 6.23907091e-02, 1.90869278e-01, 1.69166327e-02,\n",
       "        3.43242846e-01, 1.10903231e-01, 3.23451873e-01, 2.31735664e-01,\n",
       "        1.42118102e-01, 2.13739503e-01, 2.12587392e-01, 1.48791977e-01,\n",
       "        1.92248802e-01, 3.06133036e-02, 1.04981688e-01, 2.25980079e-01,\n",
       "        3.87253223e-01, 2.14940277e-01, 2.38883950e-01, 1.46980458e-01,\n",
       "        3.97555612e-01, 1.40723646e-01, 1.70545776e-01, 2.82358155e-01,\n",
       "        1.43083766e-01, 3.89302676e-01, 1.05883082e-01, 2.05539004e-01,\n",
       "        1.26546839e-01, 1.85352042e-01, 1.73866650e-01, 1.07094523e-01,\n",
       "        2.45962763e-01, 2.71260358e-01, 1.93968988e-01, 1.02875783e-01,\n",
       "        2.21689064e-01, 2.47128597e-01, 2.65110809e-02, 2.21339392e-01,\n",
       "        9.74428065e-02, 1.37592270e-01, 2.36567889e-01, 1.22359037e-01,\n",
       "        9.11778771e-02, 2.62038416e-01, 3.29817726e-02, 1.72429060e-01,\n",
       "        3.43760788e-01, 9.93077241e-03, 1.52486643e-01, 9.12438423e-02,\n",
       "        1.20266633e-01, 2.55033203e-01, 1.99777043e-02, 2.30176586e-02,\n",
       "        2.12113401e-01, 3.00463972e-01, 2.01288276e-02, 1.87464884e-01,\n",
       "        2.25703535e-01, 7.99609046e-02, 9.89536369e-02, 1.13437603e-01,\n",
       "        1.00626865e-02, 4.79405039e-02, 3.62148121e-03, 1.21134244e-01,\n",
       "        8.39434140e-03, 1.28005828e-01, 6.29255552e-02, 6.87578487e-03,\n",
       "        1.15963442e-01, 3.12330116e-03, 8.58538892e-02, 7.33689202e-02,\n",
       "        1.18180482e-01, 8.23564463e-03, 1.23051550e-01, 6.83440895e-02,\n",
       "        9.15364110e-02, 5.15352260e-04, 1.17405906e-01, 7.99380872e-03,\n",
       "        1.28278603e-01, 4.56542424e-02, 5.79573472e-03, 1.17869378e-01,\n",
       "        5.25947448e-03, 7.07527501e-02, 3.99826920e-03, 1.25532335e-01,\n",
       "        1.05901087e-01, 5.40412152e-02, 1.29503209e-01, 6.31926453e-02,\n",
       "        1.79700878e-03, 1.18742106e-01, 1.11175670e+00, 6.82871513e-01,\n",
       "        1.17340341e-01, 6.76751696e-02, 1.46945343e-01, 3.07222142e-03,\n",
       "        2.58495737e-01, 2.65885184e-01, 7.89376376e-01, 1.61743635e-01,\n",
       "        2.45405946e-01, 1.49632008e-01, 1.51716589e-01, 1.79236941e-01,\n",
       "        1.49109501e-01, 7.74830421e-02, 3.45513446e-01, 4.06583510e-01,\n",
       "        1.84601485e-01, 8.77397047e-02, 1.98096073e-01, 3.39584098e-01,\n",
       "        1.22213652e-01, 1.93594970e-01, 1.33276952e-01, 4.10549463e-01,\n",
       "        2.74260838e-02, 1.01105430e-01, 8.08992231e-03, 1.02186157e-01,\n",
       "        1.17795311e-01, 1.07580192e-01, 7.64346413e-03, 7.71386299e-02,\n",
       "        4.87090526e-02, 4.32803898e-02, 1.11671049e-01, 1.13575584e-01,\n",
       "        2.26292593e-02, 9.63923391e-02, 1.48558034e-01, 1.33844290e-01,\n",
       "        3.18927844e-02, 1.09261547e-01, 1.28253226e-01, 5.36848721e-02,\n",
       "        1.01292439e-01, 2.66886069e-01, 3.66803401e-01, 1.22757554e-01,\n",
       "        1.70325424e-01, 1.61787594e-01, 4.41849978e-01, 3.06397367e-01,\n",
       "        1.15688142e-01, 3.53437793e-02, 2.86948387e-01, 9.99645508e-03,\n",
       "        3.41845042e-01, 2.23932093e-02, 3.33685935e-01, 7.89797831e-02,\n",
       "        4.08324110e-02, 1.76347310e-01, 8.78331272e-02, 3.02348169e-01,\n",
       "        8.24637077e-02, 1.50639586e-01, 9.25103655e-02, 1.61519009e-01,\n",
       "        3.06799014e-01, 9.47626022e-02, 2.08891832e-01, 1.97920170e-01,\n",
       "        3.60564342e-02, 2.83473460e-01, 3.45734018e-02, 3.47420205e-01,\n",
       "        5.70447339e-02, 1.83417644e-01, 4.88734459e-02, 1.82923847e-01,\n",
       "        5.06553687e-02, 4.57878107e-02, 2.82799195e-02, 1.13686543e-01,\n",
       "        8.91112676e-02, 5.56528170e-02, 9.92026178e-03, 5.52238535e-02,\n",
       "        1.24882101e-01, 1.12343624e-01, 1.20649312e-01, 2.21944215e-01,\n",
       "        1.76802538e-01, 1.78804112e-01, 1.07374541e-01, 1.17625281e-01,\n",
       "        1.33775197e-01, 1.26357517e-02, 1.71071374e-01, 4.29879328e-02,\n",
       "        2.32277846e-01, 1.64233577e-01, 1.43812056e-01, 7.46508313e-02,\n",
       "        8.79892773e-03, 2.84520606e-02, 4.90021463e-01, 5.21584404e-01,\n",
       "        1.33249247e-01, 2.25365827e-02, 1.69435681e-01, 1.81637729e-01,\n",
       "        1.55273793e-01, 3.44481700e-02, 1.33694871e-01, 1.23361028e-01,\n",
       "        2.54679153e-01, 1.60922356e-01, 1.00668570e-01, 1.16007521e-01,\n",
       "        9.16116529e-02, 1.21974499e-01, 1.43988815e-02, 1.39425234e-01,\n",
       "        2.43198359e-03, 1.52253204e-01, 1.00178264e-01, 2.15545813e-02,\n",
       "        1.38699312e-01, 1.97893962e-01, 2.96946165e-02, 1.69960751e-01,\n",
       "        5.23601801e-02, 1.35911558e-01, 1.00068507e-02, 1.34734587e-01,\n",
       "        7.06278867e-02, 1.13901130e-01, 1.85094589e-03, 1.87706982e-02,\n",
       "        2.35229224e-03, 9.52601010e-03, 2.66734119e-02, 1.28291799e-01,\n",
       "        3.50593865e-03, 6.80024847e-03, 2.41969189e-03, 7.41824509e-02,\n",
       "        7.16682136e-03, 1.82542066e-02, 2.39128395e-02, 8.78582724e-02,\n",
       "        3.35338531e-02, 1.83743649e-01, 1.39265455e-02, 1.36509431e-01,\n",
       "        1.08117765e-02, 1.30884822e-01, 1.29194603e-01, 4.81788345e-02,\n",
       "        2.17414102e-03, 1.22636201e-02, 1.27540258e-01, 1.07314039e-02,\n",
       "        1.01397943e-01, 9.27591708e-03, 1.18788233e-02, 1.58915825e-01,\n",
       "        1.17343860e-01, 1.17310371e-02, 3.88341744e-02, 1.64716639e-02,\n",
       "        1.73929539e-01, 1.40311416e-01, 1.62875469e-01, 3.16037065e-02,\n",
       "        1.74932454e-01, 1.06873100e-01, 1.23848200e-01, 1.25800925e-02,\n",
       "        1.39945046e-01, 1.73289798e-03, 4.31579112e-02, 4.86310098e-03,\n",
       "        1.22664326e-01, 7.38350103e-03, 2.03243628e-02, 5.59068434e-02,\n",
       "        2.34054200e-02, 1.09749192e-02, 1.35021375e-01, 8.35833902e-02,\n",
       "        2.14330298e-02, 5.37590307e-03, 1.33273435e-01, 9.15679833e-02,\n",
       "        1.26736924e-01, 5.19101245e-03, 1.23644693e-01, 9.69603156e-02,\n",
       "        1.17452303e-01, 2.35099085e-02, 1.17535012e-02, 1.18276432e-01,\n",
       "        1.39325288e-02, 1.75448999e-02, 7.15742459e-02, 9.90937917e-02,\n",
       "        5.73903698e-03, 1.46100092e-02, 1.31994177e-01, 1.05189760e-01,\n",
       "        1.18428397e-01, 7.13801327e-03, 1.28957972e-01, 1.05867052e-01,\n",
       "        1.22254739e-01, 1.75645879e-02, 1.93439710e-01, 1.87589480e-01,\n",
       "        1.33009308e-01, 8.02469441e-03, 1.93922857e-02, 7.11995995e-02,\n",
       "        1.34611983e-01, 4.75121334e-03, 1.38190006e-01, 1.06488398e-01,\n",
       "        1.51288519e-02, 6.42211130e-03, 1.38339629e-01, 1.02044259e-01,\n",
       "        1.93254767e-02, 1.79016860e-01, 1.47452208e-01, 2.98009289e-02,\n",
       "        1.85302622e-01, 1.32496606e-01, 9.70852822e-02, 4.68630929e-02,\n",
       "        1.23375139e-01, 1.55945042e-01, 5.60462361e-03, 1.41505949e-02,\n",
       "        1.34133396e-02, 7.61051616e-02, 1.30777378e-01, 8.81790879e-03,\n",
       "        1.76105990e-01, 7.79557910e-03, 1.34399066e-01, 5.12982052e-03,\n",
       "        1.47241014e-01, 5.01370593e-03, 1.35528512e-01, 2.97823959e-02,\n",
       "        1.24418166e-01, 8.25879948e-03, 1.24848819e-01, 1.06255474e-01,\n",
       "        1.29479382e-01, 3.56681552e-03, 1.34622135e-01, 9.91172646e-02,\n",
       "        1.64159630e-02, 1.07603147e-02, 1.04149593e-01, 4.54863419e-02,\n",
       "        1.23310401e-01, 1.14582240e-02, 1.18068089e-01, 1.54601162e-02,\n",
       "        1.45474077e-01, 1.27503770e-01, 1.32753698e-01, 1.42442606e-02,\n",
       "        1.46345754e-01, 2.08912044e-01, 1.06395309e-01, 3.56559082e-01,\n",
       "        1.26403115e-01, 1.47943012e-01, 1.79845992e-01, 9.14917349e-02,\n",
       "        1.70486437e-01, 1.22487063e-01, 1.92966764e-01, 1.59812672e-02,\n",
       "        1.64916190e-01, 1.22318866e-02, 2.79845545e-02, 1.74737433e-01,\n",
       "        1.35205862e-01, 1.32000136e-01, 3.81154812e-02, 9.70434336e-03,\n",
       "        1.48235313e-01, 3.90100776e-03, 1.69508124e-01, 5.43469936e-03,\n",
       "        5.44224757e-02, 1.32171406e-01, 1.34075124e-01, 1.96195910e-01,\n",
       "        1.20678061e-01, 1.33969596e-01, 9.21605948e-02, 1.48717795e-02,\n",
       "        1.48069702e-01, 1.39394942e-02, 1.75019259e-01, 2.27508312e-02,\n",
       "        1.16145160e-01, 9.00766957e-02, 2.24547402e-02, 1.63939323e-01,\n",
       "        1.41308995e-02, 1.47298043e-01, 1.61607442e-01, 1.23017522e-01,\n",
       "        3.91563810e-01, 2.68733574e-01, 8.01067172e-02, 1.43813697e-01,\n",
       "        1.81233152e-01, 2.50269184e-01, 3.82994212e-02, 1.55581930e-01,\n",
       "        1.86442949e-01, 1.10472049e-01, 2.18571697e-01, 1.72580373e-01,\n",
       "        1.12350111e-02, 3.25416841e-01, 1.82732879e-01, 1.21230232e-01,\n",
       "        1.59589131e-01, 2.40874948e-01, 6.56342855e-02, 1.26414291e-01,\n",
       "        2.33719846e-01, 1.39991517e-01, 4.97405516e-02, 2.42736013e-01,\n",
       "        1.32617211e-01, 1.20713054e-01, 2.47684653e-01, 2.10829596e-01,\n",
       "        9.38486072e-02, 2.12749273e-01, 1.65574636e-01, 1.19810385e-01,\n",
       "        2.91289283e-01, 3.78474017e-01, 3.83716757e-02, 1.82787989e-01,\n",
       "        2.46644478e-01, 1.58639684e-01, 2.50340219e-01, 3.15834649e-01,\n",
       "        1.39597197e-01, 2.21403169e-02, 3.48444370e-01, 9.45456105e-02,\n",
       "        1.31775009e-01, 2.58953603e-01, 1.22517144e-01, 1.47076080e-02,\n",
       "        1.40624100e-01, 7.02041304e-02, 1.46469848e-02, 8.48028625e-03,\n",
       "        2.76873903e-02, 8.18750353e-03, 1.20683794e-01, 1.90538813e-02,\n",
       "        1.59571941e-01, 1.61257416e-02, 2.09071610e-01, 6.98272824e-03,\n",
       "        9.26153371e-02, 1.65982936e-02, 2.98387656e-03, 1.75072546e-01,\n",
       "        5.35222416e-03, 1.04946251e-02, 7.17277050e-03, 1.38893988e-01,\n",
       "        5.48271568e-02, 1.40320898e-01, 4.81796835e-03, 1.33579967e-01,\n",
       "        9.47166375e-02, 1.15339252e-01, 6.07408446e-03, 1.39125076e-01,\n",
       "        4.42631284e-03, 7.52419883e-02, 5.94627609e-03, 3.50322563e-03,\n",
       "        4.30328454e-02, 1.46672449e-01, 5.71583980e-02, 1.28502970e-01,\n",
       "        2.04821432e-02, 1.37844595e-01, 5.39727096e-03, 5.76125457e-02,\n",
       "        1.67146053e-02, 1.22096692e-01, 1.47158116e-01, 1.36789933e-01,\n",
       "        1.33320590e-01, 6.36175293e-02, 1.62342662e-01, 1.11654672e-01,\n",
       "        1.33480028e-01, 1.27236615e-01, 3.11471628e-01, 4.50699045e-02,\n",
       "        1.32867645e-01, 1.16085027e-01, 4.41077738e-02, 1.89491437e-02,\n",
       "        1.14089873e-01, 1.18083183e-01, 1.05961797e-01, 7.23146975e-03,\n",
       "        2.26745933e-01, 5.30579282e-02, 4.05731725e-03, 1.60909079e-02,\n",
       "        9.95964079e-02, 6.05585696e-03, 7.64709476e-02, 2.93057414e-02,\n",
       "        9.60284582e-02, 1.55183462e-01, 1.50943873e-02, 1.29578469e-01,\n",
       "        4.13611712e-02, 1.30971627e-01, 1.40340606e-01, 1.83935903e-01,\n",
       "        2.18163114e-02, 1.31943574e-01, 1.62628545e-01, 1.46585375e-01,\n",
       "        2.54983680e-02, 1.20858139e-01, 1.17560222e-01, 1.47215281e-01,\n",
       "        9.37380205e-02, 1.11847821e-01, 1.43327264e-01, 9.66891247e-03,\n",
       "        1.51390994e-01, 1.14039009e-01, 2.64832991e-02, 3.87770139e-02,\n",
       "        1.54823702e-01, 1.96643277e-02, 2.88597961e-01, 1.39115154e-02,\n",
       "        1.53453203e-01, 1.14257045e-02, 1.29553525e-01, 1.11266987e-01,\n",
       "        1.54259838e-01, 2.12387739e-01, 1.26258181e-01, 1.25854446e-02,\n",
       "        1.60930790e-01, 1.45323479e-01, 1.47299348e-01, 1.15597822e-01,\n",
       "        2.04257697e-02, 1.79152910e-01, 3.68268703e-03, 2.84929333e-01,\n",
       "        2.62173324e-02, 2.62629412e-01, 4.27948949e-01, 1.24588848e-01,\n",
       "        2.21354344e-01, 1.62001951e-02, 1.35569895e-01, 1.32483516e-01,\n",
       "        6.44700676e-02, 1.41727922e-01, 1.58814385e-02, 1.59442155e-01,\n",
       "        2.14894629e-02, 1.00177670e-01, 1.54374189e-02, 1.14514054e-01,\n",
       "        1.22966512e-01, 2.03886705e-02, 1.75771540e-01, 9.29873781e-03,\n",
       "        1.68379612e-02, 1.33507355e-01, 1.33543275e-01, 4.48340776e-03,\n",
       "        1.59015183e-01, 1.88344743e-02, 1.68872958e-02, 1.03679447e-02,\n",
       "        1.66596924e-01, 8.15313388e-04, 4.08855751e-02, 3.17004203e-02,\n",
       "        1.90625150e-03, 1.75479184e-01, 9.00163466e-03, 1.31640534e-01,\n",
       "        6.24450958e-02, 1.61016039e-01, 8.82748858e-03, 1.54685268e-01,\n",
       "        4.35774228e-03, 1.60477309e-01, 8.33501105e-02, 1.17345930e-01,\n",
       "        9.83890081e-03, 1.63896439e-01, 9.74586673e-03, 5.74409818e-04,\n",
       "        8.48114387e-02, 8.74906730e-03, 1.65506038e-01, 2.26543094e-03,\n",
       "        1.84617755e-02, 7.68417961e-03, 1.66870683e-01, 2.80927557e-03,\n",
       "        1.67396921e-01, 1.49936076e-03, 1.73326990e-01, 8.76119850e-03,\n",
       "        1.94918887e-01, 1.66140359e-02, 1.47059717e-01, 2.24476829e-03,\n",
       "        1.96437658e-03, 1.85077037e-01, 7.81108895e-02, 1.51894288e-01,\n",
       "        9.97303701e-03, 1.55208764e-01, 1.11759335e-02, 1.38799413e-01,\n",
       "        6.44005181e-02, 1.45678696e-01, 7.40837785e-03, 1.51268467e-01,\n",
       "        7.75797945e-04, 8.27299486e-02, 9.03225179e-04, 1.08907675e-02,\n",
       "        1.62597859e-01, 2.31959441e-03, 1.41284461e-01, 4.03381788e-03,\n",
       "        1.97398420e-02, 7.19152741e-03, 1.71397563e-01, 7.61968845e-02,\n",
       "        1.49760179e-01, 7.77268031e-03, 1.53508379e-01, 3.85278737e-02,\n",
       "        2.52209947e-01, 2.93915253e-02, 4.93227809e-03, 1.75129729e-01,\n",
       "        9.76190450e-04, 1.53513856e-01, 7.22005102e-02, 1.41899294e-01,\n",
       "        3.40463446e-03, 1.35135753e-01, 4.43120554e-02, 9.90289399e-02,\n",
       "        1.91427107e-02, 6.85182348e-03, 1.18345490e-02, 3.22862165e-03,\n",
       "        1.61245851e-01, 2.25043818e-03, 1.58782024e-01, 1.13689517e-02,\n",
       "        1.50427295e-01, 1.00681288e-01, 1.25034601e-01, 1.36378236e-02,\n",
       "        1.47841507e-01, 1.10897309e-01, 1.34319468e-01, 8.38170390e-03,\n",
       "        1.59591466e-02, 1.23669490e-01, 1.56544402e-02, 1.61465367e-01,\n",
       "        6.32443055e-02, 1.63040385e-01, 5.16532337e-02, 1.49602130e-01,\n",
       "        1.14873175e-01, 1.60587108e-01, 9.00320256e-02, 2.82038303e-01,\n",
       "        2.79726867e-02, 1.64231129e-02, 1.61444644e-01, 5.23375543e-02,\n",
       "        1.41734935e-01, 5.66384456e-03, 2.89624015e-02, 9.53527687e-02,\n",
       "        1.34283723e-01, 1.91483855e-02, 1.57893313e-01, 1.44192585e-01,\n",
       "        1.17080358e-01, 1.64482290e-02, 1.40727190e-01, 1.31235907e-01,\n",
       "        3.92597292e-02, 1.54219147e-01, 1.97007577e-02, 1.76398470e-01,\n",
       "        1.08067882e-01, 8.41476572e-03, 5.63605419e-02, 1.35493070e-01,\n",
       "        8.89164975e-02, 2.87573794e-02]),\n",
       " 'mean_score_time': array([0.32521025, 0.32823984, 0.31856028, 0.32429274, 0.546971  ,\n",
       "        0.32534695, 0.35707331, 0.39473828, 0.36817447, 0.34357707,\n",
       "        0.31098215, 0.31939467, 0.35851479, 0.42951767, 0.38305291,\n",
       "        0.36868032, 0.36191249, 0.43003774, 0.32373365, 0.3966581 ,\n",
       "        0.4108123 , 0.39751283, 0.54554145, 0.43904297, 0.34978366,\n",
       "        0.48442141, 0.39993103, 0.36977498, 0.40792791, 0.38576261,\n",
       "        0.50387271, 0.37162542, 0.46153426, 0.40635562, 0.31326127,\n",
       "        0.34164453, 0.37993892, 0.319724  , 0.3250246 , 0.36008318,\n",
       "        0.31832862, 0.35166105, 0.38364061, 0.39076797, 0.51832056,\n",
       "        0.49388647, 0.47002602, 0.37005329, 0.35420903, 0.32313546,\n",
       "        0.48065646, 0.41069969, 0.41299812, 0.34556246, 0.45967825,\n",
       "        0.36273003, 0.38351242, 0.41675003, 0.38930607, 0.53307907,\n",
       "        0.36913292, 0.32224679, 0.37457236, 0.46691465, 0.25749906,\n",
       "        0.27577209, 0.25727963, 0.2433749 , 0.23221652, 0.24590858,\n",
       "        0.36338035, 0.27250616, 0.24134382, 0.24739615, 0.26562762,\n",
       "        0.24970063, 0.24280985, 0.26421944, 0.27066882, 0.26023658,\n",
       "        0.27985795, 0.24933306, 0.27846026, 0.26560132, 0.24389084,\n",
       "        0.27223309, 0.26124477, 0.25170604, 0.37451863, 0.29249175,\n",
       "        0.25865491, 0.274266  , 0.23047908, 0.24660428, 0.2480731 ,\n",
       "        0.31332207, 0.24549158, 0.27744031, 0.36436272, 0.25492787,\n",
       "        0.25185474, 0.28490829, 0.26141206, 0.25187866, 0.25462794,\n",
       "        0.26752369, 0.28780214, 0.27030698, 0.26108964, 0.27053332,\n",
       "        0.24704536, 0.3294758 , 0.26765291, 0.24976055, 0.32806198,\n",
       "        0.25766404, 0.24630992, 0.25514587, 0.35306811, 0.24661501,\n",
       "        0.24738828, 0.25341582, 0.24838487, 0.27834058, 0.24596477,\n",
       "        0.24503342, 0.25015259, 0.3347079 , 0.25151928, 0.2682519 ,\n",
       "        0.24415445, 0.24713381, 0.24617934, 0.24723967, 0.26949406,\n",
       "        0.20883369, 0.21860774, 0.34288843, 0.21452602, 0.21565898,\n",
       "        0.21114413, 0.20798882, 0.26053548, 0.21316353, 0.21344741,\n",
       "        0.21256447, 0.33516502, 0.25244244, 0.2123692 , 0.21162764,\n",
       "        0.20759225, 0.22134407, 0.30986047, 0.21269178, 0.21326772,\n",
       "        0.21352228, 0.28982623, 0.22914298, 0.21661894, 0.2077136 ,\n",
       "        0.21365293, 0.30527695, 0.21681277, 0.21795003, 0.23699872,\n",
       "        0.36456561, 0.27162242, 0.30146194, 0.21124872, 0.20932913,\n",
       "        0.49761518, 0.26814644, 0.26827892, 0.46679409, 0.27145425,\n",
       "        0.26468992, 0.65828443, 0.39144516, 0.49190974, 0.32434821,\n",
       "        0.32815488, 0.30049928, 0.36459851, 0.37836043, 0.33670346,\n",
       "        0.33667986, 0.5261422 , 0.32681656, 0.36268648, 0.34056791,\n",
       "        0.39289697, 0.45987105, 0.39696185, 0.43095636, 0.36482032,\n",
       "        0.36636178, 0.25054367, 0.35501758, 0.24649103, 0.24792878,\n",
       "        0.28211339, 0.25012485, 0.24688037, 0.33682251, 0.28057138,\n",
       "        0.32493798, 0.26090384, 0.32298875, 0.24243132, 0.24313887,\n",
       "        0.26735759, 0.26658217, 0.34469239, 0.27717932, 0.24864189,\n",
       "        0.24874632, 0.28234967, 0.29331589, 0.41985178, 0.37817415,\n",
       "        0.42495386, 0.36692874, 0.43799988, 0.33084273, 0.34543753,\n",
       "        0.28900099, 0.30306101, 0.28938079, 0.30005256, 0.28379107,\n",
       "        0.28661625, 0.41813254, 0.27955564, 0.2948788 , 0.27741281,\n",
       "        0.34921718, 0.30603369, 0.31659253, 0.32785074, 0.28037532,\n",
       "        0.36500057, 0.36496298, 0.34540741, 0.3011752 , 0.29925386,\n",
       "        0.30732568, 0.27970918, 0.3004787 , 0.28785769, 0.31203334,\n",
       "        0.22958938, 0.25388789, 0.24796645, 0.23312179, 0.33824523,\n",
       "        0.23930144, 0.24019949, 0.22964668, 0.23733457, 0.23402031,\n",
       "        0.33277305, 0.22882962, 0.23493258, 0.29110916, 0.22986563,\n",
       "        0.26671084, 0.22530611, 0.22871582, 0.22878114, 0.23062134,\n",
       "        0.20212062, 0.19938064, 0.44512534, 0.24565132, 0.33150522,\n",
       "        0.21930726, 0.3062729 , 0.20811351, 0.55207539, 0.42828878,\n",
       "        0.2255861 , 0.22040224, 0.20311546, 0.3031253 , 0.2257127 ,\n",
       "        0.32773129, 0.28113087, 0.48205972, 0.2313803 , 0.2319506 ,\n",
       "        0.2797548 , 0.22463377, 0.23726026, 0.20703348, 0.20793414,\n",
       "        0.20181044, 0.20309965, 0.35281579, 0.22843353, 0.31257764,\n",
       "        0.22566875, 0.26790182, 0.22403248, 0.21661313, 0.21017075,\n",
       "        0.20082744, 0.20017362, 0.19525536, 0.20456139, 0.22142561,\n",
       "        0.20240378, 0.29851524, 0.19990524, 0.29830941, 0.25562008,\n",
       "        0.21020699, 0.20764661, 0.30365245, 0.20207373, 0.24303381,\n",
       "        0.20883679, 0.30470053, 0.20932651, 0.23484445, 0.26427674,\n",
       "        0.2173245 , 0.20563849, 0.19818068, 0.20649052, 0.22583071,\n",
       "        0.20665201, 0.21065187, 0.31257232, 0.20195731, 0.22994645,\n",
       "        0.20710444, 0.21322378, 0.20217395, 0.20098869, 0.24277067,\n",
       "        0.20888948, 0.20149247, 0.311807  , 0.20509466, 0.23129773,\n",
       "        0.21215781, 0.2419215 , 0.20266136, 0.19990651, 0.20204409,\n",
       "        0.19602998, 0.19567124, 0.19680031, 0.19480522, 0.21088616,\n",
       "        0.19826047, 0.19455743, 0.19639333, 0.28675207, 0.22687062,\n",
       "        0.30921642, 0.20181028, 0.20179137, 0.23385866, 0.29887128,\n",
       "        0.20069242, 0.20146211, 0.2299153 , 0.20448629, 0.20637512,\n",
       "        0.20064267, 0.20477438, 0.20372407, 0.20220407, 0.30014388,\n",
       "        0.20926062, 0.30709473, 0.20637178, 0.31736398, 0.22207125,\n",
       "        0.29877098, 0.20228227, 0.19861714, 0.20991818, 0.19920619,\n",
       "        0.20686062, 0.20055866, 0.20955332, 0.19947577, 0.20404506,\n",
       "        0.23987937, 0.24553315, 0.21290676, 0.2030286 , 0.30516187,\n",
       "        0.24554046, 0.20260676, 0.20245449, 0.19743204, 0.21373645,\n",
       "        0.30267342, 0.20286854, 0.19859163, 0.2166609 , 0.2973183 ,\n",
       "        0.28389764, 0.26125987, 0.25016173, 0.2826395 , 0.26548743,\n",
       "        0.37058306, 0.27327426, 0.25682894, 0.27284265, 0.35358087,\n",
       "        0.24434956, 0.34739208, 0.27448026, 0.25013836, 0.24879853,\n",
       "        0.3916022 , 0.2505753 , 0.24422089, 0.24785797, 0.36136874,\n",
       "        0.25228914, 0.24405026, 0.26810527, 0.27047054, 0.25025423,\n",
       "        0.24627161, 0.29394301, 0.25110086, 0.25281461, 0.24480645,\n",
       "        0.25811013, 0.34841037, 0.24688903, 0.28557364, 0.250537  ,\n",
       "        0.2468222 , 0.25521358, 0.36973874, 0.25551295, 0.23742215,\n",
       "        0.29756943, 0.36063671, 0.25927742, 0.28245417, 0.36065102,\n",
       "        0.41441544, 0.28742019, 0.26332339, 0.30154928, 0.25321794,\n",
       "        0.29798754, 0.25867661, 0.25562827, 0.26384115, 0.26031423,\n",
       "        0.26567841, 0.24967051, 0.35720428, 0.27850795, 0.25014305,\n",
       "        0.26742848, 0.3553559 , 0.24723681, 0.25488838, 0.24830874,\n",
       "        0.27179639, 0.24810648, 0.35812744, 0.25219337, 0.25622741,\n",
       "        0.25314005, 0.24786798, 0.28422697, 0.2503682 , 0.24755168,\n",
       "        0.26497388, 0.25372489, 0.37148468, 0.2474374 , 0.25402323,\n",
       "        0.28896403, 0.35217269, 0.2736849 , 0.25349458, 0.24901811,\n",
       "        0.28629239, 0.25092467, 0.28788487, 0.28018228, 0.29019109,\n",
       "        0.25236758, 0.37322895, 0.25471703, 0.36557778, 0.29092693,\n",
       "        0.25237528, 0.25164398, 0.2538898 , 0.26266042, 0.25869163,\n",
       "        0.24471331, 0.26016378, 0.25269485, 0.267193  , 0.3040235 ,\n",
       "        0.29990156, 0.24832392, 0.25061886, 0.29158394, 0.24881959,\n",
       "        0.35161034, 0.25690889, 0.36260279, 0.24833798, 0.27333188,\n",
       "        0.25247256, 0.25620723, 0.28493889, 0.24967098, 0.2588644 ,\n",
       "        0.25247812, 0.25522542, 0.27203091, 0.31782691, 0.35190892,\n",
       "        0.28612693, 0.25985408, 0.27534087, 0.25193183, 0.2553033 ,\n",
       "        0.27524797, 0.2496407 , 0.24915115, 0.26165549, 0.25616701,\n",
       "        0.20871234, 0.26030644, 0.32688785, 0.21662823, 0.32647554,\n",
       "        0.21182569, 0.23794794, 0.22859502, 0.23333836, 0.21967745,\n",
       "        0.24305638, 0.2310675 , 0.22586346, 0.21879681, 0.21591059,\n",
       "        0.23931575, 0.32106113, 0.21473916, 0.21391543, 0.23339256,\n",
       "        0.22918518, 0.21277793, 0.21439322, 0.21263885, 0.22415884,\n",
       "        0.22221478, 0.21935884, 0.20969733, 0.2111036 , 0.36297456,\n",
       "        0.22093264, 0.33704893, 0.21615028, 0.2123425 , 0.25649659,\n",
       "        0.21562775, 0.21372358, 0.21537781, 0.21609823, 0.22400324,\n",
       "        0.22705197, 0.26462499, 0.25124613, 0.27007858, 0.24468875,\n",
       "        0.23285707, 0.22039016, 0.29340847, 0.27052975, 0.2540044 ,\n",
       "        0.24843677, 0.25340303, 0.23238571, 0.31155483, 0.33085235,\n",
       "        0.22149833, 0.22497249, 0.22549931, 0.21586951, 0.22699412,\n",
       "        0.24567135, 0.21836742, 0.33911705, 0.22330721, 0.35656993,\n",
       "        0.22114499, 0.34017746, 0.23482505, 0.24592241, 0.21889281,\n",
       "        0.2219286 , 0.26207542, 0.22514502, 0.2172691 , 0.2405103 ,\n",
       "        0.23233819, 0.22381345, 0.22111789, 0.25343045, 0.23271624,\n",
       "        0.22031283, 0.21654669, 0.23002529, 0.35829377, 0.23302873,\n",
       "        0.26145124, 0.22293417, 0.22470307, 0.22027516, 0.26447646,\n",
       "        0.32880131, 0.24558385, 0.2219588 , 0.22518539, 0.22333137,\n",
       "        0.22863698, 0.2368962 , 0.24025687, 0.21917256, 0.22623189,\n",
       "        0.22717992, 0.23171989, 0.22225746, 0.22265538, 0.23472587,\n",
       "        0.22269853, 0.23141114, 0.22529761, 0.22114587, 0.22103095,\n",
       "        0.22215668, 0.23536881, 0.22277602, 0.26062401, 0.23863419,\n",
       "        0.22704856, 0.22638106, 0.34274499, 0.23450192, 0.22507135,\n",
       "        0.23427057, 0.21837807, 0.22686195, 0.22578375, 0.23038308,\n",
       "        0.33396308, 0.21872274, 0.22052272, 0.22364759, 0.220016  ,\n",
       "        0.23167109, 0.21973364, 0.34283169, 0.23645099, 0.22355509,\n",
       "        0.18781066, 0.24523815, 0.19794321, 0.3079896 , 0.1902655 ,\n",
       "        0.18901443, 0.18627572, 0.31771668, 0.19683282, 0.19967779,\n",
       "        0.19367409, 0.1931715 , 0.20200173, 0.22141798, 0.20394699,\n",
       "        0.20257815, 0.18315196, 0.19594614, 0.18826127, 0.23126237,\n",
       "        0.2046593 , 0.19833732, 0.18751287, 0.1940786 , 0.30689883,\n",
       "        0.2037557 , 0.1932714 , 0.19199816, 0.19550927, 0.30979951,\n",
       "        0.19393396, 0.20753805, 0.19990563, 0.1932044 , 0.193597  ,\n",
       "        0.18784229, 0.1894331 , 0.21783654, 0.20251258, 0.19723479,\n",
       "        0.18857153, 0.19106817, 0.18433762, 0.21383238, 0.19309441,\n",
       "        0.19730242, 0.19170753, 0.20146863, 0.20224984, 0.21692769,\n",
       "        0.19497315, 0.19933232, 0.19419479, 0.19331209, 0.20132589,\n",
       "        0.19528739, 0.19266589, 0.19412422, 0.19107747, 0.21795122,\n",
       "        0.19698548, 0.30567582, 0.19693971, 0.19044439, 0.21615203,\n",
       "        0.19478703, 0.20095078, 0.19586205, 0.21090515, 0.2170016 ,\n",
       "        0.1943442 , 0.19945423, 0.19299912, 0.1987466 , 0.20462561,\n",
       "        0.22221541, 0.2008299 , 0.19411246, 0.19713926, 0.21803323,\n",
       "        0.21040916, 0.20356933, 0.31799102, 0.19646207, 0.19422221,\n",
       "        0.21891093, 0.19896007, 0.19360367, 0.20075965, 0.19395304,\n",
       "        0.21745483, 0.20079875, 0.20495772, 0.20036888, 0.21106299,\n",
       "        0.19898915, 0.20047204, 0.3288637 , 0.21679489, 0.20109018,\n",
       "        0.21250097, 0.30160896, 0.32077734, 0.23733044, 0.23243078,\n",
       "        0.2722822 , 0.2309796 , 0.21385471, 0.23145016, 0.20370054,\n",
       "        0.20750459, 0.19826174, 0.23830684, 0.19892955, 0.20852558,\n",
       "        0.31974379, 0.21875739, 0.20188451, 0.19794234, 0.19844842,\n",
       "        0.25032504, 0.20100347, 0.20401231, 0.19744976, 0.22336149,\n",
       "        0.19829567, 0.19788758, 0.23428146, 0.21820426, 0.18087673,\n",
       "        0.27504373, 0.17976022, 0.175378  , 0.19268489, 0.27703985]),\n",
       " 'std_score_time': array([1.87030647e-02, 9.66504961e-03, 4.58496402e-03, 5.95014023e-03,\n",
       "        2.39451083e-01, 5.38362843e-03, 4.81688948e-02, 9.76353486e-02,\n",
       "        9.28189046e-02, 4.25828252e-02, 3.41225652e-03, 5.11194896e-03,\n",
       "        3.23757869e-02, 5.46892067e-02, 2.96658441e-03, 1.83035883e-02,\n",
       "        4.53921593e-02, 5.65563889e-02, 7.64448551e-03, 7.61462850e-02,\n",
       "        6.71513652e-02, 5.55359346e-02, 9.04890550e-02, 5.85717051e-02,\n",
       "        1.11241563e-02, 8.52720046e-02, 6.23199015e-02, 2.17486239e-02,\n",
       "        3.98999326e-02, 1.65249574e-02, 1.72328538e-01, 3.58377328e-02,\n",
       "        4.58629518e-02, 1.29470489e-02, 6.01984445e-03, 3.39950327e-02,\n",
       "        3.04285381e-02, 4.86733725e-03, 2.81926052e-03, 5.22993090e-02,\n",
       "        9.37560578e-03, 5.31903086e-02, 9.61530930e-02, 7.95268173e-02,\n",
       "        6.50107336e-02, 5.93628085e-02, 7.37558313e-02, 7.29560528e-02,\n",
       "        4.61056648e-02, 6.66541950e-03, 1.58397419e-01, 8.13257255e-02,\n",
       "        1.20649873e-01, 6.09321817e-02, 1.06656009e-01, 3.48289460e-02,\n",
       "        4.52989229e-02, 8.13345018e-02, 6.74785833e-02, 1.49472052e-01,\n",
       "        4.28587095e-02, 4.80350141e-03, 5.76527474e-02, 2.50392341e-01,\n",
       "        1.85789419e-02, 1.72292376e-02, 1.33229816e-02, 2.19933785e-02,\n",
       "        6.75810090e-03, 3.50960820e-03, 1.44855517e-01, 6.36706668e-02,\n",
       "        8.16918423e-03, 1.69913631e-02, 1.10525494e-02, 1.72186539e-02,\n",
       "        9.47647685e-03, 6.71646940e-03, 3.28031198e-02, 1.77113163e-02,\n",
       "        6.92346446e-03, 1.41276095e-02, 4.06935811e-02, 3.18225862e-02,\n",
       "        2.29759079e-02, 1.80603272e-02, 2.66973464e-02, 2.94862628e-02,\n",
       "        1.58383234e-01, 5.97620360e-02, 1.77623941e-02, 2.05526321e-02,\n",
       "        1.03267705e-02, 3.21904579e-03, 3.72103020e-03, 1.48154872e-02,\n",
       "        1.74573626e-02, 1.08664616e-02, 1.59534069e-01, 2.10686680e-03,\n",
       "        2.18240522e-03, 4.65439974e-02, 1.13311586e-02, 6.52884058e-04,\n",
       "        4.19062135e-03, 2.50017704e-02, 2.61889232e-02, 1.65623767e-02,\n",
       "        1.32018102e-02, 3.38037140e-02, 3.02613327e-03, 1.17615324e-01,\n",
       "        3.45708976e-02, 2.33024811e-03, 1.12980295e-01, 5.01397289e-03,\n",
       "        3.62110133e-03, 6.56274884e-04, 1.15886944e-01, 1.20255981e-03,\n",
       "        4.59098737e-03, 1.10719925e-02, 5.88085657e-03, 4.51089635e-02,\n",
       "        3.43231183e-03, 4.95765121e-03, 7.68448014e-03, 1.24982876e-01,\n",
       "        6.65948683e-03, 2.91835577e-02, 1.94648206e-03, 2.42750919e-03,\n",
       "        1.35664426e-03, 5.24291469e-03, 2.12994032e-02, 2.62331644e-03,\n",
       "        7.04806138e-03, 1.16556528e-01, 1.58422071e-03, 1.86087334e-03,\n",
       "        1.86262680e-03, 4.77723166e-03, 3.79479925e-02, 7.60915285e-04,\n",
       "        7.88573107e-03, 3.28916936e-03, 1.42194649e-01, 5.19098057e-02,\n",
       "        3.55710370e-03, 3.55634195e-03, 3.29764960e-03, 1.49959803e-02,\n",
       "        1.40954360e-01, 6.84248279e-04, 1.12149267e-02, 1.86059554e-03,\n",
       "        4.58958575e-02, 1.76246554e-02, 3.66480669e-03, 5.02002949e-03,\n",
       "        3.58456386e-03, 1.28560116e-01, 3.53538815e-03, 2.95214033e-03,\n",
       "        1.96358568e-02, 1.04103504e-01, 3.84900617e-03, 1.26854977e-01,\n",
       "        2.44213545e-03, 3.33320123e-03, 1.58739888e-01, 5.08351948e-03,\n",
       "        4.99228429e-03, 2.12614385e-01, 6.48902620e-04, 4.20383234e-03,\n",
       "        4.28987408e-01, 8.17428056e-02, 1.20821968e-01, 5.88827610e-02,\n",
       "        3.13867758e-02, 1.75592470e-02, 7.47825201e-02, 1.06673882e-01,\n",
       "        3.12684948e-02, 3.10623507e-02, 1.23448673e-01, 1.02950830e-02,\n",
       "        9.27999401e-02, 2.69335545e-02, 8.79558815e-02, 1.14063644e-01,\n",
       "        1.39869686e-01, 4.57246806e-02, 1.10668548e-01, 9.96056587e-02,\n",
       "        5.03671448e-03, 1.32132413e-01, 1.92156004e-03, 4.03702525e-03,\n",
       "        3.02857173e-02, 5.35603642e-03, 1.71186045e-03, 1.05594718e-01,\n",
       "        2.15759488e-02, 1.15082219e-01, 1.08157254e-02, 1.09157918e-01,\n",
       "        3.06614255e-03, 3.84574024e-03, 2.49001950e-02, 2.56608641e-02,\n",
       "        1.36815832e-01, 3.95350681e-02, 2.68855490e-03, 7.40542916e-03,\n",
       "        1.51107272e-02, 2.05276807e-02, 1.01002795e-01, 2.35151331e-02,\n",
       "        7.75425503e-02, 1.36014811e-02, 3.15966980e-02, 4.79987711e-02,\n",
       "        3.30826874e-02, 1.18590527e-02, 2.74188601e-02, 6.79744377e-03,\n",
       "        5.88120327e-03, 9.71783600e-03, 5.77070525e-03, 1.78553543e-01,\n",
       "        4.16391238e-03, 8.11372353e-03, 6.58333527e-03, 5.64154328e-02,\n",
       "        9.37589143e-03, 2.68143089e-02, 5.19547604e-02, 1.53440539e-03,\n",
       "        4.82805825e-02, 2.93945844e-02, 4.01350277e-02, 4.71077494e-03,\n",
       "        1.48423869e-02, 2.35840762e-02, 1.12211930e-02, 1.66674806e-02,\n",
       "        1.09205748e-02, 7.25620549e-02, 3.52218700e-03, 2.20000911e-02,\n",
       "        5.56545647e-03, 4.74346245e-03, 1.45988449e-01, 6.33554175e-03,\n",
       "        1.12925066e-02, 3.01864855e-03, 9.86968222e-03, 7.11487262e-03,\n",
       "        1.28259693e-01, 8.77472159e-03, 3.84947685e-03, 6.54755462e-02,\n",
       "        1.19409067e-02, 4.40642917e-02, 4.95630356e-03, 3.67158788e-03,\n",
       "        3.50458736e-03, 7.45860221e-03, 5.65308150e-03, 5.67105317e-03,\n",
       "        6.89114608e-02, 2.64273583e-02, 1.19136705e-01, 1.40629651e-02,\n",
       "        1.40653977e-01, 7.26194371e-03, 3.50360403e-01, 2.35769837e-01,\n",
       "        1.08198591e-02, 1.60780709e-02, 1.16050201e-02, 7.13862985e-02,\n",
       "        1.03432930e-02, 1.32669587e-01, 4.87516291e-02, 2.00588502e-01,\n",
       "        1.03195894e-02, 1.06666656e-02, 3.24926611e-02, 2.42448417e-02,\n",
       "        9.98227891e-03, 1.01304258e-03, 4.75678812e-03, 3.23618095e-03,\n",
       "        6.31091232e-03, 1.55626874e-01, 1.89076365e-02, 1.52301437e-01,\n",
       "        2.94114516e-02, 2.75051289e-02, 1.12649908e-02, 1.26254806e-02,\n",
       "        7.62464308e-03, 1.02584521e-02, 5.30211642e-03, 5.66736892e-03,\n",
       "        1.23365221e-02, 2.19291758e-02, 2.81230057e-03, 1.44025381e-01,\n",
       "        5.96999117e-04, 1.42009578e-01, 5.03666456e-02, 7.05915299e-03,\n",
       "        1.74492254e-03, 1.39982369e-01, 1.50378885e-03, 4.71754238e-02,\n",
       "        5.07209523e-03, 1.34929325e-01, 8.31588369e-03, 2.19735100e-02,\n",
       "        2.68380398e-02, 1.07564965e-02, 3.60970601e-03, 4.33186356e-03,\n",
       "        7.57407558e-03, 1.16323092e-02, 6.31818020e-03, 3.58942211e-03,\n",
       "        1.53132669e-01, 1.64599621e-03, 2.37082083e-02, 3.90059210e-03,\n",
       "        1.84345847e-02, 2.04252545e-03, 1.02364774e-03, 3.01478476e-02,\n",
       "        6.25575300e-03, 5.75007427e-03, 1.42540934e-01, 5.64560748e-03,\n",
       "        1.13002791e-02, 7.00443094e-03, 4.12495011e-02, 1.30040201e-03,\n",
       "        4.03172106e-03, 4.30517273e-03, 3.20383211e-03, 2.15665212e-03,\n",
       "        4.57261039e-03, 1.02383794e-03, 1.25048974e-02, 3.12640006e-03,\n",
       "        6.72824822e-03, 1.81052658e-03, 1.35281666e-01, 2.05844414e-02,\n",
       "        1.45623581e-01, 2.21084720e-03, 3.17776003e-03, 4.05513450e-02,\n",
       "        1.38777741e-01, 4.79782584e-03, 4.03463165e-03, 4.13300778e-02,\n",
       "        2.72689415e-03, 2.97366269e-03, 1.51351561e-03, 4.42615249e-03,\n",
       "        5.60361156e-03, 1.33982978e-03, 1.41975588e-01, 4.72459748e-03,\n",
       "        1.43128957e-01, 5.18937185e-03, 1.62924600e-01, 2.33353154e-02,\n",
       "        1.38955029e-01, 4.25018356e-03, 8.12931149e-04, 1.05580049e-02,\n",
       "        4.57022354e-03, 9.93716784e-04, 5.06311840e-03, 8.07806985e-03,\n",
       "        3.26407711e-03, 3.38344301e-03, 1.88813657e-02, 2.91412204e-02,\n",
       "        4.13880624e-03, 3.84533956e-03, 1.32979262e-01, 5.94350413e-02,\n",
       "        3.31219702e-03, 2.38126307e-03, 3.06878770e-03, 5.10791717e-03,\n",
       "        1.40920437e-01, 2.47580570e-03, 2.58444652e-03, 2.07594912e-02,\n",
       "        1.35802661e-01, 4.93603068e-02, 3.18450537e-02, 2.27164445e-03,\n",
       "        1.74418775e-02, 3.70243110e-03, 1.63838738e-01, 4.74694747e-03,\n",
       "        7.68840569e-03, 2.40321459e-02, 1.46986866e-01, 4.52646754e-04,\n",
       "        1.44447888e-01, 3.39946125e-02, 7.41518995e-04, 2.62406145e-04,\n",
       "        1.30074145e-01, 5.96429924e-04, 4.49870765e-03, 1.14465595e-03,\n",
       "        1.50958911e-01, 6.62643572e-03, 3.15074514e-03, 2.63575824e-02,\n",
       "        3.44930907e-02, 6.32000131e-04, 3.12328965e-03, 3.38375940e-02,\n",
       "        1.46105746e-03, 6.16365924e-03, 5.05565621e-04, 1.21730941e-02,\n",
       "        1.37557475e-01, 2.24884724e-03, 5.66929437e-02, 1.18675324e-03,\n",
       "        2.16142825e-03, 7.72917675e-03, 1.42007399e-01, 6.25915838e-03,\n",
       "        1.97218643e-03, 1.93521482e-02, 1.23137415e-01, 4.35543515e-03,\n",
       "        3.17487032e-02, 5.42198410e-02, 1.58168105e-01, 1.85341983e-02,\n",
       "        1.11200897e-02, 3.65506350e-02, 1.52545726e-02, 4.99211726e-02,\n",
       "        4.39667443e-03, 1.40481970e-03, 2.43210365e-02, 6.06853072e-03,\n",
       "        2.16412007e-02, 1.04794380e-03, 1.50330770e-01, 3.56189464e-02,\n",
       "        3.84394142e-03, 1.65302720e-02, 1.46597117e-01, 2.03740955e-03,\n",
       "        2.70692942e-03, 3.20082417e-03, 3.73828932e-02, 1.22472953e-03,\n",
       "        1.26111017e-01, 2.51828346e-03, 4.29974237e-03, 6.37258327e-03,\n",
       "        3.69327633e-03, 5.15479264e-02, 1.53171892e-03, 3.22200601e-03,\n",
       "        2.37929046e-02, 5.12576506e-03, 1.74842961e-01, 5.67959466e-03,\n",
       "        5.46577069e-03, 5.30080102e-02, 1.44805314e-01, 2.85537607e-02,\n",
       "        1.30982252e-03, 1.52727372e-03, 5.16206779e-02, 5.16571764e-03,\n",
       "        3.20444137e-02, 2.36805550e-02, 2.48960937e-02, 4.41141381e-03,\n",
       "        1.23440848e-01, 8.30260683e-03, 1.50308716e-01, 3.11865435e-02,\n",
       "        2.88895767e-03, 4.14741530e-03, 8.80317933e-03, 1.55207313e-02,\n",
       "        4.41809542e-03, 1.66864462e-03, 1.06222235e-02, 4.93519318e-03,\n",
       "        1.99129860e-02, 4.27027552e-02, 2.95745572e-02, 1.64904183e-03,\n",
       "        3.22705714e-03, 6.12906824e-02, 2.53985163e-03, 1.47261708e-01,\n",
       "        8.20352858e-03, 1.60325198e-01, 2.23583653e-03, 3.67595409e-02,\n",
       "        3.90016482e-03, 4.30739624e-03, 4.32916767e-02, 5.35577285e-03,\n",
       "        1.13805517e-02, 6.80112819e-03, 1.25921921e-02, 2.52591835e-02,\n",
       "        3.41339468e-02, 1.31943355e-01, 1.00005936e-02, 8.91391054e-03,\n",
       "        3.06993863e-02, 6.43037558e-03, 2.44096435e-03, 3.33098782e-02,\n",
       "        3.97812756e-03, 5.38800577e-03, 1.90443346e-02, 3.55527177e-03,\n",
       "        7.71112511e-03, 2.53607362e-02, 1.54131549e-01, 1.66285915e-03,\n",
       "        1.55401299e-01, 1.53362505e-03, 9.02979622e-03, 3.76065734e-03,\n",
       "        2.35349784e-02, 5.81271565e-03, 3.52626046e-02, 1.84008187e-02,\n",
       "        1.71926423e-02, 8.33801566e-03, 3.12568054e-03, 1.58791831e-02,\n",
       "        1.44578870e-01, 5.20837937e-03, 1.29539795e-03, 3.29397540e-02,\n",
       "        1.62255129e-02, 1.97323129e-03, 3.05505779e-03, 3.41934648e-03,\n",
       "        1.30424874e-02, 5.47469740e-03, 1.27284586e-03, 6.16243421e-03,\n",
       "        3.88929794e-03, 1.48394755e-01, 8.32871422e-04, 1.49411889e-01,\n",
       "        1.43454226e-03, 5.71503534e-03, 2.77146858e-02, 6.93802674e-03,\n",
       "        3.60117034e-03, 9.45463828e-03, 3.64064893e-03, 8.64552879e-03,\n",
       "        9.13076529e-03, 2.41463824e-02, 2.28283967e-02, 3.06591942e-02,\n",
       "        8.12338138e-03, 9.36920107e-03, 8.17043922e-03, 8.43554807e-02,\n",
       "        1.07541214e-02, 4.37435008e-02, 1.17550697e-02, 1.47551937e-02,\n",
       "        4.80725637e-03, 4.96458661e-02, 1.56332875e-01, 4.82731188e-03,\n",
       "        8.39874850e-03, 7.65726117e-03, 6.25006853e-03, 2.07051079e-03,\n",
       "        3.50238411e-02, 1.93094270e-03, 1.68971780e-01, 5.41589089e-03,\n",
       "        1.34462837e-01, 1.39437532e-03, 1.64720412e-01, 2.01369205e-02,\n",
       "        3.43535931e-02, 1.64680806e-04, 2.11780476e-03, 4.02427699e-02,\n",
       "        5.80748954e-03, 3.26546605e-03, 2.55552957e-02, 1.59322460e-02,\n",
       "        3.54902391e-03, 4.49725154e-03, 1.14139730e-02, 8.37561004e-03,\n",
       "        1.94041657e-03, 7.17104165e-03, 1.06333663e-02, 1.62403633e-01,\n",
       "        4.10100882e-03, 3.18383986e-02, 6.15524972e-03, 3.31041669e-03,\n",
       "        3.52945237e-03, 1.39632229e-02, 1.45502355e-01, 2.36266877e-02,\n",
       "        3.89905839e-03, 2.55025128e-03, 2.61909917e-03, 4.34737252e-03,\n",
       "        1.50978466e-02, 2.37693162e-02, 5.41721976e-03, 4.85670231e-03,\n",
       "        3.31715845e-03, 1.23957620e-02, 3.11749648e-03, 2.42727452e-03,\n",
       "        2.38505436e-02, 2.62483348e-03, 7.80624017e-03, 3.60842053e-03,\n",
       "        1.92753046e-03, 9.65462566e-04, 1.75129282e-03, 1.36834358e-02,\n",
       "        3.65363640e-03, 4.58553520e-02, 7.84603144e-03, 3.59022037e-04,\n",
       "        6.19220281e-03, 1.57268359e-01, 1.70364539e-02, 2.01237319e-03,\n",
       "        9.90734051e-03, 5.58036553e-03, 2.89775856e-03, 5.16958318e-03,\n",
       "        4.15592800e-03, 1.55847570e-01, 2.04074574e-03, 2.00229672e-03,\n",
       "        7.86996299e-03, 6.03548701e-03, 4.42237000e-03, 3.66698028e-03,\n",
       "        1.60336912e-01, 1.55808856e-02, 6.63417003e-03, 1.18818043e-03,\n",
       "        5.50423474e-02, 1.66790898e-03, 1.62428828e-01, 3.14614951e-03,\n",
       "        3.52558721e-03, 5.73941845e-04, 1.53288953e-01, 1.75215868e-03,\n",
       "        1.23046104e-03, 2.99513338e-03, 2.02511812e-03, 1.73999794e-03,\n",
       "        1.84921371e-02, 1.00222144e-02, 1.85476474e-03, 4.67885956e-03,\n",
       "        1.51036445e-03, 2.33970504e-03, 4.45854533e-02, 1.39964392e-02,\n",
       "        2.48204269e-03, 2.75720359e-03, 2.09624438e-03, 1.68843463e-01,\n",
       "        3.34323695e-03, 1.60396042e-03, 7.12591504e-03, 1.21505683e-03,\n",
       "        1.73089549e-01, 2.78978347e-03, 1.03736205e-02, 5.15227929e-03,\n",
       "        5.39017525e-03, 2.04212610e-03, 1.17559912e-03, 3.11027713e-03,\n",
       "        2.28532004e-02, 2.80358624e-03, 1.16570551e-02, 3.32670724e-03,\n",
       "        1.08685992e-03, 5.14728135e-03, 1.96827665e-02, 3.61679679e-03,\n",
       "        3.61428207e-03, 7.06228061e-03, 4.51474299e-03, 9.96124848e-03,\n",
       "        2.86398843e-02, 5.81419276e-03, 1.22133260e-03, 7.97563768e-03,\n",
       "        1.54204146e-03, 1.07005178e-02, 4.07250447e-03, 1.79788522e-03,\n",
       "        3.57304497e-03, 9.93304584e-04, 1.11697819e-02, 7.62351525e-04,\n",
       "        1.63263786e-01, 2.38068658e-03, 2.42191979e-03, 2.34053754e-02,\n",
       "        6.58548641e-03, 3.63404445e-03, 3.97784930e-03, 1.36579524e-02,\n",
       "        1.56372503e-02, 1.83697753e-03, 4.47906463e-03, 7.58924000e-03,\n",
       "        1.56612087e-03, 2.71392334e-02, 3.00151316e-02, 7.63892159e-03,\n",
       "        3.03142993e-03, 3.63536632e-03, 2.23620734e-02, 1.94434720e-02,\n",
       "        1.74659805e-03, 1.66812319e-01, 1.34096212e-03, 2.85948542e-03,\n",
       "        2.66132667e-02, 2.91297672e-03, 8.15225926e-03, 2.35880862e-03,\n",
       "        2.39947377e-03, 1.30440981e-02, 5.28475964e-03, 5.12801264e-03,\n",
       "        3.53085594e-03, 7.65630055e-03, 5.17082180e-03, 1.45158433e-03,\n",
       "        1.75236949e-01, 9.66737363e-03, 5.18083732e-03, 1.35609440e-02,\n",
       "        6.00196048e-03, 1.32229785e-01, 2.01539760e-02, 7.60949752e-03,\n",
       "        6.00576978e-02, 1.13861410e-02, 6.17045090e-03, 1.05101105e-02,\n",
       "        1.09409457e-03, 4.95702890e-03, 3.27770444e-03, 2.30028372e-02,\n",
       "        2.38662922e-03, 1.24396948e-03, 1.70472833e-01, 1.09036214e-02,\n",
       "        4.80724738e-03, 4.17756225e-03, 3.92643150e-03, 4.19368278e-02,\n",
       "        4.31821675e-03, 2.16915591e-03, 7.91412903e-03, 1.48169511e-02,\n",
       "        7.12518789e-04, 2.13743508e-03, 4.53848357e-02, 2.99090719e-02,\n",
       "        1.65672914e-03, 1.38854873e-01, 4.09995919e-03, 3.83381914e-03,\n",
       "        1.23550175e-02, 1.49402402e-01]),\n",
       " 'param_activation': masked_array(data=['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_neurons': masked_array(data=[8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16,\n",
       "                    32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8,\n",
       "                    16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'}],\n",
       " 'split0_test_score': array([0.4976798 , 0.50116009, 0.41995358, 0.52784222, 0.53132248,\n",
       "        0.37819025, 0.54872388, 0.53944314, 0.42343387, 0.58468676,\n",
       "        0.57888633, 0.47679815, 0.53132248, 0.57540601, 0.49187934,\n",
       "        0.55916476, 0.58816707, 0.51972157, 0.47447795, 0.56728536,\n",
       "        0.56612527, 0.56264502, 0.54524362, 0.54408354, 0.22853829,\n",
       "        0.51856148, 0.58236659, 0.49419954, 0.48955917, 0.55452436,\n",
       "        0.41995358, 0.44315544, 0.5765661 , 0.48375869, 0.512761  ,\n",
       "        0.54176337, 0.47911832, 0.4976798 , 0.55452436, 0.41415313,\n",
       "        0.29582366, 0.5684455 , 0.3201856 , 0.45475638, 0.53248262,\n",
       "        0.55220419, 0.54756379, 0.38283062, 0.54756379, 0.55684453,\n",
       "        0.37703016, 0.56960559, 0.55800462, 0.36310905, 0.58468676,\n",
       "        0.5812065 , 0.45475638, 0.58700699, 0.57888633, 0.51624131,\n",
       "        0.5638051 , 0.57888633, 0.51972157, 0.51856148, 0.56264502,\n",
       "        0.57424593, 0.49071926, 0.57076567, 0.56148493, 0.39559165,\n",
       "        0.57308584, 0.56496519, 0.42575407, 0.53248262, 0.57076567,\n",
       "        0.47563806, 0.49419954, 0.57540601, 0.47563806, 0.49883991,\n",
       "        0.53132248, 0.47795823, 0.53944314, 0.58468676, 0.33526683,\n",
       "        0.54060322, 0.58700699, 0.44431555, 0.55336428, 0.55336428,\n",
       "        0.56264502, 0.57076567, 0.37587008, 0.57888633, 0.58468676,\n",
       "        0.42459396, 0.57772624, 0.57888633, 0.43967518, 0.57192576,\n",
       "        0.5812065 , 0.53712296, 0.5638051 , 0.55916476, 0.5638051 ,\n",
       "        0.57772624, 0.57888633, 0.55336428, 0.50812066, 0.51856148,\n",
       "        0.57424593, 0.51624131, 0.55684453, 0.54872388, 0.49187934,\n",
       "        0.55336428, 0.5684455 , 0.53132248, 0.55220419, 0.55800462,\n",
       "        0.51160091, 0.54640371, 0.54872388, 0.48027843, 0.51160091,\n",
       "        0.55916476, 0.29582366, 0.55336428, 0.54408354, 0.31438515,\n",
       "        0.5       , 0.54872388, 0.49071926, 0.47679815, 0.56032485,\n",
       "        0.4361949 , 0.47679815, 0.26798144, 0.48955917, 0.49651971,\n",
       "        0.33526683, 0.51856148, 0.53596288, 0.39907193, 0.57308584,\n",
       "        0.5812065 , 0.36774942, 0.57308584, 0.58004642, 0.41415313,\n",
       "        0.55220419, 0.57308584, 0.48143852, 0.49651971, 0.53828305,\n",
       "        0.54640371, 0.38863108, 0.53364271, 0.54756379, 0.53364271,\n",
       "        0.50116009, 0.54060322, 0.4013921 , 0.53828305, 0.56032485,\n",
       "        0.53596288, 0.48723897, 0.57308584, 0.36658934, 0.53596288,\n",
       "        0.54176337, 0.37587008, 0.48607889, 0.55104411, 0.50928074,\n",
       "        0.48375869, 0.51856148, 0.44431555, 0.23317866, 0.51160091,\n",
       "        0.52204174, 0.512761  , 0.35962877, 0.54060322, 0.52900231,\n",
       "        0.38051045, 0.5684455 , 0.55452436, 0.36658934, 0.57772624,\n",
       "        0.58352667, 0.50232017, 0.58236659, 0.56960559, 0.51856148,\n",
       "        0.58352667, 0.56032485, 0.49187934, 0.50696057, 0.56264502,\n",
       "        0.57772624, 0.52436197, 0.53132248, 0.57424593, 0.49883991,\n",
       "        0.53132248, 0.5765661 , 0.31090486, 0.50116009, 0.56728536,\n",
       "        0.47215778, 0.47795823, 0.56496519, 0.47331786, 0.40835267,\n",
       "        0.56032485, 0.46867749, 0.48375869, 0.55568445, 0.51972157,\n",
       "        0.3399072 , 0.56960559, 0.44779584, 0.3549884 , 0.52320188,\n",
       "        0.56032485, 0.55104411, 0.37122971, 0.5638051 , 0.5638051 ,\n",
       "        0.40487239, 0.58700699, 0.57308584, 0.36542922, 0.57540601,\n",
       "        0.58352667, 0.50696057, 0.5812065 , 0.55452436, 0.51392114,\n",
       "        0.58352667, 0.58816707, 0.54060322, 0.55568445, 0.54872388,\n",
       "        0.55568445, 0.5174014 , 0.50580049, 0.56728536, 0.53828305,\n",
       "        0.55684453, 0.58468676, 0.49303943, 0.50580049, 0.57540601,\n",
       "        0.44895592, 0.52668214, 0.57772624, 0.48955917, 0.52088165,\n",
       "        0.54060322, 0.45127609, 0.55916476, 0.54988396, 0.48027843,\n",
       "        0.46519721, 0.59164733, 0.48839906, 0.47911832, 0.53364271,\n",
       "        0.36774942, 0.41531321, 0.3573086 , 0.51392114, 0.50928074,\n",
       "        0.23549885, 0.50812066, 0.46171695, 0.4013921 , 0.5638051 ,\n",
       "        0.57772624, 0.4187935 , 0.55220419, 0.55684453, 0.38283062,\n",
       "        0.57308584, 0.56264502, 0.38747099, 0.54640371, 0.55684453,\n",
       "        0.54408354, 0.55916476, 0.55916476, 0.5174014 , 0.4361949 ,\n",
       "        0.54640371, 0.53248262, 0.43851507, 0.54408354, 0.53828305,\n",
       "        0.52668214, 0.52900231, 0.54756379, 0.53828305, 0.54872388,\n",
       "        0.54988396, 0.45359629, 0.48607889, 0.58236659, 0.512761  ,\n",
       "        0.53132248, 0.54988396, 0.45707658, 0.49651971, 0.56264502,\n",
       "        0.4825986 , 0.49071926, 0.26566124, 0.50116009, 0.51160091,\n",
       "        0.30974478, 0.53016239, 0.52784222, 0.36542922, 0.57888633,\n",
       "        0.5812065 , 0.40023202, 0.57424593, 0.57308584, 0.42807424,\n",
       "        0.5638051 , 0.57424593, 0.39791185, 0.55916476, 0.53248262,\n",
       "        0.53480279, 0.5684455 , 0.57192576, 0.55800462, 0.27726218,\n",
       "        0.59280741, 0.54524362, 0.55684453, 0.5684455 , 0.57540601,\n",
       "        0.50348026, 0.55568445, 0.5684455 , 0.53712296, 0.5046404 ,\n",
       "        0.56960559, 0.49419954, 0.51044083, 0.58352667, 0.50348026,\n",
       "        0.49651971, 0.54988396, 0.28190255, 0.53248262, 0.57192576,\n",
       "        0.51972157, 0.52668214, 0.42807424, 0.54292345, 0.54176337,\n",
       "        0.36426914, 0.55916476, 0.55452436, 0.37122971, 0.57192576,\n",
       "        0.5812065 , 0.45591646, 0.58004642, 0.57888633, 0.47563806,\n",
       "        0.58004642, 0.58468676, 0.49187934, 0.53944314, 0.54292345,\n",
       "        0.56496519, 0.46403712, 0.55336428, 0.57076567, 0.55104411,\n",
       "        0.55916476, 0.57424593, 0.51624131, 0.55684453, 0.56612527,\n",
       "        0.52204174, 0.54292345, 0.57888633, 0.51392114, 0.5812065 ,\n",
       "        0.56032485, 0.49651971, 0.52088165, 0.58468676, 0.5       ,\n",
       "        0.5174014 , 0.56264502, 0.512761  , 0.55568445, 0.55104411,\n",
       "        0.47911832, 0.46171695, 0.41647333, 0.51856148, 0.51044083,\n",
       "        0.42227378, 0.54060322, 0.53828305, 0.37238979, 0.56032485,\n",
       "        0.56728536, 0.42575407, 0.56612527, 0.57424593, 0.45591646,\n",
       "        0.54988396, 0.56032485, 0.49419954, 0.49071926, 0.5638051 ,\n",
       "        0.54988396, 0.54408354, 0.53480279, 0.55220419, 0.55452436,\n",
       "        0.52436197, 0.57308584, 0.55568445, 0.36658934, 0.54640371,\n",
       "        0.49303943, 0.50580049, 0.52552205, 0.42923433, 0.36658934,\n",
       "        0.48839906, 0.45707658, 0.36658934, 0.54640371, 0.48955917,\n",
       "        0.48143852, 0.50812066, 0.42807424, 0.48723897, 0.51392114,\n",
       "        0.53712296, 0.53596288, 0.36310905, 0.55336428, 0.56612527,\n",
       "        0.37006959, 0.5684455 , 0.56148493, 0.37122971, 0.54292345,\n",
       "        0.55916476, 0.4849188 , 0.56960559, 0.58932716, 0.50928074,\n",
       "        0.57540601, 0.56032485, 0.51044083, 0.54872388, 0.58352667,\n",
       "        0.55220419, 0.50928074, 0.58352667, 0.56612527, 0.52784222,\n",
       "        0.53944314, 0.58700699, 0.52668214, 0.56728536, 0.56496519,\n",
       "        0.53248262, 0.49071926, 0.56612527, 0.2563805 , 0.58236659,\n",
       "        0.54872388, 0.41299304, 0.4825986 , 0.53944314, 0.36658934,\n",
       "        0.52784222, 0.56148493, 0.45823666, 0.43271461, 0.57424593,\n",
       "        0.54060322, 0.56612527, 0.36426914, 0.56496519, 0.56728536,\n",
       "        0.36658934, 0.57308584, 0.58004642, 0.37703016, 0.55800462,\n",
       "        0.57540601, 0.54060322, 0.58932716, 0.58352667, 0.53596288,\n",
       "        0.58236659, 0.58584684, 0.54756379, 0.55568445, 0.56032485,\n",
       "        0.57192576, 0.53944314, 0.55568445, 0.57772624, 0.5       ,\n",
       "        0.53828305, 0.55568445, 0.48607889, 0.47795823, 0.55800462,\n",
       "        0.51392114, 0.54292345, 0.57540601, 0.48955917, 0.57308584,\n",
       "        0.60208815, 0.50580049, 0.49535963, 0.56264502, 0.27262181,\n",
       "        0.21113689, 0.55800462, 0.43271461, 0.46867749, 0.58932716,\n",
       "        0.4187935 , 0.48143852, 0.31786543, 0.4849188 , 0.51044083,\n",
       "        0.28770301, 0.49419954, 0.52436197, 0.38979119, 0.57888633,\n",
       "        0.59628773, 0.42227378, 0.54060322, 0.56960559, 0.37935033,\n",
       "        0.5812065 , 0.56032485, 0.42691416, 0.52900231, 0.57076567,\n",
       "        0.51972157, 0.52436197, 0.55104411, 0.55336428, 0.49071926,\n",
       "        0.5939675 , 0.55220419, 0.42343387, 0.54988396, 0.51508123,\n",
       "        0.38283062, 0.53712296, 0.45823666, 0.42923433, 0.57308584,\n",
       "        0.58468676, 0.45011601, 0.4849188 , 0.50580049, 0.50348026,\n",
       "        0.54640371, 0.52900231, 0.44431555, 0.54756379, 0.54640371,\n",
       "        0.512761  , 0.50928074, 0.34570765, 0.52088165, 0.53596288,\n",
       "        0.41531321, 0.54872388, 0.56496519, 0.40835267, 0.55568445,\n",
       "        0.57076567, 0.47215778, 0.5765661 , 0.5939675 , 0.36658934,\n",
       "        0.58700699, 0.55916476, 0.47447795, 0.50812066, 0.57308584,\n",
       "        0.56496519, 0.55104411, 0.49419954, 0.55220419, 0.49303943,\n",
       "        0.57888633, 0.58236659, 0.48839906, 0.53596288, 0.58584684,\n",
       "        0.4849188 , 0.54524362, 0.5812065 , 0.3549884 , 0.50580049,\n",
       "        0.56728536, 0.1937355 , 0.55916476, 0.50580049, 0.48723897,\n",
       "        0.48027843, 0.55800462, 0.49535963, 0.51624131, 0.58352667,\n",
       "        0.54408354, 0.54988396, 0.35614848, 0.56960559, 0.56148493,\n",
       "        0.4849188 , 0.56728536, 0.57424593, 0.36658934, 0.56148493,\n",
       "        0.5765661 , 0.51044083, 0.56032485, 0.58700699, 0.52900231,\n",
       "        0.56032485, 0.58236659, 0.51392114, 0.54292345, 0.58004642,\n",
       "        0.58236659, 0.57308584, 0.56960559, 0.55916476, 0.54988396,\n",
       "        0.56496519, 0.57192576, 0.38515082, 0.52088165, 0.59048724,\n",
       "        0.53712296, 0.51392114, 0.54872388, 0.47215778, 0.55800462,\n",
       "        0.55452436, 0.48607889, 0.47679815, 0.5765661 , 0.46519721,\n",
       "        0.52784222, 0.56960559, 0.42227378, 0.47563806, 0.58932716,\n",
       "        0.48143852, 0.44895592, 0.24593967, 0.4825986 , 0.40719259,\n",
       "        0.28306264, 0.5       , 0.47911832, 0.25290024, 0.55452436,\n",
       "        0.53944314, 0.40255222, 0.55800462, 0.5684455 , 0.38979119,\n",
       "        0.56032485, 0.58816707, 0.38167053, 0.50232017, 0.56032485,\n",
       "        0.48839906, 0.59744781, 0.58236659, 0.51508123, 0.55220419,\n",
       "        0.5939675 , 0.50348026, 0.53364271, 0.54640371, 0.53944314,\n",
       "        0.52784222, 0.55452436, 0.53828305, 0.53016239, 0.56032485,\n",
       "        0.53364271, 0.53016239, 0.57540601, 0.53248262, 0.38051045,\n",
       "        0.512761  , 0.57192576, 0.47099769, 0.53712296, 0.56960559,\n",
       "        0.40603247, 0.48839906, 0.27958238, 0.46287704, 0.50580049,\n",
       "        0.42575407, 0.52204174, 0.53712296, 0.27030161, 0.58468676,\n",
       "        0.56728536, 0.38167053, 0.57424593, 0.58584684, 0.37935033,\n",
       "        0.5812065 , 0.57424593, 0.42227378, 0.54408354, 0.58700699,\n",
       "        0.54060322, 0.54872388, 0.57888633, 0.52784222, 0.57076567,\n",
       "        0.58584684, 0.54176337, 0.55336428, 0.5638051 , 0.56496519,\n",
       "        0.47679815, 0.50696057, 0.55336428, 0.52088165, 0.5812065 ,\n",
       "        0.54756379, 0.46519721, 0.53828305, 0.5812065 , 0.51856148,\n",
       "        0.52320188, 0.5684455 , 0.44895592, 0.4976798 , 0.56148493,\n",
       "        0.44779584, 0.52436197, 0.38863108, 0.53480279, 0.54060322,\n",
       "        0.4037123 , 0.55336428, 0.55800462, 0.43851507, 0.59280741,\n",
       "        0.58352667, 0.38283062, 0.59164733, 0.55684453, 0.46055683,\n",
       "        0.56496519, 0.56728536, 0.47447795, 0.52436197, 0.57888633,\n",
       "        0.56032485, 0.51044083, 0.57308584, 0.58700699, 0.5684455 ,\n",
       "        0.57308584, 0.56960559, 0.53596288, 0.54060322, 0.57076567,\n",
       "        0.49303943, 0.58700699, 0.5684455 , 0.52088165, 0.56032485,\n",
       "        0.58584684, 0.51392114, 0.54756379, 0.57308584, 0.4976798 ,\n",
       "        0.55800462, 0.58816707, 0.53016239, 0.55916476, 0.54408354]),\n",
       " 'split1_test_score': array([0.51856148, 0.48839906, 0.4037123 , 0.53944314, 0.54640371,\n",
       "        0.43851507, 0.54060322, 0.55220419, 0.48723897, 0.56148493,\n",
       "        0.55336428, 0.5174014 , 0.55800462, 0.55336428, 0.50348026,\n",
       "        0.57076567, 0.57076567, 0.51508123, 0.55800462, 0.54756379,\n",
       "        0.56264502, 0.47447795, 0.55800462, 0.55800462, 0.54408354,\n",
       "        0.53944314, 0.56728536, 0.2587007 , 0.51508123, 0.55220419,\n",
       "        0.49419954, 0.52552205, 0.55800462, 0.39559165, 0.31554523,\n",
       "        0.52436197, 0.45475638, 0.53944314, 0.56612527, 0.42807424,\n",
       "        0.51972157, 0.52784222, 0.43735498, 0.42575407, 0.56612527,\n",
       "        0.54176337, 0.54872388, 0.45475638, 0.55336428, 0.55220419,\n",
       "        0.39907193, 0.56032485, 0.55800462, 0.4338747 , 0.56612527,\n",
       "        0.55452436, 0.52900231, 0.54756379, 0.56960559, 0.53480279,\n",
       "        0.56960559, 0.56612527, 0.52784222, 0.50580049, 0.54640371,\n",
       "        0.55452436, 0.56612527, 0.54756379, 0.55104411, 0.46171695,\n",
       "        0.4849188 , 0.56032485, 0.23317866, 0.53944314, 0.5765661 ,\n",
       "        0.25406033, 0.49303943, 0.55104411, 0.34338748, 0.46055683,\n",
       "        0.55452436, 0.25522041, 0.37470996, 0.54524362, 0.46403712,\n",
       "        0.48723897, 0.55916476, 0.4825986 , 0.53248262, 0.57540601,\n",
       "        0.55684453, 0.56032485, 0.4187935 , 0.56148493, 0.55336428,\n",
       "        0.4013921 , 0.55916476, 0.56264502, 0.44779584, 0.55220419,\n",
       "        0.55800462, 0.55104411, 0.55568445, 0.55916476, 0.54872388,\n",
       "        0.55800462, 0.56612527, 0.55916476, 0.52668214, 0.57076567,\n",
       "        0.55800462, 0.50580049, 0.54524362, 0.57888633, 0.49071926,\n",
       "        0.54988396, 0.56148493, 0.54524362, 0.46867749, 0.55684453,\n",
       "        0.45823666, 0.46519721, 0.5638051 , 0.53828305, 0.53248262,\n",
       "        0.56264502, 0.47679815, 0.51972157, 0.54176337, 0.24477959,\n",
       "        0.52552205, 0.57308584, 0.52088165, 0.25754061, 0.53480279,\n",
       "        0.50696057, 0.50812066, 0.4013921 , 0.52668214, 0.50348026,\n",
       "        0.37587008, 0.52668214, 0.52668214, 0.40603247, 0.5684455 ,\n",
       "        0.56496519, 0.42343387, 0.54524362, 0.56264502, 0.43503481,\n",
       "        0.55800462, 0.55800462, 0.42923433, 0.45591646, 0.54292345,\n",
       "        0.54292345, 0.52668214, 0.54872388, 0.53364271, 0.5174014 ,\n",
       "        0.54756379, 0.55452436, 0.46751741, 0.56148493, 0.57076567,\n",
       "        0.31670535, 0.45127609, 0.54408354, 0.54060322, 0.53016239,\n",
       "        0.51392114, 0.35382831, 0.46751741, 0.53132248, 0.41763341,\n",
       "        0.46403712, 0.54060322, 0.28770301, 0.2587007 , 0.55336428,\n",
       "        0.53828305, 0.54060322, 0.4037123 , 0.54292345, 0.55220419,\n",
       "        0.4849188 , 0.54872388, 0.55568445, 0.38747099, 0.58236659,\n",
       "        0.56264502, 0.48143852, 0.56612527, 0.57540601, 0.46055683,\n",
       "        0.55452436, 0.56612527, 0.48027843, 0.4825986 , 0.54292345,\n",
       "        0.55452436, 0.50232017, 0.54524362, 0.55336428, 0.55568445,\n",
       "        0.5046404 , 0.56612527, 0.26218098, 0.56612527, 0.53944314,\n",
       "        0.2563805 , 0.46983758, 0.55104411, 0.52204174, 0.54524362,\n",
       "        0.54408354, 0.51972157, 0.47331786, 0.55104411, 0.47099769,\n",
       "        0.54292345, 0.55568445, 0.25058004, 0.47215778, 0.54408354,\n",
       "        0.55916476, 0.55684453, 0.41067284, 0.55452436, 0.56264502,\n",
       "        0.38399071, 0.56496519, 0.55220419, 0.42343387, 0.57888633,\n",
       "        0.56728536, 0.51044083, 0.56496519, 0.55452436, 0.53132248,\n",
       "        0.55916476, 0.54060322, 0.54640371, 0.48143852, 0.56496519,\n",
       "        0.57772624, 0.53944314, 0.55336428, 0.57192576, 0.46055683,\n",
       "        0.55104411, 0.55104411, 0.54292345, 0.55104411, 0.55104411,\n",
       "        0.53016239, 0.43155453, 0.52436197, 0.44199535, 0.39095128,\n",
       "        0.56148493, 0.4361949 , 0.53132248, 0.5638051 , 0.29698375,\n",
       "        0.47679815, 0.5765661 , 0.33526683, 0.43271461, 0.55452436,\n",
       "        0.44663572, 0.46983758, 0.19953597, 0.43735498, 0.50348026,\n",
       "        0.29582366, 0.51972157, 0.4976798 , 0.45011601, 0.55684453,\n",
       "        0.54988396, 0.37354988, 0.55220419, 0.56032485, 0.4013921 ,\n",
       "        0.54872388, 0.55452436, 0.37470996, 0.54408354, 0.58004642,\n",
       "        0.53712296, 0.46287704, 0.54640371, 0.53364271, 0.49651971,\n",
       "        0.53944314, 0.54872388, 0.46867749, 0.53016239, 0.54176337,\n",
       "        0.38631091, 0.4976798 , 0.54524362, 0.51856148, 0.53132248,\n",
       "        0.55336428, 0.5174014 , 0.54872388, 0.55452436, 0.39675173,\n",
       "        0.49651971, 0.54872388, 0.48027843, 0.54988396, 0.5638051 ,\n",
       "        0.49651971, 0.5046404 , 0.39443156, 0.51624131, 0.51856148,\n",
       "        0.35962877, 0.53596288, 0.53712296, 0.36542922, 0.57888633,\n",
       "        0.54524362, 0.38631091, 0.5765661 , 0.56148493, 0.39327148,\n",
       "        0.56728536, 0.5638051 , 0.46287704, 0.53364271, 0.55684453,\n",
       "        0.53596288, 0.56148493, 0.55568445, 0.56032485, 0.5046404 ,\n",
       "        0.55104411, 0.55684453, 0.53828305, 0.49303943, 0.55800462,\n",
       "        0.47447795, 0.54292345, 0.55684453, 0.512761  , 0.54292345,\n",
       "        0.55916476, 0.51044083, 0.56496519, 0.57076567, 0.52436197,\n",
       "        0.54408354, 0.56032485, 0.44663572, 0.54408354, 0.55336428,\n",
       "        0.52784222, 0.52668214, 0.42227378, 0.54872388, 0.54872388,\n",
       "        0.45243621, 0.55916476, 0.55220419, 0.43503481, 0.57308584,\n",
       "        0.56496519, 0.45475638, 0.55916476, 0.56264502, 0.46751741,\n",
       "        0.54640371, 0.55800462, 0.49187934, 0.53132248, 0.56960559,\n",
       "        0.55220419, 0.4338747 , 0.55916476, 0.56496519, 0.55220419,\n",
       "        0.54988396, 0.55452436, 0.53132248, 0.57308584, 0.55452436,\n",
       "        0.47331786, 0.53712296, 0.55684453, 0.53132248, 0.54524362,\n",
       "        0.54524362, 0.52552205, 0.53828305, 0.5684455 , 0.53712296,\n",
       "        0.55104411, 0.55104411, 0.52668214, 0.54060322, 0.56960559,\n",
       "        0.47563806, 0.51044083, 0.31322506, 0.51508123, 0.53016239,\n",
       "        0.41067284, 0.53132248, 0.54872388, 0.39095128, 0.5765661 ,\n",
       "        0.54988396, 0.48607889, 0.55916476, 0.55684453, 0.46287704,\n",
       "        0.54060322, 0.56728536, 0.48839906, 0.52088165, 0.5684455 ,\n",
       "        0.54988396, 0.48143852, 0.54292345, 0.56032485, 0.49535963,\n",
       "        0.52900231, 0.51972157, 0.37587008, 0.4825986 , 0.53712296,\n",
       "        0.46635732, 0.55916476, 0.54756379, 0.41531321, 0.53248262,\n",
       "        0.57308584, 0.25406033, 0.38399071, 0.55220419, 0.52436197,\n",
       "        0.38399071, 0.54292345, 0.39907193, 0.45707658, 0.55568445,\n",
       "        0.54292345, 0.54756379, 0.43271461, 0.53480279, 0.55800462,\n",
       "        0.38051045, 0.56496519, 0.54872388, 0.38747099, 0.5638051 ,\n",
       "        0.55800462, 0.52436197, 0.52552205, 0.57772624, 0.4976798 ,\n",
       "        0.56496519, 0.54756379, 0.53712296, 0.53712296, 0.55916476,\n",
       "        0.54408354, 0.52436197, 0.54524362, 0.57308584, 0.55220419,\n",
       "        0.50116009, 0.57308584, 0.36194897, 0.54756379, 0.56032485,\n",
       "        0.52436197, 0.53712296, 0.57076567, 0.27030161, 0.53828305,\n",
       "        0.54988396, 0.46751741, 0.47099769, 0.54408354, 0.50348026,\n",
       "        0.48375869, 0.50812066, 0.43735498, 0.47563806, 0.55104411,\n",
       "        0.56728536, 0.55568445, 0.40719259, 0.56148493, 0.5638051 ,\n",
       "        0.46983758, 0.54756379, 0.55336428, 0.4037123 , 0.57308584,\n",
       "        0.56612527, 0.54872388, 0.57192576, 0.57076567, 0.53944314,\n",
       "        0.56960559, 0.58816707, 0.55452436, 0.54292345, 0.51392114,\n",
       "        0.57540601, 0.48143852, 0.54176337, 0.54640371, 0.56728536,\n",
       "        0.55800462, 0.58004642, 0.29582366, 0.42691416, 0.51508123,\n",
       "        0.30626449, 0.54640371, 0.55916476, 0.53364271, 0.49187934,\n",
       "        0.56728536, 0.33062646, 0.20881671, 0.55684453, 0.46519721,\n",
       "        0.512761  , 0.56960559, 0.21577726, 0.48955917, 0.54988396,\n",
       "        0.44199535, 0.50812066, 0.337587  , 0.5174014 , 0.53016239,\n",
       "        0.39443156, 0.53132248, 0.53944314, 0.38515082, 0.54756379,\n",
       "        0.54872388, 0.38399071, 0.55916476, 0.5765661 , 0.40951276,\n",
       "        0.54524362, 0.57888633, 0.43155453, 0.56264502, 0.55336428,\n",
       "        0.53944314, 0.54176337, 0.54408354, 0.55104411, 0.55568445,\n",
       "        0.54524362, 0.54872388, 0.40835267, 0.48607889, 0.51972157,\n",
       "        0.50348026, 0.49535963, 0.52668214, 0.46867749, 0.53944314,\n",
       "        0.54524362, 0.38399071, 0.56032485, 0.49419954, 0.28074247,\n",
       "        0.54524362, 0.55220419, 0.46055683, 0.38399071, 0.512761  ,\n",
       "        0.51160091, 0.5174014 , 0.35846868, 0.54408354, 0.54524362,\n",
       "        0.40951276, 0.54988396, 0.54176337, 0.40835267, 0.54988396,\n",
       "        0.55220419, 0.50116009, 0.54872388, 0.54872388, 0.50348026,\n",
       "        0.57772624, 0.55336428, 0.4976798 , 0.55800462, 0.52552205,\n",
       "        0.5638051 , 0.45243621, 0.5812065 , 0.55684453, 0.52784222,\n",
       "        0.56496519, 0.56148493, 0.56032485, 0.54988396, 0.57424593,\n",
       "        0.44895592, 0.55336428, 0.57308584, 0.54524362, 0.38399071,\n",
       "        0.57076567, 0.52668214, 0.53480279, 0.56728536, 0.4338747 ,\n",
       "        0.38399071, 0.53596288, 0.51160091, 0.52552205, 0.51856148,\n",
       "        0.53364271, 0.55800462, 0.3074246 , 0.55220419, 0.55916476,\n",
       "        0.42343387, 0.55220419, 0.56148493, 0.40951276, 0.57772624,\n",
       "        0.58004642, 0.49883991, 0.57076567, 0.5684455 , 0.53016239,\n",
       "        0.54176337, 0.58700699, 0.54872388, 0.54176337, 0.56612527,\n",
       "        0.55684453, 0.56264502, 0.56496519, 0.56612527, 0.54756379,\n",
       "        0.54524362, 0.56032485, 0.53364271, 0.54640371, 0.55452436,\n",
       "        0.53364271, 0.54408354, 0.54524362, 0.48723897, 0.54060322,\n",
       "        0.54872388, 0.50348026, 0.53596288, 0.51508123, 0.41763341,\n",
       "        0.51856148, 0.5638051 , 0.48955917, 0.49535963, 0.56148493,\n",
       "        0.39095128, 0.41183296, 0.21461716, 0.47331786, 0.41531321,\n",
       "        0.37238979, 0.5046404 , 0.49535963, 0.23317866, 0.54176337,\n",
       "        0.54640371, 0.37122971, 0.57308584, 0.55800462, 0.38399071,\n",
       "        0.55336428, 0.55800462, 0.42459396, 0.54988396, 0.57888633,\n",
       "        0.5       , 0.58236659, 0.56264502, 0.53364271, 0.54756379,\n",
       "        0.54872388, 0.512761  , 0.44547564, 0.5638051 , 0.54408354,\n",
       "        0.45939675, 0.54292345, 0.54640371, 0.53248262, 0.55684453,\n",
       "        0.5174014 , 0.48723897, 0.56148493, 0.54176337, 0.50580049,\n",
       "        0.55568445, 0.55104411, 0.53828305, 0.54756379, 0.55684453,\n",
       "        0.45823666, 0.48027843, 0.38747099, 0.52204174, 0.5046404 ,\n",
       "        0.2737819 , 0.53712296, 0.53016239, 0.42691416, 0.55336428,\n",
       "        0.54408354, 0.46055683, 0.57076567, 0.56032485, 0.40835267,\n",
       "        0.55800462, 0.54176337, 0.45359629, 0.38399071, 0.56032485,\n",
       "        0.53596288, 0.54176337, 0.5638051 , 0.55104411, 0.52436197,\n",
       "        0.53944314, 0.55336428, 0.52088165, 0.38399071, 0.56032485,\n",
       "        0.51856148, 0.57192576, 0.55684453, 0.55452436, 0.55800462,\n",
       "        0.56032485, 0.55684453, 0.55104411, 0.5046404 , 0.5046404 ,\n",
       "        0.56264502, 0.56264502, 0.49651971, 0.56496519, 0.55916476,\n",
       "        0.52436197, 0.512761  , 0.39443156, 0.54640371, 0.55104411,\n",
       "        0.37819025, 0.56032485, 0.55452436, 0.46055683, 0.56728536,\n",
       "        0.5638051 , 0.41183296, 0.56148493, 0.57308584, 0.38399071,\n",
       "        0.57424593, 0.55336428, 0.46751741, 0.48839906, 0.56960559,\n",
       "        0.55568445, 0.54292345, 0.55916476, 0.55336428, 0.57888633,\n",
       "        0.56032485, 0.5638051 , 0.38399071, 0.49651971, 0.55336428,\n",
       "        0.5638051 , 0.55800462, 0.56264502, 0.5       , 0.5684455 ,\n",
       "        0.55800462, 0.21577726, 0.56612527, 0.56264502, 0.46287704,\n",
       "        0.54176337, 0.54292345, 0.53944314, 0.54640371, 0.52784222]),\n",
       " 'split2_test_score': array([0.51684088, 0.51103365, 0.41347271, 0.53542393, 0.54819977,\n",
       "        0.38675958, 0.55400699, 0.56562138, 0.39605111, 0.58188152,\n",
       "        0.55981416, 0.43437862, 0.53890824, 0.57723576, 0.4738676 ,\n",
       "        0.53077817, 0.56678283, 0.5087108 , 0.55516839, 0.52148664,\n",
       "        0.57375145, 0.49593496, 0.48780489, 0.57258999, 0.46573752,\n",
       "        0.56794423, 0.57375145, 0.49825785, 0.50290358, 0.56097561,\n",
       "        0.42276424, 0.39140534, 0.57375145, 0.53193963, 0.53077817,\n",
       "        0.5714286 , 0.49361208, 0.54587686, 0.58072007, 0.26248547,\n",
       "        0.48664343, 0.54587686, 0.41579559, 0.28919861, 0.56562138,\n",
       "        0.55168408, 0.55981416, 0.38792104, 0.55865276, 0.57026714,\n",
       "        0.42740998, 0.57491291, 0.56678283, 0.40650406, 0.55168408,\n",
       "        0.57491291, 0.52032518, 0.58072007, 0.57955867, 0.51800233,\n",
       "        0.56329846, 0.5888502 , 0.52497095, 0.54703832, 0.54703832,\n",
       "        0.57607436, 0.47967479, 0.52380955, 0.57258999, 0.55284554,\n",
       "        0.54123116, 0.55981416, 0.5261324 , 0.54587686, 0.5888502 ,\n",
       "        0.55168408, 0.42044136, 0.55981416, 0.40534264, 0.33914053,\n",
       "        0.57375145, 0.34610918, 0.4773519 , 0.55168408, 0.26945412,\n",
       "        0.51567942, 0.57723576, 0.48315912, 0.51800233, 0.58072007,\n",
       "        0.57607436, 0.57955867, 0.41347271, 0.57723576, 0.56678283,\n",
       "        0.41114983, 0.57607436, 0.56213707, 0.40650406, 0.58072007,\n",
       "        0.56910568, 0.54703832, 0.58536583, 0.56445992, 0.54239255,\n",
       "        0.5574913 , 0.55632985, 0.54819977, 0.5400697 , 0.52380955,\n",
       "        0.57839721, 0.42973286, 0.57607436, 0.58304298, 0.39605111,\n",
       "        0.45644599, 0.5574913 , 0.51684088, 0.5714286 , 0.55516839,\n",
       "        0.54703832, 0.45876887, 0.5888502 , 0.51567942, 0.46573752,\n",
       "        0.57258999, 0.48896632, 0.54355401, 0.56445992, 0.42160279,\n",
       "        0.47851336, 0.56678283, 0.40069687, 0.41114983, 0.57375145,\n",
       "        0.44134727, 0.47270617, 0.37862951, 0.4912892 , 0.50174218,\n",
       "        0.39605111, 0.53193963, 0.52148664, 0.38095239, 0.58072007,\n",
       "        0.57375145, 0.43437862, 0.57026714, 0.59117305, 0.41347271,\n",
       "        0.58536583, 0.56678283, 0.48432055, 0.47619048, 0.51335657,\n",
       "        0.5400697 , 0.45760745, 0.53542393, 0.54936123, 0.46922183,\n",
       "        0.5714286 , 0.55865276, 0.50638795, 0.57491291, 0.53426248,\n",
       "        0.44599304, 0.55284554, 0.58304298, 0.47038329, 0.52845526,\n",
       "        0.53077817, 0.4018583 , 0.34843206, 0.55052263, 0.28455284,\n",
       "        0.48199767, 0.57375145, 0.38792104, 0.25319397, 0.51335657,\n",
       "        0.50987226, 0.51219511, 0.39024389, 0.53542393, 0.55516839,\n",
       "        0.46689895, 0.56445992, 0.57258999, 0.4018583 , 0.57375145,\n",
       "        0.55865276, 0.41463414, 0.56097561, 0.58304298, 0.49245062,\n",
       "        0.54471546, 0.57607436, 0.4738676 , 0.53077817, 0.56794423,\n",
       "        0.57955867, 0.39024389, 0.50290358, 0.56678283, 0.52148664,\n",
       "        0.55400699, 0.57258999, 0.4738676 , 0.5261324 , 0.57491291,\n",
       "        0.51219511, 0.39721254, 0.56794423, 0.49941927, 0.49245062,\n",
       "        0.55400699, 0.43786296, 0.50754935, 0.52961671, 0.48896632,\n",
       "        0.51567942, 0.53542393, 0.23228803, 0.5226481 , 0.56213707,\n",
       "        0.56678283, 0.56445992, 0.40069687, 0.56910568, 0.56910568,\n",
       "        0.44947734, 0.5714286 , 0.57491291, 0.41579559, 0.55284554,\n",
       "        0.56794423, 0.51800233, 0.57955867, 0.58768874, 0.53658539,\n",
       "        0.5714286 , 0.57839721, 0.51335657, 0.48315912, 0.53077817,\n",
       "        0.5888502 , 0.53077817, 0.52497095, 0.5714286 , 0.48432055,\n",
       "        0.52961671, 0.56445992, 0.48083624, 0.54819977, 0.57258999,\n",
       "        0.54936123, 0.51335657, 0.55052263, 0.47154471, 0.47851336,\n",
       "        0.56794423, 0.44715446, 0.48315912, 0.56213707, 0.49245062,\n",
       "        0.53542393, 0.54355401, 0.2950058 , 0.47619048, 0.53774679,\n",
       "        0.42740998, 0.48548201, 0.22183508, 0.45876887, 0.45876887,\n",
       "        0.21254355, 0.49825785, 0.49245062, 0.2857143 , 0.58188152,\n",
       "        0.56213707, 0.39140534, 0.58304298, 0.56213707, 0.44715446,\n",
       "        0.56329846, 0.55632985, 0.40882695, 0.55284554, 0.56213707,\n",
       "        0.4599303 , 0.55168408, 0.56794423, 0.51916379, 0.46922183,\n",
       "        0.54471546, 0.51684088, 0.52148664, 0.57375145, 0.52148664,\n",
       "        0.22299652, 0.56329846, 0.57375145, 0.51916379, 0.47038329,\n",
       "        0.52729386, 0.46922183, 0.55516839, 0.54239255, 0.25900117,\n",
       "        0.56678283, 0.52845526, 0.51103365, 0.48664343, 0.54703832,\n",
       "        0.49709639, 0.49012777, 0.34727061, 0.51916379, 0.50638795,\n",
       "        0.2857143 , 0.5400697 , 0.52961671, 0.34146342, 0.56678283,\n",
       "        0.57839721, 0.45296168, 0.57026714, 0.57258999, 0.3844367 ,\n",
       "        0.55865276, 0.55981416, 0.45876887, 0.57839721, 0.57607436,\n",
       "        0.55052263, 0.54471546, 0.55632985, 0.55168408, 0.53426248,\n",
       "        0.55516839, 0.55865276, 0.54471546, 0.55400699, 0.53890824,\n",
       "        0.49825785, 0.57258999, 0.52729386, 0.51103365, 0.54936123,\n",
       "        0.55981416, 0.52845526, 0.48780489, 0.53774679, 0.42973286,\n",
       "        0.5574913 , 0.58304298, 0.52845526, 0.51219511, 0.56562138,\n",
       "        0.51451802, 0.54123116, 0.32171893, 0.55168408, 0.54239255,\n",
       "        0.38559815, 0.56678283, 0.56213707, 0.39488965, 0.57026714,\n",
       "        0.57955867, 0.44134727, 0.58652729, 0.54355401, 0.40998837,\n",
       "        0.57375145, 0.58304298, 0.4912892 , 0.51916379, 0.5714286 ,\n",
       "        0.56678283, 0.55052263, 0.56562138, 0.55632985, 0.54239255,\n",
       "        0.56794423, 0.56794423, 0.52380955, 0.51684088, 0.58536583,\n",
       "        0.3263647 , 0.55865276, 0.56445992, 0.48664343, 0.54936123,\n",
       "        0.56329846, 0.48780489, 0.52845526, 0.59117305, 0.44831592,\n",
       "        0.54471546, 0.5400697 , 0.53193963, 0.51800233, 0.56213707,\n",
       "        0.48083624, 0.4738676 , 0.40766549, 0.53193963, 0.52148664,\n",
       "        0.45644599, 0.53774679, 0.55052263, 0.46689895, 0.57955867,\n",
       "        0.56213707, 0.44947734, 0.57491291, 0.58072007, 0.3844367 ,\n",
       "        0.57723576, 0.58652729, 0.46689895, 0.52380955, 0.53774679,\n",
       "        0.56097561, 0.50522649, 0.53542393, 0.56562138, 0.53193963,\n",
       "        0.56794423, 0.55632985, 0.5400697 , 0.46573752, 0.53658539,\n",
       "        0.5574913 , 0.53658539, 0.54587686, 0.51567942, 0.53890824,\n",
       "        0.57491291, 0.50987226, 0.45180023, 0.5714286 , 0.47154471,\n",
       "        0.50058073, 0.53890824, 0.48780489, 0.3844367 , 0.57026714,\n",
       "        0.49477351, 0.51335657, 0.38559815, 0.54703832, 0.57026714,\n",
       "        0.40418118, 0.58188152, 0.56213707, 0.40301976, 0.57026714,\n",
       "        0.56678283, 0.49361208, 0.56213707, 0.58188152, 0.51103365,\n",
       "        0.56910568, 0.57955867, 0.50638795, 0.50406504, 0.5261324 ,\n",
       "        0.55516839, 0.51451802, 0.5261324 , 0.56329846, 0.57026714,\n",
       "        0.55400699, 0.56794423, 0.52845526, 0.3844367 , 0.57955867,\n",
       "        0.54936123, 0.57607436, 0.55168408, 0.5574913 , 0.55168408,\n",
       "        0.57026714, 0.43902439, 0.53426248, 0.54936123, 0.29036003,\n",
       "        0.48780489, 0.55168408, 0.48199767, 0.52497095, 0.54819977,\n",
       "        0.57258999, 0.57026714, 0.40650406, 0.57491291, 0.56678283,\n",
       "        0.47154471, 0.59349591, 0.57375145, 0.39256677, 0.5574913 ,\n",
       "        0.59117305, 0.53890824, 0.55052263, 0.56445992, 0.55284554,\n",
       "        0.53310102, 0.57258999, 0.54936123, 0.53426248, 0.54703832,\n",
       "        0.57375145, 0.53658539, 0.55052263, 0.5574913 , 0.53774679,\n",
       "        0.57839721, 0.55632985, 0.51567942, 0.54936123, 0.53774679,\n",
       "        0.47851336, 0.50754935, 0.57375145, 0.35191637, 0.46573752,\n",
       "        0.56562138, 0.46341464, 0.3844367 , 0.55865276, 0.3844367 ,\n",
       "        0.47851336, 0.56329846, 0.48083624, 0.54355401, 0.56097561,\n",
       "        0.50174218, 0.46457607, 0.38559815, 0.44367015, 0.51916379,\n",
       "        0.44134727, 0.52961671, 0.54123116, 0.40534264, 0.57839721,\n",
       "        0.55052263, 0.39256677, 0.55981416, 0.58420444, 0.3844367 ,\n",
       "        0.55865276, 0.58304298, 0.45528457, 0.53890824, 0.4680604 ,\n",
       "        0.55516839, 0.48896632, 0.57723576, 0.51916379, 0.53077817,\n",
       "        0.55400699, 0.53542393, 0.5087108 , 0.54123116, 0.56794423,\n",
       "        0.52497095, 0.55052263, 0.56097561, 0.39024389, 0.56097561,\n",
       "        0.56213707, 0.3205575 , 0.51219511, 0.5261324 , 0.53193963,\n",
       "        0.51103365, 0.56910568, 0.50406504, 0.56329846, 0.56794423,\n",
       "        0.45296168, 0.53193963, 0.3844367 , 0.52729386, 0.55284554,\n",
       "        0.39953542, 0.54703832, 0.55981416, 0.38211381, 0.58304298,\n",
       "        0.56678283, 0.41811848, 0.56794423, 0.57839721, 0.46225318,\n",
       "        0.54587686, 0.55865276, 0.50058073, 0.57839721, 0.56213707,\n",
       "        0.53542393, 0.49477351, 0.57839721, 0.56910568, 0.54703832,\n",
       "        0.56678283, 0.57026714, 0.44831592, 0.51916379, 0.54703832,\n",
       "        0.4680604 , 0.49477351, 0.57839721, 0.55284554, 0.57491291,\n",
       "        0.53542393, 0.5226481 , 0.48315912, 0.56910568, 0.35540071,\n",
       "        0.53193963, 0.55284554, 0.49012777, 0.52148664, 0.5226481 ,\n",
       "        0.55052263, 0.55400699, 0.42044136, 0.55981416, 0.55168408,\n",
       "        0.40650406, 0.57026714, 0.57839721, 0.45760745, 0.56562138,\n",
       "        0.55516839, 0.49361208, 0.58420444, 0.56097561, 0.51335657,\n",
       "        0.57258999, 0.56097561, 0.52032518, 0.4680604 , 0.54936123,\n",
       "        0.58072007, 0.53774679, 0.53193963, 0.54239255, 0.54703832,\n",
       "        0.56562138, 0.55981416, 0.46573752, 0.56329846, 0.57839721,\n",
       "        0.50638795, 0.56794423, 0.56794423, 0.50058073, 0.54703832,\n",
       "        0.57258999, 0.48780489, 0.3844367 , 0.5888502 , 0.5226481 ,\n",
       "        0.55052263, 0.55284554, 0.48548201, 0.55516839, 0.50174218,\n",
       "        0.42044136, 0.49245062, 0.39256677, 0.4680604 , 0.44947734,\n",
       "        0.28106853, 0.44715446, 0.49941927, 0.33101046, 0.55284554,\n",
       "        0.56910568, 0.47270617, 0.55516839, 0.57607436, 0.38095239,\n",
       "        0.56562138, 0.5714286 , 0.40418118, 0.5574913 , 0.57375145,\n",
       "        0.51103365, 0.56213707, 0.56213707, 0.51567942, 0.54936123,\n",
       "        0.55516839, 0.5087108 , 0.52961671, 0.57026714, 0.55284554,\n",
       "        0.47270617, 0.5400697 , 0.54471546, 0.55052263, 0.56678283,\n",
       "        0.55400699, 0.54355401, 0.55981416, 0.54587686, 0.49477351,\n",
       "        0.54471546, 0.53426248, 0.47270617, 0.56097561, 0.54936123,\n",
       "        0.4425087 , 0.3844367 , 0.31823462, 0.46689895, 0.50987226,\n",
       "        0.3844367 , 0.52148664, 0.5400697 , 0.41695702, 0.57723576,\n",
       "        0.56562138, 0.3844367 , 0.57723576, 0.58304298, 0.40766549,\n",
       "        0.58188152, 0.5888502 , 0.41579559, 0.53890824, 0.56562138,\n",
       "        0.51800233, 0.52032518, 0.57491291, 0.54703832, 0.56097561,\n",
       "        0.54819977, 0.54123116, 0.44947734, 0.51916379, 0.56445992,\n",
       "        0.53658539, 0.53310102, 0.55516839, 0.53658539, 0.58768874,\n",
       "        0.55632985, 0.55168408, 0.54471546, 0.54239255, 0.53774679,\n",
       "        0.56329846, 0.55865276, 0.50406504, 0.54936123, 0.57491291,\n",
       "        0.52032518, 0.54819977, 0.39721254, 0.54471546, 0.54936123,\n",
       "        0.3844367 , 0.55400699, 0.55400699, 0.41695702, 0.5714286 ,\n",
       "        0.5714286 , 0.38327527, 0.5714286 , 0.5714286 , 0.4738676 ,\n",
       "        0.56794423, 0.58072007, 0.45412311, 0.56445992, 0.57723576,\n",
       "        0.55981416, 0.50638795, 0.56097561, 0.56910568, 0.54587686,\n",
       "        0.55516839, 0.56794423, 0.54819977, 0.54355401, 0.56794423,\n",
       "        0.55284554, 0.54936123, 0.56562138, 0.59581882, 0.54936123,\n",
       "        0.5714286 , 0.45180023, 0.3844367 , 0.55284554, 0.41347271,\n",
       "        0.50174218, 0.55981416, 0.54123116, 0.51219511, 0.57026714]),\n",
       " 'mean_test_score': array([0.51102739, 0.5001976 , 0.41237953, 0.53423643, 0.54197532,\n",
       "        0.40115497, 0.54777803, 0.5524229 , 0.43557465, 0.57601774,\n",
       "        0.56402159, 0.47619272, 0.54274511, 0.56866868, 0.4897424 ,\n",
       "        0.55356954, 0.57523853, 0.51450453, 0.52921698, 0.54544526,\n",
       "        0.56750725, 0.51101931, 0.53035104, 0.55822605, 0.41278645,\n",
       "        0.54198295, 0.5744678 , 0.4170527 , 0.50251466, 0.55590139,\n",
       "        0.44563912, 0.45336094, 0.56944072, 0.47042999, 0.45302813,\n",
       "        0.54585131, 0.47582893, 0.5276666 , 0.56712323, 0.36823761,\n",
       "        0.43406289, 0.5473882 , 0.39111206, 0.38990302, 0.55474309,\n",
       "        0.54855055, 0.55203394, 0.40850268, 0.55319361, 0.55977196,\n",
       "        0.40117069, 0.56828111, 0.56093069, 0.4011626 , 0.5674987 ,\n",
       "        0.57021459, 0.50136129, 0.57176361, 0.57601686, 0.52301548,\n",
       "        0.56556972, 0.57795393, 0.52417825, 0.52380009, 0.55202901,\n",
       "        0.56828155, 0.51217311, 0.54737967, 0.56170634, 0.47005138,\n",
       "        0.5330786 , 0.5617014 , 0.39502171, 0.53926754, 0.57872732,\n",
       "        0.42712749, 0.46922678, 0.56208809, 0.40812273, 0.43284576,\n",
       "        0.55319943, 0.35976261, 0.463835  , 0.56053815, 0.35625269,\n",
       "        0.5145072 , 0.57446917, 0.47002443, 0.53461641, 0.56983012,\n",
       "        0.56518797, 0.5702164 , 0.4027121 , 0.57253567, 0.56827796,\n",
       "        0.41237863, 0.57098846, 0.56788947, 0.43132503, 0.56828334,\n",
       "        0.56943893, 0.54506846, 0.56828513, 0.56092981, 0.55164051,\n",
       "        0.56440739, 0.56711382, 0.55357627, 0.5249575 , 0.53771224,\n",
       "        0.57021592, 0.48392489, 0.55938751, 0.57021773, 0.4595499 ,\n",
       "        0.51989808, 0.56247391, 0.53113566, 0.53077009, 0.55667251,\n",
       "        0.5056253 , 0.49012326, 0.56712639, 0.51141363, 0.50327369,\n",
       "        0.56479992, 0.42052938, 0.53887995, 0.55010227, 0.32692251,\n",
       "        0.50134514, 0.56286418, 0.47076593, 0.38182953, 0.55629303,\n",
       "        0.46150091, 0.48587499, 0.34933435, 0.50251017, 0.50058072,\n",
       "        0.36906267, 0.52572775, 0.52804389, 0.39535226, 0.57408381,\n",
       "        0.57330771, 0.40852064, 0.56286554, 0.57795483, 0.42088688,\n",
       "        0.56519155, 0.56595776, 0.4649978 , 0.47620889, 0.53152102,\n",
       "        0.54313229, 0.45764022, 0.53926351, 0.54352258, 0.50675531,\n",
       "        0.54005082, 0.55126011, 0.45843249, 0.55822696, 0.55511767,\n",
       "        0.43288709, 0.4971202 , 0.56673745, 0.45919195, 0.53152684,\n",
       "        0.52882089, 0.37718556, 0.43400945, 0.5442964 , 0.40382233,\n",
       "        0.47659783, 0.54430538, 0.3733132 , 0.24835778, 0.52610725,\n",
       "        0.52339902, 0.52185311, 0.38452832, 0.5396502 , 0.5454583 ,\n",
       "        0.4441094 , 0.5605431 , 0.56093293, 0.38530621, 0.57794809,\n",
       "        0.56827482, 0.46613094, 0.56982249, 0.57601819, 0.49052298,\n",
       "        0.56092217, 0.56750816, 0.48200846, 0.50677911, 0.55783757,\n",
       "        0.57060309, 0.47230868, 0.52648989, 0.56479768, 0.525337  ,\n",
       "        0.52998996, 0.57176046, 0.34898448, 0.53113925, 0.56054713,\n",
       "        0.4135778 , 0.44833611, 0.56131784, 0.49825962, 0.48201564,\n",
       "        0.55280513, 0.47542067, 0.48820863, 0.54544842, 0.49322852,\n",
       "        0.46617002, 0.55357132, 0.3102213 , 0.44993142, 0.54314083,\n",
       "        0.56209081, 0.55744952, 0.39419981, 0.56247838, 0.56518527,\n",
       "        0.41278015, 0.57446692, 0.56673431, 0.4015529 , 0.56904596,\n",
       "        0.57291875, 0.51180124, 0.57524345, 0.56557916, 0.52727634,\n",
       "        0.57137334, 0.56905584, 0.5334545 , 0.5067607 , 0.54815574,\n",
       "        0.57408696, 0.52920757, 0.52804524, 0.57021324, 0.49438681,\n",
       "        0.54583512, 0.56673026, 0.50559971, 0.53501479, 0.5663467 ,\n",
       "        0.50949318, 0.49053108, 0.55087028, 0.46769975, 0.46344876,\n",
       "        0.55667746, 0.44487515, 0.52454879, 0.55860871, 0.4232376 ,\n",
       "        0.4924731 , 0.57058915, 0.37289056, 0.46267447, 0.54197129,\n",
       "        0.41393171, 0.4568776 , 0.25955988, 0.470015  , 0.49050996,\n",
       "        0.24795535, 0.50870002, 0.48394912, 0.37907414, 0.56751039,\n",
       "        0.56324909, 0.39458291, 0.56248379, 0.55976882, 0.41045906,\n",
       "        0.56170273, 0.55783308, 0.39033597, 0.54777759, 0.56634267,\n",
       "        0.51371227, 0.52457529, 0.55783757, 0.52340263, 0.46731215,\n",
       "        0.54352077, 0.53268246, 0.4762264 , 0.54933246, 0.53384435,\n",
       "        0.37866319, 0.52999352, 0.55551962, 0.52533611, 0.51680988,\n",
       "        0.54351403, 0.48007317, 0.52999038, 0.55976117, 0.38950463,\n",
       "        0.53154168, 0.54235437, 0.48279622, 0.5110157 , 0.55782948,\n",
       "        0.49207157, 0.49516248, 0.3357878 , 0.51218839, 0.51218345,\n",
       "        0.31836261, 0.53539832, 0.5315273 , 0.35744062, 0.57485183,\n",
       "        0.56828245, 0.4131682 , 0.57369306, 0.56905359, 0.40192747,\n",
       "        0.56324774, 0.56595506, 0.43985259, 0.55706823, 0.55513384,\n",
       "        0.54042943, 0.5582153 , 0.56131335, 0.55667118, 0.43872169,\n",
       "        0.56633997, 0.5535803 , 0.54661435, 0.53849731, 0.55743963,\n",
       "        0.49207202, 0.55706596, 0.5508613 , 0.52030587, 0.53230836,\n",
       "        0.5628615 , 0.51103188, 0.5210703 , 0.56401304, 0.48585836,\n",
       "        0.53269818, 0.56441726, 0.41899784, 0.52958709, 0.56363714,\n",
       "        0.52069394, 0.53153181, 0.39068899, 0.54777714, 0.54429326,\n",
       "        0.40076783, 0.56170412, 0.55628854, 0.40038472, 0.57175958,\n",
       "        0.57524345, 0.45067337, 0.57524616, 0.56169512, 0.45104795,\n",
       "        0.56673386, 0.57524478, 0.49168263, 0.52997647, 0.56131921,\n",
       "        0.5613174 , 0.48281148, 0.55938347, 0.56402024, 0.54854695,\n",
       "        0.55899765, 0.56557151, 0.52379111, 0.54892375, 0.56867182,\n",
       "        0.44057477, 0.54623306, 0.56673026, 0.51062902, 0.55860378,\n",
       "        0.55628898, 0.50328222, 0.52920665, 0.5814351 , 0.49514629,\n",
       "        0.53772032, 0.55125294, 0.52379425, 0.53809667, 0.56092892,\n",
       "        0.47853087, 0.48200846, 0.37912129, 0.52186078, 0.52069662,\n",
       "        0.42979754, 0.5365575 , 0.54584318, 0.41008001, 0.57214987,\n",
       "        0.5597688 , 0.4537701 , 0.56673431, 0.57060351, 0.43441007,\n",
       "        0.55590765, 0.57137916, 0.48316585, 0.51180349, 0.5566658 ,\n",
       "        0.55358118, 0.51024952, 0.53771673, 0.55938347, 0.52727454,\n",
       "        0.54043617, 0.54971242, 0.49054141, 0.43830849, 0.54003735,\n",
       "        0.50562935, 0.53385021, 0.53965424, 0.45340899, 0.47932673,\n",
       "        0.54546594, 0.40700306, 0.40079342, 0.55667883, 0.49515528,\n",
       "        0.45533665, 0.52998412, 0.43831702, 0.44291742, 0.54662424,\n",
       "        0.52493997, 0.53229441, 0.39380727, 0.54506846, 0.56479901,\n",
       "        0.38492041, 0.57176407, 0.55744863, 0.38724015, 0.55899856,\n",
       "        0.5613174 , 0.50096428, 0.55242157, 0.58297831, 0.50599807,\n",
       "        0.56982563, 0.56248244, 0.51798391, 0.52997063, 0.55627461,\n",
       "        0.55048537, 0.51605358, 0.55163423, 0.56750319, 0.55010452,\n",
       "        0.53153674, 0.57601235, 0.47236212, 0.49976195, 0.5682829 ,\n",
       "        0.53540194, 0.53463886, 0.56285834, 0.36139114, 0.55744457,\n",
       "        0.55629166, 0.43984495, 0.49595292, 0.54429597, 0.38680988,\n",
       "        0.49980193, 0.54042989, 0.45919644, 0.47777454, 0.55782994,\n",
       "        0.56015952, 0.56402562, 0.39265526, 0.56712101, 0.56595776,\n",
       "        0.43599054, 0.57138185, 0.56905405, 0.39110308, 0.56286059,\n",
       "        0.57756811, 0.54274511, 0.57059185, 0.57291742, 0.54275052,\n",
       "        0.56169107, 0.5822013 , 0.55048313, 0.54429013, 0.5404281 ,\n",
       "        0.57369441, 0.51915568, 0.54932348, 0.56054042, 0.53501072,\n",
       "        0.55822829, 0.56402024, 0.43252732, 0.48474454, 0.53694421,\n",
       "        0.43289966, 0.53229217, 0.56944074, 0.45837275, 0.51023424,\n",
       "        0.57833163, 0.43328053, 0.36287101, 0.55938077, 0.37408524,\n",
       "        0.40080375, 0.56363622, 0.37644271, 0.50059689, 0.56672891,\n",
       "        0.45417701, 0.48471175, 0.34701686, 0.48199678, 0.51992234,\n",
       "        0.37449395, 0.51837958, 0.53501209, 0.39342822, 0.56828245,\n",
       "        0.56517808, 0.39961042, 0.55319405, 0.57679204, 0.39109993,\n",
       "        0.56170096, 0.57408472, 0.43791775, 0.54351852, 0.53073012,\n",
       "        0.53811103, 0.51836388, 0.55745447, 0.54119072, 0.52572729,\n",
       "        0.56440604, 0.54545067, 0.44683245, 0.52573134, 0.53424901,\n",
       "        0.47042727, 0.52766841, 0.51529814, 0.42938523, 0.55783486,\n",
       "        0.56402248, 0.38488807, 0.51914625, 0.50871081, 0.43872078,\n",
       "        0.53422699, 0.55010406, 0.46964581, 0.49828432, 0.54236964,\n",
       "        0.4924412 , 0.51954059, 0.36287101, 0.53075302, 0.54468401,\n",
       "        0.40812046, 0.54854872, 0.55551424, 0.39960639, 0.56287046,\n",
       "        0.5632509 , 0.46381211, 0.5644114 , 0.5736962 , 0.44410759,\n",
       "        0.57020336, 0.5570606 , 0.49091282, 0.54817416, 0.55358166,\n",
       "        0.55473141, 0.49941794, 0.55126775, 0.5593848 , 0.52263999,\n",
       "        0.57021145, 0.57137289, 0.49901327, 0.53500354, 0.5690437 ,\n",
       "        0.46731171, 0.53112713, 0.57756319, 0.48435918, 0.4882347 ,\n",
       "        0.55782499, 0.41435524, 0.52570889, 0.54739718, 0.42550479,\n",
       "        0.46540292, 0.54893768, 0.49902944, 0.52108334, 0.54157875,\n",
       "        0.54274962, 0.55396519, 0.36133815, 0.56054131, 0.55744459,\n",
       "        0.43828558, 0.56325223, 0.57137603, 0.41123651, 0.56827752,\n",
       "        0.57059364, 0.50096427, 0.57176499, 0.5721427 , 0.52417376,\n",
       "        0.55822607, 0.57678306, 0.52765673, 0.51758241, 0.56517764,\n",
       "        0.5733104 , 0.55782588, 0.55550347, 0.5558942 , 0.54816202,\n",
       "        0.55861006, 0.56402159, 0.46151035, 0.54352794, 0.57446961,\n",
       "        0.52571787, 0.54198297, 0.55397058, 0.48665916, 0.54854872,\n",
       "        0.55861274, 0.49245468, 0.46573257, 0.56016584, 0.46849291,\n",
       "        0.53230878, 0.56208541, 0.46577166, 0.50872203, 0.55085142,\n",
       "        0.43094372, 0.45107984, 0.28437454, 0.47465896, 0.42399438,\n",
       "        0.31217365, 0.48393162, 0.49129907, 0.27236312, 0.54971109,\n",
       "        0.55165084, 0.41549603, 0.56208628, 0.56750816, 0.38491143,\n",
       "        0.55977017, 0.57253343, 0.40348189, 0.53656514, 0.57098754,\n",
       "        0.4998109 , 0.58065049, 0.56904956, 0.52146779, 0.54970974,\n",
       "        0.56595325, 0.50831735, 0.50291169, 0.56015865, 0.5454574 ,\n",
       "        0.48664838, 0.54583917, 0.54313407, 0.53772255, 0.5613174 ,\n",
       "        0.53501703, 0.52031846, 0.56556837, 0.54004095, 0.46036148,\n",
       "        0.5377203 , 0.55241078, 0.49399564, 0.54855412, 0.55860378,\n",
       "        0.43559261, 0.45103806, 0.32842933, 0.48393924, 0.50677105,\n",
       "        0.36132422, 0.52688378, 0.53578502, 0.37139093, 0.57176226,\n",
       "        0.55899676, 0.40888802, 0.57408245, 0.57640489, 0.39845617,\n",
       "        0.57369755, 0.5682865 , 0.43055522, 0.48899416, 0.5709844 ,\n",
       "        0.53152281, 0.53693748, 0.57253478, 0.54197488, 0.55203442,\n",
       "        0.55782992, 0.54545293, 0.50790776, 0.48898653, 0.56324999,\n",
       "        0.51064834, 0.53732912, 0.55512573, 0.53733047, 0.57563329,\n",
       "        0.5547395 , 0.52457527, 0.54468087, 0.54274648, 0.52031622,\n",
       "        0.54971512, 0.56324776, 0.48318022, 0.53733541, 0.56518753,\n",
       "        0.49749433, 0.52844091, 0.39342506, 0.54197399, 0.54700285,\n",
       "        0.38877975, 0.55589871, 0.55551199, 0.43867631, 0.57717379,\n",
       "        0.57292012, 0.39264628, 0.57485362, 0.56711966, 0.43947171,\n",
       "        0.56905178, 0.56712323, 0.46537282, 0.52574032, 0.57524256,\n",
       "        0.55860782, 0.51991741, 0.56440874, 0.56982565, 0.5644029 ,\n",
       "        0.56285969, 0.56711831, 0.48938445, 0.52689231, 0.56402473,\n",
       "        0.53656336, 0.56479094, 0.56557063, 0.53890016, 0.55937719,\n",
       "        0.57176002, 0.39383288, 0.49937525, 0.5628588 , 0.45800985,\n",
       "        0.53383672, 0.56363489, 0.53694556, 0.53925453, 0.54739763]),\n",
       " 'std_test_score': array([0.00946427, 0.00926556, 0.00667538, 0.00480991, 0.0075683 ,\n",
       "        0.02664822, 0.00551279, 0.01068834, 0.03820432, 0.01033986,\n",
       "        0.01083576, 0.03389661, 0.01122572, 0.0108476 , 0.01218339,\n",
       "        0.01679742, 0.00928534, 0.00451359, 0.03872366, 0.01875716,\n",
       "        0.00463829, 0.03754119, 0.03053241, 0.01163877, 0.13415181,\n",
       "        0.02024026, 0.00617769, 0.11198403, 0.01042296, 0.00371094,\n",
       "        0.03435657, 0.05522643, 0.00816778, 0.05645608, 0.09749296,\n",
       "        0.01943108, 0.01603239, 0.02136593, 0.01071761, 0.07499371,\n",
       "        0.09867828, 0.01661063, 0.05091904, 0.07218641, 0.01574187,\n",
       "        0.00480396, 0.00552179, 0.03277226, 0.00452866, 0.00765919,\n",
       "        0.02062094, 0.00602874, 0.00413809, 0.0291358 , 0.01350824,\n",
       "        0.01138829, 0.0331445 , 0.01730327, 0.00454176, 0.00836584,\n",
       "        0.00286128, 0.00930081, 0.0033623 , 0.01723798, 0.00751112,\n",
       "        0.0097564 , 0.03841547, 0.0191702 , 0.00879746, 0.06446856,\n",
       "        0.03645275, 0.00231725, 0.12155611, 0.00546958, 0.00753948,\n",
       "        0.12625353, 0.03449975, 0.01007484, 0.05402685, 0.0680779 ,\n",
       "        0.01734687, 0.09144341, 0.06792783, 0.01727689, 0.0808123 ,\n",
       "        0.02180163, 0.01153366, 0.01818036, 0.01451509, 0.0118435 ,\n",
       "        0.00805384, 0.00786178, 0.01910407, 0.00784305, 0.01283098,\n",
       "        0.00951189, 0.00838777, 0.00777872, 0.01786144, 0.01192306,\n",
       "        0.00947506, 0.00585148, 0.01252462, 0.00249616, 0.00898163,\n",
       "        0.00942018, 0.00923514, 0.00447895, 0.01310003, 0.02347031,\n",
       "        0.00879944, 0.03855589, 0.01271439, 0.01529289, 0.04490293,\n",
       "        0.04488989, 0.00452638, 0.01159612, 0.04460204, 0.00116426,\n",
       "        0.03649853, 0.03988272, 0.01654899, 0.02387162, 0.02787752,\n",
       "        0.0056887 , 0.08832007, 0.01412664, 0.01019648, 0.07273009,\n",
       "        0.01921477, 0.01032451, 0.05105355, 0.09188118, 0.01615428,\n",
       "        0.03221358, 0.01581852, 0.05827095, 0.01710675, 0.00295793,\n",
       "        0.02527763, 0.00550314, 0.00598783, 0.01057133, 0.00506051,\n",
       "        0.00663791, 0.0291738 , 0.0125136 , 0.01174005, 0.01000795,\n",
       "        0.01446058, 0.00618446, 0.02531595, 0.01657621, 0.01298317,\n",
       "        0.00259006, 0.05635912, 0.0067289 , 0.00702455, 0.02735589,\n",
       "        0.02917475, 0.00772174, 0.04334308, 0.01513048, 0.0153505 ,\n",
       "        0.08998997, 0.0420501 , 0.01652647, 0.07148026, 0.00321324,\n",
       "        0.01145049, 0.01963021, 0.06098497, 0.00917642, 0.09226309,\n",
       "        0.00891081, 0.02268278, 0.0647658 , 0.01096617, 0.01928695,\n",
       "        0.0116383 , 0.01326034, 0.01844524, 0.00313495, 0.0116989 ,\n",
       "        0.04556899, 0.00851437, 0.00825638, 0.01447963, 0.00352061,\n",
       "        0.01090715, 0.03739832, 0.00911576, 0.00550284, 0.02371949,\n",
       "        0.01647779, 0.00650364, 0.00745433, 0.01966964, 0.01076549,\n",
       "        0.01139396, 0.05872213, 0.01761978, 0.00863969, 0.02336585,\n",
       "        0.02017584, 0.00430262, 0.09051832, 0.02675718, 0.01524421,\n",
       "        0.11235061, 0.03630153, 0.00736573, 0.01990833, 0.0563705 ,\n",
       "        0.00668473, 0.03375708, 0.01432481, 0.01135387, 0.02011846,\n",
       "        0.08997142, 0.01403437, 0.09756609, 0.07022797, 0.01590919,\n",
       "        0.00335139, 0.00549366, 0.01674513, 0.00602627, 0.00281232,\n",
       "        0.0273133 , 0.00925144, 0.01030139, 0.02573293, 0.01154321,\n",
       "        0.00750575, 0.00460928, 0.0072989 , 0.01563384, 0.00968488,\n",
       "        0.00994578, 0.02051058, 0.01440733, 0.03460145, 0.01396257,\n",
       "        0.01378224, 0.00906678, 0.01953914, 0.00208025, 0.03252013,\n",
       "        0.01171007, 0.01382806, 0.02685797, 0.02069024, 0.01088147,\n",
       "        0.04351795, 0.04205606, 0.02178726, 0.01960726, 0.05410288,\n",
       "        0.01166809, 0.00636433, 0.03139667, 0.0062068 , 0.08941315,\n",
       "        0.03073789, 0.02008374, 0.08331425, 0.02121851, 0.00903311,\n",
       "        0.03358581, 0.03007641, 0.06971571, 0.03225369, 0.02256891,\n",
       "        0.03512139, 0.0087721 , 0.01586481, 0.06894708, 0.01055176,\n",
       "        0.01139373, 0.01860679, 0.01453754, 0.00219615, 0.02703142,\n",
       "        0.01000953, 0.00348148, 0.01407476, 0.00370665, 0.00992798,\n",
       "        0.03813561, 0.04373402, 0.00884382, 0.00727649, 0.0246645 ,\n",
       "        0.00296455, 0.01301695, 0.03429101, 0.0181781 , 0.00885298,\n",
       "        0.12409702, 0.02679787, 0.0129266 , 0.00915817, 0.03358843,\n",
       "        0.01155707, 0.02715494, 0.03116138, 0.01673418, 0.10372368,\n",
       "        0.02868522, 0.00983956, 0.02209971, 0.02777819, 0.00764519,\n",
       "        0.00670253, 0.00670625, 0.05319361, 0.00788893, 0.00498687,\n",
       "        0.0307846 , 0.00406429, 0.0040225 , 0.01129759, 0.00570564,\n",
       "        0.01633123, 0.02870645, 0.00260109, 0.00535568, 0.01883708,\n",
       "        0.00354621, 0.00608472, 0.02970397, 0.01833099, 0.01783732,\n",
       "        0.00715266, 0.0099598 , 0.00750873, 0.00365142, 0.1148078 ,\n",
       "        0.01879089, 0.00594097, 0.00769573, 0.03267957, 0.01490551,\n",
       "        0.01262225, 0.01215065, 0.01732462, 0.01191237, 0.01973995,\n",
       "        0.00477615, 0.01399108, 0.03238484, 0.01928986, 0.040592  ,\n",
       "        0.02616108, 0.01384295, 0.10253438, 0.01317842, 0.00770649,\n",
       "        0.00548286, 0.00685847, 0.04882665, 0.00363863, 0.00314343,\n",
       "        0.03755838, 0.00359119, 0.00424262, 0.02633654, 0.00115671,\n",
       "        0.0072989 , 0.00661153, 0.01167501, 0.01443999, 0.02922217,\n",
       "        0.01460349, 0.0122091 , 0.0002782 , 0.00833354, 0.01302904,\n",
       "        0.0064866 , 0.04943711, 0.00500633, 0.00593116, 0.00437751,\n",
       "        0.00737402, 0.00822425, 0.00615687, 0.02363512, 0.01271909,\n",
       "        0.08317235, 0.00909572, 0.00914061, 0.01838809, 0.01607069,\n",
       "        0.00790403, 0.01612337, 0.00712393, 0.00955912, 0.03641741,\n",
       "        0.0145981 , 0.00921752, 0.00809155, 0.01548542, 0.0076257 ,\n",
       "        0.00216242, 0.02070764, 0.04673421, 0.00726707, 0.00807065,\n",
       "        0.01942937, 0.00388105, 0.00539602, 0.04088542, 0.00845034,\n",
       "        0.0072988 , 0.02481386, 0.00644356, 0.01008169, 0.03545058,\n",
       "        0.0155499 , 0.01108186, 0.01174366, 0.01495664, 0.01351123,\n",
       "        0.00522865, 0.02582018, 0.00369043, 0.00551784, 0.02437811,\n",
       "        0.01954317, 0.02228272, 0.08133507, 0.05117813, 0.00450704,\n",
       "        0.03825555, 0.02187156, 0.01001666, 0.04439711, 0.07976053,\n",
       "        0.04035927, 0.11027376, 0.03676024, 0.01069511, 0.02192264,\n",
       "        0.05105088, 0.01554646, 0.03694203, 0.04314656, 0.02387863,\n",
       "        0.02146195, 0.01420391, 0.02900317, 0.00770465, 0.00509324,\n",
       "        0.01427085, 0.00729385, 0.00617507, 0.01297926, 0.01166895,\n",
       "        0.00389356, 0.01692103, 0.01926366, 0.00479913, 0.00592528,\n",
       "        0.00429274, 0.01315065, 0.01363412, 0.01892036, 0.02352006,\n",
       "        0.00468574, 0.0062519 , 0.02386288, 0.00411276, 0.01738342,\n",
       "        0.02228725, 0.00805276, 0.07807725, 0.08194376, 0.00819514,\n",
       "        0.01041257, 0.03489032, 0.00812533, 0.13878018, 0.01845223,\n",
       "        0.0098935 , 0.02226704, 0.02749984, 0.00405183, 0.08817297,\n",
       "        0.01989617, 0.02319381, 0.01823793, 0.03769378, 0.0116658 ,\n",
       "        0.01399694, 0.0061357 , 0.02007399, 0.00568995, 0.00153592,\n",
       "        0.04907901, 0.01879038, 0.0113881 , 0.010942  , 0.00723338,\n",
       "        0.01033937, 0.00428388, 0.01586994, 0.00793128, 0.00727828,\n",
       "        0.02087668, 0.00686191, 0.0029503 , 0.00879871, 0.01951234,\n",
       "        0.00142138, 0.02669557, 0.00574616, 0.01296786, 0.02753718,\n",
       "        0.0163773 , 0.01133528, 0.09741651, 0.0502186 , 0.01753259,\n",
       "        0.09070383, 0.01755341, 0.00729754, 0.0773975 , 0.04570625,\n",
       "        0.01681213, 0.07462142, 0.11797039, 0.00242335, 0.07895858,\n",
       "        0.13484154, 0.00474209, 0.11529372, 0.03154887, 0.01660857,\n",
       "        0.03494201, 0.01792704, 0.02844436, 0.03017148, 0.00806914,\n",
       "        0.06428982, 0.01711204, 0.00756607, 0.00863514, 0.01465166,\n",
       "        0.0220101 , 0.01640342, 0.008907  , 0.0059621 , 0.01318438,\n",
       "        0.01483916, 0.00987657, 0.01242546, 0.01411616, 0.04488   ,\n",
       "        0.01450173, 0.02196763, 0.01427322, 0.01560417, 0.02676132,\n",
       "        0.02120706, 0.00723094, 0.04418566, 0.02826016, 0.02390131,\n",
       "        0.06255847, 0.02349157, 0.04270846, 0.03202056, 0.01391297,\n",
       "        0.01615769, 0.05289584, 0.03117431, 0.01319796, 0.11231012,\n",
       "        0.016407  , 0.01643935, 0.02522508, 0.08107267, 0.02270833,\n",
       "        0.02792025, 0.00937331, 0.01611459, 0.00978285, 0.00690367,\n",
       "        0.00651606, 0.00116831, 0.00994814, 0.01236912, 0.01445935,\n",
       "        0.00797864, 0.03441138, 0.01163781, 0.01876737, 0.0573395 ,\n",
       "        0.01761377, 0.00262204, 0.0116814 , 0.02952036, 0.02033839,\n",
       "        0.01366066, 0.04039024, 0.04036961, 0.00712998, 0.02234976,\n",
       "        0.00617879, 0.00856068, 0.0463393 , 0.01255979, 0.01626495,\n",
       "        0.01469133, 0.0259188 , 0.00336729, 0.09153159, 0.07892714,\n",
       "        0.01590353, 0.15601041, 0.03168847, 0.02942269, 0.05414717,\n",
       "        0.06130895, 0.00941322, 0.00914238, 0.00379956, 0.02970854,\n",
       "        0.00695545, 0.00331538, 0.0462846 , 0.00712267, 0.00418198,\n",
       "        0.03369122, 0.00790642, 0.00719646, 0.03717797, 0.00689137,\n",
       "        0.01099945, 0.00703261, 0.00977438, 0.0109441 , 0.00766356,\n",
       "        0.01267212, 0.01133696, 0.0151244 , 0.03502055, 0.01254508,\n",
       "        0.01166251, 0.01482409, 0.0167695 , 0.00996102, 0.00123635,\n",
       "        0.0094553 , 0.00559298, 0.06069521, 0.01743558, 0.01494215,\n",
       "        0.01374197, 0.02210479, 0.00998249, 0.01161086, 0.00718392,\n",
       "        0.01016314, 0.00782804, 0.06235319, 0.03227168, 0.04293536,\n",
       "        0.01342488, 0.00694948, 0.03080264, 0.03381502, 0.03653843,\n",
       "        0.03768032, 0.03294627, 0.07756479, 0.00601047, 0.01832161,\n",
       "        0.04258702, 0.02607429, 0.0087711 , 0.04224427, 0.00566153,\n",
       "        0.01266533, 0.0424266 , 0.00786358, 0.00740666, 0.00366669,\n",
       "        0.00501929, 0.01233853, 0.01753039, 0.0244132 , 0.00782566,\n",
       "        0.0092415 , 0.01446653, 0.00941884, 0.00861243, 0.0019104 ,\n",
       "        0.01998301, 0.00379905, 0.04064666, 0.01007764, 0.00555708,\n",
       "        0.02963089, 0.00625089, 0.00349875, 0.00910045, 0.00411755,\n",
       "        0.01497574, 0.02402114, 0.00698963, 0.00560217, 0.05664238,\n",
       "        0.01820815, 0.01540631, 0.0313237 , 0.00976295, 0.00835782,\n",
       "        0.02186616, 0.04721082, 0.04463136, 0.02699252, 0.00224345,\n",
       "        0.06415879, 0.00724374, 0.00415381, 0.07159643, 0.01336023,\n",
       "        0.0105671 , 0.03655282, 0.00264393, 0.01142778, 0.01351278,\n",
       "        0.0111    , 0.01967958, 0.01650575, 0.07427871, 0.01153417,\n",
       "        0.00974631, 0.01208548, 0.0063824 , 0.01012622, 0.01997139,\n",
       "        0.02013092, 0.00559838, 0.04339251, 0.07644739, 0.00207864,\n",
       "        0.02504119, 0.0266899 , 0.00142113, 0.01374468, 0.01274316,\n",
       "        0.00532967, 0.04203946, 0.00520974, 0.03125898, 0.01357246,\n",
       "        0.01874959, 0.00402053, 0.02439549, 0.02875525, 0.0069418 ,\n",
       "        0.03518076, 0.01475252, 0.00357493, 0.00511742, 0.00457708,\n",
       "        0.01086249, 0.00314073, 0.00177516, 0.01779991, 0.0111833 ,\n",
       "        0.00812008, 0.01356824, 0.01254965, 0.00729704, 0.03960556,\n",
       "        0.00386894, 0.01116854, 0.00844706, 0.03106701, 0.0040425 ,\n",
       "        0.00207762, 0.01635165, 0.00618002, 0.01374401, 0.0137759 ,\n",
       "        0.00753117, 0.00243899, 0.07469189, 0.02151043, 0.00762557,\n",
       "        0.0310996 , 0.01610055, 0.00236831, 0.0411405 , 0.00781989,\n",
       "        0.01136896, 0.12843313, 0.08162633, 0.00826445, 0.03454925,\n",
       "        0.02364303, 0.01866717, 0.00485165, 0.01983045, 0.01747772]),\n",
       " 'rank_test_score': array([529, 561, 725, 424, 376, 743, 328, 292, 696,  17, 157, 625, 370,\n",
       "         93, 593, 287,  26, 520, 458, 349, 109, 530, 450, 236, 723, 375,\n",
       "         31, 717, 553, 267, 678, 669,  83, 632, 670, 339, 626, 466, 113,\n",
       "        788, 698, 333, 761, 766, 277, 321, 296, 732, 290, 213, 741, 101,\n",
       "        201, 742, 111,  74, 555,  53,  18, 494, 136,   8, 487, 489, 297,\n",
       "        100, 524, 334, 187, 634, 430, 190, 752, 391,   5, 710, 638, 184,\n",
       "        733, 703, 288, 794, 650, 209, 796, 519,  30, 635, 422,  78, 139,\n",
       "         72, 738,  46, 102, 726,  63, 105, 705,  96,  84, 350,  95, 202,\n",
       "        299, 151, 118, 285, 482, 403,  73, 609, 218,  71, 657, 508, 182,\n",
       "        445, 447, 258, 548, 592, 112, 527, 551, 144, 715, 395, 311, 802,\n",
       "        556, 173, 631, 776, 261, 655, 601, 797, 554, 560, 787, 476, 464,\n",
       "        751,  35,  42, 731, 172,   7, 714, 138, 129, 649, 624, 443, 366,\n",
       "        663, 392, 360, 545, 386, 302, 660, 234, 276, 702, 572, 119, 659,\n",
       "        441, 461, 780, 699, 355, 736, 622, 354, 784, 809, 473, 493, 497,\n",
       "        775, 390, 344, 680, 206, 200, 771,   9, 104, 644,  81,  16, 590,\n",
       "        204, 107, 615, 542, 238,  67, 630, 472, 146, 480, 453,  55, 798,\n",
       "        444, 205, 721, 676, 195, 570, 614, 291, 627, 598, 348, 579, 643,\n",
       "        286, 805, 675, 364, 183, 248, 754, 181, 141, 724,  32, 120, 740,\n",
       "         90,  44, 526,  23, 133, 468,  61,  85, 429, 544, 327,  33, 459,\n",
       "        463,  75, 577, 342, 123, 549, 417, 126, 536, 589, 304, 640, 652,\n",
       "        257, 679, 486, 229, 713, 580,  70, 785, 653, 379, 720, 664, 808,\n",
       "        636, 591, 810, 539, 606, 778, 106, 168, 753, 179, 215, 728, 189,\n",
       "        241, 765, 329, 127, 521, 484, 238, 492, 641, 361, 432, 623, 316,\n",
       "        427, 779, 451, 270, 481, 516, 363, 618, 452, 217, 767, 437, 373,\n",
       "        613, 531, 244, 584, 574, 800, 522, 523, 803, 415, 440, 795,  28,\n",
       "         98, 722,  40,  87, 739, 170, 131, 684, 253, 274, 384, 237, 199,\n",
       "        259, 687, 128, 284, 337, 396, 252, 583, 254, 305, 505, 434, 174,\n",
       "        528, 500, 161, 602, 431, 148, 716, 457, 162, 502, 439, 764, 330,\n",
       "        357, 746, 188, 264, 747,  57,  23, 674,  21, 192, 672, 122,  22,\n",
       "        585, 455, 194, 196, 612, 220, 159, 324, 225, 134, 491, 319,  92,\n",
       "        683, 338, 123, 533, 231, 263, 550, 460,   3, 576, 400, 303, 490,\n",
       "        398, 203, 620, 615, 777, 496, 501, 708, 412, 340, 729,  49, 216,\n",
       "        667, 120,  66, 697, 266,  59, 611, 525, 260, 283, 534, 402, 220,\n",
       "        469, 382, 313, 588, 691, 388, 547, 426, 389, 668, 619, 343, 735,\n",
       "        745, 256, 575, 665, 454, 690, 682, 336, 483, 435, 756, 350, 145,\n",
       "        772,  52, 249, 769, 224, 196, 557, 293,   1, 546,  80, 180, 514,\n",
       "        456, 265, 307, 517, 300, 110, 309, 438,  19, 629, 564,  97, 414,\n",
       "        421, 178, 791, 251, 262, 685, 573, 356, 770, 563, 383, 658, 621,\n",
       "        242, 211, 154, 759, 115, 129, 694,  58,  86, 762, 175,  10, 370,\n",
       "         69,  45, 367, 193,   2, 308, 358, 385,  39, 510, 317, 208, 419,\n",
       "        233, 159, 704, 603, 408, 701, 436,  82, 661, 535,   6, 700, 789,\n",
       "        222, 783, 744, 163, 781, 559, 125, 666, 604, 799, 617, 506, 782,\n",
       "        512, 418, 757,  98, 142, 748, 289,  13, 763, 191,  34, 693, 362,\n",
       "        449, 397, 513, 247, 381, 477, 152, 347, 677, 475, 423, 633, 465,\n",
       "        518, 709, 240, 156, 774, 511, 538, 688, 425, 310, 637, 569, 372,\n",
       "        582, 509, 789, 448, 352, 734, 322, 271, 749, 171, 166, 651, 149,\n",
       "         38, 681,  77, 255, 587, 325, 282, 279, 565, 301, 219, 495,  76,\n",
       "         62, 568, 420,  91, 642, 446,  11, 605, 597, 246, 719, 479, 332,\n",
       "        711, 647, 318, 567, 499, 380, 368, 281, 792, 207, 250, 692, 165,\n",
       "         60, 727, 103,  68, 558,  51,  50, 488, 235,  14, 467, 515, 143,\n",
       "         41, 245, 273, 269, 326, 228, 157, 654, 359,  29, 478, 374, 280,\n",
       "        599, 322, 227, 581, 646, 210, 639, 433, 186, 645, 537, 306, 706,\n",
       "        671, 806, 628, 712, 804, 608, 586, 807, 314, 298, 718, 185, 107,\n",
       "        773, 214,  48, 737, 410,  64, 562,   4,  89, 498, 315, 132, 540,\n",
       "        552, 212, 345, 600, 341, 365, 399, 196, 416, 503, 137, 387, 656,\n",
       "        401, 294, 578, 320, 231, 695, 673, 801, 607, 543, 793, 471, 413,\n",
       "        786,  54, 226, 730,  36,  15, 750,  37,  94, 707, 595,  65, 442,\n",
       "        409,  47, 377, 295, 243, 346, 541, 596, 167, 532, 406, 275, 405,\n",
       "         20, 278, 485, 353, 369, 504, 312, 169, 610, 404, 140, 571, 462,\n",
       "        758, 378, 335, 768, 268, 272, 689,  12,  43, 760,  27, 116, 686,\n",
       "         88, 113, 648, 474,  25, 230, 507, 150,  79, 153, 176, 117, 594,\n",
       "        470, 155, 411, 147, 135, 394, 223,  56, 755, 566, 177, 662, 428,\n",
       "        164, 407, 393, 331])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details in the traininf results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>neurons</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.582978</td>\n",
       "      <td>0.004799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.582201</td>\n",
       "      <td>0.006862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.581435</td>\n",
       "      <td>0.009559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.580650</td>\n",
       "      <td>0.014467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.578727</td>\n",
       "      <td>0.007539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.284375</td>\n",
       "      <td>0.077565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.272363</td>\n",
       "      <td>0.042244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.259560</td>\n",
       "      <td>0.069716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>tanh</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.300</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.248358</td>\n",
       "      <td>0.010966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.247955</td>\n",
       "      <td>0.035121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    activation  batch_size  epochs  learning_rate  neurons optimizer  \\\n",
       "463       relu          10      10          0.010       16      adam   \n",
       "511       relu          10      20          0.010       32      adam   \n",
       "398       tanh          50      20          0.300        8       sgd   \n",
       "696       relu          50       5          0.100       16   rmsprop   \n",
       "74        tanh          10      10          0.200        8       sgd   \n",
       "..         ...         ...     ...            ...      ...       ...   \n",
       "677       relu          50       5          0.001        8       sgd   \n",
       "683       relu          50       5          0.001       32       sgd   \n",
       "272       tanh          50       5          0.001        8       sgd   \n",
       "178       tanh          20       5          0.300       32      adam   \n",
       "275       tanh          50       5          0.001       16       sgd   \n",
       "\n",
       "         Mean       Std  \n",
       "463  0.582978  0.004799  \n",
       "511  0.582201  0.006862  \n",
       "398  0.581435  0.009559  \n",
       "696  0.580650  0.014467  \n",
       "74   0.578727  0.007539  \n",
       "..        ...       ...  \n",
       "677  0.284375  0.077565  \n",
       "683  0.272363  0.042244  \n",
       "272  0.259560  0.069716  \n",
       "178  0.248358  0.010966  \n",
       "275  0.247955  0.035121  \n",
       "\n",
       "[810 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Hyperparameter listed out and shown as dataframe\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "df = pd.DataFrame(params)\n",
    "df['Mean'] = means\n",
    "df['Std'] = stds\n",
    "\n",
    "df.sort_values('Mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 51.71294626758024 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.80      0.65       736\n",
      "           1       0.34      0.31      0.33       652\n",
      "           2       0.37      0.21      0.27       584\n",
      "           3       0.67      0.65      0.66       801\n",
      "\n",
      "    accuracy                           0.52      2773\n",
      "   macro avg       0.48      0.49      0.48      2773\n",
      "weighted avg       0.50      0.52      0.50      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test data with the best hyperparameters\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print('Accuracy on test data:',accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though thhe result wasn't ideal, we observed that the 'rather similar' and 'rather dissimilar' categories are the hardest for our model to predict, and to figure out what happened there, we conducted the following research:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction correct: 51.712946267580236 %\n",
      "Miss by 1 label: 34.15073927154706 %\n",
      "Miss by 2 labels: 11.64803461954562 %\n",
      "Miss by 3 labels: 2.4882798413270826 %\n"
     ]
    }
   ],
   "source": [
    "# Check how far our model has mis-labeled prediction\n",
    "pred_correct = 0\n",
    "miss_1_label = 0\n",
    "miss_2_label = 0\n",
    "miss_3_label = 0\n",
    "\n",
    "for pos,i in enumerate(y_test):\n",
    "    if i-y_pred[pos] == 0:\n",
    "        pred_correct +=1\n",
    "    elif abs(i-y_pred[pos]) == 1:\n",
    "        miss_1_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 2:\n",
    "        miss_2_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 3:\n",
    "        miss_3_label +=1\n",
    "\n",
    "print ('Prediction correct:', pred_correct*100/len(y_test),'%')\n",
    "print ('Miss by 1 label:', miss_1_label*100/len(y_test),'%')\n",
    "print ('Miss by 2 labels:', miss_2_label*100/len(y_test),'%')\n",
    "print ('Miss by 3 labels:', miss_3_label*100/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))#,labels=labels_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#,display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the model tends to miscategorize by 1 category quite often. And as the training labels were also provided as an average score (of all the annotators score, so oftentime instead of 1,2,3,4, the labels are floating numbers like 2.333 or 3.6666), meaning even the human annotators are not uniformly agreeing on whether each pair is 'similar' or 'rather similar' (or 'dissimilar' or 'rather dissimilar'), thus making it even harder for the model to predict. That is why in the next notebook, we will group the data into only 2 categories, 1 for similar (including the entries labeled 1.0 to 2.5), and 0 for dissimilar (including the entries labeled 2.5 to 4.0), to see if our assumption is grounded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the result for analysis in the final report\n",
    "df.to_csv('model/NN_multiclass-gridsearch-imbalanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Balanced Data\n",
    "\n",
    "Then we repeat the same process but using balanced data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check training data label balance:\n",
      "overall\n",
      "0    497\n",
      "1    497\n",
      "2    497\n",
      "3    497\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We first balance the data by randomly sampling the same amount of them \n",
    "balancing = train_df.groupby('overall')\n",
    "balance_train_df = balancing.apply(lambda x: x.sample(balancing.size().min()))\n",
    "balance_train_df = balance_train_df.reset_index(drop=True)\n",
    "print('Check training data label balance:')\n",
    "print(balance_train_df.groupby('overall').size(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then using the balanced data to create train and test \n",
    "target_column = ['overall']\n",
    "predictors = list(set(list(balance_train_df.drop(['pair_id'], axis=1).columns))-set(target_column))\n",
    "\n",
    "X_train = balance_train_df[predictors].values\n",
    "y_train = balance_train_df[target_column].values\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(y_train)\n",
    "dummy_y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1988, 5)\n",
      "(2773, 5)\n",
      "(1988, 4)\n",
      "(2773, 4)\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced training data shape : 2585\n",
    "# Balanced training data shape : 1988\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "print(dummy_y_train.shape); print(dummy_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create KerasClassifier again for the balanced data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model with random hyperparameter\n",
    "hidden_size = 8\n",
    "epoch = 100\n",
    "input_size = X_train.shape[1]\n",
    "output_size = dummy_y_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "kfold = 5\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_dim=input_size, activation='relu'))\n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassfier\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# Number of folds\n",
    "kfold = KFold(n_splits=kfold, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(s) used: 110.26552414894104\n",
      "Baseline: 52.97% (0.68%)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results_binn = cross_val_score(estimator, X_train, dummy_y_train, cv=kfold)\n",
    "\n",
    "print('Time(s) used:',time.time() - start)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results_binn.mean()*100, results_binn.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While now that the data is balanced, the performance we get from cross validation is 6% lower (from 58% to 52%), more importantly we want to see how it performs on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 1s 805us/step - loss: 1.2015 - accuracy: 0.4331\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 892us/step - loss: 1.0497 - accuracy: 0.5382\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 870us/step - loss: 1.0430 - accuracy: 0.5277\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 878us/step - loss: 1.0438 - accuracy: 0.5418\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 889us/step - loss: 1.0433 - accuracy: 0.5216\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 906us/step - loss: 1.0388 - accuracy: 0.5327\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 896us/step - loss: 1.0360 - accuracy: 0.5377\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 913us/step - loss: 1.0409 - accuracy: 0.5277\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 886us/step - loss: 1.0322 - accuracy: 0.5372\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 884us/step - loss: 1.0338 - accuracy: 0.5362\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0335 - accuracy: 0.5262\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0262 - accuracy: 0.5392\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0240 - accuracy: 0.5402\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 967us/step - loss: 1.0225 - accuracy: 0.5332\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0212 - accuracy: 0.5317\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0167 - accuracy: 0.5382\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0150 - accuracy: 0.5372\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0148 - accuracy: 0.5448\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0145 - accuracy: 0.5307\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0101 - accuracy: 0.5563\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0084 - accuracy: 0.5297\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 1.0115 - accuracy: 0.5443\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 1.0078 - accuracy: 0.5397\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0068 - accuracy: 0.5337\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 1.0040 - accuracy: 0.5327\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 1.0051 - accuracy: 0.5418\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0050 - accuracy: 0.5352\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0032 - accuracy: 0.5453\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0025 - accuracy: 0.5342\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0036 - accuracy: 0.5473\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 983us/step - loss: 1.0065 - accuracy: 0.5302\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 998us/step - loss: 1.0042 - accuracy: 0.5418\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0007 - accuracy: 0.5397\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0012 - accuracy: 0.5453\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0022 - accuracy: 0.5382\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0039 - accuracy: 0.5438\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0024 - accuracy: 0.5397\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0021 - accuracy: 0.5307\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 917us/step - loss: 1.0001 - accuracy: 0.5357\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 905us/step - loss: 1.0030 - accuracy: 0.5342\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 909us/step - loss: 1.0033 - accuracy: 0.5418\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 887us/step - loss: 1.0048 - accuracy: 0.5473\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 870us/step - loss: 0.9987 - accuracy: 0.5513\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 894us/step - loss: 0.9984 - accuracy: 0.5372\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 977us/step - loss: 1.0052 - accuracy: 0.5292\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 979us/step - loss: 1.0022 - accuracy: 0.5357\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 966us/step - loss: 1.0021 - accuracy: 0.5322\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0007 - accuracy: 0.5433\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0007 - accuracy: 0.5443\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0008 - accuracy: 0.5438\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0057 - accuracy: 0.5332\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 998us/step - loss: 0.9986 - accuracy: 0.5332\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 899us/step - loss: 1.0042 - accuracy: 0.5428\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 914us/step - loss: 0.9999 - accuracy: 0.5352\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.5407\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9994 - accuracy: 0.5407\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9990 - accuracy: 0.5337\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9987 - accuracy: 0.5372\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 943us/step - loss: 0.9951 - accuracy: 0.5418\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9983 - accuracy: 0.5372\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.9967 - accuracy: 0.5438\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9992 - accuracy: 0.5357\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 1s 1ms/step - loss: 0.9964 - accuracy: 0.5382\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 1.0006 - accuracy: 0.5448\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 932us/step - loss: 0.9954 - accuracy: 0.5412\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 893us/step - loss: 0.9939 - accuracy: 0.5493\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 924us/step - loss: 0.9953 - accuracy: 0.5357\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 957us/step - loss: 0.9980 - accuracy: 0.5428\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 989us/step - loss: 0.9962 - accuracy: 0.5377\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 963us/step - loss: 0.9942 - accuracy: 0.5488\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 990us/step - loss: 0.9969 - accuracy: 0.5458\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9941 - accuracy: 0.5377\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 974us/step - loss: 0.9955 - accuracy: 0.5367\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 948us/step - loss: 0.9967 - accuracy: 0.5367\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 921us/step - loss: 0.9944 - accuracy: 0.5402\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 881us/step - loss: 0.9941 - accuracy: 0.5538\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 987us/step - loss: 0.9937 - accuracy: 0.5488\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 913us/step - loss: 0.9963 - accuracy: 0.5498\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 898us/step - loss: 0.9912 - accuracy: 0.5453\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 907us/step - loss: 0.9938 - accuracy: 0.5448\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 858us/step - loss: 0.9897 - accuracy: 0.5573\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 850us/step - loss: 0.9916 - accuracy: 0.5362\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 861us/step - loss: 0.9920 - accuracy: 0.5387\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 853us/step - loss: 0.9907 - accuracy: 0.5402\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 850us/step - loss: 0.9886 - accuracy: 0.5357\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 925us/step - loss: 0.9911 - accuracy: 0.5468\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 866us/step - loss: 0.9921 - accuracy: 0.5342\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 858us/step - loss: 0.9928 - accuracy: 0.5428\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 897us/step - loss: 0.9896 - accuracy: 0.5387\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 935us/step - loss: 0.9981 - accuracy: 0.5347\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 942us/step - loss: 0.9925 - accuracy: 0.5402\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 1ms/step - loss: 0.9915 - accuracy: 0.5317\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 958us/step - loss: 0.9927 - accuracy: 0.5412\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 977us/step - loss: 0.9922 - accuracy: 0.5423\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 974us/step - loss: 0.9892 - accuracy: 0.5493\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 955us/step - loss: 0.9914 - accuracy: 0.5397\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 985us/step - loss: 0.9903 - accuracy: 0.5443\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 887us/step - loss: 0.9899 - accuracy: 0.5332\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 867us/step - loss: 0.9900 - accuracy: 0.5528\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 883us/step - loss: 0.9916 - accuracy: 0.5372\n"
     ]
    }
   ],
   "source": [
    "# Fit train data\n",
    "train_result = estimator.fit(X_train, dummy_y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 52.181752614496936 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.66       736\n",
      "           1       0.36      0.33      0.34       652\n",
      "           2       0.37      0.43      0.40       584\n",
      "           3       0.74      0.54      0.62       801\n",
      "\n",
      "    accuracy                           0.52      2773\n",
      "   macro avg       0.52      0.51      0.51      2773\n",
      "weighted avg       0.54      0.52      0.52      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction and get accuracy\n",
    "y_pred = estimator.predict(X_test)\n",
    "print('Accuracy on test data:',accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))#,labels=labels_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#,display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the accuracy stays about the same now that the data is balanced (both are roughly 52%), we can see that the model predicts less as 0 (perhaps because the data is now balanced), and more coorrectly predicts for the 'rather similar' and 'rather disimilar' categories. While the performance on 'disimilar' category decreases, the overal f1 score of each category seems to show an improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we conduct GridSearch to get the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_grid(neurons = 5 , activation = 'relu', learning_rate = '0.001', optimizer='adam',):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Activation functions\n",
    "    if activation=='relu':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='relu'))\n",
    "        #model.add(Dense(neurons, activation='relu'))\n",
    "    if activation=='tanh':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='tanh'))\n",
    "        #model.add(Dense(neurons, activation='tanh'))\n",
    "    if activation=='sigmoid':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='sigmoid'))\n",
    "        #model.add(Dense(neurons, activation='sigmoid'))\n",
    "        \n",
    "    # Output layer    \n",
    "    model.add(Dense(output_size, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizers\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    if optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "\n",
    "estimator_grid = KerasClassifier(build_fn=create_model_grid, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hyperparameters to be searched\n",
    "activation_list = ['tanh','relu']\n",
    "optimizer_list = ['rmsprop','adam','sgd']\n",
    "epoch_list = [5,10,20]\n",
    "batch_list = [10,20,50]\n",
    "learning_rate_list = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "neurons_list = [8, 16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearch\n",
    "param_grid = dict(activation = activation_list,\n",
    "                 optimizer = optimizer_list,\n",
    "                 epochs = epoch_list, \n",
    "                  batch_size = batch_list,\n",
    "                 learning_rate = learning_rate_list,\n",
    "                 neurons = neurons_list)\n",
    "\n",
    "# Search with 3 folds (cross_validation)\n",
    "grid = GridSearchCV(estimator = estimator_grid, param_grid = param_grid, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 810 candidates, totalling 2430 fits\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=adam; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=16, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=16, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=16, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n"
     ]
    }
   ],
   "source": [
    "# Training to get the best hyperparameter combination\n",
    "grid_result = grid.fit(X_train,dummy_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.547794 using {'activation': 'relu', 'batch_size': 20, 'epochs': 20, 'learning_rate': 0.01, 'neurons': 32, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Print Best Result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.94340595, 0.87899049, 0.82470218, 1.17031161, 0.99439526,\n",
       "        1.04271841, 1.06311472, 1.04496876, 0.89089282, 1.0345579 ,\n",
       "        1.01124779, 0.96512381, 1.2226394 , 1.0599606 , 1.06886768,\n",
       "        1.18436249, 1.1606319 , 0.98450661, 1.29274432, 1.138954  ,\n",
       "        1.06020935, 1.28774055, 1.06090347, 1.0314796 , 1.18724306,\n",
       "        1.29877496, 1.00127618, 1.3627464 , 1.11281514, 1.10411787,\n",
       "        1.13745832, 1.20578965, 0.99839441, 1.13644632, 1.18318041,\n",
       "        1.15947851, 1.27540358, 1.0560023 , 1.06070805, 1.30536493,\n",
       "        1.17352978, 0.97169177, 1.23712238, 1.18864401, 1.12609752,\n",
       "        1.67468937, 1.77100658, 1.50394519, 1.70569261, 1.85493279,\n",
       "        1.52983205, 1.88396573, 1.76400359, 1.60645469, 1.82640529,\n",
       "        1.72405259, 1.52453725, 1.8727595 , 1.71663626, 1.47248991,\n",
       "        1.95226002, 1.6179599 , 1.70084381, 1.92439103, 1.62169226,\n",
       "        1.81493513, 1.75064786, 1.78115233, 1.70982854, 1.71123274,\n",
       "        1.6143802 , 1.6535821 , 1.82899547, 1.72867878, 1.63756227,\n",
       "        1.751604  , 1.97750123, 1.7173512 , 2.37541588, 2.00460426,\n",
       "        1.58351247, 2.24735204, 1.80745705, 1.75258557, 1.79079898,\n",
       "        1.73006964, 1.66221444, 1.83654714, 1.63880873, 1.92883603,\n",
       "        3.05835176, 2.98542198, 3.15929453, 3.01350943, 2.98728188,\n",
       "        2.58974965, 3.10106858, 2.92214616, 2.5574375 , 3.09395623,\n",
       "        2.76417629, 2.80735914, 2.86396837, 2.98676594, 2.8241082 ,\n",
       "        2.84512615, 3.072342  , 2.62209074, 3.11678179, 2.87121614,\n",
       "        2.73340623, 2.96198106, 2.88798579, 2.80107148, 2.85924768,\n",
       "        3.08190552, 2.72254372, 2.93943739, 2.978043  , 2.68138631,\n",
       "        3.12229935, 2.97680656, 2.74618014, 3.01788648, 2.98211161,\n",
       "        2.76833542, 3.01505645, 2.81660755, 2.72523506, 2.94204855,\n",
       "        2.88960687, 2.72860988, 3.0549926 , 3.0352718 , 2.61498054,\n",
       "        1.00725214, 0.93133863, 0.7570916 , 1.00094954, 0.85590927,\n",
       "        0.87685347, 1.02409728, 1.07554944, 0.88795924, 0.99309405,\n",
       "        1.15966741, 0.91919613, 1.13326406, 0.93615627, 0.84477615,\n",
       "        1.00123596, 0.95369029, 0.7426339 , 0.87759844, 0.98853151,\n",
       "        0.82780751, 0.89060442, 0.81373421, 0.86024038, 0.91611902,\n",
       "        1.01372631, 0.75204531, 0.99602898, 0.78662539, 0.78623001,\n",
       "        1.06716681, 0.81740276, 0.71133256, 0.87505976, 1.01885414,\n",
       "        0.78957669, 1.02426171, 0.80424587, 0.74366999, 1.00353718,\n",
       "        0.83468231, 0.85683314, 0.87937228, 0.95268114, 0.83667835,\n",
       "        1.17793862, 1.18245625, 1.01517979, 1.41522145, 1.11658271,\n",
       "        1.11123021, 1.15961536, 1.92980258, 1.22050603, 1.25631865,\n",
       "        1.39936606, 1.07531913, 1.30367867, 1.1089619 , 1.30456281,\n",
       "        1.19131001, 1.11255868, 1.04097191, 1.31251478, 1.23979386,\n",
       "        0.99305145, 1.3756268 , 1.1253589 , 1.11991978, 1.15677444,\n",
       "        1.23752387, 1.04067993, 1.18915375, 1.21788502, 1.10884047,\n",
       "        1.29723636, 1.08961447, 1.20207755, 1.50757408, 1.24585581,\n",
       "        1.13022741, 1.44978905, 1.41794968, 1.13829311, 1.4657747 ,\n",
       "        1.41039666, 1.34097163, 1.3621997 , 1.43671497, 1.15744424,\n",
       "        1.97034136, 2.50399899, 1.9644258 , 2.99319379, 2.47357138,\n",
       "        2.19339569, 2.38372397, 2.39020125, 1.94595917, 2.35001071,\n",
       "        2.20858788, 2.17840997, 2.30372095, 2.22486051, 1.96671359,\n",
       "        2.89936384, 2.41524307, 2.31156182, 2.46014698, 2.61195223,\n",
       "        2.0320979 , 2.37643019, 2.25626842, 2.17840568, 2.29012585,\n",
       "        2.3146766 , 2.09488074, 2.57581536, 2.12829343, 2.1669604 ,\n",
       "        2.35220202, 2.04881589, 2.12963645, 2.18142255, 2.39523594,\n",
       "        1.97761059, 2.81797695, 2.12932611, 2.08202839, 2.23135869,\n",
       "        2.01916869, 1.70120597, 1.88271332, 1.95690838, 1.73497009,\n",
       "        0.90996488, 0.80418166, 0.67407044, 0.94497712, 0.66158168,\n",
       "        0.72859629, 0.74072409, 0.74329718, 0.59551207, 0.7308294 ,\n",
       "        0.62129958, 0.58175159, 0.74392049, 0.72204177, 0.58802001,\n",
       "        0.82698027, 0.7951959 , 0.56939713, 0.79089149, 0.78103876,\n",
       "        0.60931818, 0.8561755 , 0.65034127, 0.71754162, 0.79398743,\n",
       "        0.80917899, 0.5901467 , 0.72172149, 0.77471813, 0.58356611,\n",
       "        0.92909416, 0.67413235, 0.57930795, 0.70759598, 0.78566003,\n",
       "        0.57168714, 0.84242964, 0.65016484, 0.60575644, 0.8669947 ,\n",
       "        0.65229289, 0.5889283 , 0.9447976 , 0.661333  , 0.71393037,\n",
       "        0.84654824, 0.89984608, 0.7244579 , 0.93415793, 0.89015619,\n",
       "        0.70235817, 0.95566225, 0.75197466, 0.89929136, 0.85959236,\n",
       "        0.83616662, 0.7277844 , 0.99453266, 1.06075613, 0.9189585 ,\n",
       "        1.14552975, 0.90728116, 1.01806617, 0.96207722, 0.84390847,\n",
       "        0.8745029 , 0.87862126, 0.98514152, 0.71636621, 0.98342013,\n",
       "        0.76267727, 0.69372559, 1.058213  , 0.77273409, 0.83012883,\n",
       "        0.84454886, 0.74489617, 0.78746295, 0.87479377, 0.75546575,\n",
       "        0.69017259, 0.80101705, 0.86193927, 0.71536485, 0.86792938,\n",
       "        0.87265889, 0.68039211, 0.87174137, 1.07498248, 0.80002618,\n",
       "        1.31235695, 1.04373678, 1.15968609, 1.11243852, 1.00244371,\n",
       "        1.03429333, 1.24458933, 1.1679879 , 0.93248423, 1.18879112,\n",
       "        1.09383289, 0.93203147, 1.19273051, 0.99717466, 0.99526993,\n",
       "        1.09742212, 1.11981138, 0.92424186, 1.20543122, 1.0861764 ,\n",
       "        0.9236238 , 1.1753672 , 1.01017833, 1.15567843, 1.11257823,\n",
       "        1.1205225 , 0.92155663, 1.20480855, 1.12950007, 0.89696336,\n",
       "        1.18826501, 1.18871061, 1.04881771, 1.0615538 , 1.00543984,\n",
       "        0.95898755, 1.14399489, 1.11199474, 0.96060348, 1.48942177,\n",
       "        1.10399302, 0.96586212, 1.43855604, 1.25424759, 0.95512811,\n",
       "        1.2084136 , 1.13130522, 1.14191167, 1.23884344, 1.14583755,\n",
       "        0.99782284, 1.23163176, 1.11536423, 0.96506095, 1.21989155,\n",
       "        1.29508654, 1.00291673, 1.13750203, 1.2906247 , 1.04726028,\n",
       "        1.13288196, 1.07575472, 1.10776504, 1.17816774, 1.16261546,\n",
       "        1.1222647 , 1.2625827 , 1.10143511, 0.98663322, 1.1650215 ,\n",
       "        1.35333443, 1.01396521, 1.27167177, 1.06844322, 1.10300382,\n",
       "        1.28143684, 1.06588356, 1.14659333, 1.27280164, 1.06178355,\n",
       "        1.03887359, 1.35422953, 1.22299393, 1.08561714, 1.41972987,\n",
       "        1.21808672, 1.14624532, 1.15564299, 1.09478744, 1.12743862,\n",
       "        1.71855013, 1.66891487, 1.70324087, 1.70350726, 1.8030978 ,\n",
       "        1.53404721, 1.81156341, 1.79595637, 1.52756977, 1.74055211,\n",
       "        1.75894213, 1.53070839, 1.77671059, 1.86533141, 1.56192199,\n",
       "        2.01685476, 1.62006513, 1.60548751, 1.89473446, 1.65212027,\n",
       "        1.48768973, 2.25927687, 2.1282448 , 1.82402277, 1.91123422,\n",
       "        1.72943306, 1.59703326, 1.84759053, 1.8164804 , 1.53880707,\n",
       "        1.72492091, 1.78731497, 1.52389359, 1.71223593, 1.92110809,\n",
       "        1.54041004, 2.02725204, 1.91755764, 1.69192664, 1.9068617 ,\n",
       "        1.68539286, 1.73494045, 1.84237798, 1.7583824 , 1.72126722,\n",
       "        2.85981615, 2.88644155, 2.60940727, 3.12676024, 2.89832322,\n",
       "        2.79719106, 2.96735493, 2.72882915, 2.87143326, 2.82067664,\n",
       "        3.31376553, 3.07791336, 2.90108593, 2.88988709, 2.64477038,\n",
       "        3.06678128, 2.88862133, 3.41601745, 3.64005574, 3.43539906,\n",
       "        2.98692465, 3.05782533, 3.03539562, 2.63223489, 3.05644766,\n",
       "        2.76206724, 2.74468414, 3.02871974, 2.85467315, 2.86972467,\n",
       "        3.08549881, 3.04574188, 2.77215656, 2.89992197, 3.01638556,\n",
       "        2.60799011, 3.00996375, 2.71165673, 2.80625971, 3.35444125,\n",
       "        2.83011174, 2.90573176, 2.82348045, 2.9077727 , 2.72767178,\n",
       "        0.98538423, 0.94499763, 0.72518897, 0.85939781, 0.82561374,\n",
       "        0.88901281, 1.13760885, 0.82259528, 0.88093058, 0.98181621,\n",
       "        0.81085094, 0.71694438, 0.87986565, 0.80976152, 0.82965597,\n",
       "        1.04298075, 0.80757697, 0.73345272, 1.0059038 , 0.94623836,\n",
       "        0.87456417, 0.86985683, 0.93374793, 0.70529413, 1.00236495,\n",
       "        0.79358212, 0.75269254, 1.00164088, 0.82337674, 0.8863337 ,\n",
       "        1.04461424, 0.98489348, 0.89284396, 0.93511224, 0.87652389,\n",
       "        0.87940486, 0.90803607, 0.92734186, 0.7863822 , 0.94496576,\n",
       "        0.94954515, 0.72726663, 1.01555045, 0.92223612, 0.89365967,\n",
       "        1.1617225 , 1.08484379, 1.17834846, 1.26222809, 1.22500714,\n",
       "        1.01324471, 1.49742349, 1.36642758, 1.12082362, 1.37514114,\n",
       "        1.23340058, 1.15264519, 1.15912851, 1.14095942, 1.18602133,\n",
       "        1.1645987 , 1.19741686, 1.04952733, 1.20821325, 1.07971581,\n",
       "        0.97729913, 1.41651464, 1.10918005, 1.13042736, 1.16323535,\n",
       "        1.2335488 , 1.14844608, 1.1566844 , 1.20334641, 1.17014559,\n",
       "        1.19322745, 1.06062667, 1.01985916, 1.49111787, 1.12709292,\n",
       "        1.13316369, 1.13998501, 1.225818  , 1.14045382, 1.1437846 ,\n",
       "        1.19429056, 1.15363391, 1.16890097, 1.05619661, 0.98668424,\n",
       "        2.02233346, 1.67348814, 1.79441547, 1.75958157, 1.63362789,\n",
       "        1.94404689, 1.73058383, 1.78814753, 1.70269513, 1.71681301,\n",
       "        1.7324218 , 1.65621456, 1.83694084, 1.7950751 , 1.73533297,\n",
       "        1.70803714, 1.83124073, 1.69093259, 1.69857891, 1.92913294,\n",
       "        1.54145511, 1.84198968, 1.66300122, 1.52850087, 2.01409419,\n",
       "        1.66431745, 1.65232666, 1.87194308, 1.68265947, 2.17573841,\n",
       "        1.8548824 , 1.78255749, 1.77031493, 1.7585837 , 1.70483732,\n",
       "        1.99434821, 2.01806474, 1.83413982, 1.69890078, 1.81258678,\n",
       "        1.79921714, 1.67270494, 1.78959211, 1.7924815 , 1.54263266,\n",
       "        0.72125133, 0.88962777, 0.58869322, 0.86098019, 0.63634555,\n",
       "        0.5773317 , 0.69893789, 0.7157294 , 0.5820725 , 0.73186541,\n",
       "        0.81590223, 0.56910674, 0.71077275, 0.71825218, 0.60376732,\n",
       "        0.88925568, 0.64799174, 0.58010825, 0.85967938, 0.7230703 ,\n",
       "        0.7110676 , 0.73220038, 0.79757794, 0.57314992, 0.71658937,\n",
       "        0.87021581, 0.59520809, 0.71940994, 0.62331088, 0.58483958,\n",
       "        0.71427568, 0.71217895, 0.76021091, 0.71062692, 0.64087439,\n",
       "        0.72658181, 0.73522123, 0.87188657, 0.58516582, 0.73231594,\n",
       "        0.80075542, 0.57268858, 0.74788642, 0.75785581, 0.59666832,\n",
       "        0.98107171, 0.7576077 , 0.69290853, 1.12205855, 0.78834343,\n",
       "        0.68795069, 0.82212496, 0.76077167, 0.91688259, 0.86100721,\n",
       "        0.88757078, 0.6767168 , 0.85042   , 0.77978929, 0.75178822,\n",
       "        1.00298715, 0.75361975, 0.69168615, 1.00425951, 0.87467925,\n",
       "        0.69300826, 0.84191036, 0.75643571, 0.83087103, 0.9374609 ,\n",
       "        0.92542307, 0.73893642, 0.84770354, 0.73047225, 0.7767152 ,\n",
       "        0.99483665, 0.76420204, 0.67821225, 0.96980445, 0.86919832,\n",
       "        0.71567178, 0.86192497, 0.75223128, 0.83339214, 0.87974318,\n",
       "        1.00928124, 0.73083584, 0.82745536, 0.73929962, 0.70129418,\n",
       "        1.34852823, 1.04208223, 1.03141785, 1.47876334, 1.19532633,\n",
       "        0.95090413, 1.18885295, 1.13377674, 1.34718283, 1.14722204,\n",
       "        1.23091817, 1.24813787, 1.12804341, 1.1174465 , 0.87992803,\n",
       "        1.37893724, 1.44158888, 1.69410189, 1.63204551, 1.10999966,\n",
       "        1.47381171, 2.3935372 , 1.88361239, 1.92379642, 1.93217953,\n",
       "        1.92878183, 1.84682298, 1.92445207, 2.09882609, 1.58380119,\n",
       "        1.87546937, 2.13463235, 1.63914076, 2.18293691, 1.73561748,\n",
       "        1.63823732, 2.16079823, 1.70949308, 1.74071773, 2.05755226,\n",
       "        1.81490485, 1.90465816, 1.86889251, 2.12030927, 1.67058754]),\n",
       " 'std_fit_time': array([1.66654494e-02, 3.71689676e-02, 3.13281703e-02, 6.64014579e-02,\n",
       "        6.23046993e-03, 1.83747566e-01, 5.11240620e-03, 8.38619018e-02,\n",
       "        1.68618653e-02, 6.38780901e-03, 3.22660655e-02, 1.04145967e-02,\n",
       "        1.42917525e-01, 3.45655718e-03, 1.48679675e-01, 4.32705285e-02,\n",
       "        1.39919275e-01, 1.52107084e-02, 1.48497717e-01, 1.06993858e-01,\n",
       "        1.01645591e-01, 1.31061482e-01, 8.54376505e-03, 1.26972101e-01,\n",
       "        3.56628131e-02, 1.32151199e-01, 1.13142537e-02, 1.82000831e-01,\n",
       "        1.52326877e-02, 1.40627607e-01, 7.60583908e-03, 1.25756703e-01,\n",
       "        3.17835558e-02, 1.08959624e-02, 1.45099318e-01, 1.18182428e-01,\n",
       "        1.45389162e-01, 3.61402748e-03, 1.65082000e-01, 8.11289514e-02,\n",
       "        1.46083822e-01, 5.72744931e-03, 1.46603807e-01, 1.20707553e-01,\n",
       "        1.33650199e-01, 1.11831534e-02, 1.85151305e-01, 2.06676904e-02,\n",
       "        1.08272910e-02, 2.56645566e-01, 7.43686492e-03, 1.40227622e-01,\n",
       "        1.58724223e-01, 1.40009398e-01, 1.05692654e-01, 1.41159730e-01,\n",
       "        1.76507101e-02, 2.08711538e-01, 1.49000720e-01, 2.92108306e-03,\n",
       "        2.09396328e-01, 1.73343635e-02, 2.12593597e-01, 2.18330991e-01,\n",
       "        7.17191379e-03, 8.71651875e-02, 4.22215555e-02, 1.35942306e-01,\n",
       "        1.46424525e-01, 3.24207973e-02, 1.92900600e-02, 1.74466354e-01,\n",
       "        1.38955549e-01, 1.64885879e-01, 1.37178601e-01, 7.11352400e-02,\n",
       "        3.11005229e-01, 1.38203579e-01, 5.68193939e-01, 1.30728616e-01,\n",
       "        7.58527177e-02, 2.24934876e-01, 1.09520588e-01, 1.60356618e-01,\n",
       "        2.72492389e-02, 1.43775105e-01, 9.74930200e-02, 1.15233289e-01,\n",
       "        1.93688500e-02, 2.07069816e-01, 3.01549333e-01, 2.50315723e-01,\n",
       "        4.51715476e-01, 2.54298811e-02, 2.68626324e-01, 3.79194878e-02,\n",
       "        2.13228357e-01, 2.33768373e-01, 3.03803995e-02, 3.51187128e-01,\n",
       "        3.40373350e-02, 1.49313571e-01, 2.59870443e-02, 1.87891345e-01,\n",
       "        2.23900569e-01, 1.91907681e-02, 1.13794416e-01, 4.71251763e-02,\n",
       "        2.28864657e-01, 2.14996971e-01, 1.24838441e-01, 1.13700153e-01,\n",
       "        1.38317346e-01, 1.29515009e-01, 1.24595807e-02, 3.30204196e-01,\n",
       "        2.39500693e-01, 1.40792641e-01, 2.93096377e-01, 1.37940294e-01,\n",
       "        2.27995763e-01, 2.28703230e-01, 1.41210923e-01, 1.69274133e-01,\n",
       "        1.26805481e-01, 1.87060206e-01, 2.64642746e-01, 4.73782344e-02,\n",
       "        2.14941949e-01, 1.42457807e-01, 2.03847070e-01, 1.28186015e-01,\n",
       "        2.41715533e-01, 1.67466446e-01, 2.92712236e-02, 1.69668461e-01,\n",
       "        1.06057145e-01, 7.76070474e-03, 1.68282241e-01, 1.26011475e-02,\n",
       "        1.82196901e-01, 1.20009281e-01, 2.30247858e-01, 2.55687955e-02,\n",
       "        5.02984101e-02, 2.09629864e-01, 6.03490438e-02, 1.76298247e-01,\n",
       "        9.94496148e-03, 8.53942606e-02, 6.13214512e-02, 1.62833447e-01,\n",
       "        5.54523630e-03, 5.30907307e-03, 1.55990945e-01, 7.42757876e-02,\n",
       "        1.86655844e-02, 5.47888788e-03, 1.85353666e-01, 6.14509987e-02,\n",
       "        1.38879729e-01, 7.79349485e-03, 1.68896442e-01, 1.25272797e-02,\n",
       "        8.12625662e-02, 2.26269777e-01, 7.74372676e-03, 1.84491485e-02,\n",
       "        9.57723096e-03, 1.84328174e-01, 5.03021545e-02, 1.75307913e-01,\n",
       "        3.10703146e-03, 6.33682494e-03, 1.03800647e-01, 9.60421190e-03,\n",
       "        1.86711553e-01, 3.40677451e-03, 1.75059308e-01, 7.62861788e-02,\n",
       "        1.42325389e-02, 1.71063324e-01, 1.34686081e-03, 2.09007747e-01,\n",
       "        7.80618062e-03, 1.70829145e-01, 8.88712298e-03, 9.17281031e-01,\n",
       "        3.61415489e-02, 1.27790053e-02, 1.70573660e-01, 2.38265065e-03,\n",
       "        1.73763251e-01, 1.32619907e-02, 6.50422652e-02, 2.34686632e-02,\n",
       "        1.26213888e-02, 7.93768837e-02, 1.34535753e-01, 1.65257356e-01,\n",
       "        9.33021251e-03, 1.54873275e-01, 3.08283471e-03, 1.63142706e-01,\n",
       "        3.67965077e-03, 1.37639082e-01, 3.98315122e-02, 3.06260502e-02,\n",
       "        1.63272310e-01, 9.31030188e-02, 1.59336283e-01, 6.07566387e-03,\n",
       "        1.98385895e-01, 1.32149140e-01, 1.26995546e-02, 3.72547666e-02,\n",
       "        1.71772267e-01, 1.36182281e-01, 3.26455305e-03, 1.43984792e-01,\n",
       "        2.06215849e-01, 2.11920629e-01, 4.93478410e-02, 1.29942685e-01,\n",
       "        8.20443417e-03, 2.61934425e-02, 5.08599168e-01, 7.64271587e-02,\n",
       "        3.47625140e-01, 1.98020035e-01, 2.13565451e-01, 1.91436640e-01,\n",
       "        2.70633939e-01, 5.27180774e-02, 1.32528863e-01, 1.54969949e-01,\n",
       "        2.51486203e-01, 1.91819749e-01, 1.22197506e-01, 1.65265206e-02,\n",
       "        1.69536773e-01, 1.45458122e-01, 2.42460642e-01, 1.33327349e-01,\n",
       "        1.23787724e-01, 2.79793870e-02, 1.48851330e-01, 1.81547768e-01,\n",
       "        1.56061341e-01, 5.23681981e-02, 2.63337122e-01, 1.21923320e-01,\n",
       "        3.20356019e-01, 4.59909048e-02, 1.49774005e-01, 1.55246836e-01,\n",
       "        6.86472067e-02, 2.01706977e-01, 1.63570989e-02, 2.72681057e-01,\n",
       "        3.87412199e-02, 7.18597772e-01, 5.34771942e-02, 5.74044698e-03,\n",
       "        3.44514176e-02, 1.43344419e-01, 4.20739461e-02, 1.96181314e-02,\n",
       "        9.83329632e-02, 9.68201002e-02, 2.13429435e-01, 1.12362143e-01,\n",
       "        5.68857877e-03, 2.31102147e-01, 8.15157236e-03, 1.98467238e-01,\n",
       "        2.14565923e-02, 8.02324388e-02, 4.76599157e-03, 1.54874249e-02,\n",
       "        9.93642318e-03, 1.21471174e-02, 6.32641928e-02, 4.85204161e-02,\n",
       "        2.40976730e-02, 6.75117140e-02, 1.83122546e-01, 5.46854314e-03,\n",
       "        4.64929997e-02, 1.79850193e-01, 1.12190062e-02, 1.88426845e-01,\n",
       "        7.02670100e-03, 1.93917591e-01, 6.70680380e-02, 1.88048658e-01,\n",
       "        1.48034814e-02, 2.23473584e-03, 1.85251050e-01, 1.40978518e-02,\n",
       "        1.80753622e-01, 8.93849663e-03, 1.44339069e-02, 1.08807000e-02,\n",
       "        1.94298460e-01, 1.12863603e-02, 8.81006217e-02, 1.40709745e-02,\n",
       "        1.02706920e-02, 1.96770984e-01, 6.30698728e-03, 1.96651353e-03,\n",
       "        1.49802210e-01, 4.21850817e-03, 1.90692096e-01, 1.46981349e-02,\n",
       "        1.76109525e-01, 7.66897216e-02, 1.04710907e-01, 1.63819835e-01,\n",
       "        1.21217992e-02, 1.75688270e-01, 6.30005148e-03, 1.20293090e-01,\n",
       "        8.40767441e-03, 3.37836170e-02, 1.18666133e-02, 9.57932734e-02,\n",
       "        2.18279517e-01, 1.36736859e-02, 2.06075056e-01, 1.44524235e-02,\n",
       "        7.42046300e-02, 2.62937736e-02, 3.34448476e-02, 2.22621355e-01,\n",
       "        4.41830212e-02, 1.82985656e-01, 1.00061756e-02, 1.72169283e-01,\n",
       "        1.19805389e-02, 6.09932541e-04, 1.52544492e-01, 3.09447743e-04,\n",
       "        1.81575983e-01, 1.14497620e-02, 1.64444429e-02, 6.45813740e-02,\n",
       "        2.29068561e-02, 1.77900353e-02, 6.73792552e-03, 1.74614596e-02,\n",
       "        1.01125656e-01, 4.86832294e-02, 1.39273392e-02, 1.81156876e-01,\n",
       "        1.29669101e-02, 6.78421068e-02, 1.63411595e-01, 2.73177630e-02,\n",
       "        2.51835738e-01, 4.17980047e-02, 1.00241852e-01, 1.43213849e-02,\n",
       "        6.43531704e-03, 1.78959278e-01, 1.43625200e-01, 1.83063712e-01,\n",
       "        7.30152380e-03, 1.70827340e-01, 9.52450895e-02, 5.44284419e-03,\n",
       "        1.69635068e-01, 6.13973195e-03, 8.71357343e-02, 1.86768566e-02,\n",
       "        1.76520648e-01, 3.97322767e-03, 2.22177387e-01, 1.18002805e-01,\n",
       "        7.16144214e-03, 1.76345162e-01, 1.57353294e-02, 2.03656578e-01,\n",
       "        5.90206928e-03, 1.75547305e-01, 1.56109046e-02, 1.26687171e-01,\n",
       "        1.65443056e-01, 1.27044230e-02, 1.66491132e-01, 1.28918955e-01,\n",
       "        1.66025255e-01, 1.02331401e-02, 8.71462394e-03, 9.08239169e-02,\n",
       "        5.72365924e-02, 1.73254536e-01, 4.93468371e-02, 1.63438110e-01,\n",
       "        9.75955763e-02, 2.43721406e-02, 2.21146483e-01, 7.17806357e-02,\n",
       "        2.15217057e-02, 5.80339080e-03, 6.18572158e-02, 1.13349401e-01,\n",
       "        4.50140053e-02, 5.60470670e-02, 1.28951486e-02, 7.42540521e-02,\n",
       "        2.91831332e-02, 2.49682182e-02, 1.11805902e-01, 1.46361801e-01,\n",
       "        5.03508765e-03, 4.40408226e-03, 1.83681057e-01, 3.92700773e-02,\n",
       "        4.53290594e-02, 4.93651268e-03, 1.00848140e-01, 2.96030589e-02,\n",
       "        7.91163808e-02, 1.79149357e-01, 1.25480061e-01, 3.35607498e-02,\n",
       "        5.82932219e-03, 2.58303967e-03, 1.62892763e-01, 2.78038467e-02,\n",
       "        1.84929095e-01, 9.07866943e-04, 9.85711389e-02, 1.82339387e-01,\n",
       "        1.03583949e-02, 1.44583446e-01, 1.36953754e-01, 4.23015943e-02,\n",
       "        6.85716610e-02, 1.32582771e-01, 8.49566435e-02, 3.75948009e-02,\n",
       "        2.23256632e-01, 8.65692540e-02, 1.90291700e-01, 4.08121960e-03,\n",
       "        7.29265105e-03, 1.46050575e-01, 7.57325426e-03, 5.67449389e-02,\n",
       "        2.39398381e-01, 3.30217734e-02, 1.16665484e-01, 1.30631124e-02,\n",
       "        1.57085286e-01, 2.07740538e-01, 2.32213313e-02, 1.35484479e-02,\n",
       "        1.89121132e-01, 2.35464476e-02, 1.15476721e-01, 2.03634863e-01,\n",
       "        4.41402581e-02, 2.87911734e-01, 2.78651540e-02, 1.42650108e-01,\n",
       "        1.74054422e-01, 6.02377488e-03, 3.72134598e-02, 4.72138602e-02,\n",
       "        2.13333182e-01, 1.65101516e-01, 1.41926224e-01, 1.26337634e-01,\n",
       "        7.20361329e-02, 1.46567079e-01, 9.78022694e-02, 4.01884342e-02,\n",
       "        1.83164052e-02, 1.40327415e-01, 3.20260336e-02, 7.66082668e-03,\n",
       "        3.31741838e-01, 1.25943076e-02, 2.41542762e-01, 8.20016352e-02,\n",
       "        1.34942532e-01, 1.11184525e-01, 1.46114428e-02, 1.44552214e-01,\n",
       "        1.45770520e-01, 1.43949079e-01, 9.53791560e-02, 1.68121364e-02,\n",
       "        2.55530232e-01, 9.67765553e-03, 1.91959745e-01, 1.69286939e-01,\n",
       "        1.58796194e-01, 1.19051474e-01, 2.35509359e-02, 1.96979189e-01,\n",
       "        2.60855243e-02, 1.44594151e-01, 2.00858075e-01, 1.08628429e-01,\n",
       "        1.03488019e-01, 9.16348895e-02, 1.91707647e-01, 1.91169305e-01,\n",
       "        3.18919300e-01, 2.94565267e-01, 1.93842531e-01, 2.48951483e-01,\n",
       "        2.62266655e-01, 1.77215494e-01, 4.64352280e-02, 2.04505689e-01,\n",
       "        1.26536574e-01, 1.74288601e-01, 1.52682841e-01, 1.08699264e-01,\n",
       "        2.55019284e-01, 1.32634084e-01, 2.15724969e-01, 1.50920025e-01,\n",
       "        1.52451874e-01, 1.72469409e-01, 5.28060086e-02, 2.33437745e-01,\n",
       "        7.16337884e-03, 2.22560182e-01, 3.07793922e-02, 5.02561626e-02,\n",
       "        2.35239808e-01, 3.00604463e-02, 1.94958232e-01, 1.44888450e-01,\n",
       "        1.14404429e-01, 1.87965775e-01, 3.64786931e-03, 5.66916520e-03,\n",
       "        8.41101161e-02, 2.96522827e-02, 2.24639835e-01, 5.96935461e-03,\n",
       "        1.84235366e-01, 8.05319065e-02, 3.35609153e-04, 1.43181629e-02,\n",
       "        5.57440876e-03, 4.46563308e-02, 5.60069741e-02, 1.85152259e-01,\n",
       "        1.29518108e-02, 4.67693939e-03, 2.11680077e-01, 7.22753670e-02,\n",
       "        1.84449900e-01, 2.05416731e-02, 2.04939293e-01, 1.62314098e-02,\n",
       "        6.56650457e-02, 2.83118576e-02, 2.15890917e-02, 1.93791997e-01,\n",
       "        1.05257498e-02, 4.52580149e-02, 1.75877800e-01, 6.63306478e-02,\n",
       "        1.72209068e-01, 8.44372715e-02, 5.23618628e-02, 1.90210712e-01,\n",
       "        4.68992346e-02, 1.94847299e-01, 6.88017077e-02, 4.81656136e-02,\n",
       "        1.82569919e-01, 5.51881095e-03, 2.09441328e-01, 9.75187867e-02,\n",
       "        1.81773020e-01, 1.58059914e-02, 1.04229985e-02, 1.67086903e-01,\n",
       "        6.00877608e-02, 1.72917719e-01, 1.80498203e-02, 2.89866139e-01,\n",
       "        4.97617473e-03, 4.45943269e-02, 1.37502612e-01, 1.03464674e-01,\n",
       "        1.65761317e-01, 1.15368427e-02, 8.19271021e-02, 2.38901682e-01,\n",
       "        6.81546248e-03, 1.87987676e-01, 8.13016972e-02, 6.08383779e-02,\n",
       "        2.60899266e-02, 7.98966499e-03, 1.88082276e-01, 1.52086142e-02,\n",
       "        1.86455611e-01, 2.61242287e-02, 1.23448944e-01, 1.61483859e-01,\n",
       "        1.54906343e-02, 1.87187840e-01, 1.23242995e-01, 4.81990936e-03,\n",
       "        1.87723600e-02, 3.54281571e-02, 3.55080407e-01, 1.02416064e-02,\n",
       "        1.81976283e-01, 1.20473738e-02, 1.00797032e-01, 1.65513516e-01,\n",
       "        3.16753056e-03, 1.89186697e-01, 1.25284656e-01, 1.09752941e-02,\n",
       "        2.75508765e-02, 6.82149384e-03, 1.88437224e-01, 3.47869425e-02,\n",
       "        3.27718205e-01, 1.61053006e-02, 1.36750858e-02, 1.95618462e-01,\n",
       "        1.21871468e-02, 1.64553794e-01, 1.59205721e-01, 4.04381799e-02,\n",
       "        1.60096809e-01, 6.18488901e-02, 1.67557537e-01, 1.04620173e-01,\n",
       "        1.67300006e-01, 7.54639256e-03, 1.16965486e-01, 1.87535171e-01,\n",
       "        1.24087587e-02, 1.87433294e-01, 1.61411839e-02, 2.01799079e-01,\n",
       "        1.57910178e-02, 9.55404119e-03, 3.41761869e-01, 3.29456194e-02,\n",
       "        1.70951756e-01, 1.22707880e-01, 3.57148842e-02, 1.09135005e-01,\n",
       "        8.40477020e-02, 1.61328342e-01, 1.75566516e-01, 3.68979365e-02,\n",
       "        1.12829144e-01, 2.89616012e-01, 1.94578483e-01, 8.15536726e-02,\n",
       "        1.49877931e-01, 5.08435080e-02, 8.96575967e-02, 1.72660569e-01,\n",
       "        9.46825823e-02, 1.76104831e-01, 1.02698778e-02, 9.79461355e-03,\n",
       "        1.98388451e-01, 2.95034270e-03, 1.91953578e-01, 7.59145196e-03,\n",
       "        4.82848491e-03, 7.12733766e-03, 2.82346191e-02, 1.36453930e-02,\n",
       "        6.17300000e-03, 2.27688601e-01, 1.02295152e-02, 1.30961198e-02,\n",
       "        4.78972272e-02, 2.40708007e-02, 2.28637280e-01, 7.92787100e-03,\n",
       "        2.06261773e-03, 2.33651045e-01, 3.61934518e-02, 2.08554147e-01,\n",
       "        1.27541940e-02, 2.07114875e-01, 7.93414455e-03, 5.48878871e-03,\n",
       "        2.34068727e-01, 4.55609050e-03, 1.28764367e-02, 7.46224045e-03,\n",
       "        5.83680219e-03, 1.34901339e-02, 4.05949133e-02, 2.04283439e-01,\n",
       "        1.02554158e-02, 5.76863522e-03, 2.34272532e-01, 2.28990142e-02,\n",
       "        1.57390572e-01, 5.53232356e-03, 2.89946219e-03, 2.19666001e-01,\n",
       "        1.48255472e-02, 3.66555367e-02, 4.18334091e-02, 1.30126930e-03,\n",
       "        2.19208788e-01, 6.42417487e-03, 5.53727018e-03, 1.49209091e-01,\n",
       "        1.24291691e-02, 2.00936759e-02, 5.86889792e-03, 2.47345205e-03,\n",
       "        1.65338107e-01, 1.50534410e-02, 1.96451355e-01, 7.84524299e-03,\n",
       "        2.97215802e-02, 7.38537695e-02, 6.71962666e-02, 1.98401151e-01,\n",
       "        3.75776914e-03, 4.76201103e-03, 1.94314666e-01, 6.74670862e-02,\n",
       "        2.68056499e-02, 6.05888575e-03, 4.80876080e-03, 2.08672303e-01,\n",
       "        5.52636058e-02, 1.85265117e-01, 5.26032820e-02, 1.95387757e-02,\n",
       "        4.88608388e-03, 5.49791537e-02, 2.06551887e-01, 1.73821023e-02,\n",
       "        6.58850551e-03, 2.26319755e-01, 9.49386071e-02, 3.04672811e-02,\n",
       "        1.36171752e-02, 8.67851952e-03, 2.27927928e-01, 8.75128194e-02,\n",
       "        1.68379853e-01, 1.08000268e-02, 6.47718028e-03, 1.44518827e-02,\n",
       "        1.26562332e-02, 1.74108463e-01, 2.92690784e-02, 2.51635014e-02,\n",
       "        2.48536198e-01, 1.19953352e-01, 4.45291793e-02, 7.60030387e-02,\n",
       "        1.63959225e-01, 2.48947101e-01, 5.95896125e-02, 2.27468193e-01,\n",
       "        2.41077334e-01, 9.63296908e-02, 2.20769965e-01, 4.59845390e-03,\n",
       "        4.07264642e-01, 1.30671097e-01, 2.77560437e-01, 3.54691672e-01,\n",
       "        9.20478132e-02, 1.75867526e-01, 4.83247848e-01, 2.13949121e-01,\n",
       "        1.66843388e-01, 3.74847708e-02, 2.47678972e-01, 2.67688386e-01,\n",
       "        2.69228049e-02, 2.74711805e-01, 2.17066983e-02, 8.22955431e-02,\n",
       "        5.13869548e-01, 2.50383519e-02, 2.76235181e-01, 2.65361967e-02,\n",
       "        1.51498561e-02, 2.76602322e-01, 4.08809448e-03, 1.44174338e-01,\n",
       "        2.51160442e-01, 1.43241326e-01, 2.49444485e-01, 6.06686008e-02,\n",
       "        2.41188599e-01, 4.45946065e-02]),\n",
       " 'mean_score_time': array([0.29168344, 0.17011444, 0.19209584, 0.32034683, 0.19416857,\n",
       "        0.19814404, 0.193103  , 0.32152788, 0.1877478 , 0.31779075,\n",
       "        0.20338019, 0.21639148, 0.3170011 , 0.20812805, 0.20275164,\n",
       "        0.23193868, 0.33019598, 0.21114349, 0.21782947, 0.23147655,\n",
       "        0.21326852, 0.21712931, 0.21067254, 0.34597739, 0.21403543,\n",
       "        0.21913624, 0.20924338, 0.22024306, 0.21412826, 0.207244  ,\n",
       "        0.2107265 , 0.34809065, 0.21169798, 0.20791284, 0.20590202,\n",
       "        0.24964698, 0.21533473, 0.20840184, 0.20142293, 0.22226977,\n",
       "        0.20915643, 0.20744348, 0.22063208, 0.23304971, 0.21223386,\n",
       "        0.21018902, 0.33494782, 0.21634595, 0.21175496, 0.24473588,\n",
       "        0.21396454, 0.2237494 , 0.21431486, 0.21552308, 0.22896934,\n",
       "        0.21370737, 0.21406825, 0.21568823, 0.21037316, 0.20943228,\n",
       "        0.21957699, 0.21149095, 0.23940738, 0.22394331, 0.211634  ,\n",
       "        0.22148148, 0.22346441, 0.21179557, 0.22740587, 0.33298373,\n",
       "        0.22793221, 0.21346935, 0.21565247, 0.2414    , 0.21234886,\n",
       "        0.22725582, 0.23262842, 0.2313114 , 0.30100592, 0.24110953,\n",
       "        0.22852763, 0.25930587, 0.22681618, 0.22284047, 0.22204304,\n",
       "        0.21407437, 0.24725048, 0.21776843, 0.21631861, 0.24648817,\n",
       "        0.22656171, 0.21897252, 0.24354744, 0.23219252, 0.34504779,\n",
       "        0.21378326, 0.21551975, 0.21610578, 0.21265777, 0.23411671,\n",
       "        0.21222289, 0.21455137, 0.23205535, 0.21555877, 0.22052328,\n",
       "        0.21518143, 0.21497424, 0.21728357, 0.21850538, 0.23232309,\n",
       "        0.21554931, 0.25384649, 0.21921015, 0.21864088, 0.23569703,\n",
       "        0.21301468, 0.2167623 , 0.21643472, 0.21256955, 0.21385074,\n",
       "        0.22476125, 0.22316368, 0.21698006, 0.2288239 , 0.21924488,\n",
       "        0.23460039, 0.25736094, 0.21826784, 0.2239755 , 0.22169216,\n",
       "        0.21165752, 0.21441031, 0.22256557, 0.21403869, 0.21564388,\n",
       "        0.18625355, 0.1955634 , 0.18541916, 0.18373322, 0.20171905,\n",
       "        0.18506527, 0.1998779 , 0.22604744, 0.21418333, 0.212943  ,\n",
       "        0.24785272, 0.23591296, 0.21315241, 0.22564157, 0.3480684 ,\n",
       "        0.21282689, 0.18663367, 0.1880188 , 0.18980161, 0.19211888,\n",
       "        0.21569562, 0.31910443, 0.19133313, 0.18064173, 0.19196868,\n",
       "        0.18920112, 0.19105983, 0.18211794, 0.18522429, 0.19440667,\n",
       "        0.1906325 , 0.1866564 , 0.31635261, 0.18737721, 0.20609681,\n",
       "        0.18976204, 0.18864028, 0.18750008, 0.18413528, 0.34639088,\n",
       "        0.18869861, 0.1786809 , 0.18441812, 0.18763423, 0.21157559,\n",
       "        0.19125493, 0.18713442, 0.19240491, 0.19822272, 0.19277525,\n",
       "        0.18778054, 0.19211984, 0.56069509, 0.20048062, 0.2119387 ,\n",
       "        0.21784671, 0.20223467, 0.19511628, 0.19584775, 0.21746111,\n",
       "        0.19522937, 0.32382226, 0.20355113, 0.20060436, 0.19585896,\n",
       "        0.18936467, 0.22772527, 0.19703341, 0.1874481 , 0.19143136,\n",
       "        0.33441456, 0.20322363, 0.19794575, 0.18887854, 0.22782993,\n",
       "        0.1912694 , 0.19744539, 0.20634397, 0.21506739, 0.34193826,\n",
       "        0.21880396, 0.23792791, 0.22085706, 0.23299122, 0.22930654,\n",
       "        0.2176013 , 0.23884519, 0.21773068, 0.36617819, 0.21270553,\n",
       "        0.22021262, 0.42523042, 0.24334963, 0.28240331, 0.26666975,\n",
       "        0.23624277, 0.23700929, 0.26044051, 0.38747064, 0.23867075,\n",
       "        0.23025497, 0.23967926, 0.23440663, 0.28171237, 0.23751593,\n",
       "        0.47606556, 0.25065311, 0.4411389 , 0.25402284, 0.25403214,\n",
       "        0.23589007, 0.25795976, 0.24009856, 0.26450737, 0.40630492,\n",
       "        0.25514674, 0.2365586 , 0.25479952, 0.23848836, 0.24306631,\n",
       "        0.23475091, 0.40525293, 0.23473374, 0.23582888, 0.26046348,\n",
       "        0.24212742, 0.30560009, 0.24326158, 0.21774999, 0.23607779,\n",
       "        0.35963583, 0.20923106, 0.212279  , 0.37366454, 0.20686849,\n",
       "        0.17998052, 0.19694638, 0.19206206, 0.18660251, 0.17535416,\n",
       "        0.17237345, 0.18398046, 0.33941809, 0.17526968, 0.30872949,\n",
       "        0.16626795, 0.17018414, 0.31631192, 0.19841973, 0.30803625,\n",
       "        0.19739493, 0.17156943, 0.16916299, 0.20976567, 0.17299326,\n",
       "        0.18573451, 0.16831104, 0.17164755, 0.17131066, 0.1912322 ,\n",
       "        0.17166082, 0.17234365, 0.17406805, 0.16877302, 0.16906158,\n",
       "        0.18296178, 0.17336138, 0.30062842, 0.16991154, 0.16762257,\n",
       "        0.16746736, 0.19199038, 0.30494555, 0.17473396, 0.16831326,\n",
       "        0.16967781, 0.17013399, 0.18603373, 0.17236026, 0.16871564,\n",
       "        0.17711433, 0.1674219 , 0.17362261, 0.18002121, 0.17271511,\n",
       "        0.17315793, 0.16824619, 0.1804204 , 0.20279733, 0.17572522,\n",
       "        0.32757123, 0.18442885, 0.21817406, 0.22968276, 0.2282788 ,\n",
       "        0.19973882, 0.23525222, 0.36505254, 0.20680221, 0.18756485,\n",
       "        0.17851679, 0.19038582, 0.18002772, 0.1771667 , 0.17315292,\n",
       "        0.17096575, 0.17268872, 0.18000301, 0.17308124, 0.16983517,\n",
       "        0.17475033, 0.29766242, 0.22737447, 0.3052814 , 0.17239634,\n",
       "        0.17383901, 0.31092691, 0.1942064 , 0.30956006, 0.18430408,\n",
       "        0.1693809 , 0.1718301 , 0.17795499, 0.22297629, 0.19073105,\n",
       "        0.19425583, 0.18754784, 0.21424898, 0.18258349, 0.18210403,\n",
       "        0.17568644, 0.19505692, 0.18170365, 0.18023562, 0.17492278,\n",
       "        0.1984907 , 0.17672666, 0.17667445, 0.1815296 , 0.35172367,\n",
       "        0.17975895, 0.17274539, 0.1808362 , 0.18334405, 0.17567873,\n",
       "        0.17847641, 0.17209872, 0.17786646, 0.18402354, 0.18429073,\n",
       "        0.17316683, 0.17833487, 0.19704318, 0.17553767, 0.17967669,\n",
       "        0.17680415, 0.18273759, 0.17529424, 0.17852465, 0.31638304,\n",
       "        0.20729589, 0.18299572, 0.17607864, 0.18805424, 0.23561454,\n",
       "        0.18673118, 0.18485061, 0.21231071, 0.1953067 , 0.30797656,\n",
       "        0.22481378, 0.3619744 , 0.26282271, 0.36404363, 0.22422759,\n",
       "        0.21829613, 0.38729262, 0.21323291, 0.35107652, 0.22489818,\n",
       "        0.21294522, 0.21594898, 0.21517793, 0.22741985, 0.21005392,\n",
       "        0.35489861, 0.21219095, 0.39003873, 0.21629492, 0.22308842,\n",
       "        0.20925109, 0.26589274, 0.33864864, 0.21157424, 0.21234838,\n",
       "        0.26529288, 0.20954315, 0.21000711, 0.22348102, 0.22126023,\n",
       "        0.21525542, 0.21105822, 0.22434608, 0.21868626, 0.34000826,\n",
       "        0.23654151, 0.39680338, 0.22488999, 0.22674044, 0.23308078,\n",
       "        0.25433588, 0.20921151, 0.21447039, 0.35005824, 0.21670938,\n",
       "        0.21447706, 0.37227146, 0.21457322, 0.35766252, 0.23560532,\n",
       "        0.21302231, 0.21174391, 0.22412642, 0.34551263, 0.22043649,\n",
       "        0.37864733, 0.21326272, 0.22340902, 0.22509034, 0.21601892,\n",
       "        0.24167744, 0.21232963, 0.21349827, 0.23553006, 0.35998956,\n",
       "        0.22322599, 0.26636998, 0.25415595, 0.2544322 , 0.21749099,\n",
       "        0.25385221, 0.21532671, 0.22118044, 0.22096626, 0.34724251,\n",
       "        0.2192409 , 0.36487707, 0.2128373 , 0.23359386, 0.21912162,\n",
       "        0.21481943, 0.23709345, 0.2660803 , 0.22196118, 0.24295481,\n",
       "        0.21946112, 0.22037768, 0.21440069, 0.21709903, 0.22633044,\n",
       "        0.35815366, 0.21224364, 0.21506421, 0.24752967, 0.25538794,\n",
       "        0.21343025, 0.26752861, 0.2147429 , 0.21920506, 0.22031633,\n",
       "        0.23708081, 0.271619  , 0.35752217, 0.22783701, 0.2386229 ,\n",
       "        0.21585433, 0.23140216, 0.29401207, 0.26993704, 0.29891109,\n",
       "        0.22228932, 0.21687547, 0.22074731, 0.21447412, 0.35656238,\n",
       "        0.21859161, 0.24663115, 0.25280531, 0.21444345, 0.23868299,\n",
       "        0.23837598, 0.25150545, 0.2206769 , 0.21140424, 0.23155991,\n",
       "        0.21190103, 0.35158674, 0.21509735, 0.22173055, 0.22237937,\n",
       "        0.21911558, 0.21741136, 0.21173859, 0.22733625, 0.21821284,\n",
       "        0.19543338, 0.18061892, 0.18537951, 0.33556191, 0.21789336,\n",
       "        0.21470237, 0.2064147 , 0.19091733, 0.18677807, 0.22872972,\n",
       "        0.31969428, 0.18250291, 0.18686851, 0.33443594, 0.23795756,\n",
       "        0.18724847, 0.18532062, 0.18532817, 0.18394566, 0.23332802,\n",
       "        0.18171748, 0.18415181, 0.18279187, 0.17869902, 0.22700318,\n",
       "        0.32955003, 0.18417176, 0.18407281, 0.18875233, 0.19723662,\n",
       "        0.19050694, 0.22013028, 0.20773403, 0.22628554, 0.1926345 ,\n",
       "        0.18298984, 0.19239354, 0.17832025, 0.22235711, 0.19086456,\n",
       "        0.18330868, 0.18500535, 0.18076952, 0.226547  , 0.18721644,\n",
       "        0.18893321, 0.19356267, 0.21640444, 0.19343193, 0.19095008,\n",
       "        0.19225796, 0.40201132, 0.22466143, 0.20977608, 0.2009418 ,\n",
       "        0.19484345, 0.19178128, 0.19148469, 0.19875622, 0.18774962,\n",
       "        0.18696547, 0.1818552 , 0.22902481, 0.32679653, 0.18983865,\n",
       "        0.18529209, 0.20542256, 0.18920636, 0.1868434 , 0.19361774,\n",
       "        0.20513066, 0.1907866 , 0.18881583, 0.18661586, 0.19895355,\n",
       "        0.33479802, 0.18840766, 0.19680421, 0.21133478, 0.19416992,\n",
       "        0.18661292, 0.18843055, 0.19390416, 0.18750318, 0.18728495,\n",
       "        0.1936655 , 0.20303122, 0.34187476, 0.18484584, 0.19251378,\n",
       "        0.19624551, 0.19741551, 0.19944414, 0.19053896, 0.19061335,\n",
       "        0.20539967, 0.19141952, 0.18994459, 0.21882804, 0.34573738,\n",
       "        0.23334964, 0.19578369, 0.19429588, 0.19536908, 0.2108806 ,\n",
       "        0.19246499, 0.20672139, 0.19371716, 0.20765893, 0.19339355,\n",
       "        0.19428666, 0.3371675 , 0.19269586, 0.19000713, 0.20453922,\n",
       "        0.19168997, 0.19167693, 0.19502536, 0.20060666, 0.23806063,\n",
       "        0.19625036, 0.19042985, 0.21727022, 0.33670878, 0.20946884,\n",
       "        0.22685099, 0.20859599, 0.22641818, 0.19074289, 0.1963977 ,\n",
       "        0.23612134, 0.19345586, 0.2027576 , 0.34276398, 0.19393873,\n",
       "        0.16967893, 0.18547479, 0.17444348, 0.16894428, 0.16805323,\n",
       "        0.32695961, 0.16288273, 0.22061435, 0.3167069 , 0.17433469,\n",
       "        0.17075777, 0.16788793, 0.31777541, 0.1883591 , 0.1759665 ,\n",
       "        0.16666563, 0.16613483, 0.16527414, 0.16612172, 0.19598103,\n",
       "        0.16590031, 0.17369954, 0.165718  , 0.16341821, 0.16889087,\n",
       "        0.19523493, 0.17043209, 0.32139007, 0.16636809, 0.1704913 ,\n",
       "        0.33507419, 0.21153053, 0.171194  , 0.16916243, 0.16750526,\n",
       "        0.1623923 , 0.17993569, 0.19326814, 0.16876682, 0.17145944,\n",
       "        0.16921123, 0.16494028, 0.30761751, 0.20292926, 0.17232196,\n",
       "        0.17012644, 0.17498978, 0.17423209, 0.18873763, 0.17557112,\n",
       "        0.32436403, 0.17619999, 0.16973623, 0.20260692, 0.17665124,\n",
       "        0.16837883, 0.16893291, 0.32661295, 0.20112642, 0.17648538,\n",
       "        0.17308768, 0.17309888, 0.16895413, 0.18102185, 0.1847535 ,\n",
       "        0.32614994, 0.17780566, 0.16976484, 0.16614326, 0.2017138 ,\n",
       "        0.17195463, 0.18282104, 0.32717331, 0.17159669, 0.21681341,\n",
       "        0.16959977, 0.17390156, 0.17143544, 0.16930207, 0.21733658,\n",
       "        0.32836866, 0.17811259, 0.17277455, 0.16748412, 0.17760547,\n",
       "        0.17774121, 0.18391633, 0.32867312, 0.1695706 , 0.18352207,\n",
       "        0.20868866, 0.18322786, 0.1920623 , 0.20014358, 0.19326973,\n",
       "        0.34010164, 0.22368137, 0.19864249, 0.22247569, 0.18563135,\n",
       "        0.19081664, 0.22053464, 0.17654792, 0.16837112, 0.17412535,\n",
       "        0.21521966, 0.22844752, 0.31618977, 0.21276943, 0.2066892 ,\n",
       "        0.22653238, 0.39986865, 0.36163759, 0.30797815, 0.27972213,\n",
       "        0.28248803, 0.30949481, 0.30172745, 0.32550462, 0.28203543,\n",
       "        0.2837019 , 0.29060404, 0.3017242 , 0.33343879, 0.29006449,\n",
       "        0.30640825, 0.28739222, 0.28997183, 0.31546712, 0.28322506,\n",
       "        0.28867507, 0.2728165 , 0.27673864, 0.31507786, 0.28761411]),\n",
       " 'std_score_time': array([1.63605956e-01, 2.21081459e-03, 5.71143932e-03, 1.74513929e-01,\n",
       "        2.68780988e-03, 9.08886529e-04, 3.04847691e-03, 1.87451547e-01,\n",
       "        2.61239371e-03, 1.83401007e-01, 5.97377845e-03, 1.13851103e-02,\n",
       "        1.60877904e-01, 4.97072095e-03, 1.89172708e-03, 2.45754001e-02,\n",
       "        1.62634777e-01, 4.06853109e-03, 9.26026314e-03, 2.93219989e-02,\n",
       "        4.12882762e-03, 4.15722454e-03, 4.50469137e-03, 1.53412873e-01,\n",
       "        1.26710180e-03, 1.49628124e-02, 1.74039601e-03, 9.29129197e-03,\n",
       "        6.85300133e-04, 6.02730973e-03, 3.55387237e-03, 1.57787315e-01,\n",
       "        6.03265355e-04, 1.93309190e-03, 4.56637319e-03, 2.50592001e-02,\n",
       "        3.53501218e-03, 1.05299948e-03, 3.93208624e-03, 1.22910127e-02,\n",
       "        2.03495819e-03, 1.73673629e-03, 1.51862780e-02, 2.80347410e-02,\n",
       "        5.60837790e-03, 2.89956984e-03, 1.55546432e-01, 3.64302109e-03,\n",
       "        2.83597874e-03, 4.13945698e-02, 6.81699503e-04, 1.48164143e-02,\n",
       "        1.54114006e-03, 2.96477967e-03, 2.71756800e-02, 1.45019094e-03,\n",
       "        4.64502104e-03, 7.15175197e-03, 3.04172406e-03, 1.62647384e-03,\n",
       "        5.29100848e-03, 2.14570620e-03, 3.80231815e-02, 6.07776587e-03,\n",
       "        6.08642189e-04, 1.35208619e-02, 1.38250342e-02, 3.91639517e-03,\n",
       "        1.83215450e-02, 1.63462239e-01, 1.87105640e-02, 4.91543501e-03,\n",
       "        5.22206042e-03, 3.71768861e-02, 1.25088219e-03, 1.26923273e-02,\n",
       "        7.99585819e-03, 1.41555215e-02, 9.71942822e-02, 1.91149832e-02,\n",
       "        7.25205662e-03, 2.93458870e-02, 5.33561787e-03, 1.43717663e-02,\n",
       "        4.58720572e-03, 1.31684892e-03, 4.81418158e-02, 3.84303338e-03,\n",
       "        2.72528457e-03, 1.35436188e-02, 1.65564216e-02, 4.16965538e-03,\n",
       "        1.81552365e-02, 1.00016313e-02, 1.59942900e-01, 3.34052127e-03,\n",
       "        3.27295422e-03, 2.93178694e-03, 4.90215226e-03, 2.25515898e-02,\n",
       "        3.37788624e-03, 6.52133457e-03, 2.48203803e-02, 4.33067372e-03,\n",
       "        4.06773908e-03, 4.21133080e-04, 2.87075386e-03, 1.88229596e-03,\n",
       "        1.00505960e-02, 2.61170077e-02, 3.04026368e-03, 5.25625305e-02,\n",
       "        5.07899970e-03, 7.87071879e-03, 2.43825866e-02, 3.06408041e-03,\n",
       "        3.10504976e-03, 3.68792332e-03, 7.83723160e-04, 2.52533459e-03,\n",
       "        8.93186485e-03, 7.42658913e-03, 3.33976242e-03, 1.25529225e-02,\n",
       "        7.39323580e-04, 2.83708582e-02, 5.79362673e-02, 1.16369690e-03,\n",
       "        1.73788065e-02, 6.20970550e-03, 2.28574358e-03, 1.09050528e-03,\n",
       "        2.66357385e-03, 1.37884632e-03, 6.62036366e-03, 8.77270331e-03,\n",
       "        1.03380138e-02, 2.22000162e-03, 6.60313936e-03, 7.34387387e-03,\n",
       "        1.22199819e-02, 8.34323592e-03, 3.20099571e-02, 1.68845811e-02,\n",
       "        8.56166639e-03, 6.45818534e-02, 3.17193791e-02, 2.79453966e-03,\n",
       "        6.29803923e-03, 1.68210487e-01, 2.91875246e-02, 6.29487554e-03,\n",
       "        2.53962098e-03, 3.32467559e-03, 1.57395119e-02, 3.36670327e-02,\n",
       "        1.86042383e-01, 1.16675168e-03, 7.71639729e-03, 1.13931732e-02,\n",
       "        3.16569845e-03, 2.45100358e-03, 7.44964104e-03, 1.06308630e-03,\n",
       "        1.59514875e-02, 3.62387509e-03, 3.93177145e-03, 1.94694485e-01,\n",
       "        3.73025252e-04, 1.53801819e-02, 2.81159370e-03, 7.22403309e-03,\n",
       "        1.95827450e-03, 1.41017287e-03, 1.75786538e-01, 2.14257880e-03,\n",
       "        3.99457895e-03, 7.18654513e-04, 7.97130844e-03, 2.45789251e-02,\n",
       "        1.74012819e-03, 3.56829722e-03, 1.76864180e-03, 3.87479571e-03,\n",
       "        1.15462103e-03, 1.96635482e-03, 2.21986998e-03, 4.73679446e-01,\n",
       "        1.97582389e-03, 1.69547770e-02, 1.73347384e-02, 3.53124129e-03,\n",
       "        3.54156574e-03, 5.86053333e-04, 3.23847332e-02, 2.38628271e-03,\n",
       "        1.80623806e-01, 1.89177265e-02, 4.77857004e-03, 4.43073100e-03,\n",
       "        1.23004473e-03, 3.30699232e-02, 1.97432786e-03, 5.16608409e-03,\n",
       "        2.18715183e-03, 1.70491326e-01, 9.37106064e-03, 7.00271559e-03,\n",
       "        5.17976498e-03, 5.38391917e-02, 3.52339525e-03, 5.30725362e-03,\n",
       "        6.03809373e-03, 5.25385678e-03, 1.83030016e-01, 4.54003251e-03,\n",
       "        2.92894918e-02, 1.25432433e-02, 2.48360166e-02, 2.72235124e-02,\n",
       "        4.50257846e-03, 2.70636536e-02, 1.87049639e-03, 1.66848636e-01,\n",
       "        3.58635992e-03, 5.96765441e-03, 2.71536501e-01, 1.45104617e-02,\n",
       "        2.83702761e-02, 2.86177789e-02, 2.09800374e-03, 6.79512835e-03,\n",
       "        5.72872250e-03, 2.21317739e-01, 5.53962434e-03, 3.46313138e-03,\n",
       "        3.34573872e-03, 2.63566430e-03, 6.87769584e-02, 4.01290512e-03,\n",
       "        2.86472668e-01, 6.35356554e-03, 2.73240299e-01, 5.41312980e-03,\n",
       "        1.37193546e-02, 7.37934462e-04, 1.65878076e-02, 3.30385295e-03,\n",
       "        3.42794288e-02, 2.28902721e-01, 2.51103866e-02, 2.29841377e-03,\n",
       "        2.08657696e-02, 1.42830517e-03, 1.84685902e-02, 5.11741384e-03,\n",
       "        2.04216336e-01, 4.74215866e-04, 7.05108090e-03, 3.54197035e-02,\n",
       "        1.96528777e-02, 1.05909544e-01, 1.46742890e-02, 1.15126519e-02,\n",
       "        1.02303809e-02, 1.83579235e-01, 2.53109387e-03, 5.96494152e-03,\n",
       "        2.32262509e-01, 5.26578808e-04, 5.06734193e-03, 3.07526261e-03,\n",
       "        5.04023021e-03, 9.07363953e-03, 3.48710966e-03, 4.48566657e-03,\n",
       "        1.55094445e-02, 1.67343054e-01, 1.89339181e-03, 1.94998725e-01,\n",
       "        3.70937397e-03, 4.93127128e-04, 1.89509129e-01, 3.23840838e-02,\n",
       "        1.92112775e-01, 7.80097292e-03, 7.65939847e-03, 1.83633482e-03,\n",
       "        3.10701481e-02, 1.81815203e-03, 1.59857218e-02, 2.65138155e-03,\n",
       "        3.90867698e-03, 3.69615999e-03, 2.32716532e-02, 1.01888124e-02,\n",
       "        4.67324104e-03, 3.25156158e-03, 3.32824062e-03, 1.83070490e-03,\n",
       "        7.59833607e-03, 1.91681595e-03, 1.82837159e-01, 2.50860206e-03,\n",
       "        3.19302271e-03, 2.28494392e-03, 9.01052656e-03, 1.90012355e-01,\n",
       "        1.84347801e-03, 2.20853748e-03, 8.54892304e-04, 1.19041174e-03,\n",
       "        3.48438724e-03, 1.69639911e-03, 1.19514611e-03, 2.50008933e-03,\n",
       "        1.05677737e-02, 7.86362350e-03, 4.12875896e-03, 5.22520986e-03,\n",
       "        1.81402049e-03, 6.17297662e-03, 1.24089981e-02, 4.23723107e-02,\n",
       "        3.54500137e-03, 1.97113187e-01, 1.50035518e-03, 1.95437417e-02,\n",
       "        3.62563763e-02, 7.94588689e-03, 1.60031553e-02, 3.48671575e-02,\n",
       "        1.81669097e-01, 3.85580296e-03, 7.86280637e-03, 4.10867695e-03,\n",
       "        1.81095859e-02, 1.31436312e-02, 6.40898720e-03, 3.68680408e-03,\n",
       "        2.20684630e-03, 6.04616198e-04, 4.43763844e-03, 3.38518374e-03,\n",
       "        7.15233834e-03, 7.47364809e-04, 1.85335437e-01, 5.37844986e-02,\n",
       "        1.83578405e-01, 3.03696967e-03, 2.03292424e-03, 2.05886337e-01,\n",
       "        2.03515638e-02, 1.89065486e-01, 2.12190342e-02, 5.65310717e-03,\n",
       "        2.17562995e-03, 9.98805058e-03, 2.79515540e-02, 1.12752410e-03,\n",
       "        2.30468148e-02, 5.79524700e-03, 5.06318513e-02, 2.08900787e-03,\n",
       "        1.23352517e-03, 3.01028149e-03, 1.30001114e-02, 3.61084048e-03,\n",
       "        1.51993272e-03, 8.77069158e-03, 1.51756877e-02, 4.54751632e-03,\n",
       "        2.34845989e-03, 1.79787398e-03, 1.59693526e-01, 1.59430190e-03,\n",
       "        3.42523444e-03, 1.33595529e-03, 1.17780496e-02, 1.82463710e-03,\n",
       "        2.54003637e-03, 5.77174888e-03, 1.71329128e-03, 6.92394280e-03,\n",
       "        1.29420933e-03, 6.50224131e-03, 2.20521296e-03, 1.10371498e-02,\n",
       "        2.33441721e-03, 4.69768742e-03, 4.32832970e-03, 3.19713580e-03,\n",
       "        9.04471277e-04, 3.45468371e-03, 1.93862606e-01, 3.93542403e-02,\n",
       "        2.80695876e-03, 6.38515092e-03, 7.35598555e-03, 4.73875297e-02,\n",
       "        4.31444085e-03, 2.58731640e-03, 5.20583247e-03, 7.72660492e-03,\n",
       "        1.83397467e-01, 1.98662799e-03, 2.04817710e-01, 3.75988150e-02,\n",
       "        1.99932631e-01, 5.99654787e-03, 3.79878166e-03, 2.42564536e-01,\n",
       "        1.58989808e-03, 1.99156358e-01, 1.56888458e-02, 5.31381390e-03,\n",
       "        1.50268352e-03, 5.21907172e-03, 1.65550254e-02, 6.27832765e-04,\n",
       "        2.01281494e-01, 2.50874322e-03, 2.10603659e-01, 7.34634958e-03,\n",
       "        1.20146290e-02, 5.15799055e-03, 3.23289076e-02, 1.77771351e-01,\n",
       "        1.99242891e-03, 2.93337307e-03, 4.90803038e-02, 1.97101017e-03,\n",
       "        5.74641737e-03, 1.57703833e-02, 1.78550729e-02, 6.97654609e-03,\n",
       "        4.09451218e-03, 2.99400693e-02, 6.15789330e-03, 1.90128934e-01,\n",
       "        1.16401387e-02, 2.02240091e-01, 8.35781387e-03, 1.24929862e-02,\n",
       "        1.89490925e-02, 4.97230297e-02, 3.90897919e-03, 1.85372567e-03,\n",
       "        1.89834241e-01, 3.53414844e-03, 4.30900705e-03, 1.94036117e-01,\n",
       "        4.30865858e-03, 2.00290029e-01, 2.75819376e-02, 1.09609441e-03,\n",
       "        1.33451290e-03, 8.29220744e-03, 1.87990581e-01, 3.90383887e-03,\n",
       "        1.83164232e-01, 2.92546122e-03, 1.36548586e-02, 1.40096492e-02,\n",
       "        3.68697009e-03, 3.40071807e-02, 1.91981900e-03, 6.06173745e-03,\n",
       "        2.43686575e-02, 1.97727664e-01, 1.44784211e-02, 1.58464411e-02,\n",
       "        1.15352091e-02, 2.50579331e-02, 5.86052287e-03, 5.68968617e-02,\n",
       "        2.11548896e-03, 1.33727624e-03, 1.02848667e-02, 1.82752590e-01,\n",
       "        3.83466624e-03, 1.91697171e-01, 2.50021421e-03, 1.80665315e-02,\n",
       "        2.78767900e-03, 1.79010558e-03, 1.98879658e-02, 3.25557394e-02,\n",
       "        6.30629090e-03, 3.22319804e-02, 3.89836897e-03, 9.97432994e-03,\n",
       "        4.39129350e-03, 6.87584986e-03, 3.63170357e-03, 2.02950821e-01,\n",
       "        2.63085982e-03, 8.60907279e-04, 4.54185479e-02, 5.79973752e-02,\n",
       "        2.35745887e-03, 6.90792967e-02, 2.16407313e-03, 6.51862735e-03,\n",
       "        6.06489769e-03, 2.95965951e-02, 4.31534299e-02, 2.01202206e-01,\n",
       "        2.25701362e-02, 2.30466586e-02, 2.01912565e-03, 2.16680533e-02,\n",
       "        6.10863060e-02, 3.54138776e-02, 4.22180828e-02, 8.98534960e-03,\n",
       "        3.18586051e-03, 6.08178304e-03, 2.78237766e-03, 1.83419502e-01,\n",
       "        4.37773414e-03, 4.39962193e-02, 4.73702235e-02, 4.20464171e-03,\n",
       "        3.04554756e-02, 7.50086170e-03, 4.71893599e-02, 1.29998766e-02,\n",
       "        3.19360333e-03, 2.11117130e-02, 2.40075600e-03, 1.93021221e-01,\n",
       "        2.71730160e-03, 8.21030112e-03, 9.95936041e-03, 3.45415182e-03,\n",
       "        5.46882320e-03, 2.34301890e-03, 1.16515670e-02, 5.65257899e-03,\n",
       "        1.91522772e-03, 6.28968400e-03, 1.13167352e-03, 2.14393418e-01,\n",
       "        4.37670435e-02, 4.87420117e-03, 8.15782582e-03, 1.02073028e-02,\n",
       "        6.86104397e-03, 4.22090397e-02, 1.91039194e-01, 2.54477971e-03,\n",
       "        5.44765335e-04, 2.17392022e-01, 3.41821256e-02, 6.02706846e-03,\n",
       "        2.79468950e-03, 1.76406185e-03, 3.49648031e-03, 3.26246736e-02,\n",
       "        7.81958260e-03, 2.63195543e-03, 3.30924808e-03, 2.84555077e-03,\n",
       "        3.06126901e-02, 1.99237095e-01, 2.28165328e-03, 3.74321994e-03,\n",
       "        3.30476633e-03, 3.07337909e-03, 7.56248491e-03, 1.69535885e-02,\n",
       "        3.38577625e-02, 6.12382023e-02, 5.27255223e-03, 4.94931151e-03,\n",
       "        6.15362267e-03, 5.95154366e-03, 3.15433545e-02, 2.88245610e-03,\n",
       "        4.55354669e-03, 2.25217475e-04, 7.75979805e-03, 3.72947722e-02,\n",
       "        8.37775657e-03, 2.73459893e-03, 3.94415459e-03, 4.52134362e-02,\n",
       "        1.29030915e-03, 5.70061697e-03, 2.02351317e-03, 2.08895446e-01,\n",
       "        7.43155238e-03, 1.15017179e-02, 1.44987794e-02, 2.36701013e-03,\n",
       "        1.96451658e-03, 1.73879519e-03, 8.59004596e-03, 3.09522042e-03,\n",
       "        1.56628386e-03, 4.65389906e-03, 5.71426979e-02, 1.91335444e-01,\n",
       "        4.97561962e-04, 1.36007077e-03, 1.56557749e-02, 3.92379602e-03,\n",
       "        5.58771738e-03, 4.15973251e-03, 1.85076020e-02, 2.70276789e-03,\n",
       "        2.97313144e-03, 5.33725461e-03, 1.21158704e-02, 2.02223880e-01,\n",
       "        3.68594363e-03, 6.65812564e-03, 1.40098456e-02, 1.49205186e-03,\n",
       "        4.90488947e-03, 5.00702726e-03, 1.00209165e-02, 1.86287144e-03,\n",
       "        1.31857211e-03, 1.64997302e-02, 1.69637216e-02, 2.16115372e-01,\n",
       "        7.74772356e-03, 5.53202251e-03, 3.10638946e-03, 6.05092390e-03,\n",
       "        8.92019568e-03, 2.96996798e-03, 4.54049912e-03, 1.05145353e-02,\n",
       "        2.87207404e-03, 1.20385021e-03, 3.68781364e-02, 2.16822586e-01,\n",
       "        5.36376571e-02, 3.86719512e-03, 2.80274317e-03, 9.33579321e-03,\n",
       "        2.69264260e-02, 2.62621072e-03, 1.29780585e-02, 1.05381523e-03,\n",
       "        2.08763730e-02, 3.03702721e-03, 2.28803915e-03, 2.09997605e-01,\n",
       "        2.95063131e-03, 1.59448150e-03, 1.50923479e-02, 1.10450002e-03,\n",
       "        1.45930872e-03, 4.25384441e-03, 9.40084222e-03, 2.50788072e-02,\n",
       "        1.40799156e-03, 2.66735294e-03, 2.17312347e-02, 1.96634618e-01,\n",
       "        1.36160283e-02, 3.25727653e-02, 5.50319649e-03, 4.33961013e-02,\n",
       "        4.83003555e-03, 3.00011845e-03, 6.07664855e-02, 3.35754932e-03,\n",
       "        1.01308589e-02, 2.06747748e-01, 2.67781362e-03, 4.37090130e-03,\n",
       "        1.37918085e-02, 1.11140467e-03, 3.64468534e-03, 2.78050417e-03,\n",
       "        2.17900257e-01, 3.59597353e-03, 3.50823942e-02, 2.08828780e-01,\n",
       "        7.80493953e-04, 1.86021981e-03, 3.68899458e-03, 2.10239740e-01,\n",
       "        2.71059824e-02, 9.37295871e-03, 5.13801752e-03, 4.84122174e-03,\n",
       "        4.03816283e-03, 3.71848468e-03, 2.50675929e-02, 7.89090662e-05,\n",
       "        3.00939846e-03, 3.28423167e-03, 5.96788654e-04, 3.29120895e-03,\n",
       "        2.93679446e-02, 1.32848368e-03, 2.16952982e-01, 4.44815959e-03,\n",
       "        1.05685949e-03, 2.24012901e-01, 4.71520988e-02, 3.79105714e-03,\n",
       "        1.77833499e-03, 2.31026708e-03, 3.38668563e-03, 1.50267197e-02,\n",
       "        3.83804980e-02, 1.42279214e-03, 2.78502087e-03, 5.16739113e-03,\n",
       "        2.96402719e-03, 1.94437561e-01, 2.99808559e-02, 9.77981761e-04,\n",
       "        1.53669144e-03, 1.66353877e-03, 3.20176201e-03, 1.12825972e-02,\n",
       "        2.04651100e-03, 2.16899103e-01, 1.84460123e-03, 1.70238130e-03,\n",
       "        4.35129291e-02, 2.99565252e-03, 5.84149906e-03, 1.13887164e-03,\n",
       "        2.13648328e-01, 3.97384002e-02, 4.76320088e-03, 3.76425073e-03,\n",
       "        1.02803309e-03, 1.47011751e-03, 1.66691230e-02, 8.59282004e-03,\n",
       "        2.16516818e-01, 2.62706802e-03, 2.27446406e-03, 2.55318021e-03,\n",
       "        1.94666567e-02, 5.41974016e-03, 1.02779975e-02, 2.16990450e-01,\n",
       "        3.52567548e-03, 3.86161037e-02, 4.75993503e-03, 2.89139991e-03,\n",
       "        1.97495596e-03, 3.03292444e-03, 4.16200844e-02, 2.19554726e-01,\n",
       "        3.80436536e-03, 2.67889609e-03, 1.31037853e-03, 9.97716461e-03,\n",
       "        6.84997796e-03, 6.89396823e-03, 2.18289569e-01, 1.67337400e-03,\n",
       "        9.20046975e-03, 4.29453969e-02, 8.05496800e-03, 2.57824416e-03,\n",
       "        1.46164299e-02, 1.08038833e-02, 2.32502937e-01, 5.31939312e-02,\n",
       "        1.47481562e-02, 2.28543865e-02, 8.52350432e-03, 1.02435293e-02,\n",
       "        3.60323352e-02, 1.24779476e-02, 3.49610044e-03, 2.72025300e-03,\n",
       "        2.68296372e-02, 5.97858949e-03, 4.58325621e-02, 2.90305663e-02,\n",
       "        3.19489496e-02, 2.01635076e-02, 8.72992602e-02, 1.00999973e-01,\n",
       "        2.83845956e-02, 1.88588021e-03, 3.36921270e-02, 5.98559839e-02,\n",
       "        2.72805146e-02, 6.50775652e-02, 1.23729237e-02, 1.61067037e-02,\n",
       "        6.77751699e-03, 1.65672490e-02, 6.90088186e-02, 5.81520581e-03,\n",
       "        2.70316115e-02, 7.75085172e-03, 7.60997789e-03, 3.63142082e-02,\n",
       "        1.07671010e-02, 1.04544470e-02, 7.94821483e-03, 6.14126668e-03,\n",
       "        2.88907681e-02, 5.64384725e-03]),\n",
       " 'param_activation': masked_array(data=['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_neurons': masked_array(data=[8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16,\n",
       "                    32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8,\n",
       "                    16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16,\n",
       "                    16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32, 32, 8, 8,\n",
       "                    8, 16, 16, 16, 32, 32, 32, 8, 8, 8, 16, 16, 16, 32, 32,\n",
       "                    32],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 16,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'}],\n",
       " 'split0_test_score': array([0.40723982, 0.44343892, 0.26244345, 0.47209653, 0.46455505,\n",
       "        0.30015084, 0.46606335, 0.46304676, 0.21568628, 0.48567119,\n",
       "        0.47511312, 0.27300152, 0.49472097, 0.49019608, 0.3152338 ,\n",
       "        0.4841629 , 0.46153846, 0.38914028, 0.4826546 , 0.48114631,\n",
       "        0.46153846, 0.49321267, 0.50829566, 0.45248869, 0.41327301,\n",
       "        0.45852187, 0.45399699, 0.44343892, 0.44494721, 0.47662142,\n",
       "        0.39215687, 0.48868778, 0.46153846, 0.42081448, 0.45248869,\n",
       "        0.4826546 , 0.44343892, 0.49019608, 0.49472097, 0.35143289,\n",
       "        0.42533937, 0.48717949, 0.39366516, 0.42081448, 0.4826546 ,\n",
       "        0.45701358, 0.44042233, 0.36651585, 0.49019608, 0.48114631,\n",
       "        0.30920061, 0.4826546 , 0.4826546 , 0.26244345, 0.50980395,\n",
       "        0.48717949, 0.26998493, 0.49924585, 0.49622926, 0.39969835,\n",
       "        0.48567119, 0.50226247, 0.46907994, 0.50226247, 0.49622926,\n",
       "        0.46606335, 0.42986426, 0.48567119, 0.48114631, 0.4494721 ,\n",
       "        0.49622926, 0.48567119, 0.48114631, 0.44193062, 0.47963801,\n",
       "        0.33634993, 0.34539971, 0.48567119, 0.37858221, 0.42383108,\n",
       "        0.47963801, 0.39819005, 0.49321267, 0.49170437, 0.37858221,\n",
       "        0.35444948, 0.4841629 , 0.42986426, 0.43891403, 0.47360483,\n",
       "        0.49773756, 0.4826546 , 0.34238312, 0.50075418, 0.47963801,\n",
       "        0.15987934, 0.4826546 , 0.49472097, 0.38461539, 0.49622926,\n",
       "        0.50075418, 0.44645551, 0.50226247, 0.49773756, 0.44494721,\n",
       "        0.49924585, 0.49924585, 0.45550528, 0.45399699, 0.4841629 ,\n",
       "        0.49622926, 0.47360483, 0.48868778, 0.49170437, 0.47662142,\n",
       "        0.48567119, 0.49019608, 0.4479638 , 0.43137255, 0.47963801,\n",
       "        0.42835596, 0.4162896 , 0.48114631, 0.46003017, 0.47511312,\n",
       "        0.47662142, 0.39969835, 0.42986426, 0.50377077, 0.40271494,\n",
       "        0.43589744, 0.48868778, 0.38763198, 0.49321267, 0.4826546 ,\n",
       "        0.42684767, 0.33484164, 0.173454  , 0.45399699, 0.4509804 ,\n",
       "        0.26998493, 0.44343892, 0.4494721 , 0.2413273 , 0.51432884,\n",
       "        0.50226247, 0.22021116, 0.49321267, 0.51432884, 0.34389141,\n",
       "        0.48567119, 0.49321267, 0.17797889, 0.43589744, 0.49170437,\n",
       "        0.4162896 , 0.44494721, 0.49321267, 0.47963801, 0.47058824,\n",
       "        0.4826546 , 0.46003017, 0.32579187, 0.42835596, 0.42684767,\n",
       "        0.42684767, 0.45701358, 0.48114631, 0.34389141, 0.49321267,\n",
       "        0.48567119, 0.4509804 , 0.46606335, 0.4841629 , 0.31975868,\n",
       "        0.47058824, 0.46606335, 0.41930619, 0.50075418, 0.47360483,\n",
       "        0.44494721, 0.43891403, 0.26395175, 0.46153846, 0.46606335,\n",
       "        0.29411766, 0.47812971, 0.50377077, 0.17647059, 0.50226247,\n",
       "        0.4841629 , 0.27752641, 0.49773756, 0.49019608, 0.27752641,\n",
       "        0.49622926, 0.47963801, 0.30165914, 0.45399699, 0.49924585,\n",
       "        0.4479638 , 0.4826546 , 0.50226247, 0.46003017, 0.4147813 ,\n",
       "        0.50829566, 0.45248869, 0.39517346, 0.49924585, 0.48114631,\n",
       "        0.44645551, 0.4147813 , 0.48567119, 0.44645551, 0.47511312,\n",
       "        0.49472097, 0.43891403, 0.47812971, 0.47058824, 0.35595778,\n",
       "        0.43137255, 0.47812971, 0.43740574, 0.46757165, 0.47662142,\n",
       "        0.48868778, 0.47963801, 0.23378582, 0.49170437, 0.48868778,\n",
       "        0.33182505, 0.49622926, 0.4841629 , 0.36048266, 0.50980395,\n",
       "        0.50377077, 0.39215687, 0.50678736, 0.50377077, 0.27149323,\n",
       "        0.48567119, 0.51432884, 0.42081448, 0.43288085, 0.50527906,\n",
       "        0.46757165, 0.47662142, 0.49622926, 0.47360483, 0.39064857,\n",
       "        0.48567119, 0.47812971, 0.4162896 , 0.46606335, 0.4841629 ,\n",
       "        0.43438914, 0.47511312, 0.49170437, 0.33333334, 0.4841629 ,\n",
       "        0.48717949, 0.41327301, 0.3800905 , 0.50075418, 0.43891403,\n",
       "        0.47058824, 0.47058824, 0.41176471, 0.43891403, 0.47360483,\n",
       "        0.23831071, 0.26093516, 0.25037709, 0.32126698, 0.31221721,\n",
       "        0.2428356 , 0.39517346, 0.35444948, 0.19457014, 0.47360483,\n",
       "        0.4826546 , 0.26998493, 0.49321267, 0.49321267, 0.22473605,\n",
       "        0.49019608, 0.48868778, 0.39215687, 0.4494721 , 0.50377077,\n",
       "        0.35294119, 0.47812971, 0.49472097, 0.41176471, 0.47209653,\n",
       "        0.49321267, 0.46606335, 0.4479638 , 0.49472097, 0.45852187,\n",
       "        0.43589744, 0.50377077, 0.43438914, 0.40422323, 0.41327301,\n",
       "        0.46003017, 0.46304676, 0.50377077, 0.44494721, 0.37405732,\n",
       "        0.46304676, 0.45701358, 0.47812971, 0.51131225, 0.44042233,\n",
       "        0.37104073, 0.346908  , 0.34539971, 0.42232278, 0.47812971,\n",
       "        0.23378582, 0.46003017, 0.46757165, 0.30316743, 0.48567119,\n",
       "        0.49019608, 0.22624435, 0.47963801, 0.4841629 , 0.33634993,\n",
       "        0.4841629 , 0.48717949, 0.19306184, 0.47511312, 0.50226247,\n",
       "        0.42533937, 0.51432884, 0.50829566, 0.46153846, 0.47812971,\n",
       "        0.50527906, 0.46304676, 0.41930619, 0.47812971, 0.42232278,\n",
       "        0.49622926, 0.50678736, 0.46455505, 0.43288085, 0.41327301,\n",
       "        0.47058824, 0.36651585, 0.49622926, 0.45248869, 0.43438914,\n",
       "        0.49924585, 0.46304676, 0.35746607, 0.47209653, 0.47511312,\n",
       "        0.43137255, 0.46153846, 0.23076923, 0.47812971, 0.47662142,\n",
       "        0.24434389, 0.48717949, 0.4826546 , 0.24434389, 0.49924585,\n",
       "        0.49622926, 0.25188538, 0.49773756, 0.49773756, 0.26546004,\n",
       "        0.47963801, 0.49472097, 0.18552037, 0.47511312, 0.50075418,\n",
       "        0.40422323, 0.44193062, 0.50226247, 0.49019608, 0.49924585,\n",
       "        0.49924585, 0.45399699, 0.50980395, 0.50527906, 0.4841629 ,\n",
       "        0.48868778, 0.49170437, 0.49472097, 0.36802414, 0.47511312,\n",
       "        0.4826546 , 0.49019608, 0.46455505, 0.48114631, 0.39517346,\n",
       "        0.48717949, 0.4841629 , 0.44193062, 0.43740574, 0.49019608,\n",
       "        0.39215687, 0.34087482, 0.35294119, 0.45852187, 0.49472097,\n",
       "        0.23076923, 0.46153846, 0.49019608, 0.21568628, 0.49472097,\n",
       "        0.46153846, 0.28506789, 0.51282054, 0.50226247, 0.42383108,\n",
       "        0.50075418, 0.49622926, 0.26847664, 0.4841629 , 0.49773756,\n",
       "        0.46003017, 0.50226247, 0.50527906, 0.47812971, 0.48114631,\n",
       "        0.48868778, 0.47662142, 0.26244345, 0.47360483, 0.47812971,\n",
       "        0.4509804 , 0.49773756, 0.47058824, 0.48717949, 0.50829566,\n",
       "        0.48868778, 0.43740574, 0.42684767, 0.48114631, 0.4826546 ,\n",
       "        0.48717949, 0.49019608, 0.46304676, 0.47662142, 0.48567119,\n",
       "        0.43438914, 0.47360483, 0.29713425, 0.48567119, 0.47963801,\n",
       "        0.29562595, 0.4841629 , 0.47511312, 0.24585219, 0.51131225,\n",
       "        0.51131225, 0.2820513 , 0.50377077, 0.50829566, 0.35897437,\n",
       "        0.50075418, 0.50226247, 0.33936653, 0.47511312, 0.51282054,\n",
       "        0.50075418, 0.42684767, 0.50829566, 0.47812971, 0.49622926,\n",
       "        0.50829566, 0.49019608, 0.39517346, 0.26244345, 0.50075418,\n",
       "        0.42232278, 0.44193062, 0.49321267, 0.4826546 , 0.47209653,\n",
       "        0.47812971, 0.26244345, 0.46003017, 0.47662142, 0.32277527,\n",
       "        0.26244345, 0.47963801, 0.24585219, 0.4479638 , 0.50226247,\n",
       "        0.50377077, 0.48717949, 0.33484164, 0.49170437, 0.48717949,\n",
       "        0.25188538, 0.49170437, 0.48717949, 0.21719457, 0.51885372,\n",
       "        0.49170437, 0.31221721, 0.50226247, 0.49924585, 0.4162896 ,\n",
       "        0.50678736, 0.49472097, 0.46455505, 0.50075418, 0.49170437,\n",
       "        0.49019608, 0.46304676, 0.50226247, 0.49773756, 0.49321267,\n",
       "        0.50980395, 0.48567119, 0.42533937, 0.50829566, 0.50226247,\n",
       "        0.42081448, 0.49170437, 0.47511312, 0.41930619, 0.43891403,\n",
       "        0.49321267, 0.40573153, 0.38763198, 0.48717949, 0.31070891,\n",
       "        0.42835596, 0.48868778, 0.36802414, 0.45248869, 0.49622926,\n",
       "        0.22926094, 0.22775264, 0.21719457, 0.33634993, 0.40723982,\n",
       "        0.22473605, 0.45399699, 0.46455505, 0.2428356 , 0.4841629 ,\n",
       "        0.48567119, 0.33936653, 0.46455505, 0.49622926, 0.280543  ,\n",
       "        0.47511312, 0.50829566, 0.26093516, 0.49321267, 0.49019608,\n",
       "        0.32126698, 0.46907994, 0.49622926, 0.43288085, 0.49321267,\n",
       "        0.50075418, 0.44645551, 0.39819005, 0.49321267, 0.44343892,\n",
       "        0.4147813 , 0.50075418, 0.46907994, 0.44343892, 0.4509804 ,\n",
       "        0.45852187, 0.41025642, 0.46153846, 0.47662142, 0.46606335,\n",
       "        0.49472097, 0.45701358, 0.44042233, 0.42684767, 0.4479638 ,\n",
       "        0.47058824, 0.27601811, 0.32428357, 0.45550528, 0.49170437,\n",
       "        0.24434389, 0.46757165, 0.46907994, 0.18099548, 0.49321267,\n",
       "        0.50527906, 0.2413273 , 0.50678736, 0.51282054, 0.31221721,\n",
       "        0.50075418, 0.49773756, 0.3484163 , 0.51131225, 0.48868778,\n",
       "        0.41025642, 0.47058824, 0.50226247, 0.46153846, 0.46455505,\n",
       "        0.50075418, 0.46907994, 0.25641027, 0.38612369, 0.47360483,\n",
       "        0.46003017, 0.51734543, 0.47963801, 0.47058824, 0.49924585,\n",
       "        0.46907994, 0.44042233, 0.4479638 , 0.48114631, 0.3831071 ,\n",
       "        0.24585219, 0.47511312, 0.46606335, 0.49472097, 0.47360483,\n",
       "        0.47209653, 0.49019608, 0.24886878, 0.48567119, 0.4826546 ,\n",
       "        0.22021116, 0.47662142, 0.49773756, 0.2413273 , 0.50226247,\n",
       "        0.49019608, 0.280543  , 0.49924585, 0.50829566, 0.36802414,\n",
       "        0.49472097, 0.50226247, 0.3484163 , 0.47812971, 0.49472097,\n",
       "        0.47209653, 0.47511312, 0.50829566, 0.47812971, 0.49622926,\n",
       "        0.49019608, 0.4826546 , 0.47963801, 0.49321267, 0.49170437,\n",
       "        0.49622926, 0.49773756, 0.48114631, 0.44494721, 0.45399699,\n",
       "        0.49472097, 0.44042233, 0.49019608, 0.49622926, 0.39517346,\n",
       "        0.40271494, 0.50527906, 0.41930619, 0.50226247, 0.4826546 ,\n",
       "        0.36349925, 0.25188538, 0.25791857, 0.31975868, 0.40874812,\n",
       "        0.3152338 , 0.36199096, 0.42081448, 0.10105581, 0.47058824,\n",
       "        0.47963801, 0.25791857, 0.48567119, 0.49773756, 0.26244345,\n",
       "        0.47058824, 0.4826546 , 0.23076923, 0.50980395, 0.50377077,\n",
       "        0.27752641, 0.48868778, 0.50678736, 0.27149323, 0.49924585,\n",
       "        0.48717949, 0.42081448, 0.46606335, 0.50678736, 0.38612369,\n",
       "        0.42232278, 0.49622926, 0.3815988 , 0.45399699, 0.50075418,\n",
       "        0.46907994, 0.42835596, 0.50527906, 0.42383108, 0.35294119,\n",
       "        0.4841629 , 0.41930619, 0.44645551, 0.49773756, 0.4509804 ,\n",
       "        0.29411766, 0.37858221, 0.28657618, 0.4162896 , 0.4494721 ,\n",
       "        0.27149323, 0.45701358, 0.4479638 , 0.18702866, 0.47963801,\n",
       "        0.49622926, 0.18552037, 0.47511312, 0.47812971, 0.21719457,\n",
       "        0.50527906, 0.50377077, 0.30769232, 0.49924585, 0.24585219,\n",
       "        0.37858221, 0.49321267, 0.50377077, 0.45701358, 0.51432884,\n",
       "        0.49472097, 0.45399699, 0.42986426, 0.50678736, 0.47209653,\n",
       "        0.48868778, 0.49622926, 0.47209653, 0.46003017, 0.49773756,\n",
       "        0.45399699, 0.34389141, 0.4826546 , 0.44494721, 0.47812971,\n",
       "        0.46304676, 0.48567119, 0.51131225, 0.48567119, 0.45852187,\n",
       "        0.26546004, 0.34539971, 0.26696834, 0.47058824, 0.4494721 ,\n",
       "        0.21266969, 0.46153846, 0.47209653, 0.2413273 , 0.52036202,\n",
       "        0.48114631, 0.24886878, 0.49773756, 0.50075418, 0.33333334,\n",
       "        0.49019608, 0.48868778, 0.28959277, 0.50678736, 0.50527906,\n",
       "        0.47963801, 0.50226247, 0.50527906, 0.45852187, 0.47812971,\n",
       "        0.50678736, 0.45248869, 0.42835596, 0.49019608, 0.47511312,\n",
       "        0.47963801, 0.51885372, 0.47360483, 0.39969835, 0.47511312,\n",
       "        0.46757165, 0.46003017, 0.49472097, 0.47209653, 0.49019608,\n",
       "        0.49170437, 0.47963801, 0.49472097, 0.46606335, 0.48717949]),\n",
       " 'split1_test_score': array([0.3831071 , 0.39969835, 0.25339368, 0.47662142, 0.49321267,\n",
       "        0.28506789, 0.51432884, 0.48717949, 0.21870287, 0.5595777 ,\n",
       "        0.57315236, 0.23227753, 0.54600304, 0.55656111, 0.42383108,\n",
       "        0.55806941, 0.55203623, 0.30920061, 0.45248869, 0.54449475,\n",
       "        0.41779789, 0.53544497, 0.47963801, 0.50226247, 0.57616895,\n",
       "        0.54449475, 0.48868778, 0.34992459, 0.5279035 , 0.51734543,\n",
       "        0.52941179, 0.41176471, 0.52941179, 0.50075418, 0.52337861,\n",
       "        0.53393668, 0.49924585, 0.44193062, 0.54449475, 0.33936653,\n",
       "        0.48567119, 0.54449475, 0.29864255, 0.45852187, 0.52941179,\n",
       "        0.52187032, 0.5263952 , 0.21417798, 0.52488691, 0.52941179,\n",
       "        0.13122173, 0.53544497, 0.53242838, 0.27601811, 0.5595777 ,\n",
       "        0.56410259, 0.3152338 , 0.55354452, 0.57013577, 0.47360483,\n",
       "        0.55052793, 0.55505282, 0.32428357, 0.47209653, 0.55052793,\n",
       "        0.51282054, 0.52036202, 0.43137255, 0.52036202, 0.49622926,\n",
       "        0.55354452, 0.53996986, 0.47209653, 0.52488691, 0.54600304,\n",
       "        0.51432884, 0.46304676, 0.54449475, 0.50678736, 0.52036202,\n",
       "        0.54298645, 0.47812971, 0.32126698, 0.55505282, 0.41025642,\n",
       "        0.52488691, 0.56259429, 0.39064857, 0.48717949, 0.54449475,\n",
       "        0.54600304, 0.54751134, 0.15384616, 0.55203623, 0.55203623,\n",
       "        0.18702866, 0.55052793, 0.55203623, 0.26093516, 0.55354452,\n",
       "        0.56711918, 0.46455505, 0.56711918, 0.56410259, 0.38763198,\n",
       "        0.55052793, 0.55656111, 0.46757165, 0.52187032, 0.53393668,\n",
       "        0.55052793, 0.54449475, 0.51282054, 0.54901963, 0.49924585,\n",
       "        0.53242838, 0.55656111, 0.41025642, 0.51282054, 0.55656111,\n",
       "        0.50075418, 0.54449475, 0.55203623, 0.39064857, 0.52337861,\n",
       "        0.54901963, 0.55354452, 0.47360483, 0.56711918, 0.47963801,\n",
       "        0.41176471, 0.55052793, 0.35746607, 0.50527906, 0.55505282,\n",
       "        0.31070891, 0.23227753, 0.15082957, 0.43438914, 0.39668176,\n",
       "        0.2820513 , 0.49773756, 0.50226247, 0.25037709, 0.54449475,\n",
       "        0.54449475, 0.27450982, 0.55505282, 0.57315236, 0.32277527,\n",
       "        0.55203623, 0.56259429, 0.29864255, 0.35897437, 0.561086  ,\n",
       "        0.45550528, 0.49472097, 0.50829566, 0.4841629 , 0.37405732,\n",
       "        0.50829566, 0.49773756, 0.44193062, 0.44645551, 0.5263952 ,\n",
       "        0.43137255, 0.44193062, 0.51282054, 0.36802414, 0.40723982,\n",
       "        0.49472097, 0.48567119, 0.50678736, 0.50075418, 0.42684767,\n",
       "        0.45550528, 0.4841629 , 0.35444948, 0.50075418, 0.52488691,\n",
       "        0.48717949, 0.44343892, 0.35143289, 0.49170437, 0.52187032,\n",
       "        0.24434389, 0.52941179, 0.53393668, 0.19607843, 0.55505282,\n",
       "        0.56259429, 0.24585219, 0.55354452, 0.561086  , 0.29411766,\n",
       "        0.51734543, 0.57918555, 0.31825039, 0.5279035 , 0.57315236,\n",
       "        0.48717949, 0.52488691, 0.55354452, 0.49773756, 0.37254903,\n",
       "        0.54449475, 0.51282054, 0.48114631, 0.51282054, 0.51432884,\n",
       "        0.39668176, 0.53092009, 0.5263952 , 0.53242838, 0.54298645,\n",
       "        0.53695327, 0.53544497, 0.52337861, 0.55354452, 0.49019608,\n",
       "        0.53242838, 0.56259429, 0.47511312, 0.42533937, 0.5279035 ,\n",
       "        0.52337861, 0.49019608, 0.22926094, 0.53393668, 0.53092009,\n",
       "        0.23680241, 0.55203623, 0.53996986, 0.2066365 , 0.53242838,\n",
       "        0.561086  , 0.23831071, 0.57013577, 0.5595777 , 0.38914028,\n",
       "        0.52941179, 0.57013577, 0.41327301, 0.49321267, 0.55203623,\n",
       "        0.51131225, 0.45248869, 0.53544497, 0.54147816, 0.49321267,\n",
       "        0.54600304, 0.53092009, 0.4841629 , 0.52337861, 0.55354452,\n",
       "        0.52941179, 0.40723982, 0.55052793, 0.41779789, 0.51583713,\n",
       "        0.561086  , 0.51885372, 0.50527906, 0.56259429, 0.4479638 ,\n",
       "        0.51282054, 0.5595777 , 0.43137255, 0.5263952 , 0.561086  ,\n",
       "        0.31674209, 0.29110107, 0.20211162, 0.34539971, 0.30316743,\n",
       "        0.22021116, 0.44645551, 0.3815988 , 0.36048266, 0.54751134,\n",
       "        0.51282054, 0.24886878, 0.55806941, 0.53996986, 0.38763198,\n",
       "        0.5263952 , 0.54298645, 0.22775264, 0.50377077, 0.56862748,\n",
       "        0.25791857, 0.53242838, 0.50527906, 0.35595778, 0.48868778,\n",
       "        0.5263952 , 0.3484163 , 0.46455505, 0.52187032, 0.29411766,\n",
       "        0.41930619, 0.50226247, 0.47812971, 0.51282054, 0.55354452,\n",
       "        0.4826546 , 0.40271494, 0.49622926, 0.43438914, 0.51432884,\n",
       "        0.52941179, 0.47058824, 0.48114631, 0.50678736, 0.49773756,\n",
       "        0.3484163 , 0.24886878, 0.23981901, 0.44042233, 0.32428357,\n",
       "        0.23378582, 0.46757165, 0.50377077, 0.21568628, 0.561086  ,\n",
       "        0.54449475, 0.39215687, 0.54147816, 0.5595777 , 0.29562595,\n",
       "        0.54600304, 0.55656111, 0.28355959, 0.51282054, 0.55203623,\n",
       "        0.35294119, 0.4147813 , 0.561086  , 0.49924585, 0.54600304,\n",
       "        0.51432884, 0.44042233, 0.46304676, 0.54901963, 0.45701358,\n",
       "        0.51432884, 0.55354452, 0.50678736, 0.51282054, 0.55354452,\n",
       "        0.50678736, 0.47058824, 0.48717949, 0.48717949, 0.42986426,\n",
       "        0.45399699, 0.51282054, 0.52187032, 0.53092009, 0.51885372,\n",
       "        0.46757165, 0.39064857, 0.23680241, 0.51885372, 0.53393668,\n",
       "        0.24585219, 0.52488691, 0.51131225, 0.22322775, 0.57164407,\n",
       "        0.55656111, 0.27752641, 0.55354452, 0.55052793, 0.25490198,\n",
       "        0.55203623, 0.55806941, 0.29713425, 0.53393668, 0.55052793,\n",
       "        0.53544497, 0.54147816, 0.54901963, 0.50377077, 0.4841629 ,\n",
       "        0.56862748, 0.49472097, 0.53242838, 0.54147816, 0.51583713,\n",
       "        0.47963801, 0.48114631, 0.52036202, 0.41779789, 0.54901963,\n",
       "        0.51432884, 0.49924585, 0.56711918, 0.52941179, 0.49321267,\n",
       "        0.48868778, 0.54600304, 0.49019608, 0.46304676, 0.54751134,\n",
       "        0.4509804 , 0.47662142, 0.22171946, 0.42533937, 0.47662142,\n",
       "        0.26847664, 0.50377077, 0.5263952 , 0.25188538, 0.54901963,\n",
       "        0.55806941, 0.30165914, 0.55052793, 0.54901963, 0.27149323,\n",
       "        0.55354452, 0.56711918, 0.31221721, 0.55656111, 0.57466066,\n",
       "        0.3815988 , 0.46455505, 0.52187032, 0.50075418, 0.49019608,\n",
       "        0.49321267, 0.48868778, 0.42533937, 0.51432884, 0.33182505,\n",
       "        0.38612369, 0.55052793, 0.52036202, 0.50226247, 0.54751134,\n",
       "        0.53695327, 0.23529412, 0.47209653, 0.51885372, 0.3152338 ,\n",
       "        0.30165914, 0.53996986, 0.48567119, 0.48868778, 0.55203623,\n",
       "        0.50226247, 0.51885372, 0.22473605, 0.52337861, 0.51131225,\n",
       "        0.25942686, 0.53393668, 0.53242838, 0.24434389, 0.58672702,\n",
       "        0.55505282, 0.27752641, 0.54147816, 0.54147816, 0.43137255,\n",
       "        0.5595777 , 0.561086  , 0.30015084, 0.42232278, 0.55354452,\n",
       "        0.52187032, 0.52337861, 0.52337861, 0.52941179, 0.51282054,\n",
       "        0.47209653, 0.51131225, 0.50527906, 0.54600304, 0.561086  ,\n",
       "        0.51131225, 0.51282054, 0.54147816, 0.45701358, 0.5279035 ,\n",
       "        0.54449475, 0.45701358, 0.22624435, 0.54298645, 0.37858221,\n",
       "        0.41025642, 0.54147816, 0.39668176, 0.37254903, 0.56259429,\n",
       "        0.53393668, 0.55656111, 0.27300152, 0.52488691, 0.56259429,\n",
       "        0.29411766, 0.54298645, 0.56561089, 0.23680241, 0.55203623,\n",
       "        0.54600304, 0.42986426, 0.55656111, 0.55052793, 0.18552037,\n",
       "        0.56561089, 0.55052793, 0.34389141, 0.4841629 , 0.45399699,\n",
       "        0.53393668, 0.50980395, 0.52036202, 0.561086  , 0.4479638 ,\n",
       "        0.53544497, 0.55354452, 0.35294119, 0.50377077, 0.561086  ,\n",
       "        0.44193062, 0.50377077, 0.54449475, 0.42835596, 0.42986426,\n",
       "        0.56561089, 0.42835596, 0.40120664, 0.53846157, 0.42081448,\n",
       "        0.26696834, 0.55656111, 0.46757165, 0.49472097, 0.55354452,\n",
       "        0.4509804 , 0.42383108, 0.21719457, 0.4162896 , 0.37707391,\n",
       "        0.2081448 , 0.45701358, 0.43438914, 0.26998493, 0.54449475,\n",
       "        0.561086  , 0.25641027, 0.55354452, 0.55203623, 0.22775264,\n",
       "        0.561086  , 0.54600304, 0.27300152, 0.46455505, 0.56259429,\n",
       "        0.3152338 , 0.49924585, 0.55052793, 0.46907994, 0.53846157,\n",
       "        0.54449475, 0.48114631, 0.44042233, 0.51583713, 0.48868778,\n",
       "        0.46455505, 0.55203623, 0.4841629 , 0.4509804 , 0.56259429,\n",
       "        0.52187032, 0.46153846, 0.561086  , 0.51432884, 0.46606335,\n",
       "        0.51885372, 0.47209653, 0.3800905 , 0.49472097, 0.51432884,\n",
       "        0.46304676, 0.4509804 , 0.27601811, 0.4826546 , 0.50980395,\n",
       "        0.29562595, 0.50226247, 0.52337861, 0.2428356 , 0.561086  ,\n",
       "        0.55656111, 0.35746607, 0.57013577, 0.56259429, 0.28506789,\n",
       "        0.52036202, 0.56711918, 0.28657618, 0.4494721 , 0.54449475,\n",
       "        0.44494721, 0.50980395, 0.56259429, 0.50075418, 0.47209653,\n",
       "        0.53996986, 0.49321267, 0.38612369, 0.53846157, 0.5279035 ,\n",
       "        0.54449475, 0.55656111, 0.51131225, 0.54600304, 0.51432884,\n",
       "        0.53544497, 0.23529412, 0.22624435, 0.53695327, 0.29411766,\n",
       "        0.43891403, 0.55656111, 0.4162896 , 0.52337861, 0.53695327,\n",
       "        0.51885372, 0.50527906, 0.27450982, 0.51131225, 0.52187032,\n",
       "        0.29110107, 0.53544497, 0.55052793, 0.19306184, 0.54449475,\n",
       "        0.56561089, 0.41025642, 0.57013577, 0.56259429, 0.32126698,\n",
       "        0.57013577, 0.57918555, 0.23227753, 0.49019608, 0.53846157,\n",
       "        0.50527906, 0.39215687, 0.53242838, 0.52036202, 0.53092009,\n",
       "        0.53695327, 0.53092009, 0.42684767, 0.50678736, 0.55203623,\n",
       "        0.53242838, 0.4494721 , 0.561086  , 0.31975868, 0.56410259,\n",
       "        0.54298645, 0.4841629 , 0.3815988 , 0.55052793, 0.46003017,\n",
       "        0.53544497, 0.56561089, 0.49773756, 0.52941179, 0.55806941,\n",
       "        0.26847664, 0.25942686, 0.26546004, 0.26998493, 0.2066365 ,\n",
       "        0.31674209, 0.44645551, 0.29713425, 0.22473605, 0.50377077,\n",
       "        0.54147816, 0.24886878, 0.54449475, 0.53242838, 0.24434389,\n",
       "        0.55052793, 0.55354452, 0.20361991, 0.50226247, 0.56259429,\n",
       "        0.30920061, 0.51432884, 0.56711918, 0.34087482, 0.53393668,\n",
       "        0.5595777 , 0.34389141, 0.47360483, 0.49472097, 0.46003017,\n",
       "        0.54901963, 0.53544497, 0.38763198, 0.48717949, 0.53242838,\n",
       "        0.46153846, 0.41327301, 0.5595777 , 0.46757165, 0.45550528,\n",
       "        0.48114631, 0.49773756, 0.52337861, 0.54449475, 0.46907994,\n",
       "        0.30165914, 0.39668176, 0.27450982, 0.23680241, 0.4147813 ,\n",
       "        0.25339368, 0.40874812, 0.46907994, 0.23680241, 0.54449475,\n",
       "        0.55354452, 0.30015084, 0.56410259, 0.55505282, 0.24585219,\n",
       "        0.54147816, 0.55806941, 0.25490198, 0.56862748, 0.55505282,\n",
       "        0.30467573, 0.52187032, 0.561086  , 0.31674209, 0.56410259,\n",
       "        0.5279035 , 0.48114631, 0.54147816, 0.55354452, 0.43740574,\n",
       "        0.35143289, 0.53846157, 0.50377077, 0.54298645, 0.54751134,\n",
       "        0.49773756, 0.23529412, 0.55203623, 0.50377077, 0.49170437,\n",
       "        0.51885372, 0.48567119, 0.43137255, 0.55656111, 0.50829566,\n",
       "        0.47511312, 0.30015084, 0.24434389, 0.50377077, 0.37707391,\n",
       "        0.30769232, 0.52036202, 0.49773756, 0.28506789, 0.54449475,\n",
       "        0.55656111, 0.26093516, 0.54751134, 0.56862748, 0.24585219,\n",
       "        0.56410259, 0.56862748, 0.26847664, 0.52187032, 0.57315236,\n",
       "        0.47058824, 0.57013577, 0.56711918, 0.48567119, 0.55505282,\n",
       "        0.55354452, 0.49622926, 0.54449475, 0.56259429, 0.51432884,\n",
       "        0.49924585, 0.53695327, 0.5263952 , 0.51885372, 0.51885372,\n",
       "        0.53092009, 0.50377077, 0.22624435, 0.52488691, 0.55052793,\n",
       "        0.53092009, 0.56561089, 0.48868778, 0.53092009, 0.54147816]),\n",
       " 'split2_test_score': array([0.3836858 , 0.43051359, 0.24169184, 0.43957704, 0.43957704,\n",
       "        0.36706948, 0.45619336, 0.46525681, 0.22356495, 0.52719033,\n",
       "        0.5060423 , 0.26132929, 0.53625375, 0.49244714, 0.2794562 ,\n",
       "        0.47734138, 0.51057404, 0.30211481, 0.5589124 , 0.54531723,\n",
       "        0.43957704, 0.48489425, 0.5120846 , 0.45921451, 0.48187312,\n",
       "        0.54682779, 0.43806645, 0.4879154 , 0.47280967, 0.45317221,\n",
       "        0.5060423 , 0.5060423 , 0.4486405 , 0.45317221, 0.46525681,\n",
       "        0.49697885, 0.48640484, 0.50906342, 0.5181269 , 0.35498488,\n",
       "        0.43504533, 0.51661628, 0.36253777, 0.40332326, 0.50302112,\n",
       "        0.46072507, 0.43202418, 0.2794562 , 0.45468277, 0.45921451,\n",
       "        0.31419939, 0.50906342, 0.50151056, 0.23716012, 0.51057404,\n",
       "        0.52719033, 0.26737159, 0.50755286, 0.50906342, 0.23867069,\n",
       "        0.53927493, 0.52265859, 0.38519639, 0.51510572, 0.53927493,\n",
       "        0.47734138, 0.53776437, 0.4939577 , 0.48338369, 0.50151056,\n",
       "        0.54078549, 0.50453174, 0.52416921, 0.5181269 , 0.51359516,\n",
       "        0.42447129, 0.49244714, 0.51057404, 0.49093655, 0.46525681,\n",
       "        0.52416921, 0.48338369, 0.35649547, 0.51661628, 0.46223566,\n",
       "        0.47280967, 0.51963747, 0.41389728, 0.45921451, 0.52567977,\n",
       "        0.49697885, 0.48942599, 0.19335347, 0.50906342, 0.51510572,\n",
       "        0.33383685, 0.53474319, 0.53172207, 0.18277946, 0.53474319,\n",
       "        0.54833835, 0.39123866, 0.53172207, 0.5649547 , 0.40483382,\n",
       "        0.55589122, 0.56646526, 0.43806645, 0.46525681, 0.4939577 ,\n",
       "        0.51359516, 0.45619336, 0.53625375, 0.5060423 , 0.49093655,\n",
       "        0.48338369, 0.51057404, 0.53625375, 0.51510572, 0.5181269 ,\n",
       "        0.41238672, 0.42296073, 0.54682779, 0.4879154 , 0.48489425,\n",
       "        0.53172207, 0.49697885, 0.49546829, 0.54531723, 0.40785497,\n",
       "        0.51510572, 0.55135953, 0.47129908, 0.38821751, 0.50151056,\n",
       "        0.39728096, 0.31722054, 0.12537764, 0.39879155, 0.45619336,\n",
       "        0.28851965, 0.43202418, 0.43806645, 0.21601209, 0.5060423 ,\n",
       "        0.47885197, 0.24471299, 0.49546829, 0.52870089, 0.2794562 ,\n",
       "        0.54682779, 0.51510572, 0.30060422, 0.47734138, 0.45619336,\n",
       "        0.41389728, 0.4879154 , 0.5649547 , 0.43806645, 0.43051359,\n",
       "        0.5       , 0.4410876 , 0.49848944, 0.53021151, 0.43806645,\n",
       "        0.43957704, 0.50453174, 0.44259819, 0.3308157 , 0.48942599,\n",
       "        0.4879154 , 0.43957704, 0.50151056, 0.45619336, 0.3897281 ,\n",
       "        0.5120846 , 0.44259819, 0.3308157 , 0.51359516, 0.50151056,\n",
       "        0.43353474, 0.43202418, 0.26737159, 0.45770392, 0.4410876 ,\n",
       "        0.26435044, 0.46374622, 0.47885197, 0.2205438 , 0.49848944,\n",
       "        0.52719033, 0.23111783, 0.56797582, 0.52719033, 0.37613294,\n",
       "        0.51510572, 0.48489425, 0.40936556, 0.49848944, 0.53172207,\n",
       "        0.43655589, 0.51510572, 0.5       , 0.44561934, 0.37613294,\n",
       "        0.52416921, 0.44712991, 0.49093655, 0.50453174, 0.45166162,\n",
       "        0.40332326, 0.50755286, 0.50302112, 0.51057404, 0.47129908,\n",
       "        0.51963747, 0.48338369, 0.4486405 , 0.4879154 , 0.4410876 ,\n",
       "        0.4486405 , 0.50453174, 0.42447129, 0.45921451, 0.51661628,\n",
       "        0.46827793, 0.46223566, 0.31722054, 0.49546829, 0.50302112,\n",
       "        0.41691843, 0.5181269 , 0.51359516, 0.25679758, 0.55135953,\n",
       "        0.55740184, 0.36404833, 0.53625375, 0.55740184, 0.40332326,\n",
       "        0.45619336, 0.53776437, 0.41389728, 0.46374622, 0.54833835,\n",
       "        0.46072507, 0.42296073, 0.53021151, 0.5060423 , 0.46978852,\n",
       "        0.54531723, 0.49697885, 0.43051359, 0.53776437, 0.5120846 ,\n",
       "        0.3957704 , 0.4879154 , 0.51963747, 0.46978852, 0.54531723,\n",
       "        0.51963747, 0.47129908, 0.43202418, 0.53625375, 0.40483382,\n",
       "        0.51661628, 0.50302112, 0.40332326, 0.50151056, 0.5181269 ,\n",
       "        0.32930514, 0.2265861 , 0.23413897, 0.30664653, 0.28096676,\n",
       "        0.21601209, 0.40030211, 0.34290031, 0.25981873, 0.48942599,\n",
       "        0.46223566, 0.26888219, 0.5120846 , 0.49697885, 0.24622357,\n",
       "        0.52719033, 0.51359516, 0.22507553, 0.51963747, 0.4939577 ,\n",
       "        0.28247735, 0.40483382, 0.50151056, 0.37915409, 0.4410876 ,\n",
       "        0.53021151, 0.43051359, 0.43655589, 0.51963747, 0.43202418,\n",
       "        0.41691843, 0.53021151, 0.43504533, 0.47280967, 0.45015106,\n",
       "        0.43504533, 0.41842902, 0.50302112, 0.39879155, 0.42145014,\n",
       "        0.51963747, 0.43051359, 0.42296073, 0.53776437, 0.42598188,\n",
       "        0.36706948, 0.25377643, 0.22960725, 0.38670695, 0.28247735,\n",
       "        0.25075528, 0.43353474, 0.43957704, 0.2734139 , 0.51359516,\n",
       "        0.51510572, 0.22809668, 0.52114803, 0.47885197, 0.20241691,\n",
       "        0.53021151, 0.53172207, 0.25377643, 0.48338369, 0.50302112,\n",
       "        0.2794562 , 0.53021151, 0.56193352, 0.42900303, 0.55287009,\n",
       "        0.51963747, 0.44410875, 0.46223566, 0.51510572, 0.45468277,\n",
       "        0.53172207, 0.54380667, 0.42900303, 0.36706948, 0.49546829,\n",
       "        0.4486405 , 0.45468277, 0.52567977, 0.43353474, 0.44410875,\n",
       "        0.51510572, 0.45770392, 0.4410876 , 0.50755286, 0.47280967,\n",
       "        0.46223566, 0.41993958, 0.24018127, 0.46978852, 0.46676737,\n",
       "        0.20090635, 0.46223566, 0.46676737, 0.33534744, 0.51510572,\n",
       "        0.55135953, 0.24320242, 0.52416921, 0.54984891, 0.24018127,\n",
       "        0.5       , 0.51057404, 0.20694864, 0.52114803, 0.56797582,\n",
       "        0.43504533, 0.45921451, 0.51963747, 0.46223566, 0.53172207,\n",
       "        0.56193352, 0.43051359, 0.48036253, 0.53625375, 0.48489425,\n",
       "        0.46978852, 0.53776437, 0.47885197, 0.53776437, 0.5060423 ,\n",
       "        0.48338369, 0.5181269 , 0.5060423 , 0.49697885, 0.49093655,\n",
       "        0.51963747, 0.52416921, 0.4486405 , 0.50302112, 0.50302112,\n",
       "        0.2794562 , 0.45015106, 0.18126889, 0.40483382, 0.3776435 ,\n",
       "        0.23564954, 0.4879154 , 0.45770392, 0.24471299, 0.52265859,\n",
       "        0.52567977, 0.38066465, 0.48489425, 0.54833835, 0.2854985 ,\n",
       "        0.54531723, 0.52416921, 0.20996979, 0.49546829, 0.5181269 ,\n",
       "        0.35347432, 0.51661628, 0.54229605, 0.45770392, 0.53021151,\n",
       "        0.53172207, 0.43202418, 0.52567977, 0.40785497, 0.46525681,\n",
       "        0.52719033, 0.47129908, 0.46072507, 0.52870089, 0.49546829,\n",
       "        0.47129908, 0.37160119, 0.35951662, 0.50302112, 0.41540787,\n",
       "        0.4486405 , 0.45921451, 0.50906342, 0.49697885, 0.50906342,\n",
       "        0.41087613, 0.46525681, 0.12839879, 0.47280967, 0.45317221,\n",
       "        0.23867069, 0.50151056, 0.4879154 , 0.31570998, 0.54531723,\n",
       "        0.56193352, 0.26132929, 0.56042296, 0.52265859, 0.29909366,\n",
       "        0.54380667, 0.54531723, 0.34592146, 0.52416921, 0.54984891,\n",
       "        0.46374622, 0.49848944, 0.54380667, 0.46072507, 0.52114803,\n",
       "        0.52416921, 0.46676737, 0.49697885, 0.52870089, 0.4939577 ,\n",
       "        0.45015106, 0.51359516, 0.51510572, 0.46525681, 0.54078549,\n",
       "        0.50906342, 0.42749244, 0.24471299, 0.50906342, 0.4939577 ,\n",
       "        0.36253777, 0.49848944, 0.52870089, 0.47583082, 0.53323263,\n",
       "        0.4879154 , 0.5060423 , 0.22356495, 0.50302112, 0.50906342,\n",
       "        0.27643505, 0.52870089, 0.52870089, 0.31268883, 0.54682779,\n",
       "        0.52870089, 0.37160119, 0.5649547 , 0.55287009, 0.39274925,\n",
       "        0.55740184, 0.55287009, 0.41540787, 0.46676737, 0.5060423 ,\n",
       "        0.4939577 , 0.52114803, 0.5181269 , 0.50906342, 0.5060423 ,\n",
       "        0.52265859, 0.5120846 , 0.4879154 , 0.40634441, 0.4879154 ,\n",
       "        0.52567977, 0.45770392, 0.55135953, 0.51057404, 0.48942599,\n",
       "        0.49244714, 0.31570998, 0.42296073, 0.54531723, 0.49244714,\n",
       "        0.45921451, 0.5       , 0.35045317, 0.43957704, 0.55438066,\n",
       "        0.39879155, 0.26283988, 0.24471299, 0.36706948, 0.29607251,\n",
       "        0.37311178, 0.4410876 , 0.45015106, 0.22507553, 0.49848944,\n",
       "        0.51510572, 0.21299094, 0.45619336, 0.52567977, 0.26737159,\n",
       "        0.51963747, 0.4939577 , 0.28096676, 0.53474319, 0.54984891,\n",
       "        0.41389728, 0.54531723, 0.54229605, 0.38066465, 0.51057404,\n",
       "        0.53474319, 0.44410875, 0.41842902, 0.54531723, 0.48640484,\n",
       "        0.56042296, 0.53474319, 0.48640484, 0.51963747, 0.55589122,\n",
       "        0.42749244, 0.40332326, 0.38821751, 0.42447129, 0.4410876 ,\n",
       "        0.43504533, 0.45166162, 0.51359516, 0.44410875, 0.46223566,\n",
       "        0.36706948, 0.35196376, 0.35800603, 0.44259819, 0.45317221,\n",
       "        0.25830814, 0.46525681, 0.46676737, 0.15861027, 0.48640484,\n",
       "        0.4879154 , 0.12537764, 0.52114803, 0.51661628, 0.34743202,\n",
       "        0.52416921, 0.55287009, 0.24320242, 0.45317221, 0.55287009,\n",
       "        0.46223566, 0.49697885, 0.54984891, 0.41691843, 0.47734138,\n",
       "        0.55287009, 0.43353474, 0.45770392, 0.51057404, 0.46072507,\n",
       "        0.5       , 0.5181269 , 0.49848944, 0.49848944, 0.5060423 ,\n",
       "        0.5       , 0.43806645, 0.48036253, 0.4939577 , 0.48640484,\n",
       "        0.52114803, 0.47734138, 0.34743202, 0.49697885, 0.5181269 ,\n",
       "        0.47885197, 0.46374622, 0.23262841, 0.48489425, 0.48036253,\n",
       "        0.26888219, 0.5060423 , 0.52567977, 0.22507553, 0.52719033,\n",
       "        0.55287009, 0.25679758, 0.55589122, 0.53172207, 0.38217524,\n",
       "        0.54984891, 0.56193352, 0.35498488, 0.54229605, 0.52719033,\n",
       "        0.49546829, 0.49697885, 0.55135953, 0.4939577 , 0.50453174,\n",
       "        0.52719033, 0.48489425, 0.41842902, 0.50453174, 0.5120846 ,\n",
       "        0.47280967, 0.54682779, 0.49697885, 0.40936556, 0.40634441,\n",
       "        0.52719033, 0.4018127 , 0.43051359, 0.53625375, 0.46072507,\n",
       "        0.48489425, 0.4879154 , 0.52870089, 0.45015106, 0.54380667,\n",
       "        0.26283988, 0.35498488, 0.25075528, 0.22507553, 0.36102718,\n",
       "        0.31268883, 0.37915409, 0.45166162, 0.11480363, 0.49697885,\n",
       "        0.46978852, 0.28096676, 0.51661628, 0.53776437, 0.27039275,\n",
       "        0.54682779, 0.51963747, 0.27492446, 0.53776437, 0.52114803,\n",
       "        0.29305136, 0.49093655, 0.53625375, 0.24018127, 0.45770392,\n",
       "        0.55740184, 0.25679758, 0.46978852, 0.52719033, 0.32779455,\n",
       "        0.50453174, 0.55740184, 0.41993958, 0.45166162, 0.54682779,\n",
       "        0.36253777, 0.46676737, 0.52719033, 0.3957704 , 0.45619336,\n",
       "        0.53172207, 0.38066465, 0.53776437, 0.54078549, 0.37009063,\n",
       "        0.3897281 , 0.22507553, 0.27039275, 0.4018127 , 0.33836859,\n",
       "        0.2205438 , 0.41842902, 0.43353474, 0.25528702, 0.51057404,\n",
       "        0.52416921, 0.24018127, 0.53323263, 0.52567977, 0.20694864,\n",
       "        0.55135953, 0.52114803, 0.25981873, 0.48338369, 0.53776437,\n",
       "        0.41540787, 0.50453174, 0.51359516, 0.37915409, 0.54682779,\n",
       "        0.54229605, 0.42447129, 0.45619336, 0.48338369, 0.23111783,\n",
       "        0.53776437, 0.56948638, 0.44712991, 0.49093655, 0.53323263,\n",
       "        0.43957704, 0.53625375, 0.51661628, 0.41842902, 0.45770392,\n",
       "        0.45015106, 0.44259819, 0.45770392, 0.51359516, 0.45166162,\n",
       "        0.23867069, 0.42296073, 0.25981873, 0.41540787, 0.45770392,\n",
       "        0.27643505, 0.46676737, 0.46827793, 0.27190334, 0.51963747,\n",
       "        0.51963747, 0.21903323, 0.53927493, 0.53776437, 0.28398791,\n",
       "        0.55287009, 0.56344414, 0.20090635, 0.50302112, 0.53474319,\n",
       "        0.43655589, 0.54984891, 0.54380667, 0.42900303, 0.55589122,\n",
       "        0.5649547 , 0.45166162, 0.54531723, 0.52870089, 0.48036253,\n",
       "        0.46223566, 0.53172207, 0.46525681, 0.48942599, 0.53474319,\n",
       "        0.47129908, 0.4939577 , 0.47583082, 0.50453174, 0.53625375,\n",
       "        0.52567977, 0.49546829, 0.47734138, 0.5       , 0.49546829]),\n",
       " 'mean_test_score': array([0.39134424, 0.42455028, 0.25250966, 0.462765  , 0.46578159,\n",
       "        0.3174294 , 0.47886185, 0.47182769, 0.21931803, 0.52414641,\n",
       "        0.5181026 , 0.25553611, 0.52565925, 0.51306811, 0.33950702,\n",
       "        0.50652456, 0.50804958, 0.33348524, 0.49801856, 0.52365276,\n",
       "        0.4396378 , 0.5045173 , 0.50000609, 0.47132189, 0.49043836,\n",
       "        0.5166148 , 0.46025041, 0.42709297, 0.48188679, 0.48237968,\n",
       "        0.47587032, 0.4688316 , 0.47986358, 0.45824696, 0.4803747 ,\n",
       "        0.50452338, 0.4763632 , 0.48039671, 0.51911421, 0.34859476,\n",
       "        0.4486853 , 0.51609684, 0.35161516, 0.42755321, 0.50502917,\n",
       "        0.47986965, 0.46628057, 0.28671667, 0.48992192, 0.4899242 ,\n",
       "        0.25154058, 0.50905433, 0.50553118, 0.25854056, 0.5266519 ,\n",
       "        0.52615747, 0.28419677, 0.52011441, 0.52514282, 0.37065796,\n",
       "        0.52515802, 0.52665796, 0.3928533 , 0.49648824, 0.52867737,\n",
       "        0.48540843, 0.49599688, 0.47033381, 0.494964  , 0.48240397,\n",
       "        0.53018642, 0.5100576 , 0.49247068, 0.49498148, 0.51307874,\n",
       "        0.42505002, 0.4336312 , 0.51357999, 0.45876871, 0.46981664,\n",
       "        0.51559789, 0.45323448, 0.39032504, 0.52112449, 0.41702476,\n",
       "        0.45071535, 0.52213155, 0.41147004, 0.46176934, 0.51459311,\n",
       "        0.51357315, 0.50653064, 0.22986092, 0.52061794, 0.51559332,\n",
       "        0.22691495, 0.52264191, 0.52615975, 0.27611   , 0.52817232,\n",
       "        0.53873724, 0.43408307, 0.53370124, 0.54226495, 0.41247101,\n",
       "        0.53522167, 0.54075741, 0.45371446, 0.4803747 , 0.50401909,\n",
       "        0.52011745, 0.49143098, 0.51258736, 0.51558877, 0.48893461,\n",
       "        0.50049442, 0.51911041, 0.46482466, 0.48643294, 0.51810868,\n",
       "        0.44716562, 0.46124836, 0.52667011, 0.44619805, 0.49446199,\n",
       "        0.51912104, 0.48340724, 0.46631246, 0.53873573, 0.43006931,\n",
       "        0.45425596, 0.53019175, 0.40546571, 0.46223641, 0.51307266,\n",
       "        0.37827918, 0.2947799 , 0.14988707, 0.42905923, 0.4346185 ,\n",
       "        0.28018529, 0.45773355, 0.46326701, 0.23590549, 0.52162196,\n",
       "        0.5085364 , 0.24647799, 0.51457793, 0.53872736, 0.31537429,\n",
       "        0.5281784 , 0.52363756, 0.25907522, 0.42407106, 0.50299458,\n",
       "        0.42856405, 0.47586119, 0.52215434, 0.46728912, 0.42505305,\n",
       "        0.49698342, 0.46628511, 0.42207064, 0.46834099, 0.46376977,\n",
       "        0.43259909, 0.46782531, 0.47885501, 0.34757709, 0.46329283,\n",
       "        0.48943585, 0.45874288, 0.49145376, 0.48037014, 0.37877815,\n",
       "        0.47939271, 0.46427481, 0.36819046, 0.50503451, 0.50000076,\n",
       "        0.45522048, 0.43812571, 0.29425208, 0.47031559, 0.47634042,\n",
       "        0.267604  , 0.49042924, 0.50551981, 0.19769761, 0.51860158,\n",
       "        0.52464917, 0.25149881, 0.53975263, 0.52615747, 0.31592567,\n",
       "        0.50956014, 0.5145726 , 0.3430917 , 0.49346331, 0.53470676,\n",
       "        0.45723306, 0.50754908, 0.51860233, 0.46779569, 0.38782109,\n",
       "        0.5256532 , 0.47081305, 0.4557521 , 0.50553271, 0.48237892,\n",
       "        0.41548684, 0.48441808, 0.50502917, 0.49648598, 0.49646622,\n",
       "        0.5171039 , 0.48591423, 0.48338294, 0.50401605, 0.42908049,\n",
       "        0.47081381, 0.51508525, 0.44566338, 0.45070851, 0.50704707,\n",
       "        0.49344811, 0.47735658, 0.2600891 , 0.50703645, 0.507543  ,\n",
       "        0.3285153 , 0.5221308 , 0.51257597, 0.27463892, 0.53119729,\n",
       "        0.54075287, 0.3315053 , 0.53772563, 0.5402501 , 0.35465226,\n",
       "        0.49042545, 0.54074299, 0.41599492, 0.46327991, 0.53521788,\n",
       "        0.47986965, 0.45069028, 0.52062858, 0.50704176, 0.45121659,\n",
       "        0.52566382, 0.50200955, 0.44365536, 0.50906878, 0.51659734,\n",
       "        0.45319045, 0.45675611, 0.52062326, 0.40697325, 0.51510575,\n",
       "        0.52263432, 0.4678086 , 0.43913125, 0.53320074, 0.43057055,\n",
       "        0.50000835, 0.51106235, 0.41548684, 0.48893993, 0.51760591,\n",
       "        0.29478598, 0.25954078, 0.22887589, 0.32443774, 0.2987838 ,\n",
       "        0.22635295, 0.41397703, 0.35964953, 0.27162384, 0.50351405,\n",
       "        0.4859036 , 0.26257863, 0.52112223, 0.51005379, 0.2861972 ,\n",
       "        0.51459387, 0.5150898 , 0.28166168, 0.49096011, 0.52211865,\n",
       "        0.29777903, 0.47179731, 0.50050353, 0.38229219, 0.46729064,\n",
       "        0.51660646, 0.41499775, 0.44969158, 0.51207625, 0.3948879 ,\n",
       "        0.42404069, 0.51208158, 0.44918806, 0.46328448, 0.47232286,\n",
       "        0.45924337, 0.42806357, 0.50100705, 0.42604264, 0.4366121 ,\n",
       "        0.50403201, 0.45270513, 0.46074558, 0.51862133, 0.45471392,\n",
       "        0.3621755 , 0.2831844 , 0.27160866, 0.41648402, 0.36163021,\n",
       "        0.23944231, 0.45371219, 0.47030649, 0.2640892 , 0.52011745,\n",
       "        0.51659885, 0.28216596, 0.51408806, 0.50753086, 0.27813093,\n",
       "        0.52012582, 0.52515422, 0.24346596, 0.49043912, 0.51910661,\n",
       "        0.35257892, 0.48644055, 0.54377172, 0.46326245, 0.52566762,\n",
       "        0.51308179, 0.44919261, 0.4481962 , 0.51408502, 0.44467304,\n",
       "        0.51409339, 0.53471285, 0.46678181, 0.43759029, 0.48742861,\n",
       "        0.4753387 , 0.43059562, 0.50302951, 0.45773431, 0.43612072,\n",
       "        0.48944952, 0.47785707, 0.44014133, 0.50352316, 0.48892551,\n",
       "        0.45372662, 0.42404221, 0.23591764, 0.48892399, 0.49244182,\n",
       "        0.23036748, 0.49143402, 0.48691141, 0.2676397 , 0.52866521,\n",
       "        0.53471664, 0.25753807, 0.52515043, 0.5327048 , 0.25351443,\n",
       "        0.51055808, 0.52112147, 0.22986775, 0.51006594, 0.53975264,\n",
       "        0.45823785, 0.48087443, 0.52363986, 0.48540084, 0.50504361,\n",
       "        0.54326895, 0.45974385, 0.50753162, 0.52767032, 0.49496476,\n",
       "        0.47937144, 0.50353835, 0.49797832, 0.44119547, 0.51005835,\n",
       "        0.49345571, 0.50252295, 0.51257218, 0.50251232, 0.45977423,\n",
       "        0.49850158, 0.51811172, 0.46025573, 0.46782454, 0.51357618,\n",
       "        0.37419782, 0.4225491 , 0.25197651, 0.42956502, 0.44966196,\n",
       "        0.24496514, 0.48440821, 0.49143173, 0.23742822, 0.52213306,\n",
       "        0.51509588, 0.32246389, 0.51608091, 0.53320682, 0.32694093,\n",
       "        0.53320531, 0.52917255, 0.26355454, 0.5120641 , 0.53017504,\n",
       "        0.39836776, 0.49447794, 0.52314848, 0.4788626 , 0.50051796,\n",
       "        0.50454084, 0.46577779, 0.40448753, 0.46526288, 0.42507052,\n",
       "        0.4547648 , 0.50652152, 0.48389178, 0.50604762, 0.51709176,\n",
       "        0.49898005, 0.34810035, 0.41948694, 0.50100705, 0.40443209,\n",
       "        0.41249304, 0.49646015, 0.48592712, 0.48742935, 0.51559028,\n",
       "        0.44917591, 0.48590512, 0.21675636, 0.49395316, 0.48137415,\n",
       "        0.2645745 , 0.50653671, 0.49848563, 0.26863535, 0.5477855 ,\n",
       "        0.54276619, 0.27363567, 0.53522396, 0.52414413, 0.36314686,\n",
       "        0.53471285, 0.5362219 , 0.32847961, 0.47386837, 0.53873799,\n",
       "        0.4954569 , 0.48290524, 0.52516031, 0.48942219, 0.51006594,\n",
       "        0.50152046, 0.48942523, 0.46581046, 0.44571579, 0.51859929,\n",
       "        0.46126203, 0.48944878, 0.51659885, 0.46830833, 0.51359517,\n",
       "        0.51056263, 0.38231649, 0.31032917, 0.5095571 , 0.39843839,\n",
       "        0.34507921, 0.5065352 , 0.39041161, 0.43211455, 0.53269647,\n",
       "        0.50854095, 0.5165943 , 0.27713604, 0.50653747, 0.5196124 ,\n",
       "        0.27414603, 0.52113057, 0.52716375, 0.25556194, 0.53923925,\n",
       "        0.5221361 , 0.37122755, 0.54125943, 0.53421463, 0.33151974,\n",
       "        0.54326669, 0.53270633, 0.40795144, 0.48389482, 0.48391455,\n",
       "        0.50603015, 0.49799958, 0.5135838 , 0.52262899, 0.48240626,\n",
       "        0.52263584, 0.51710011, 0.42206532, 0.47280361, 0.51708796,\n",
       "        0.46280829, 0.48439302, 0.5236558 , 0.4527454 , 0.45273476,\n",
       "        0.51709023, 0.38326582, 0.40393312, 0.52365276, 0.40799018,\n",
       "        0.38484627, 0.51508297, 0.39534965, 0.46226223, 0.53471815,\n",
       "        0.35967763, 0.30480787, 0.22636738, 0.37323634, 0.36012875,\n",
       "        0.26866421, 0.45069939, 0.44969842, 0.24596535, 0.50904903,\n",
       "        0.52062097, 0.26958925, 0.49143098, 0.52464842, 0.25855575,\n",
       "        0.5186122 , 0.51608547, 0.27163448, 0.49750364, 0.5342131 ,\n",
       "        0.35013268, 0.50454768, 0.52968441, 0.42754181, 0.51408276,\n",
       "        0.52666404, 0.45723686, 0.4190138 , 0.51812235, 0.47284385,\n",
       "        0.47991977, 0.52917786, 0.47988256, 0.47135226, 0.5231553 ,\n",
       "        0.46929488, 0.42503938, 0.47028066, 0.47180718, 0.4577381 ,\n",
       "        0.48287334, 0.46025724, 0.44470267, 0.4552258 , 0.47484277,\n",
       "        0.43356816, 0.35965409, 0.3194359 , 0.46025269, 0.48489351,\n",
       "        0.26609266, 0.47836364, 0.48640864, 0.19414711, 0.51356784,\n",
       "        0.51658519, 0.24139034, 0.53269039, 0.53067704, 0.3149057 ,\n",
       "        0.51509513, 0.53924228, 0.29273163, 0.47131885, 0.52868421,\n",
       "        0.43914643, 0.49245701, 0.53823523, 0.45973702, 0.47133099,\n",
       "        0.53119804, 0.46527578, 0.36674596, 0.47838643, 0.48741113,\n",
       "        0.50150831, 0.53067782, 0.4964799 , 0.50502691, 0.506539  ,\n",
       "        0.50150831, 0.37126097, 0.38485689, 0.50401909, 0.38787653,\n",
       "        0.40197141, 0.50300521, 0.40992832, 0.50502614, 0.50956167,\n",
       "        0.48993408, 0.48640712, 0.25200233, 0.49395923, 0.49496248,\n",
       "        0.26006481, 0.50603623, 0.52464842, 0.21982156, 0.52464918,\n",
       "        0.53622569, 0.31586567, 0.54175761, 0.53420401, 0.35715545,\n",
       "        0.53823522, 0.54779385, 0.3118929 , 0.50354062, 0.52012429,\n",
       "        0.49094796, 0.45474961, 0.53069452, 0.49748314, 0.51056036,\n",
       "        0.51811323, 0.49948965, 0.44163823, 0.50151059, 0.5186084 ,\n",
       "        0.50048911, 0.49801248, 0.51307038, 0.39135715, 0.47481466,\n",
       "        0.52163258, 0.44213264, 0.43410282, 0.52767031, 0.4386429 ,\n",
       "        0.47435139, 0.51960178, 0.48191488, 0.49394177, 0.52817689,\n",
       "        0.29827192, 0.28876571, 0.25804463, 0.27160638, 0.3254706 ,\n",
       "        0.31488824, 0.39586685, 0.38987012, 0.14686516, 0.49044595,\n",
       "        0.49696823, 0.2625847 , 0.51559408, 0.52264344, 0.25906003,\n",
       "        0.52264799, 0.5186122 , 0.23643787, 0.51661026, 0.52917103,\n",
       "        0.29325946, 0.49798439, 0.5367201 , 0.2841831 , 0.49696215,\n",
       "        0.53471968, 0.34050116, 0.4698189 , 0.50956622, 0.39131614,\n",
       "        0.49195805, 0.52969202, 0.39639012, 0.46427936, 0.52667012,\n",
       "        0.43105206, 0.43613211, 0.53068237, 0.42905771, 0.42154661,\n",
       "        0.49901042, 0.43256946, 0.50253283, 0.5276726 , 0.43005032,\n",
       "        0.32850163, 0.3334465 , 0.27715958, 0.3516349 , 0.400874  ,\n",
       "        0.2484769 , 0.42806357, 0.45019283, 0.2263727 , 0.51156893,\n",
       "        0.52464766, 0.24195082, 0.52414945, 0.51962077, 0.2233318 ,\n",
       "        0.53270559, 0.52766273, 0.27413768, 0.51708567, 0.44622312,\n",
       "        0.36622193, 0.50653824, 0.52615064, 0.38430325, 0.54175307,\n",
       "        0.52164017, 0.45320486, 0.47584526, 0.51457186, 0.3802067 ,\n",
       "        0.45929501, 0.53472574, 0.4743324 , 0.49798439, 0.52616051,\n",
       "        0.46377053, 0.37181309, 0.51710237, 0.45571567, 0.475846  ,\n",
       "        0.47735051, 0.47131353, 0.46679624, 0.51860916, 0.47282638,\n",
       "        0.32641462, 0.35617043, 0.25704365, 0.46325562, 0.42808331,\n",
       "        0.26559902, 0.48288928, 0.47937067, 0.26609951, 0.52816474,\n",
       "        0.51911496, 0.24294572, 0.52817461, 0.53571534, 0.28772448,\n",
       "        0.53572292, 0.54025313, 0.25299192, 0.5105596 , 0.53772487,\n",
       "        0.46226071, 0.54074905, 0.53873497, 0.45773203, 0.52969125,\n",
       "        0.54176219, 0.46679319, 0.50605598, 0.52716375, 0.48993483,\n",
       "        0.48037317, 0.52917635, 0.48841895, 0.46932602, 0.50957001,\n",
       "        0.48993027, 0.48591955, 0.39893204, 0.50050506, 0.52565925,\n",
       "        0.51610141, 0.51357239, 0.48691671, 0.49899448, 0.50804198]),\n",
       " 'std_test_score': array([0.01124236, 0.01834812, 0.00849484, 0.01650009, 0.02191382,\n",
       "        0.03563684, 0.02540059, 0.01089279, 0.00324574, 0.03024888,\n",
       "        0.04092278, 0.01712273, 0.02223579, 0.03076792, 0.06138902,\n",
       "        0.03655395, 0.03698866, 0.03946023, 0.04478497, 0.03005848,\n",
       "        0.01785706, 0.02213127, 0.01448523, 0.02204993, 0.06677722,\n",
       "        0.04108895, 0.02113384, 0.05750802, 0.03446962, 0.02651313,\n",
       "        0.05995826, 0.04096964, 0.03542935, 0.03283193, 0.03085189,\n",
       "        0.02160483, 0.02386391, 0.02826923, 0.02033205, 0.00668453,\n",
       "        0.02645145, 0.02340174, 0.0395542 , 0.02303301, 0.01914128,\n",
       "        0.02973758, 0.04264551, 0.06240322, 0.02866138, 0.02932238,\n",
       "        0.08510275, 0.02155158, 0.02051798, 0.01610198, 0.02328418,\n",
       "        0.03141222, 0.02197241, 0.02388069, 0.03224338, 0.09808507,\n",
       "        0.02829681, 0.02173632, 0.0593603 , 0.0180269 , 0.02339968,\n",
       "        0.01992263, 0.04729943, 0.0277567 , 0.01798232, 0.02338595,\n",
       "        0.02456983, 0.02250908, 0.02271669, 0.037614  , 0.02709587,\n",
       "        0.07266074, 0.06353316, 0.0241085 , 0.05706848, 0.03954027,\n",
       "        0.02656259, 0.03898135, 0.07416046, 0.02605762, 0.0344851 ,\n",
       "        0.07131315, 0.03206802, 0.01610147, 0.01978693, 0.02998367,\n",
       "        0.02293349, 0.02910929, 0.0811835 , 0.02247357, 0.02955846,\n",
       "        0.07641331, 0.02900032, 0.02372712, 0.0830949 , 0.0238557 ,\n",
       "        0.02793104, 0.03118366, 0.0265146 , 0.03148754, 0.02401394,\n",
       "        0.0255328 , 0.02963028, 0.01211182, 0.02969972, 0.02152953,\n",
       "        0.02264202, 0.03818911, 0.01941942, 0.02435311, 0.00934423,\n",
       "        0.02260002, 0.02775766, 0.05280182, 0.03894475, 0.03140373,\n",
       "        0.03844957, 0.05892706, 0.03226034, 0.04089584, 0.0208334 ,\n",
       "        0.03087032, 0.06353636, 0.02727461, 0.02627727, 0.03511312,\n",
       "        0.04414082, 0.0293497 , 0.04815267, 0.05257058, 0.03066634,\n",
       "        0.04928051, 0.04477749, 0.0196384 , 0.02285047, 0.02690962,\n",
       "        0.00768095, 0.02866838, 0.02796435, 0.01454385, 0.01652352,\n",
       "        0.02716327, 0.02220244, 0.02863488, 0.0250393 , 0.02682107,\n",
       "        0.03013226, 0.02896028, 0.05734936, 0.04904138, 0.04356006,\n",
       "        0.01907535, 0.02203534, 0.03088448, 0.02074595, 0.03959729,\n",
       "        0.01068303, 0.02354637, 0.07188846, 0.04436867, 0.04451909,\n",
       "        0.00526862, 0.02667577, 0.0287139 , 0.01541223, 0.03966559,\n",
       "        0.00384781, 0.01960204, 0.01808251, 0.0183885 , 0.04439924,\n",
       "        0.02392271, 0.01701578, 0.03740991, 0.0060533 , 0.02096302,\n",
       "        0.02307372, 0.00469327, 0.04045704, 0.01520496, 0.03377055,\n",
       "        0.02044988, 0.02818334, 0.02252222, 0.0180292 , 0.0258209 ,\n",
       "        0.03206986, 0.01936237, 0.03028768, 0.0289499 , 0.04310842,\n",
       "        0.0094706 , 0.04573862, 0.04734967, 0.0303808 , 0.03024593,\n",
       "        0.02168143, 0.01805028, 0.02472512, 0.0219743 , 0.01911981,\n",
       "        0.01481543, 0.02978424, 0.04302163, 0.00558686, 0.02559863,\n",
       "        0.02206537, 0.05015621, 0.01668603, 0.0364846 , 0.0329316 ,\n",
       "        0.01733409, 0.0394492 , 0.03073699, 0.03572916, 0.05545634,\n",
       "        0.04413473, 0.03528077, 0.02148318, 0.01826025, 0.02200213,\n",
       "        0.02274521, 0.01152822, 0.04044024, 0.0190833 , 0.01753525,\n",
       "        0.07356929, 0.02295833, 0.02279449, 0.06406192, 0.01698732,\n",
       "        0.02619351, 0.06689019, 0.02588281, 0.02581008, 0.0590867 ,\n",
       "        0.03007975, 0.02288023, 0.00341746, 0.02463257, 0.0212237 ,\n",
       "        0.02240828, 0.02194376, 0.01738471, 0.02771818, 0.04388269,\n",
       "        0.02828045, 0.02184318, 0.02922585, 0.03097136, 0.02850411,\n",
       "        0.05615527, 0.03540124, 0.02402473, 0.05623097, 0.02497151,\n",
       "        0.03024653, 0.04317375, 0.0513545 , 0.02533825, 0.01856985,\n",
       "        0.0208608 , 0.03677207, 0.01174965, 0.03680357, 0.03571594,\n",
       "        0.04026206, 0.02635657, 0.02005266, 0.015979  , 0.0131291 ,\n",
       "        0.01178039, 0.023061  , 0.01622085, 0.06824594, 0.03177419,\n",
       "        0.02077859, 0.00970478, 0.02723794, 0.02120966, 0.07225967,\n",
       "        0.0172549 , 0.02219252, 0.07813954, 0.03004307, 0.03312982,\n",
       "        0.04027349, 0.05228236, 0.00436875, 0.02289089, 0.01972759,\n",
       "        0.01661512, 0.04926637, 0.01149571, 0.01230585, 0.07207179,\n",
       "        0.00844047, 0.01283457, 0.02046659, 0.04484336, 0.05937292,\n",
       "        0.01944436, 0.02555518, 0.00339224, 0.01974562, 0.05826055,\n",
       "        0.02925437, 0.01664164, 0.02674629, 0.01366164, 0.03098824,\n",
       "        0.00986338, 0.04510391, 0.05234443, 0.02231448, 0.08412705,\n",
       "        0.00799948, 0.01459601, 0.02627823, 0.03631759, 0.03113148,\n",
       "        0.02219247, 0.07777899, 0.02573497, 0.03686649, 0.05605991,\n",
       "        0.0262341 , 0.02870313, 0.03765802, 0.01618223, 0.02328682,\n",
       "        0.05955711, 0.05108392, 0.02508775, 0.02870241, 0.03373108,\n",
       "        0.00592775, 0.00991129, 0.02043101, 0.02894969, 0.01583264,\n",
       "        0.01449083, 0.02014251, 0.03179433, 0.05959573, 0.05754709,\n",
       "        0.02397484, 0.04577415, 0.01643675, 0.02221226, 0.00594279,\n",
       "        0.02589138, 0.02481894, 0.06712109, 0.02418307, 0.02118333,\n",
       "        0.01595611, 0.02908571, 0.00389305, 0.02143573, 0.02961579,\n",
       "        0.02084126, 0.02575358, 0.01843279, 0.04864653, 0.03107271,\n",
       "        0.02729741, 0.01457163, 0.02279366, 0.02472713, 0.01036655,\n",
       "        0.03048475, 0.02691583, 0.04836238, 0.0252608 , 0.02848119,\n",
       "        0.05602503, 0.04343034, 0.01929719, 0.01729233, 0.01984404,\n",
       "        0.03124876, 0.02652567, 0.02131644, 0.01597602, 0.01476202,\n",
       "        0.00771789, 0.02458229, 0.01710222, 0.07124381, 0.03030555,\n",
       "        0.01476253, 0.01163579, 0.04212544, 0.02008903, 0.04568909,\n",
       "        0.01495801, 0.02560691, 0.0213475 , 0.02699957, 0.02456036,\n",
       "        0.07116663, 0.05875478, 0.07327783, 0.02212079, 0.05145803,\n",
       "        0.0167441 , 0.01741871, 0.02805671, 0.01565024, 0.02217045,\n",
       "        0.04011292, 0.04170782, 0.02689384, 0.02188273, 0.06874984,\n",
       "        0.02319093, 0.02915613, 0.04188718, 0.03180085, 0.03253879,\n",
       "        0.04508833, 0.02195514, 0.01513912, 0.01758283, 0.02131908,\n",
       "        0.0193086 , 0.02437046, 0.10847254, 0.04386617, 0.06614362,\n",
       "        0.05765235, 0.03293601, 0.02610082, 0.01716104, 0.02213818,\n",
       "        0.02777368, 0.08416846, 0.04625433, 0.01545973, 0.06878848,\n",
       "        0.07993509, 0.03326445, 0.0187871 , 0.00835839, 0.02748368,\n",
       "        0.03874577, 0.02354613, 0.06911667, 0.02145923, 0.0237673 ,\n",
       "        0.02353507, 0.02062852, 0.02456362, 0.03329248, 0.03083738,\n",
       "        0.02241799, 0.00889583, 0.02354717, 0.01358737, 0.05408317,\n",
       "        0.02486061, 0.02486089, 0.02020942, 0.04158794, 0.0183884 ,\n",
       "        0.02402288, 0.0409203 , 0.01455195, 0.02915598, 0.01035783,\n",
       "        0.02179171, 0.01819354, 0.05006271, 0.12978548, 0.0301705 ,\n",
       "        0.03716963, 0.0336019 , 0.01973257, 0.01068798, 0.02981151,\n",
       "        0.02711414, 0.08561555, 0.10612277, 0.02709566, 0.0712814 ,\n",
       "        0.0615942 , 0.02587923, 0.11555758, 0.04362859, 0.02463328,\n",
       "        0.01908849, 0.02929119, 0.04552249, 0.01377301, 0.03167869,\n",
       "        0.01731706, 0.02160934, 0.03203793, 0.04118032, 0.01457073,\n",
       "        0.02264816, 0.04802993, 0.02778711, 0.02474514, 0.10368349,\n",
       "        0.02601158, 0.02687672, 0.04954209, 0.01387635, 0.02194979,\n",
       "        0.01979256, 0.02514553, 0.00805722, 0.02758351, 0.02491133,\n",
       "        0.01046792, 0.02793521, 0.0551516 , 0.04703004, 0.03165786,\n",
       "        0.04528495, 0.01950437, 0.03443908, 0.04105759, 0.02620635,\n",
       "        0.03431071, 0.04865395, 0.01455118, 0.02594192, 0.07474643,\n",
       "        0.08429894, 0.02969084, 0.05157   , 0.0235493 , 0.02721789,\n",
       "        0.09464778, 0.08537241, 0.01297231, 0.03292527, 0.04693894,\n",
       "        0.07416553, 0.00690723, 0.01231934, 0.01846727, 0.02573728,\n",
       "        0.03103398, 0.05242748, 0.04405337, 0.02279477, 0.02243502,\n",
       "        0.03510577, 0.0219498 , 0.0082348 , 0.02881438, 0.03155666,\n",
       "        0.0451556 , 0.03134872, 0.02389388, 0.03629229, 0.01863865,\n",
       "        0.01874858, 0.01693366, 0.01724621, 0.02133289, 0.0208133 ,\n",
       "        0.06044242, 0.02130245, 0.00769324, 0.03428133, 0.05110868,\n",
       "        0.03927543, 0.02596349, 0.07084348, 0.0368418 , 0.01177368,\n",
       "        0.03522533, 0.00865207, 0.05458702, 0.02880263, 0.02852232,\n",
       "        0.04712235, 0.07163475, 0.03364649, 0.01669396, 0.02361609,\n",
       "        0.02164735, 0.01692543, 0.02615876, 0.03562022, 0.03371517,\n",
       "        0.02914252, 0.09474972, 0.02711918, 0.02262204, 0.02553093,\n",
       "        0.01025901, 0.02991923, 0.04317335, 0.02831992, 0.02848768,\n",
       "        0.02161323, 0.01632592, 0.02596331, 0.0342495 , 0.00524799,\n",
       "        0.02216192, 0.02451146, 0.08331229, 0.06622557, 0.02911123,\n",
       "        0.03449901, 0.01830504, 0.01300879, 0.03113307, 0.00616761,\n",
       "        0.0271144 , 0.09614789, 0.11293324, 0.02386808, 0.07857332,\n",
       "        0.11538491, 0.03788067, 0.04863947, 0.01300985, 0.02656161,\n",
       "        0.02063441, 0.01716608, 0.01724099, 0.01227454, 0.01904971,\n",
       "        0.02960467, 0.02401462, 0.02156392, 0.02005146, 0.01733463,\n",
       "        0.03296084, 0.06744465, 0.03061769, 0.02223669, 0.02602627,\n",
       "        0.03186437, 0.03295692, 0.0563604 , 0.02784346, 0.01854286,\n",
       "        0.0139187 , 0.04515098, 0.01762345, 0.01742055, 0.01479012,\n",
       "        0.02013875, 0.02224348, 0.02708881, 0.00593934, 0.02505864,\n",
       "        0.02452492, 0.03974577, 0.03456194, 0.05267048, 0.06606533,\n",
       "        0.02009238, 0.03364107, 0.04440724, 0.02298322, 0.03073884,\n",
       "        0.05469722, 0.03329667, 0.04604033, 0.03288862, 0.03271152,\n",
       "        0.04618006, 0.04692513, 0.00600386, 0.03867124, 0.08625729,\n",
       "        0.00167268, 0.03645136, 0.06677246, 0.05534833, 0.01431268,\n",
       "        0.0317291 , 0.01351295, 0.02402549, 0.01774533, 0.01090019,\n",
       "        0.03684278, 0.02894977, 0.02938463, 0.01527177, 0.02467561,\n",
       "        0.01293178, 0.01159368, 0.02463257, 0.04207591, 0.03116376,\n",
       "        0.03362772, 0.06700252, 0.00307887, 0.01340041, 0.05410968,\n",
       "        0.05248236, 0.02530274, 0.01683315, 0.01622088, 0.01924513,\n",
       "        0.04854465, 0.02252056, 0.02230443, 0.0295448 , 0.04851217,\n",
       "        0.02316339, 0.04870628, 0.04008522, 0.02122137, 0.04303697,\n",
       "        0.04340299, 0.07698527, 0.0068674 , 0.08141364, 0.04641162,\n",
       "        0.02108857, 0.02084877, 0.01459661, 0.02882574, 0.026487  ,\n",
       "        0.0234013 , 0.04681442, 0.03689317, 0.03169463, 0.01646452,\n",
       "        0.0198086 , 0.02264092, 0.02381147, 0.0370164 , 0.14185934,\n",
       "        0.04604334, 0.01178515, 0.02502651, 0.05738123, 0.02063446,\n",
       "        0.019921  , 0.02314426, 0.04763796, 0.02916716, 0.1063688 ,\n",
       "        0.0788577 , 0.03002353, 0.02317752, 0.03423147, 0.02092636,\n",
       "        0.02472924, 0.12444246, 0.02832701, 0.03566299, 0.01397424,\n",
       "        0.02981568, 0.02030481, 0.03326251, 0.02915705, 0.02523645,\n",
       "        0.10571298, 0.05071209, 0.00944254, 0.03644472, 0.03622531,\n",
       "        0.0395423 , 0.02658307, 0.01308058, 0.01832254, 0.01155084,\n",
       "        0.03079018, 0.01761164, 0.02178333, 0.02774701, 0.03581163,\n",
       "        0.0325173 , 0.03652356, 0.0378255 , 0.00814434, 0.02778925,\n",
       "        0.01854774, 0.02844646, 0.02549956, 0.02314142, 0.03646112,\n",
       "        0.02516581, 0.02081718, 0.05494324, 0.02957643, 0.01738179,\n",
       "        0.01511829, 0.00760521, 0.02706867, 0.05067878, 0.02521344,\n",
       "        0.0290241 , 0.01873978, 0.12235193, 0.02173885, 0.02574446,\n",
       "        0.01738345, 0.03735999, 0.00720486, 0.0264872 , 0.02388388]),\n",
       " 'rank_test_score': array([652, 613, 777, 504, 488, 711, 431, 454, 805, 114, 171, 774, 100,\n",
       "        223, 697, 266, 251, 698, 320, 117, 575, 284, 312, 459, 363, 180,\n",
       "        515, 607, 414, 411, 440, 472, 426, 523, 418, 283, 438, 417, 156,\n",
       "        691, 561, 189, 689, 605, 277, 424, 486, 730, 370, 369, 780, 247,\n",
       "        273, 769,  92,  95, 732, 150, 107, 673, 104,  91, 650, 331,  75,\n",
       "        395, 336, 464, 340, 410,  65, 239, 350, 338, 220, 611, 587, 214,\n",
       "        521, 469, 192, 543, 655, 139, 623, 550, 132, 632, 508, 204, 216,\n",
       "        265, 797, 145, 194, 799, 125,  94, 741,  80,  23, 586,  49,   7,\n",
       "        631,  37,  12, 541, 418, 286, 148, 357, 224, 196, 377, 309, 157,\n",
       "        492, 387, 170, 563, 510,  89, 565, 343, 154, 404, 484,  24, 595,\n",
       "        539,  64, 637, 507, 221, 667, 724, 809, 599, 584, 737, 527, 500,\n",
       "        794, 137, 250, 783, 205,  26, 714,  77, 120, 766, 614, 295, 601,\n",
       "        441, 129, 480, 610, 328, 485, 618, 473, 496, 589, 475, 432, 693,\n",
       "        497, 373, 522, 354, 421, 666, 427, 494, 674, 276, 313, 535, 579,\n",
       "        725, 465, 439, 754, 364, 274, 807, 165, 109, 781,  19,  95, 712,\n",
       "        244, 206, 695, 347,  45, 530, 253, 164, 478, 658, 102, 463, 532,\n",
       "        272, 412, 626, 398, 277, 332, 334, 173, 392, 405, 288, 598, 462,\n",
       "        201, 567, 551, 257, 349, 436, 763, 259, 254, 702, 133, 225, 742,\n",
       "         59,  13, 701,  29,  17, 686, 365,  15, 625, 499,  38, 424, 553,\n",
       "        142, 258, 549,  99, 299, 570, 246, 185, 545, 531, 143, 636, 197,\n",
       "        127, 477, 577,  52, 594, 311, 231, 626, 376, 172, 723, 765, 798,\n",
       "        708, 720, 802, 629, 683, 747, 292, 394, 762, 140, 240, 731, 203,\n",
       "        200, 736, 359, 134, 722, 456, 308, 664, 479, 182, 628, 556, 228,\n",
       "        649, 616, 227, 559, 498, 453, 520, 603, 304, 608, 581, 285, 548,\n",
       "        511, 159, 538, 678, 734, 748, 624, 679, 790, 542, 466, 759, 148,\n",
       "        183, 735, 209, 256, 738, 146, 105, 786, 362, 158, 687, 386,   3,\n",
       "        501,  98, 219, 558, 562, 210, 569, 208,  43, 483, 580, 382, 444,\n",
       "        593, 293, 526, 583, 371, 435, 574, 291, 378, 540, 615, 793, 379,\n",
       "        352, 795, 355, 385, 753,  76,  42, 771, 106,  55, 775, 235, 141,\n",
       "        796, 236,  18, 524, 416, 119, 396, 275,   4, 517, 255,  83, 339,\n",
       "        428, 290, 325, 573, 238, 348, 297, 226, 298, 516, 318, 169, 513,\n",
       "        476, 215, 668, 617, 779, 597, 557, 785, 399, 356, 791, 131, 198,\n",
       "        709, 191,  50, 705,  51,  72, 760, 229,  66, 645, 342, 122, 430,\n",
       "        306, 282, 489, 638, 491, 609, 536, 267, 403, 269, 176, 317, 692,\n",
       "        621, 304, 639, 630, 335, 390, 381, 195, 560, 393, 806, 345, 415,\n",
       "        758, 263, 319, 752,   2,   6, 745,  36, 115, 677,  43,  33, 704,\n",
       "        449,  22, 337, 406, 103, 375, 236, 300, 374, 487, 566, 166, 509,\n",
       "        372, 183, 474, 212, 232, 663, 718, 245, 644, 694, 264, 654, 591,\n",
       "         56, 249, 186, 740, 262, 152, 743, 138,  86, 773,  21, 130, 672,\n",
       "         11,  46, 700,   5,  53, 635, 402, 401, 271, 322, 213, 128, 409,\n",
       "        126, 175, 619, 452, 178, 503, 400, 116, 546, 547, 177, 662, 640,\n",
       "        117, 634, 660, 202, 648, 505,  41, 681, 719, 801, 669, 680, 751,\n",
       "        552, 555, 784, 248, 144, 750, 357, 110, 768, 160, 190, 746, 326,\n",
       "         47, 690, 281,  69, 606, 211,  90, 529, 622, 167, 450, 422,  70,\n",
       "        423, 457, 121, 471, 612, 467, 455, 525, 408, 512, 568, 534, 445,\n",
       "        588, 682, 710, 514, 397, 756, 434, 388, 808, 218, 187, 789,  57,\n",
       "         63, 715, 199,  20, 727, 460,  74, 576, 351,  27, 518, 458,  58,\n",
       "        490, 675, 433, 383, 302,  62, 333, 279, 260, 302, 671, 659, 286,\n",
       "        657, 641, 294, 633, 280, 243, 367, 389, 778, 344, 341, 764, 270,\n",
       "        110, 804, 108,  32, 713,   9,  48, 684,  28,   1, 717, 289, 147,\n",
       "        360, 537,  60, 327, 233, 168, 314, 572, 301, 163, 310, 321, 222,\n",
       "        651, 446, 136, 571, 585,  84, 578, 447, 153, 413, 346,  78, 721,\n",
       "        728, 770, 749, 707, 716, 647, 656, 810, 361, 329, 761, 193, 124,\n",
       "        767, 123, 160, 792, 181,  73, 726, 323,  31, 733, 330,  40, 696,\n",
       "        468, 242, 653, 353,  67, 646, 493,  88, 592, 582,  61, 600, 620,\n",
       "        315, 590, 296,  82, 596, 703, 699, 739, 688, 642, 782, 603, 554,\n",
       "        800, 230, 112, 788, 113, 151, 803,  54,  85, 744, 179, 564, 676,\n",
       "        261,  97, 661,  10, 135, 544, 443, 207, 665, 519,  39, 448, 323,\n",
       "         93, 495, 670, 174, 533, 442, 437, 461, 481, 162, 451, 706, 685,\n",
       "        772, 502, 602, 757, 407, 429, 755,  81, 155, 787,  79,  35, 729,\n",
       "         34,  16, 776, 234,  30, 506,  14,  25, 528,  68,   8, 482, 268,\n",
       "         86, 366, 420,  71, 380, 470, 241, 368, 391, 643, 307, 100, 188,\n",
       "        217, 384, 316, 252])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details in the training results\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>neurons</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.032957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.547786</td>\n",
       "      <td>0.030837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.100</td>\n",
       "      <td>16</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.543772</td>\n",
       "      <td>0.025088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.100</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.543269</td>\n",
       "      <td>0.031249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.543267</td>\n",
       "      <td>0.026012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.216756</td>\n",
       "      <td>0.069117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>tanh</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.197698</td>\n",
       "      <td>0.018029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.194147</td>\n",
       "      <td>0.035620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tanh</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.149887</td>\n",
       "      <td>0.019638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.146865</td>\n",
       "      <td>0.055348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    activation  batch_size  epochs  learning_rate  neurons optimizer  \\\n",
       "646       relu          20      20          0.010       32      adam   \n",
       "459       relu          10      10          0.010        8   rmsprop   \n",
       "337       tanh          50      10          0.100       16      adam   \n",
       "385       tanh          50      20          0.100       32      adam   \n",
       "510       relu          10      20          0.010       32   rmsprop   \n",
       "..         ...         ...     ...            ...      ...       ...   \n",
       "452       relu          10      10          0.001        8       sgd   \n",
       "188       tanh          20      10          0.001       32       sgd   \n",
       "593       relu          20      10          0.001       32       sgd   \n",
       "137       tanh          20       5          0.001        8       sgd   \n",
       "683       relu          50       5          0.001       32       sgd   \n",
       "\n",
       "         Mean       Std  \n",
       "646  0.547794  0.032957  \n",
       "459  0.547786  0.030837  \n",
       "337  0.543772  0.025088  \n",
       "385  0.543269  0.031249  \n",
       "510  0.543267  0.026012  \n",
       "..        ...       ...  \n",
       "452  0.216756  0.069117  \n",
       "188  0.197698  0.018029  \n",
       "593  0.194147  0.035620  \n",
       "137  0.149887  0.019638  \n",
       "683  0.146865  0.055348  \n",
       "\n",
       "[810 rows x 8 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Hyperparameter listed out and shown as dataframe\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "df = pd.DataFrame(params)\n",
    "df['Mean'] = means\n",
    "df['Std'] = stds\n",
    "\n",
    "df.sort_values('Mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 51.352326000721234 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.67       736\n",
      "           1       0.36      0.36      0.36       652\n",
      "           2       0.36      0.43      0.39       584\n",
      "           3       0.73      0.49      0.59       801\n",
      "\n",
      "    accuracy                           0.51      2773\n",
      "   macro avg       0.52      0.51      0.50      2773\n",
      "weighted avg       0.53      0.51      0.52      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test data with the best hyperparameters\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print('Accuracy on test data:',accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction correct: 51.35232600072124 %\n",
      "Miss by 1 label: 38.297872340425535 %\n",
      "Miss by 2 labels: 8.835196538045437 %\n",
      "Miss by 3 labels: 1.5146051208077893 %\n"
     ]
    }
   ],
   "source": [
    "# Check how far our model has mis-labeled prediction\n",
    "pred_correct = 0\n",
    "miss_1_label = 0\n",
    "miss_2_label = 0\n",
    "miss_3_label = 0\n",
    "\n",
    "for pos,i in enumerate(y_test):\n",
    "    if i-y_pred[pos] == 0:\n",
    "        pred_correct +=1\n",
    "    elif abs(i-y_pred[pos]) == 1:\n",
    "        miss_1_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 2:\n",
    "        miss_2_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 3:\n",
    "        miss_3_label +=1\n",
    "\n",
    "print ('Prediction correct:', pred_correct*100/len(y_test),'%')\n",
    "print ('Miss by 1 label:', miss_1_label*100/len(y_test),'%')\n",
    "print ('Miss by 2 labels:', miss_2_label*100/len(y_test),'%')\n",
    "print ('Miss by 3 labels:', miss_3_label*100/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))#,labels=labels_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#,display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar result where more mid-categories are being correctly predicted and an overall improvement in f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('model/NN_multiclass-gridsearch-balanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Classifiers with balanced data\n",
    "\n",
    "To see if the prediction varies using different models, we also explored logistic regression and SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1988, 5)\n",
      "(2773, 5)\n",
      "(1988, 1)\n",
      "(2773, 1)\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced training data shape : 2585\n",
    "# Balanced training data shape : 1988\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "print(y_train.shape); print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text_cos', 'key', 'title_cos', 'title_ne', 'text_ne']\n",
      "[ 4.64133342 -0.5365956   3.31912042  0.19176666  0.78393299]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Coeficients\n",
    "coef = logres.coef_[0]\n",
    "print (predictors)\n",
    "print (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data: 0.5427565392354124\n",
      "\n",
      "Test Report:\n",
      "Accuracy on test data: 0.5128020194734945\n",
      "\n",
      "Prediction correct: 51.28020194734944 %\n",
      "Miss by 1 label: 37.035701406419044 %\n",
      "Miss by 2 labels: 9.628561125135233 %\n",
      "Miss by 3 labels: 2.0555355210962856 %\n"
     ]
    }
   ],
   "source": [
    "# Prediction on train data\n",
    "y_pred = logreg.predict(X_train)\n",
    "print('Accuracy on train data:', logreg.score(X_train, y_train))\n",
    "\n",
    "# Prediction on test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('\\nTest Report:\\nAccuracy on test data:',logreg.score(X_test, y_test))\n",
    "\n",
    "# Check how far our model has mis-labeled prediction\n",
    "pred_correct = 0\n",
    "miss_1_label = 0\n",
    "miss_2_label = 0\n",
    "miss_3_label = 0\n",
    "\n",
    "for pos,i in enumerate(y_test):\n",
    "    if i-y_pred[pos] == 0:\n",
    "        pred_correct +=1\n",
    "    elif abs(i-y_pred[pos]) == 1:\n",
    "        miss_1_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 2:\n",
    "        miss_2_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 3:\n",
    "        miss_3_label +=1\n",
    "\n",
    "print ('\\nPrediction correct:', pred_correct*100/len(y_test),'%')\n",
    "print ('Miss by 1 label:', miss_1_label*100/len(y_test),'%')\n",
    "print ('Miss by 2 labels:', miss_2_label*100/len(y_test),'%')\n",
    "print ('Miss by 3 labels:', miss_3_label*100/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.66       736\n",
      "           1       0.36      0.30      0.33       652\n",
      "           2       0.37      0.43      0.40       584\n",
      "           3       0.69      0.52      0.60       801\n",
      "\n",
      "    accuracy                           0.51      2773\n",
      "   macro avg       0.50      0.50      0.50      2773\n",
      "weighted avg       0.52      0.51      0.51      2773\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train data: 0.545271629778672\n",
      "\n",
      "Test Report:\n",
      "Accuracy on test data: 0.5243418680129823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67       736\n",
      "           1       0.38      0.31      0.35       652\n",
      "           2       0.38      0.47      0.42       584\n",
      "           3       0.71      0.53      0.61       801\n",
      "\n",
      "    accuracy                           0.52      2773\n",
      "   macro avg       0.52      0.52      0.51      2773\n",
      "weighted avg       0.53      0.52      0.52      2773\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction on train data\n",
    "y_pred = clf.predict(X_train)\n",
    "print('Accuracy on train data:',clf.score(X_train, y_train))\n",
    "\n",
    "# Prediction on test data\n",
    "y_pred = clf.predict(X_test)\n",
    "print('\\nTest Report:\\nAccuracy on test data:',clf.score(X_test, y_test))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier - GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/ <div> \n",
    "https://www.vebuso.com/2020/03/svm-hyperparameter-tuning-using-gridsearchcv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=0.1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=0.1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=0.1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.1, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=0.1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=0.1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=0.1, gamma=0.001, kernel=rbf; total time=   0.2s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=0.1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=0.1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=0.1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=0.1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ................C=0.1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=0.1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=0.1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=0.1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=0.1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=1, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...........................C=1, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=1, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=1, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.01, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=1, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=1, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=1, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=1, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..................C=1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=1, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END .........................C=10, gamma=1, kernel=poly; total time=   0.0s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..........................C=10, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ........................C=10, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=10, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=10, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=10, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=10, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=10, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=10, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .................C=10, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=1, kernel=linear; total time=   0.1s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.4s\n",
      "[CV] END ........................C=100, gamma=1, kernel=poly; total time=   0.3s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .........................C=100, gamma=1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END .......................C=100, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.01, kernel=linear; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=100, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ..................C=100, gamma=0.001, kernel=linear; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=100, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=   0.0s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=   0.1s\n",
      "[CV] END .................C=100, gamma=0.0001, kernel=linear; total time=   0.1s\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=100, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=100, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ................C=100, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=100, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=100, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=100, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END ................C=100, gamma=0.0001, kernel=sigmoid; total time=   0.1s\n",
      "[CV] END .....................C=1000, gamma=1, kernel=linear; total time=   0.4s\n",
      "[CV] END .....................C=1000, gamma=1, kernel=linear; total time=   0.4s\n",
      "[CV] END .....................C=1000, gamma=1, kernel=linear; total time=   0.5s\n",
      "[CV] END .....................C=1000, gamma=1, kernel=linear; total time=   0.4s\n",
      "[CV] END .....................C=1000, gamma=1, kernel=linear; total time=   0.4s\n",
      "[CV] END .......................C=1000, gamma=1, kernel=poly; total time=   3.3s\n",
      "[CV] END .......................C=1000, gamma=1, kernel=poly; total time=   3.4s\n",
      "[CV] END .......................C=1000, gamma=1, kernel=poly; total time=   3.3s\n",
      "[CV] END .......................C=1000, gamma=1, kernel=poly; total time=   3.7s\n",
      "[CV] END .......................C=1000, gamma=1, kernel=poly; total time=   3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.8s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.7s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.6s\n",
      "[CV] END ........................C=1000, gamma=1, kernel=rbf; total time=   0.7s\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.1, kernel=linear; total time=   0.4s\n",
      "[CV] END ...................C=1000, gamma=0.1, kernel=linear; total time=   0.4s\n",
      "[CV] END ...................C=1000, gamma=0.1, kernel=linear; total time=   0.5s\n",
      "[CV] END ...................C=1000, gamma=0.1, kernel=linear; total time=   0.4s\n",
      "[CV] END ...................C=1000, gamma=0.1, kernel=linear; total time=   0.4s\n",
      "[CV] END .....................C=1000, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.1, kernel=poly; total time=   0.0s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.1s\n",
      "[CV] END ......................C=1000, gamma=0.1, kernel=rbf; total time=   0.2s\n",
      "[CV] END ..................C=1000, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.1, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.01, kernel=linear; total time=   0.3s\n",
      "[CV] END ..................C=1000, gamma=0.01, kernel=linear; total time=   0.4s\n",
      "[CV] END ..................C=1000, gamma=0.01, kernel=linear; total time=   0.5s\n",
      "[CV] END ..................C=1000, gamma=0.01, kernel=linear; total time=   0.4s\n",
      "[CV] END ..................C=1000, gamma=0.01, kernel=linear; total time=   0.4s\n",
      "[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.1s\n",
      "[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.01, kernel=poly; total time=   0.0s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .....................C=1000, gamma=0.01, kernel=rbf; total time=   0.1s\n",
      "[CV] END .................C=1000, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=1000, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=1000, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=1000, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=1000, gamma=0.01, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END .................C=1000, gamma=0.001, kernel=linear; total time=   0.4s\n",
      "[CV] END .................C=1000, gamma=0.001, kernel=linear; total time=   0.4s\n",
      "[CV] END .................C=1000, gamma=0.001, kernel=linear; total time=   0.5s\n",
      "[CV] END .................C=1000, gamma=0.001, kernel=linear; total time=   0.4s\n",
      "[CV] END .................C=1000, gamma=0.001, kernel=linear; total time=   0.4s\n",
      "[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.001, kernel=poly; total time=   0.0s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ....................C=1000, gamma=0.001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ................C=1000, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................C=1000, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................C=1000, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................C=1000, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................C=1000, gamma=0.001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................C=1000, gamma=0.0001, kernel=linear; total time=   0.4s\n",
      "[CV] END ................C=1000, gamma=0.0001, kernel=linear; total time=   0.4s\n",
      "[CV] END ................C=1000, gamma=0.0001, kernel=linear; total time=   0.5s\n",
      "[CV] END ................C=1000, gamma=0.0001, kernel=linear; total time=   0.4s\n",
      "[CV] END ................C=1000, gamma=0.0001, kernel=linear; total time=   0.4s\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time=   0.1s\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................C=1000, gamma=0.0001, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...................C=1000, gamma=0.0001, kernel=rbf; total time=   0.1s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............C=1000, gamma=0.0001, kernel=sigmoid; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "# Initialize SVM classifier\n",
    "svm_grid = svm.SVC()\n",
    "\n",
    "# Tuning hyperparameters\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear','poly','rbf','sigmoid']}\n",
    " \n",
    "grid = GridSearchCV(svm_grid, param_grid, refit = True, verbose = 2)\n",
    " \n",
    "# Fitting the model for grid search\n",
    "svm_grid_result = grid.fit(X_train, y_train.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.543795 using {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Print search results\n",
    "print(\"Best: %f using %s\" % (svm_grid_result.best_score_, svm_grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.07679439, 0.07819085, 0.12015615, 0.14326901, 0.07420983,\n",
       "        0.11019759, 0.15777769, 0.15158811, 0.0764358 , 0.11128173,\n",
       "        0.16276603, 0.15220027, 0.07878737, 0.11428661, 0.17415586,\n",
       "        0.15341787, 0.08361406, 0.11249213, 0.16815033, 0.154985  ,\n",
       "        0.06746264, 0.08018527, 0.10789871, 0.10591893, 0.06636443,\n",
       "        0.10691481, 0.11728568, 0.11130433, 0.06320381, 0.10850468,\n",
       "        0.15326533, 0.14421477, 0.06781335, 0.11258216, 0.16875086,\n",
       "        0.14741058, 0.06465445, 0.10982714, 0.17465305, 0.15111532,\n",
       "        0.07639594, 0.11608934, 0.11269865, 0.08840499, 0.08198061,\n",
       "        0.10113473, 0.11727972, 0.10304394, 0.07767386, 0.11592302,\n",
       "        0.11426969, 0.10731254, 0.07499976, 0.1073822 , 0.14700689,\n",
       "        0.14181733, 0.07599864, 0.10730577, 0.16744251, 0.16133246,\n",
       "        0.15965667, 0.44648771, 0.18349257, 0.08058424, 0.13882837,\n",
       "        0.08277869, 0.11668086, 0.10948257, 0.13662925, 0.10930495,\n",
       "        0.10672956, 0.09714689, 0.14041381, 0.11136351, 0.11590424,\n",
       "        0.11089578, 0.13849616, 0.111134  , 0.15577731, 0.14959469,\n",
       "        0.49387941, 3.52910371, 0.71550074, 0.07598929, 0.48139539,\n",
       "        0.07799544, 0.1962924 , 0.09302435, 0.49104686, 0.1229403 ,\n",
       "        0.13683386, 0.11288686, 0.49427853, 0.12087669, 0.11127896,\n",
       "        0.10033016, 0.49778123, 0.11829233, 0.12785211, 0.11489544]),\n",
       " 'std_fit_time': array([0.00454825, 0.00079784, 0.00177198, 0.01341956, 0.00472039,\n",
       "        0.00329908, 0.00511054, 0.00142062, 0.0021071 , 0.00349312,\n",
       "        0.00330329, 0.00362117, 0.00209848, 0.00285666, 0.00818991,\n",
       "        0.00460598, 0.0116243 , 0.00135754, 0.00430579, 0.00223907,\n",
       "        0.00246665, 0.00444195, 0.00657192, 0.00318132, 0.00325642,\n",
       "        0.00364805, 0.00511094, 0.00360296, 0.00131629, 0.00172385,\n",
       "        0.00403228, 0.00446425, 0.0028207 , 0.00280135, 0.00285585,\n",
       "        0.00453794, 0.00250889, 0.00601298, 0.00580992, 0.00603938,\n",
       "        0.00119673, 0.00623182, 0.00154508, 0.00988936, 0.01089635,\n",
       "        0.00521119, 0.01163126, 0.00448973, 0.00200857, 0.00276061,\n",
       "        0.00242476, 0.00205342, 0.00193382, 0.00149479, 0.00442549,\n",
       "        0.00204699, 0.00118246, 0.00133484, 0.00525219, 0.00719136,\n",
       "        0.01028114, 0.05726926, 0.00696678, 0.00317922, 0.00342042,\n",
       "        0.0035117 , 0.0023619 , 0.00872621, 0.00454126, 0.00150638,\n",
       "        0.00201574, 0.0016187 , 0.00662566, 0.00118581, 0.00376137,\n",
       "        0.00230865, 0.00361573, 0.00286052, 0.00675498, 0.00433718,\n",
       "        0.02835916, 0.12781297, 0.04405314, 0.002711  , 0.03994344,\n",
       "        0.00262754, 0.00489646, 0.00248523, 0.04417152, 0.00777537,\n",
       "        0.00291781, 0.00181708, 0.03661533, 0.00171594, 0.00297495,\n",
       "        0.00301182, 0.0298574 , 0.00780876, 0.00985609, 0.00182165]),\n",
       " 'mean_score_time': array([0.01456113, 0.01535892, 0.05537424, 0.02479086, 0.01455245,\n",
       "        0.01706901, 0.06342301, 0.02511425, 0.01472006, 0.01734624,\n",
       "        0.06015639, 0.02432747, 0.01553202, 0.01795917, 0.06218843,\n",
       "        0.0240591 , 0.01712308, 0.01997414, 0.06186461, 0.02533255,\n",
       "        0.01396265, 0.01515951, 0.05365639, 0.02293606, 0.01456175,\n",
       "        0.01635642, 0.05550165, 0.02174377, 0.01416259, 0.01676731,\n",
       "        0.05996833, 0.02392588, 0.01477084, 0.01781969, 0.06274695,\n",
       "        0.02339959, 0.01373572, 0.01682591, 0.08836598, 0.02513285,\n",
       "        0.01336398, 0.01555839, 0.05146241, 0.02173886, 0.0159575 ,\n",
       "        0.01815014, 0.06163754, 0.02191157, 0.01396184, 0.01824894,\n",
       "        0.05387926, 0.02114329, 0.01376309, 0.01715455, 0.06044626,\n",
       "        0.02354007, 0.01396823, 0.01716084, 0.06263013, 0.02619472,\n",
       "        0.01720195, 0.01487861, 0.05255914, 0.01914921, 0.01416245,\n",
       "        0.0165555 , 0.05266623, 0.01973863, 0.01401181, 0.01695371,\n",
       "        0.05227842, 0.02114186, 0.01476078, 0.01788445, 0.0526608 ,\n",
       "        0.02234001, 0.0147222 , 0.01772919, 0.06121936, 0.0250062 ,\n",
       "        0.0161829 , 0.01817074, 0.05240755, 0.01855063, 0.01366973,\n",
       "        0.01516223, 0.05303397, 0.0162025 , 0.0135644 , 0.01922326,\n",
       "        0.0588429 , 0.02154183, 0.01436129, 0.01874981, 0.05389838,\n",
       "        0.021944  , 0.01466975, 0.01884694, 0.0591012 , 0.02299209]),\n",
       " 'std_score_time': array([0.00048868, 0.00048862, 0.0015883 , 0.00095119, 0.00078448,\n",
       "        0.00103624, 0.00396584, 0.00096323, 0.00079228, 0.0007923 ,\n",
       "        0.00058735, 0.00101337, 0.00096463, 0.00064112, 0.003513  ,\n",
       "        0.00067705, 0.00279719, 0.00558327, 0.00058441, 0.00101722,\n",
       "        0.0006309 , 0.00039892, 0.00171616, 0.00062646, 0.00048997,\n",
       "        0.00048895, 0.00178932, 0.00115944, 0.00039897, 0.00074995,\n",
       "        0.00188847, 0.00154603, 0.0004058 , 0.00072925, 0.00322337,\n",
       "        0.00045324, 0.00070461, 0.00077794, 0.03714717, 0.00193382,\n",
       "        0.0004886 , 0.00048844, 0.00101707, 0.00254303, 0.00398962,\n",
       "        0.0009829 , 0.00819467, 0.00063386, 0.00062864, 0.00074514,\n",
       "        0.0022869 , 0.00039883, 0.00039918, 0.00039919, 0.00326057,\n",
       "        0.00080449, 0.0006356 , 0.00039802, 0.00324249, 0.00131075,\n",
       "        0.00198026, 0.00065116, 0.00159709, 0.0003988 , 0.00039904,\n",
       "        0.00079778, 0.00193869, 0.00074445, 0.00063803, 0.0006298 ,\n",
       "        0.0023407 , 0.00074617, 0.00074598, 0.00063168, 0.00116919,\n",
       "        0.00101728, 0.00072475, 0.00038933, 0.00291583, 0.00110196,\n",
       "        0.00340414, 0.00342828, 0.00253551, 0.00048881, 0.00061547,\n",
       "        0.00039664, 0.00192742, 0.00096738, 0.00119684, 0.00037186,\n",
       "        0.00109201, 0.00048901, 0.00079792, 0.00074619, 0.00182392,\n",
       "        0.00062087, 0.00128532, 0.00111277, 0.00523228, 0.0006314 ]),\n",
       " 'param_C': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "                    1000, 1000, 1000, 1000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 1, 1, 1, 1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid', 'linear', 'poly',\n",
       "                    'rbf', 'sigmoid', 'linear', 'poly', 'rbf', 'sigmoid',\n",
       "                    'linear', 'poly', 'rbf', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 0.1, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 100, 'gamma': 0.0001, 'kernel': 'sigmoid'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 1, 'kernel': 'sigmoid'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.1, 'kernel': 'sigmoid'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.01, 'kernel': 'sigmoid'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.001, 'kernel': 'sigmoid'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'linear'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'poly'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'},\n",
       "  {'C': 1000, 'gamma': 0.0001, 'kernel': 'sigmoid'}],\n",
       " 'split0_test_score': array([0.48994975, 0.42462312, 0.49748744, 0.45477387, 0.48994975,\n",
       "        0.26130653, 0.44723618, 0.38190955, 0.48994975, 0.26130653,\n",
       "        0.33417085, 0.33165829, 0.48994975, 0.26130653, 0.33165829,\n",
       "        0.33165829, 0.48994975, 0.26130653, 0.33165829, 0.33165829,\n",
       "        0.48492462, 0.44221106, 0.47738693, 0.40703518, 0.48492462,\n",
       "        0.27638191, 0.47738693, 0.48492462, 0.48492462, 0.26130653,\n",
       "        0.43467337, 0.38190955, 0.48492462, 0.26130653, 0.33165829,\n",
       "        0.33165829, 0.48492462, 0.26130653, 0.33165829, 0.33165829,\n",
       "        0.48492462, 0.46231156, 0.47738693, 0.43969849, 0.48492462,\n",
       "        0.40201005, 0.48492462, 0.48743719, 0.48492462, 0.26130653,\n",
       "        0.4798995 , 0.48743719, 0.48492462, 0.26130653, 0.43467337,\n",
       "        0.38190955, 0.48492462, 0.26130653, 0.33165829, 0.33165829,\n",
       "        0.48492462, 0.46733668, 0.47487437, 0.43718593, 0.48492462,\n",
       "        0.42462312, 0.47738693, 0.50251256, 0.48492462, 0.26130653,\n",
       "        0.48492462, 0.48492462, 0.48492462, 0.26130653, 0.48492462,\n",
       "        0.48994975, 0.48492462, 0.26130653, 0.43467337, 0.38190955,\n",
       "        0.48492462, 0.45728643, 0.49497487, 0.43467337, 0.48492462,\n",
       "        0.44221106, 0.48492462, 0.48743719, 0.48492462, 0.27638191,\n",
       "        0.4798995 , 0.48492462, 0.48492462, 0.26130653, 0.48743719,\n",
       "        0.48492462, 0.48492462, 0.26130653, 0.48241206, 0.48994975]),\n",
       " 'split1_test_score': array([0.50753769, 0.48743719, 0.49748744, 0.43969849, 0.50753769,\n",
       "        0.25125628, 0.41959799, 0.43969849, 0.50753769, 0.25125628,\n",
       "        0.33668342, 0.33165829, 0.50753769, 0.25125628, 0.33165829,\n",
       "        0.33165829, 0.50753769, 0.25125628, 0.33165829, 0.33165829,\n",
       "        0.5201005 , 0.50502513, 0.54020101, 0.33165829, 0.5201005 ,\n",
       "        0.27889447, 0.51256281, 0.50753769, 0.5201005 , 0.25125628,\n",
       "        0.42211055, 0.44974874, 0.5201005 , 0.25125628, 0.33165829,\n",
       "        0.33165829, 0.5201005 , 0.25125628, 0.33165829, 0.33165829,\n",
       "        0.52261307, 0.48994975, 0.53266332, 0.3040201 , 0.52261307,\n",
       "        0.41959799, 0.53015075, 0.5201005 , 0.52261307, 0.25125628,\n",
       "        0.51005025, 0.50753769, 0.52261307, 0.25125628, 0.42211055,\n",
       "        0.44974874, 0.52261307, 0.25125628, 0.33165829, 0.33165829,\n",
       "        0.51758794, 0.48994975, 0.52261307, 0.32663317, 0.51758794,\n",
       "        0.48743719, 0.54020101, 0.48743719, 0.51758794, 0.25125628,\n",
       "        0.51005025, 0.5201005 , 0.51758794, 0.25125628, 0.51005025,\n",
       "        0.50753769, 0.51758794, 0.25125628, 0.42211055, 0.44974874,\n",
       "        0.51758794, 0.49497487, 0.52763819, 0.32663317, 0.51758794,\n",
       "        0.50502513, 0.53015075, 0.42211055, 0.51758794, 0.27889447,\n",
       "        0.52512563, 0.52261307, 0.51758794, 0.25125628, 0.51758794,\n",
       "        0.5201005 , 0.51758794, 0.25125628, 0.51005025, 0.50753769]),\n",
       " 'split2_test_score': array([0.53266332, 0.50502513, 0.51758794, 0.46231156, 0.53266332,\n",
       "        0.25376884, 0.45979899, 0.44472362, 0.53266332, 0.25376884,\n",
       "        0.34422111, 0.34673367, 0.53266332, 0.25376884, 0.34673367,\n",
       "        0.34673367, 0.53266332, 0.25376884, 0.34673367, 0.34673367,\n",
       "        0.5678392 , 0.54522613, 0.55527638, 0.37437186, 0.5678392 ,\n",
       "        0.27386935, 0.55276382, 0.53517588, 0.5678392 , 0.25376884,\n",
       "        0.45979899, 0.44221106, 0.5678392 , 0.25376884, 0.34673367,\n",
       "        0.34673367, 0.5678392 , 0.25376884, 0.34673367, 0.34673367,\n",
       "        0.56532663, 0.55025126, 0.54271357, 0.38442211, 0.56532663,\n",
       "        0.42462312, 0.55527638, 0.5678392 , 0.56532663, 0.25376884,\n",
       "        0.55025126, 0.53266332, 0.56532663, 0.25376884, 0.45226131,\n",
       "        0.44221106, 0.56532663, 0.25376884, 0.34673367, 0.34673367,\n",
       "        0.56281407, 0.53266332, 0.53768844, 0.4120603 , 0.56281407,\n",
       "        0.50502513, 0.56281407, 0.5201005 , 0.56281407, 0.25376884,\n",
       "        0.56281407, 0.5678392 , 0.56281407, 0.25376884, 0.55025126,\n",
       "        0.53266332, 0.56281407, 0.25376884, 0.45226131, 0.44221106,\n",
       "        0.56281407, 0.53015075, 0.5201005 , 0.4120603 , 0.56281407,\n",
       "        0.54522613, 0.54522613, 0.45226131, 0.56281407, 0.27386935,\n",
       "        0.56281407, 0.56532663, 0.56281407, 0.25376884, 0.57035176,\n",
       "        0.5678392 , 0.56281407, 0.25376884, 0.55025126, 0.53266332]),\n",
       " 'split3_test_score': array([0.5465995 , 0.49370277, 0.50881612, 0.45843829, 0.5465995 ,\n",
       "        0.26448363, 0.47607053, 0.47355164, 0.5465995 , 0.26448363,\n",
       "        0.36775819, 0.36523929, 0.5465995 , 0.26448363, 0.36523929,\n",
       "        0.36523929, 0.5465995 , 0.26448363, 0.36523929, 0.36523929,\n",
       "        0.55163728, 0.49622166, 0.56423174, 0.37279597, 0.55163728,\n",
       "        0.26700252, 0.55163728, 0.5440806 , 0.55163728, 0.26448363,\n",
       "        0.4861461 , 0.47103275, 0.55163728, 0.26448363, 0.36523929,\n",
       "        0.36523929, 0.55163728, 0.26448363, 0.36523929, 0.36523929,\n",
       "        0.55415617, 0.5163728 , 0.55415617, 0.33501259, 0.55415617,\n",
       "        0.44080605, 0.56171285, 0.54911839, 0.55415617, 0.26448363,\n",
       "        0.55415617, 0.5465995 , 0.55415617, 0.26448363, 0.4861461 ,\n",
       "        0.47103275, 0.55415617, 0.26448363, 0.36523929, 0.36523929,\n",
       "        0.55667506, 0.52644836, 0.5440806 , 0.3324937 , 0.55667506,\n",
       "        0.49370277, 0.55667506, 0.5163728 , 0.55667506, 0.26448363,\n",
       "        0.54911839, 0.55163728, 0.55667506, 0.26448363, 0.55415617,\n",
       "        0.5465995 , 0.55667506, 0.26448363, 0.4861461 , 0.47103275,\n",
       "        0.55667506, 0.53148615, 0.5440806 , 0.32997481, 0.55667506,\n",
       "        0.49622166, 0.54156171, 0.4534005 , 0.55667506, 0.26700252,\n",
       "        0.5768262 , 0.55415617, 0.55667506, 0.26448363, 0.55163728,\n",
       "        0.55163728, 0.55667506, 0.26448363, 0.55415617, 0.5465995 ]),\n",
       " 'split4_test_score': array([0.53148615, 0.47607053, 0.52392947, 0.4534005 , 0.53148615,\n",
       "        0.2720403 , 0.46095718, 0.41309824, 0.53148615, 0.2720403 ,\n",
       "        0.35012594, 0.34256927, 0.53148615, 0.2720403 , 0.34256927,\n",
       "        0.34256927, 0.53148615, 0.2720403 , 0.34256927, 0.34256927,\n",
       "        0.56423174, 0.52392947, 0.56171285, 0.34508816, 0.56423174,\n",
       "        0.302267  , 0.53400504, 0.53148615, 0.56423174, 0.2720403 ,\n",
       "        0.46095718, 0.41057935, 0.56423174, 0.2720403 , 0.34256927,\n",
       "        0.34256927, 0.56423174, 0.2720403 , 0.34256927, 0.34256927,\n",
       "        0.57934509, 0.54156171, 0.58942065, 0.32493703, 0.57934509,\n",
       "        0.37027708, 0.56675063, 0.56171285, 0.57934509, 0.2720403 ,\n",
       "        0.53652393, 0.53148615, 0.57934509, 0.2720403 , 0.46347607,\n",
       "        0.41057935, 0.57934509, 0.2720403 , 0.34256927, 0.34256927,\n",
       "        0.5768262 , 0.55415617, 0.57934509, 0.32997481, 0.5768262 ,\n",
       "        0.47607053, 0.57178841, 0.54911839, 0.5768262 , 0.2720403 ,\n",
       "        0.57178841, 0.56423174, 0.5768262 , 0.2720403 , 0.53400504,\n",
       "        0.53148615, 0.5768262 , 0.2720403 , 0.46347607, 0.41057935,\n",
       "        0.5768262 , 0.5465995 , 0.5440806 , 0.31989924, 0.5768262 ,\n",
       "        0.52392947, 0.58942065, 0.49118388, 0.5768262 , 0.302267  ,\n",
       "        0.5743073 , 0.57934509, 0.5768262 , 0.2720403 , 0.57178841,\n",
       "        0.56423174, 0.5768262 , 0.2720403 , 0.53652393, 0.53148615]),\n",
       " 'mean_test_score': array([0.52164728, 0.47737175, 0.50906168, 0.45372454, 0.52164728,\n",
       "        0.26057112, 0.45273217, 0.43059631, 0.52164728, 0.26057112,\n",
       "        0.3465919 , 0.34357176, 0.52164728, 0.26057112, 0.34357176,\n",
       "        0.34357176, 0.52164728, 0.26057112, 0.34357176, 0.34357176,\n",
       "        0.53774667, 0.50252269, 0.53976178, 0.36618989, 0.53774667,\n",
       "        0.27968305, 0.52567118, 0.52064099, 0.53774667, 0.26057112,\n",
       "        0.45273724, 0.43109629, 0.53774667, 0.26057112, 0.34357176,\n",
       "        0.34357176, 0.53774667, 0.26057112, 0.34357176, 0.34357176,\n",
       "        0.54127312, 0.51208941, 0.53926813, 0.35761807, 0.54127312,\n",
       "        0.41146286, 0.53976305, 0.53724162, 0.54127312, 0.26057112,\n",
       "        0.52617622, 0.52114477, 0.54127312, 0.26057112, 0.45173348,\n",
       "        0.43109629, 0.54127312, 0.26057112, 0.34357176, 0.34357176,\n",
       "        0.53976558, 0.51411086, 0.53172031, 0.36766958, 0.53976558,\n",
       "        0.47737175, 0.5417731 , 0.51510829, 0.53976558, 0.26057112,\n",
       "        0.53573915, 0.53774667, 0.53976558, 0.26057112, 0.52667747,\n",
       "        0.52164728, 0.53976558, 0.26057112, 0.45173348, 0.43109629,\n",
       "        0.53976558, 0.51209954, 0.52617496, 0.36464818, 0.53976558,\n",
       "        0.50252269, 0.53825678, 0.46127869, 0.53976558, 0.27968305,\n",
       "        0.54379454, 0.54127312, 0.53976558, 0.26057112, 0.53976052,\n",
       "        0.53774667, 0.53976558, 0.26057112, 0.52667873, 0.52164728]),\n",
       " 'std_test_score': array([0.02022169, 0.0279887 , 0.01059938, 0.00766671, 0.02022169,\n",
       "        0.00748903, 0.01892274, 0.03099734, 0.02022169, 0.00748903,\n",
       "        0.01198818, 0.01236403, 0.02022169, 0.00748903, 0.01236403,\n",
       "        0.01236403, 0.02022169, 0.00748903, 0.01236403, 0.01236403,\n",
       "        0.03130982, 0.03454068, 0.03228667, 0.02614053, 0.03130982,\n",
       "        0.01196787, 0.02821666, 0.02156688, 0.03130982, 0.00748903,\n",
       "        0.02235122, 0.0313262 , 0.03130982, 0.00748903, 0.01236403,\n",
       "        0.01236403, 0.03130982, 0.00748903, 0.01236403, 0.01236403,\n",
       "        0.03381529, 0.0325923 , 0.0363915 , 0.04880052, 0.03381529,\n",
       "        0.02402507, 0.03016765, 0.02983424, 0.03381529, 0.00748903,\n",
       "        0.02782496, 0.02101865, 0.03381529, 0.00748903, 0.02232022,\n",
       "        0.0313262 , 0.03381529, 0.00748903, 0.01236403, 0.01236403,\n",
       "        0.03373435, 0.03121416, 0.03397328, 0.04721289, 0.03373435,\n",
       "        0.0279887 , 0.03380461, 0.02053071, 0.03373435, 0.00748903,\n",
       "        0.03302617, 0.03130982, 0.03373435, 0.00748903, 0.02601638,\n",
       "        0.02022169, 0.03373435, 0.00748903, 0.02232022, 0.0313262 ,\n",
       "        0.03373435, 0.03221697, 0.01818631, 0.04858248, 0.03373435,\n",
       "        0.03454068, 0.03342832, 0.02551905, 0.03373435, 0.01196787,\n",
       "        0.03691874, 0.03381529, 0.03373435, 0.00748903, 0.03265585,\n",
       "        0.03130982, 0.03373435, 0.00748903, 0.02699499, 0.02022169]),\n",
       " 'rank_test_score': array([39, 55, 52, 58, 39, 86, 60, 66, 39, 86, 72, 73, 39, 86, 73, 73, 39,\n",
       "        86, 73, 73, 24, 53, 20, 69, 24, 84, 38, 47, 24, 86, 59, 63, 24, 86,\n",
       "        73, 73, 24, 86, 73, 73,  3, 51, 22, 71,  3, 67, 19, 31,  3, 86, 36,\n",
       "        46,  3, 86, 61, 63,  3, 86, 73, 73,  9, 49, 33, 68,  9, 55,  2, 48,\n",
       "         9, 86, 32, 24,  9, 86, 35, 39,  9, 86, 61, 63,  9, 50, 37, 70,  9,\n",
       "        53, 23, 57,  9, 84,  1,  3,  9, 86, 21, 24,  9, 86, 34, 39])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details in the traininf results\n",
    "svm_grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kernel</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.543795</td>\n",
       "      <td>0.036919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.541773</td>\n",
       "      <td>0.033805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.541273</td>\n",
       "      <td>0.033815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.541273</td>\n",
       "      <td>0.033815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.541273</td>\n",
       "      <td>0.033815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.007489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.007489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.007489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.007489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.007489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         C   gamma  kernel      Mean       Std\n",
       "90  1000.0  0.0100     rbf  0.543795  0.036919\n",
       "66   100.0  0.1000     rbf  0.541773  0.033805\n",
       "56    10.0  0.0001  linear  0.541273  0.033815\n",
       "44    10.0  0.1000  linear  0.541273  0.033815\n",
       "52    10.0  0.0010  linear  0.541273  0.033815\n",
       "..     ...     ...     ...       ...       ...\n",
       "29     1.0  0.0100    poly  0.260571  0.007489\n",
       "69   100.0  0.0100    poly  0.260571  0.007489\n",
       "13     0.1  0.0010    poly  0.260571  0.007489\n",
       "17     0.1  0.0001    poly  0.260571  0.007489\n",
       "9      0.1  0.0100    poly  0.260571  0.007489\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Hyperparameter listed out and shown as dataframe\n",
    "means = svm_grid_result.cv_results_['mean_test_score']\n",
    "stds = svm_grid_result.cv_results_['std_test_score']\n",
    "params = svm_grid_result.cv_results_['params']\n",
    "\n",
    "df = pd.DataFrame(params)\n",
    "df['Mean'] = means\n",
    "df['Std'] = stds\n",
    "\n",
    "df.sort_values('Mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.5228993869455464\n",
      "\n",
      "Prediction correct: 52.289938694554635 %\n",
      "Miss by 1 label: 37.36025964659214 %\n",
      "Miss by 2 labels: 8.65488640461594 %\n",
      "Miss by 3 labels: 1.694915254237288 %\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test data\n",
    "y_pred = grid.predict(X_test)\n",
    "print('Accuracy on test data:', grid.score(X_test, y_test))\n",
    "\n",
    "# Check how far our model has mis-labeled prediction\n",
    "pred_correct = 0\n",
    "miss_1_label = 0\n",
    "miss_2_label = 0\n",
    "miss_3_label = 0\n",
    "\n",
    "for pos,i in enumerate(y_test):\n",
    "    if i-y_pred[pos] == 0:\n",
    "        pred_correct +=1\n",
    "    elif abs(i-y_pred[pos]) == 1:\n",
    "        miss_1_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 2:\n",
    "        miss_2_label +=1\n",
    "    elif abs(i-y_pred[pos]) == 3:\n",
    "        miss_3_label +=1\n",
    "\n",
    "print ('\\nPrediction correct:', pred_correct*100/len(y_test),'%')\n",
    "print ('Miss by 1 label:', miss_1_label*100/len(y_test),'%')\n",
    "print ('Miss by 2 labels:', miss_2_label*100/len(y_test),'%')\n",
    "print ('Miss by 3 labels:', miss_3_label*100/len(y_test),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67       736\n",
      "           1       0.38      0.35      0.36       652\n",
      "           2       0.37      0.47      0.41       584\n",
      "           3       0.72      0.52      0.61       801\n",
      "\n",
      "    accuracy                           0.52      2773\n",
      "   macro avg       0.52      0.51      0.51      2773\n",
      "weighted avg       0.54      0.52      0.52      2773\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our observation\n",
    "\n",
    "Overall, the performance is very similar for KerasClassifier, Logistic Regression, and SVM, as the model performs poorly mainly because it misses the label by 1 category, so we conducted another evaluation using a binary classifier in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
