{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Summary\n",
    "\n",
    "In this notebook, we grouped the entries into binary classes (1: similar, 0: dissimilar) to analyse whether our model's performance improve once the compleixty of multi-group is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "train_df = pd.read_csv('train/_TRAIN_features_complete_df.csv')\n",
    "test_df = pd.read_csv('eval/_EVAL_features_complete_df.csv')\n",
    "all_df = pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 'overall' to 0,1\n",
    "# 0 being not similar and 1 being similar\n",
    "\n",
    "# Train data\n",
    "for idx,row in train_df.iterrows():\n",
    "    overall = row['overall']\n",
    "    if overall <=2:\n",
    "        train_df.at[idx,'overall'] = 1\n",
    "    else:\n",
    "        train_df.at[idx,'overall'] = 0\n",
    "\n",
    "# Test Data\n",
    "for idx,row in test_df.iterrows():\n",
    "    overall = row['overall']\n",
    "    if overall <=2:\n",
    "        test_df.at[idx,'overall'] = 1\n",
    "    else:\n",
    "        test_df.at[idx,'overall'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check training data label imbalance:\n",
      "overall\n",
      "0    1559\n",
      "1    1026\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check training data labels\n",
    "print('Check training data label imbalance:')\n",
    "print(train_df.groupby('overall').size(),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced training data\n",
    "target_column = ['overall']\n",
    "predictors = list(set(list(train_df.drop(['pair_id'], axis=1).columns))-set(target_column))\n",
    "\n",
    "X_train = train_df[predictors].values\n",
    "y_train = train_df[target_column].values\n",
    "X_test = test_df[predictors].values\n",
    "y_test = test_df[target_column].values\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2585, 5)\n",
      "(2773, 5)\n",
      "(2585, 1)\n",
      "(2773, 1)\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced training data shape : 2585\n",
    "# Balanced training data shape : 2052\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "print(y_train.shape); print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rinrada\\AppData\\Local\\Temp/ipykernel_3908/1808950710.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch_size, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model with random hyperparameter\n",
    "hidden_size = 8\n",
    "epoch = 100\n",
    "input_size = X_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "kfold = 5\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_dim=input_size, activation='relu'))\n",
    "    #model.add(Dense(hidden_size, input_dim=input_size, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassfier\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# Number of folds\n",
    "kfold = KFold(n_splits=kfold, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(s) used: 282.2414593696594\n",
      "Baseline: 81.74% (1.80%)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results_binn = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "\n",
    "print('Time(s) used:',time.time() - start)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results_binn.mean()*100, results_binn.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.4828 - accuracy: 0.7799\n",
      "Epoch 2/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8116\n",
      "Epoch 3/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.8174\n",
      "Epoch 4/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.4023 - accuracy: 0.8132\n",
      "Epoch 5/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8143\n",
      "Epoch 6/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.4016 - accuracy: 0.8143\n",
      "Epoch 7/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.8174\n",
      "Epoch 8/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3987 - accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3969 - accuracy: 0.8205\n",
      "Epoch 10/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.8147\n",
      "Epoch 11/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3978 - accuracy: 0.8132\n",
      "Epoch 12/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8162\n",
      "Epoch 13/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3950 - accuracy: 0.8143\n",
      "Epoch 14/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3930 - accuracy: 0.8209\n",
      "Epoch 15/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.8143\n",
      "Epoch 16/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3952 - accuracy: 0.8197\n",
      "Epoch 17/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3935 - accuracy: 0.8201\n",
      "Epoch 18/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3915 - accuracy: 0.8221\n",
      "Epoch 19/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3928 - accuracy: 0.8186\n",
      "Epoch 20/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3916 - accuracy: 0.8186\n",
      "Epoch 21/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3901 - accuracy: 0.8178\n",
      "Epoch 22/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3927 - accuracy: 0.8128\n",
      "Epoch 23/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8197\n",
      "Epoch 24/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3902 - accuracy: 0.8174\n",
      "Epoch 25/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3917 - accuracy: 0.8139\n",
      "Epoch 26/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3896 - accuracy: 0.8186\n",
      "Epoch 27/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3890 - accuracy: 0.8236\n",
      "Epoch 28/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3909 - accuracy: 0.8197\n",
      "Epoch 29/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3901 - accuracy: 0.8166\n",
      "Epoch 30/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8193\n",
      "Epoch 31/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3900 - accuracy: 0.8178\n",
      "Epoch 32/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3897 - accuracy: 0.8197\n",
      "Epoch 33/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8209\n",
      "Epoch 34/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3902 - accuracy: 0.8170\n",
      "Epoch 35/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3899 - accuracy: 0.8178\n",
      "Epoch 36/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3887 - accuracy: 0.8186\n",
      "Epoch 37/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8170\n",
      "Epoch 38/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3888 - accuracy: 0.8159\n",
      "Epoch 39/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3887 - accuracy: 0.8139\n",
      "Epoch 40/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8201\n",
      "Epoch 41/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3903 - accuracy: 0.8170\n",
      "Epoch 42/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8190\n",
      "Epoch 43/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3861 - accuracy: 0.8201\n",
      "Epoch 44/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8170\n",
      "Epoch 45/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3871 - accuracy: 0.8178\n",
      "Epoch 46/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3877 - accuracy: 0.8186\n",
      "Epoch 47/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3875 - accuracy: 0.8170\n",
      "Epoch 48/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3875 - accuracy: 0.8132\n",
      "Epoch 49/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3841 - accuracy: 0.8151\n",
      "Epoch 50/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3866 - accuracy: 0.8186\n",
      "Epoch 51/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8205\n",
      "Epoch 52/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3881 - accuracy: 0.8213\n",
      "Epoch 53/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3870 - accuracy: 0.8213\n",
      "Epoch 54/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3860 - accuracy: 0.8193\n",
      "Epoch 55/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8178\n",
      "Epoch 56/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3876 - accuracy: 0.8197\n",
      "Epoch 57/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3831 - accuracy: 0.8213\n",
      "Epoch 58/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3864 - accuracy: 0.8162\n",
      "Epoch 59/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3846 - accuracy: 0.8193\n",
      "Epoch 60/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3871 - accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8166\n",
      "Epoch 62/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3855 - accuracy: 0.8193\n",
      "Epoch 63/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3844 - accuracy: 0.8193\n",
      "Epoch 65/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3862 - accuracy: 0.8209\n",
      "Epoch 66/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3863 - accuracy: 0.8174\n",
      "Epoch 67/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3856 - accuracy: 0.8151\n",
      "Epoch 68/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3855 - accuracy: 0.8197\n",
      "Epoch 69/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3825 - accuracy: 0.8178\n",
      "Epoch 70/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3840 - accuracy: 0.8228\n",
      "Epoch 71/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8201\n",
      "Epoch 72/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3841 - accuracy: 0.8221\n",
      "Epoch 73/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3837 - accuracy: 0.8205\n",
      "Epoch 74/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8240\n",
      "Epoch 75/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8224\n",
      "Epoch 76/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3821 - accuracy: 0.8221\n",
      "Epoch 77/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3836 - accuracy: 0.8228\n",
      "Epoch 78/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8209\n",
      "Epoch 79/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3814 - accuracy: 0.8236\n",
      "Epoch 80/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3804 - accuracy: 0.8248\n",
      "Epoch 81/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3821 - accuracy: 0.8197\n",
      "Epoch 82/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3834 - accuracy: 0.8255\n",
      "Epoch 83/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3813 - accuracy: 0.8209\n",
      "Epoch 84/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8232\n",
      "Epoch 85/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3824 - accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3812 - accuracy: 0.8197\n",
      "Epoch 87/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8209\n",
      "Epoch 88/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3808 - accuracy: 0.8244\n",
      "Epoch 89/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3812 - accuracy: 0.8236\n",
      "Epoch 90/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3816 - accuracy: 0.8224\n",
      "Epoch 91/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8193\n",
      "Epoch 92/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3799 - accuracy: 0.8244\n",
      "Epoch 93/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3790 - accuracy: 0.8267\n",
      "Epoch 94/100\n",
      "517/517 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8201\n",
      "Epoch 95/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8232\n",
      "Epoch 96/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3810 - accuracy: 0.8232\n",
      "Epoch 97/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3811 - accuracy: 0.8217\n",
      "Epoch 98/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3815 - accuracy: 0.8228\n",
      "Epoch 99/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3805 - accuracy: 0.8248\n",
      "Epoch 100/100\n",
      "517/517 [==============================] - 1s 1ms/step - loss: 0.3804 - accuracy: 0.8244\n"
     ]
    }
   ],
   "source": [
    "# Fit train data\n",
    "train_result = estimator.fit(X_train, y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 77.46123332131266 %\n"
     ]
    }
   ],
   "source": [
    "# Make prediction and get accuracy\n",
    "y_pred = estimator.predict(X_test)\n",
    "dummy_y_test = np_utils.to_categorical(y_test)\n",
    "dummy_y_pred = np_utils.to_categorical(y_pred)\n",
    "print('Accuracy on test data:',accuracy_score(dummy_y_test, dummy_y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))#,labels=labels_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#,display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75      1385\n",
      "           1       0.73      0.86      0.79      1388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2773\n",
      "   macro avg       0.78      0.77      0.77      2773\n",
      "weighted avg       0.78      0.77      0.77      2773\n",
      " samples avg       0.77      0.77      0.77      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dummy_y_test, dummy_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Observation\n",
    "\n",
    "Using the same random set of hyperparmeters, our prediction drastically improved. Interesting, while the imbalanced training set fed in about 50% more entries labeled as 0 than 1, the model still predicts more entries as 'similar'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we performed GridSearch to find optimal hyperparameters:\n",
    "- activation function\n",
    "- optimizer\n",
    "- batch size\n",
    "- number of epochs\n",
    "- learning rate\n",
    "- neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_grid(neurons = 5 , activation = 'relu', learning_rate = '0.001', optimizer='adam',):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Activation functions\n",
    "    if activation=='relu':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='relu'))\n",
    "        #model.add(Dense(neurons, activation='relu'))\n",
    "    if activation=='tanh':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='tanh'))\n",
    "        #model.add(Dense(neurons, activation='tanh'))\n",
    "    if activation=='sigmoid':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='sigmoid'))\n",
    "        #model.add(Dense(neurons, activation='sigmoid'))\n",
    "        \n",
    "    # Output layer    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizers\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    if optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_grid = KerasClassifier(build_fn=create_model_grid, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hyperparameters to be searched\n",
    "activation_list = ['tanh','relu']\n",
    "optimizer_list = ['rmsprop','adam','sgd']\n",
    "epoch_list = [5,10,20]\n",
    "batch_list = [10,20,50]\n",
    "learning_rate_list = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "neurons_list = [8, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearch\n",
    "param_grid = dict(activation = activation_list,\n",
    "                 optimizer = optimizer_list,\n",
    "                 epochs = epoch_list, \n",
    "                  batch_size = batch_list,\n",
    "                 learning_rate = learning_rate_list,\n",
    "                 neurons = neurons_list)\n",
    "\n",
    "# Search with 3 folds (cross_validation)\n",
    "grid = GridSearchCV(estimator = estimator_grid, param_grid = param_grid, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 810 candidates, totalling 2430 fits\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=  10.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   7.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   7.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   8.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=  14.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   9.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   6.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   7.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=  13.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   8.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   9.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   8.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   9.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   7.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   7.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   7.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   7.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   8.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   7.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   7.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   9.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   7.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   8.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=  13.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   9.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   8.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   9.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   9.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=  10.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   9.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   9.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=  13.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   9.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   9.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=  10.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   9.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   8.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   9.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   8.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   7.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   6.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   6.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   6.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   6.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   7.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   7.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   7.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   6.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   7.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   8.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=  11.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   7.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   8.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   9.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=  10.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   8.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   8.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   8.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   8.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   8.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   6.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   7.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   6.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   6.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   7.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   6.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   6.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   6.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   5.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   6.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   6.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   6.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   6.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   6.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   6.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   6.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   6.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   6.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   6.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   6.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   8.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   7.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   6.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   8.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   7.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   7.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   8.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   7.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   9.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   9.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   7.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   9.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   7.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   6.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   6.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   7.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   8.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   9.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   7.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   9.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   8.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   7.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   9.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   8.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   7.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   8.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   8.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   8.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   9.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   8.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   6.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   7.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   8.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   8.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   6.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   7.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   8.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   8.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   6.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   7.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   8.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   7.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   7.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   7.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   7.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   6.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   8.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   7.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   7.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   7.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   7.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   6.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   8.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   8.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   8.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   8.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   7.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   7.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   6.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   6.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   6.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   6.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   8.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   6.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.1s\n"
     ]
    }
   ],
   "source": [
    "# Training to get the best hyperparameter combination\n",
    "grid_result = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.820506 using {'activation': 'tanh', 'batch_size': 50, 'epochs': 10, 'learning_rate': 0.01, 'neurons': 8, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "# Print Best Result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>neurons</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>8</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>0.009426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.819344</td>\n",
       "      <td>0.009306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.819344</td>\n",
       "      <td>0.007861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.818958</td>\n",
       "      <td>0.008201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.818958</td>\n",
       "      <td>0.010722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.566297</td>\n",
       "      <td>0.089752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>tanh</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.516863</td>\n",
       "      <td>0.066653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.501376</td>\n",
       "      <td>0.107826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>tanh</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200</td>\n",
       "      <td>32</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.499116</td>\n",
       "      <td>0.151685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>relu</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.416626</td>\n",
       "      <td>0.019060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    activation  batch_size  epochs  learning_rate  neurons optimizer  \\\n",
       "324       tanh          50      10          0.010        8   rmsprop   \n",
       "498       relu          10      20          0.001       32   rmsprop   \n",
       "777       relu          50      20          0.010       32   rmsprop   \n",
       "463       relu          10      10          0.010       32      adam   \n",
       "507       relu          10      20          0.010       32   rmsprop   \n",
       "..         ...         ...     ...            ...      ...       ...   \n",
       "722       relu          50      10          0.001        8       sgd   \n",
       "137       tanh          20       5          0.001        8       sgd   \n",
       "272       tanh          50       5          0.001        8       sgd   \n",
       "165       tanh          20       5          0.200       32   rmsprop   \n",
       "677       relu          50       5          0.001        8       sgd   \n",
       "\n",
       "         Mean       Std  \n",
       "324  0.820506  0.009426  \n",
       "498  0.819344  0.009306  \n",
       "777  0.819344  0.007861  \n",
       "463  0.818958  0.008201  \n",
       "507  0.818958  0.010722  \n",
       "..        ...       ...  \n",
       "722  0.566297  0.089752  \n",
       "137  0.516863  0.066653  \n",
       "272  0.501376  0.107826  \n",
       "165  0.499116  0.151685  \n",
       "677  0.416626  0.019060  \n",
       "\n",
       "[810 rows x 8 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Hyperparameter listed out and shown as dataframe\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "df = pd.DataFrame(params)\n",
    "df['Mean'] = means\n",
    "df['Std'] = stds\n",
    "\n",
    "df.sort_values('Mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 2.02987536,  1.77260081,  1.83775012,  2.04248365,  2.00700172,\n",
       "         1.76328198,  1.98455199,  2.01479133,  1.78641582,  2.14215493,\n",
       "         1.82497915,  1.76237408,  2.02340388,  1.91969895,  1.84401647,\n",
       "         1.8851556 ,  2.05809132,  1.82971096,  2.02842053,  2.00458066,\n",
       "         1.84334707,  2.11517954,  2.04562442,  2.133919  ,  2.02110807,\n",
       "         2.10539118,  2.08594076,  1.99009999,  2.00940331,  1.71993001,\n",
       "         2.21022153,  1.81339661,  1.85619362,  1.99541457,  2.32609208,\n",
       "         1.87949649,  2.29888272,  2.31762067,  1.8645618 ,  2.57610369,\n",
       "         1.85129094,  1.92439286,  1.9201502 ,  2.25975593,  1.6529115 ,\n",
       "         3.09207257,  2.91019026,  2.78992875,  3.03313351,  2.79749894,\n",
       "         3.1070083 ,  3.15766191,  3.20313025,  2.92031844,  3.29665208,\n",
       "         3.20929623,  3.46138374,  4.65441076,  3.05566239,  3.74198079,\n",
       "         3.90794611,  3.77466448,  3.18459153,  3.43069132,  3.91263755,\n",
       "         2.99034452,  3.51631999,  3.53594486,  3.12366645,  3.25100851,\n",
       "         3.23547006,  3.07114244,  3.15902925,  3.15812818,  2.81802281,\n",
       "         3.1791772 ,  3.23426541,  3.18075164,  3.2679557 ,  3.24989724,\n",
       "         3.14385358,  3.33421111,  5.07982588,  4.41948525,  4.91354219,\n",
       "         4.10960984,  3.92212995,  4.12190866,  4.28721515,  3.71320661,\n",
       "         7.2760791 ,  9.97443477,  7.43303108,  9.79510403,  7.92489243,\n",
       "         7.19910781,  7.26885597,  8.20560455,  9.33236583,  8.14458354,\n",
       "         8.99862711, 10.08486311,  9.0982155 ,  8.61436152,  7.07417536,\n",
       "         5.84960373,  5.80541945,  5.22823914,  5.88795837,  5.53025754,\n",
       "         5.88477619,  6.45002786,  6.05319953,  5.84518512,  8.70914181,\n",
       "         8.84787281,  8.00711695,  7.42246437,  5.72540832,  5.82041907,\n",
       "         5.62619058,  5.63668029,  5.42952426,  5.69174012,  5.98667868,\n",
       "         5.23660421,  5.610931  ,  6.16927727,  5.37869819,  6.32217805,\n",
       "         5.7059079 ,  5.11552922,  5.78841654,  5.65877096,  5.62031261,\n",
       "         1.7246627 ,  1.53099291,  1.96413088,  1.63126699,  1.71080804,\n",
       "         1.34760292,  1.79913394,  1.70508448,  1.3179547 ,  1.56769554,\n",
       "         1.62378152,  1.32232205,  1.74240597,  1.68411263,  1.43789244,\n",
       "         1.62410124,  1.48175836,  1.57559148,  1.66027959,  1.62949634,\n",
       "         1.37346085,  1.83545184,  1.64350231,  1.36407081,  1.80180526,\n",
       "         1.47997101,  1.30618326,  1.77428913,  1.72692378,  1.58554554,\n",
       "         1.86724106,  1.84135429,  2.26634614,  2.55936925,  1.68345459,\n",
       "         1.46728651,  1.76777013,  1.56041702,  1.51653616,  2.42651622,\n",
       "         2.11180409,  2.17238386,  2.20232972,  2.34232577,  1.7890408 ,\n",
       "         2.87121495,  2.66886536,  2.71643782,  3.05367462,  2.67631197,\n",
       "         2.90881054,  3.75192602,  3.47595342,  2.60979772,  3.20301636,\n",
       "         3.03148301,  2.82927291,  3.37321862,  3.17168466,  2.60229071,\n",
       "         3.17558233,  2.83763798,  2.62704174,  3.01049813,  2.66843597,\n",
       "         2.55839698,  3.0176305 ,  2.78975956,  2.64657815,  2.91429249,\n",
       "         2.76123993,  2.75715868,  3.58679438,  3.54953218,  3.59437354,\n",
       "         3.73611299,  3.37432305,  2.20967269,  3.19808968,  2.65340614,\n",
       "         2.55180216,  3.01393159,  2.81124091,  2.53192067,  2.75769273,\n",
       "         2.74534043,  2.68174171,  2.84113781,  2.870483  ,  2.43030334,\n",
       "         4.9449625 ,  4.7150778 ,  4.0839529 ,  4.45901553,  4.01957814,\n",
       "         4.04012593,  4.31202626,  4.23302054,  3.63048061,  4.70532179,\n",
       "         4.29547326,  4.46395795,  4.27431862,  4.49427215,  4.41467555,\n",
       "         5.75505225,  4.99132744,  4.56437111,  5.81653754,  5.10227553,\n",
       "         3.42755493,  3.26614626,  3.64480782,  2.95591164,  3.44314957,\n",
       "         3.15328463,  3.81340051,  3.7880729 ,  3.45132351,  3.4600757 ,\n",
       "         4.03702044,  3.97593689,  3.19297099,  4.15390778,  3.51267219,\n",
       "         3.32946269,  3.71533624,  3.29126875,  3.79616062,  3.73192223,\n",
       "         3.27125033,  3.0076561 ,  3.68223834,  4.35342193,  3.88763348,\n",
       "         1.32933633,  1.13425064,  1.22183061,  1.33873065,  1.26989381,\n",
       "         1.26822543,  1.34363667,  1.74944464,  1.28559621,  1.50784628,\n",
       "         1.16315333,  1.23387829,  1.36368593,  1.82164653,  1.77792366,\n",
       "         2.14261349,  2.06238508,  1.99667048,  2.38795606,  1.67855144,\n",
       "         1.68864918,  1.74993825,  2.33408507,  1.41877874,  1.68163101,\n",
       "         1.6519026 ,  1.43091313,  1.65350119,  1.6694444 ,  1.27077643,\n",
       "         1.68219614,  1.4382933 ,  1.4298621 ,  1.80789844,  1.57081246,\n",
       "         1.26394208,  1.88702297,  1.52113342,  1.28992311,  1.85255742,\n",
       "         1.37371294,  1.42509206,  1.69409498,  1.47982581,  1.37622881,\n",
       "         1.90147177,  1.72646379,  1.65155188,  1.88527346,  2.02343718,\n",
       "         1.53368036,  2.07156452,  1.76537728,  1.67445   ,  1.98278507,\n",
       "         1.86950604,  2.20984252,  2.3610305 ,  2.05642025,  1.66550859,\n",
       "         1.85512877,  1.96864525,  1.57662344,  2.18076253,  1.67718005,\n",
       "         1.79419891,  1.90791567,  1.66585437,  1.63430214,  1.95413113,\n",
       "         1.98194814,  1.56148108,  1.97572986,  1.87151472,  1.64552808,\n",
       "         1.95780102,  1.82796971,  1.55698641,  2.19392784,  2.15821568,\n",
       "         1.73228375,  1.93612806,  2.23446703,  1.56205662,  2.18049089,\n",
       "         1.73354077,  1.68913364,  2.04651086,  1.88267541,  1.78289143,\n",
       "         2.56086453,  2.61668086,  2.14134558,  2.6556433 ,  2.2283686 ,\n",
       "         2.20421712,  2.47417784,  2.54329459,  2.09598343,  2.70382102,\n",
       "         2.30120826,  2.27161098,  2.48134764,  2.51141326,  2.1877679 ,\n",
       "         2.66717164,  2.42940052,  2.26821971,  2.57075334,  2.37145297,\n",
       "         2.25918047,  2.56472643,  2.40000685,  2.23530467,  2.5286452 ,\n",
       "         2.45030125,  2.21161071,  2.60586866,  2.50252255,  2.10167607,\n",
       "         2.53872816,  2.25875274,  2.12940462,  2.55173771,  2.60252563,\n",
       "         2.09304452,  3.16640067,  2.64116446,  2.23859223,  2.61805224,\n",
       "         2.33380047,  2.26457365,  2.58883429,  2.48957666,  2.10624067,\n",
       "         2.81994359,  2.67094676,  2.27094404,  2.80374384,  2.38067818,\n",
       "         2.51573714,  2.59125614,  2.71678193,  2.20571677,  2.74495657,\n",
       "         2.54549432,  2.3729949 ,  2.77351371,  2.50796421,  2.35489043,\n",
       "         2.5915405 ,  2.64248745,  2.38570189,  2.60874446,  2.96214096,\n",
       "         2.39313523,  2.80695494,  2.46948942,  2.43912633,  2.7190973 ,\n",
       "         2.55720361,  2.36274378,  2.69792159,  2.48823977,  2.36920444,\n",
       "         2.70236969,  2.66691788,  2.43992225,  3.0294226 ,  2.53307517,\n",
       "         3.09781988,  3.17041548,  2.73911317,  2.75552026,  3.61304347,\n",
       "         2.85506654,  2.87000338,  3.60572163,  3.25453623,  2.79794359,\n",
       "         4.64728634,  4.25310715,  4.17884811,  5.06531747,  4.19345331,\n",
       "         4.32932591,  4.26970792,  4.75534797,  3.73532224,  4.43177342,\n",
       "         4.46314708,  4.24842509,  4.53990833,  4.60376692,  3.95260906,\n",
       "         4.61624217,  4.52988164,  4.49097753,  4.67803566,  4.73445113,\n",
       "         4.17998624,  4.85400081,  4.67193683,  4.6839215 ,  4.42659378,\n",
       "         5.31860447,  4.13459142,  4.5311745 ,  4.20705318,  3.71064742,\n",
       "         4.11123435,  4.14229576,  3.82860883,  4.36376429,  4.74597828,\n",
       "         4.52059547,  4.91324608,  5.63565461,  4.61317372,  4.8495032 ,\n",
       "         4.69395336,  4.15016619,  5.48027356,  4.84264874,  4.33056235,\n",
       "         7.62094617,  7.48932354,  6.85628637,  7.65109944,  7.17174729,\n",
       "         7.29019968,  7.61655505,  7.85668683,  7.09864624,  8.01246484,\n",
       "         7.56115143,  6.771854  ,  7.28107206,  7.60687256,  7.2929829 ,\n",
       "         8.02170014,  8.65682093,  7.6505026 ,  8.06367644,  7.83180308,\n",
       "         7.01598263,  7.82269009,  7.97762227,  7.14275392,  7.5788451 ,\n",
       "         7.40778581,  6.62257433,  7.08246469,  8.04623644,  6.98166617,\n",
       "         7.43211532,  6.73917588,  7.3965683 ,  7.32312115,  7.6138463 ,\n",
       "         6.7381618 ,  7.34065239,  6.86818727,  7.2313424 ,  7.42592939,\n",
       "         6.82993007,  7.06999453,  7.55578677,  7.17102249,  6.30122209,\n",
       "         2.07099231,  1.87800066,  1.73706977,  2.12468553,  1.75786074,\n",
       "         1.98948709,  2.21209192,  2.1044035 ,  1.70699032,  2.14677533,\n",
       "         1.82848962,  1.93986114,  2.10397887,  1.89745696,  1.78709984,\n",
       "         2.0024906 ,  1.96182775,  1.82940936,  2.12737664,  1.80713264,\n",
       "         2.16477426,  2.15233032,  2.45056852,  2.38963938,  2.74152303,\n",
       "         2.24413959,  1.77843245,  2.26504397,  2.03935003,  2.03347222,\n",
       "         2.33653529,  1.86380466,  1.74299971,  1.96539267,  1.98531961,\n",
       "         1.92719881,  2.63648311,  1.9275078 ,  1.80300554,  2.04944444,\n",
       "         1.83748921,  1.94979246,  1.99374684,  2.00363747,  1.76845415,\n",
       "         2.69333688,  2.45974843,  2.61371899,  2.74917142,  2.49328089,\n",
       "         2.43996541,  2.55987835,  2.76461585,  2.41935881,  2.66860247,\n",
       "         2.32526882,  2.34177725,  2.68502458,  2.38422314,  2.38846978,\n",
       "         2.36481627,  2.40107083,  2.0165414 ,  2.5038445 ,  2.28607527,\n",
       "         2.39287655,  2.3543729 ,  2.44809977,  2.75353161,  3.17481987,\n",
       "         3.26405565,  2.41655938,  2.93986996,  2.58025662,  2.26284742,\n",
       "         2.94253413,  2.34721557,  2.73973838,  2.68383503,  2.92938924,\n",
       "         2.4290235 ,  2.82482322,  2.39202523,  2.28733492,  2.79328775,\n",
       "         2.28294738,  2.23771032,  2.55208015,  2.42385785,  2.26718609,\n",
       "         3.7309769 ,  3.59429574,  3.33378196,  3.95815953,  3.69851438,\n",
       "         3.51211174,  3.65726415,  3.83164819,  3.41679716,  3.95195182,\n",
       "         3.67566085,  3.46692316,  3.87159745,  3.75394416,  3.50806324,\n",
       "         3.78371779,  3.83015688,  3.62508122,  4.2015396 ,  4.31628672,\n",
       "         3.47937711,  3.86361067,  4.16803988,  3.74146843,  4.15613182,\n",
       "         3.86661824,  4.03631409,  4.2184364 ,  3.50741943,  3.17693408,\n",
       "         3.62009692,  3.64509702,  3.44236437,  4.09150251,  3.82186826,\n",
       "         3.76186148,  3.68176333,  3.28718241,  3.478043  ,  4.37672623,\n",
       "         4.14131355,  3.3852396 ,  5.37372454,  3.39724835,  3.1033899 ,\n",
       "         1.48039095,  1.07635601,  1.07975133,  1.37273208,  1.23027229,\n",
       "         1.14771724,  1.26643173,  1.31444287,  1.30991602,  1.46519764,\n",
       "         1.31237125,  1.14418221,  1.22932895,  1.24015133,  1.08590515,\n",
       "         1.37140123,  1.09576909,  1.22903522,  1.29940391,  1.24963856,\n",
       "         1.13797482,  1.92838645,  0.98801502,  1.01150012,  3.45120207,\n",
       "         1.22437207,  1.21013228,  1.36919586,  1.07947707,  1.14184046,\n",
       "         1.46467543,  1.10947243,  1.23370481,  1.50854413,  1.27810057,\n",
       "         0.98749741,  1.56091094,  1.13551426,  1.16253964,  1.23185905,\n",
       "         1.37353834,  1.02835838,  1.29073819,  1.20156495,  1.14245741,\n",
       "         1.42955232,  1.58123525,  1.1916608 ,  1.49095384,  1.47966806,\n",
       "         1.35043454,  1.4137725 ,  1.45147888,  1.33399057,  1.60203473,\n",
       "         1.44130119,  1.35357388,  1.47161897,  1.46585528,  1.2758232 ,\n",
       "         1.54065212,  1.34802858,  1.25989095,  1.57418283,  1.37206793,\n",
       "         1.46268185,  1.40570196,  1.41398501,  1.34434128,  1.55745459,\n",
       "         1.3396589 ,  1.27636226,  1.43793408,  1.38540236,  1.31096443,\n",
       "         1.63559985,  1.36470493,  1.34767477,  1.57365259,  1.49430124,\n",
       "         1.17122118,  1.61336851,  1.37022082,  1.41705942,  1.61111434,\n",
       "         1.45953417,  1.20980422,  1.59128213,  1.40510829,  1.32622751,\n",
       "         2.28559462,  1.78849188,  1.94370993,  2.00854548,  2.06584104,\n",
       "         1.69199204,  2.07937868,  1.93858417,  1.86036404,  2.06180334,\n",
       "         1.78557118,  1.74630173,  2.17055845,  1.86987678,  1.91752656,\n",
       "         2.02442853,  1.97225889,  1.66596381,  1.98859994,  2.0562849 ,\n",
       "         1.69905527,  2.13263083,  1.90827576,  1.88044572,  1.97167277,\n",
       "         2.03444807,  1.75967606,  2.10473776,  1.92526372,  1.89389873,\n",
       "         2.06950172,  1.85935394,  1.70435198,  2.25520515,  1.94064927,\n",
       "         1.9341557 ,  1.93169705,  1.81396707,  1.74318401,  1.93437505,\n",
       "         2.1187346 ,  1.68161337,  2.27862422,  1.84253399,  1.87211768]),\n",
       " 'std_fit_time': array([0.20777756, 0.04880781, 0.12696843, 0.14643887, 0.08895539,\n",
       "        0.14986544, 0.13783034, 0.14294103, 0.11485641, 0.21775887,\n",
       "        0.05703607, 0.12955685, 0.09832782, 0.09610713, 0.04321804,\n",
       "        0.01196331, 0.17854354, 0.15669329, 0.0940298 , 0.05788851,\n",
       "        0.14160554, 0.19043   , 0.06973418, 0.35846191, 0.07403312,\n",
       "        0.23573876, 0.10448206, 0.17191174, 0.1826446 , 0.09115359,\n",
       "        0.18092436, 0.00499312, 0.1619011 , 0.03462226, 0.27403929,\n",
       "        0.15040135, 0.32712941, 0.09684754, 0.07291993, 0.10333708,\n",
       "        0.05032565, 0.30022403, 0.03533263, 0.14472977, 0.03849227,\n",
       "        0.10784405, 0.16289225, 0.05859483, 0.08296032, 0.10383197,\n",
       "        0.1515707 , 0.12922668, 0.49858274, 0.26200006, 0.10024625,\n",
       "        0.34060335, 0.61312261, 0.77471062, 0.15954718, 0.06433389,\n",
       "        0.5758351 , 0.63595465, 0.27887531, 0.40052382, 0.381152  ,\n",
       "        0.13348191, 0.25952276, 0.41889532, 0.21998712, 0.14599799,\n",
       "        0.35198999, 0.37013193, 0.16469674, 0.04825394, 0.18759538,\n",
       "        0.14889243, 0.17564886, 0.22303628, 0.11144588, 0.23179513,\n",
       "        0.13683463, 0.17761024, 2.45759925, 0.45302634, 0.16575807,\n",
       "        0.23363226, 0.17803474, 0.09874861, 0.23205898, 0.11832821,\n",
       "        0.71965241, 2.09276657, 1.16930264, 1.77379943, 0.64823144,\n",
       "        0.33194343, 0.3095247 , 0.86339907, 2.43677018, 0.57519497,\n",
       "        0.41354574, 1.69243772, 0.39438005, 0.3299408 , 0.74940458,\n",
       "        0.46174675, 0.11193095, 0.17853307, 0.13693506, 0.35249966,\n",
       "        0.94124253, 0.73837798, 0.45415938, 0.59186956, 1.39798646,\n",
       "        0.8834413 , 0.25898929, 1.04470523, 0.61159329, 0.29593964,\n",
       "        0.32274534, 0.10090755, 0.25592333, 0.04158416, 0.17206715,\n",
       "        0.18754854, 0.17237872, 0.36701522, 0.28770723, 0.81597324,\n",
       "        0.13839473, 0.14378651, 0.31469878, 0.18050275, 0.23287556,\n",
       "        0.31862235, 0.15410593, 0.14816117, 0.09390933, 0.16036852,\n",
       "        0.07090749, 0.17792052, 0.18779406, 0.13713983, 0.05839672,\n",
       "        0.2523178 , 0.016689  , 0.28613486, 0.05523093, 0.03661057,\n",
       "        0.09581344, 0.02178534, 0.0649829 , 0.19004615, 0.18504576,\n",
       "        0.10232219, 0.22969973, 0.41769359, 0.11949664, 0.14340349,\n",
       "        0.12228283, 0.06085097, 0.189447  , 0.24927983, 0.08307112,\n",
       "        0.15623103, 0.1660816 , 0.35646018, 0.0180978 , 0.19643615,\n",
       "        0.15996815, 0.20395984, 0.1896235 , 0.1130923 , 0.20151875,\n",
       "        0.17893295, 0.30207753, 0.06911363, 0.17532137, 0.08836022,\n",
       "        0.04175036, 0.21032181, 0.40753394, 0.21988684, 0.13221032,\n",
       "        0.25875112, 0.4563957 , 0.42534836, 0.13261312, 0.20697259,\n",
       "        0.36659056, 0.26914877, 0.23726021, 0.34737678, 0.21589331,\n",
       "        0.36888643, 0.18380818, 0.29682887, 0.20268252, 0.091377  ,\n",
       "        0.20678226, 0.21535254, 0.22948106, 0.12741548, 0.12397255,\n",
       "        0.15535007, 0.20102603, 0.61048025, 0.42395838, 0.38221048,\n",
       "        0.50335633, 0.23471223, 0.19121473, 0.34891553, 0.11357897,\n",
       "        0.21783872, 0.24281594, 0.21747667, 0.28114226, 0.07563217,\n",
       "        0.26932838, 0.12998752, 0.15218349, 0.17127381, 0.05719505,\n",
       "        0.10004525, 0.49846011, 0.51432878, 0.09283633, 0.15833175,\n",
       "        0.30955746, 0.19020813, 0.2484024 , 0.10752209, 0.05412111,\n",
       "        0.46669356, 0.53076461, 0.1687808 , 0.31275876, 0.14143759,\n",
       "        0.29932879, 0.34286346, 0.35690752, 0.33411676, 0.5096754 ,\n",
       "        0.5694104 , 0.0567339 , 0.20833126, 0.20940052, 0.35304163,\n",
       "        0.02827362, 0.56842889, 0.28937537, 0.00686024, 0.24089096,\n",
       "        0.3798788 , 0.29026728, 0.12050185, 0.27161331, 0.27469804,\n",
       "        0.2595671 , 0.20569653, 0.1452354 , 0.50308996, 0.37550549,\n",
       "        0.20555643, 0.19020572, 0.31515285, 0.62583577, 0.52361727,\n",
       "        0.11094793, 0.05780036, 0.35849953, 0.0099225 , 0.1016507 ,\n",
       "        0.24649437, 0.19969783, 0.08760357, 0.38285878, 0.05672996,\n",
       "        0.05077805, 0.32387974, 0.24291113, 0.45887897, 0.17630533,\n",
       "        0.15209583, 0.13188444, 0.23603646, 0.25476869, 0.13819286,\n",
       "        0.19274399, 0.20682034, 0.22206548, 0.11934733, 0.09979692,\n",
       "        0.16688973, 0.18750154, 0.18028501, 0.24029567, 0.06909844,\n",
       "        0.06673928, 0.0834824 , 0.15356957, 0.22183407, 0.1451737 ,\n",
       "        0.10102049, 0.09910241, 0.26949381, 0.04332808, 0.10551514,\n",
       "        0.06290639, 0.18614848, 0.17942451, 0.07233329, 0.14612394,\n",
       "        0.08316355, 0.11276939, 0.02060764, 0.04343312, 0.43266358,\n",
       "        0.10168727, 0.27605465, 0.15722891, 0.20213567, 0.26968439,\n",
       "        0.28194148, 0.39531602, 0.23441794, 0.14645452, 0.16291959,\n",
       "        0.04522967, 0.5123075 , 0.05884487, 0.34446028, 0.05845921,\n",
       "        0.19633744, 0.15490619, 0.11499371, 0.24678263, 0.17499951,\n",
       "        0.41040603, 0.10544017, 0.11772534, 0.12819342, 0.01047063,\n",
       "        0.09601893, 0.20904099, 0.02743775, 0.09874981, 0.34720717,\n",
       "        0.31059627, 0.08906603, 0.45009864, 0.02905945, 0.27203462,\n",
       "        0.10851444, 0.17594929, 0.18857547, 0.07170109, 0.17525722,\n",
       "        0.05800992, 0.29607793, 0.01238262, 0.16680362, 0.12047601,\n",
       "        0.28875334, 0.10778527, 0.16527124, 0.09401826, 0.22498256,\n",
       "        0.09278962, 0.30477581, 0.15311592, 0.23109059, 0.17180838,\n",
       "        0.05244569, 0.24703189, 0.25056764, 0.24294498, 0.27529222,\n",
       "        0.11132678, 0.27357184, 0.13763237, 0.19499763, 0.27106409,\n",
       "        0.23790089, 0.02537583, 0.13341117, 0.13621494, 0.07648438,\n",
       "        0.12205981, 0.03724486, 0.24373266, 0.27041115, 0.19637871,\n",
       "        0.0921234 , 0.07383388, 0.26829338, 0.2126255 , 0.2554417 ,\n",
       "        0.25718476, 0.04737331, 0.30997382, 0.14575569, 0.03950071,\n",
       "        0.14558069, 0.19699105, 0.08231567, 0.23871274, 0.08990403,\n",
       "        0.34899628, 0.08502103, 0.33309417, 0.10690658, 0.09162919,\n",
       "        0.2529986 , 0.23918108, 0.17171317, 0.03179884, 0.169185  ,\n",
       "        0.05231752, 0.23753348, 0.15623163, 0.01457916, 0.19345776,\n",
       "        0.11612646, 0.43159697, 0.10453958, 0.23007241, 0.23418204,\n",
       "        0.18731722, 0.13288048, 0.21187618, 0.07312344, 0.14995142,\n",
       "        0.25927196, 0.26454064, 0.2858213 , 0.24746785, 0.13399407,\n",
       "        0.41019333, 0.08436846, 0.20118976, 0.22324278, 0.16697064,\n",
       "        0.24172094, 0.18121886, 0.11465742, 0.52871497, 0.14027225,\n",
       "        0.47362539, 0.19421405, 0.22228327, 0.33623322, 0.15679688,\n",
       "        0.95615014, 0.27661042, 0.10096585, 0.0905301 , 0.28110741,\n",
       "        0.32111151, 0.07088753, 0.32698063, 0.24403507, 0.23391974,\n",
       "        0.23284764, 0.50483934, 0.64529131, 0.27023295, 0.50551358,\n",
       "        0.11474635, 0.24685222, 0.11132103, 0.68713212, 0.3322668 ,\n",
       "        0.9489231 , 0.20370349, 0.43459299, 0.28484556, 0.25868382,\n",
       "        0.28389903, 0.25118182, 0.20361397, 0.1745603 , 0.29229809,\n",
       "        0.53404964, 0.77852066, 0.96362181, 0.17354984, 0.42471515,\n",
       "        0.11445544, 0.05434771, 0.36988198, 0.52609608, 0.0752759 ,\n",
       "        0.35286051, 0.47946664, 0.49957058, 0.51617437, 0.43627862,\n",
       "        0.75839922, 0.03370282, 0.55490336, 0.2220289 , 0.44423612,\n",
       "        0.21495363, 0.55259068, 0.36732196, 0.27450595, 0.66729939,\n",
       "        0.45369192, 0.59664625, 0.08866514, 0.31245811, 0.29201152,\n",
       "        0.55029567, 0.10490748, 0.76123617, 0.28857566, 0.7265721 ,\n",
       "        0.43030155, 0.29363757, 0.31998904, 0.2887084 , 0.03781333,\n",
       "        0.32167221, 0.17587204, 0.31050078, 0.30060127, 0.47138724,\n",
       "        0.434318  , 0.03532813, 0.52537338, 0.41767798, 0.30015403,\n",
       "        0.28382867, 0.51543829, 0.37731913, 0.36468943, 0.15488527,\n",
       "        0.132769  , 0.12122761, 0.13218598, 0.07175011, 0.2125312 ,\n",
       "        0.17943054, 0.32306429, 0.27034559, 0.16497336, 0.14853494,\n",
       "        0.05270519, 0.2048225 , 0.11285444, 0.09650517, 0.1566188 ,\n",
       "        0.03664477, 0.15955794, 0.19523828, 0.33226963, 0.13580206,\n",
       "        0.29601021, 0.26281809, 0.36066711, 0.38926771, 0.27033651,\n",
       "        0.13437211, 0.20009198, 0.04173156, 0.05210773, 0.37886255,\n",
       "        0.30800584, 0.17345808, 0.24969249, 0.06311336, 0.21930958,\n",
       "        0.27735791, 0.32064736, 0.08205497, 0.16459417, 0.14903033,\n",
       "        0.11021462, 0.1887136 , 0.08141506, 0.31377886, 0.02623231,\n",
       "        0.20308119, 0.12704751, 0.36134992, 0.12362683, 0.04352224,\n",
       "        0.36213811, 0.14601323, 0.26713026, 0.22777063, 0.23431822,\n",
       "        0.05970663, 0.303385  , 0.07073778, 0.02669277, 0.21761141,\n",
       "        0.02733502, 0.2275247 , 0.03631661, 0.10304314, 0.02452234,\n",
       "        0.2233043 , 0.07581727, 0.12435743, 0.47188258, 0.33433139,\n",
       "        0.1591412 , 0.27144492, 0.3273806 , 0.22805992, 0.27026275,\n",
       "        0.29813046, 0.02344139, 0.12114593, 0.09809364, 0.57127546,\n",
       "        0.1150737 , 0.18025346, 0.16299074, 0.21059389, 0.07185508,\n",
       "        0.01086105, 0.14943984, 0.22209561, 0.08491074, 0.15587574,\n",
       "        0.16698459, 0.17866408, 0.04847658, 0.19954838, 0.13733863,\n",
       "        0.31933966, 0.10929293, 0.17318522, 0.10962961, 0.17721652,\n",
       "        0.12813163, 0.19423303, 0.13871489, 0.20677765, 0.1897849 ,\n",
       "        0.20964913, 0.34844765, 0.23195664, 0.16226102, 0.45111028,\n",
       "        0.2013872 , 0.29726658, 0.46396469, 0.25488995, 0.30605778,\n",
       "        0.14892895, 0.36983507, 0.31776479, 0.29889685, 0.07484571,\n",
       "        0.29456568, 0.19522772, 0.3827706 , 0.52719169, 0.26880413,\n",
       "        0.72666944, 0.59855735, 0.24576448, 0.4038875 , 0.23537103,\n",
       "        0.78707001, 0.37160117, 2.04938299, 0.21784917, 0.14291294,\n",
       "        0.12415554, 0.05954215, 0.0488891 , 0.13000264, 0.21351252,\n",
       "        0.20989714, 0.08713879, 0.18947236, 0.17363709, 0.19601016,\n",
       "        0.08133261, 0.13848402, 0.07794058, 0.15230454, 0.06549467,\n",
       "        0.18886832, 0.02745859, 0.09339373, 0.04670332, 0.10455461,\n",
       "        0.22469918, 0.84948642, 0.09992114, 0.16265057, 1.71947227,\n",
       "        0.16997353, 0.18268641, 0.1488311 , 0.01474262, 0.13007797,\n",
       "        0.26210179, 0.04338937, 0.16781263, 0.05466847, 0.08306317,\n",
       "        0.06313153, 0.05886871, 0.02654125, 0.16592699, 0.05932008,\n",
       "        0.31664543, 0.07406862, 0.06977232, 0.02199434, 0.17184058,\n",
       "        0.07255285, 0.21514953, 0.01610948, 0.08543407, 0.06777787,\n",
       "        0.19024328, 0.08508956, 0.26401068, 0.13379028, 0.16286908,\n",
       "        0.01377773, 0.12391509, 0.06783571, 0.18618913, 0.13872749,\n",
       "        0.11140806, 0.07584713, 0.12562937, 0.13836078, 0.03179984,\n",
       "        0.09853549, 0.04754208, 0.19637416, 0.11301382, 0.1330659 ,\n",
       "        0.09084042, 0.13906898, 0.06797031, 0.22148738, 0.04694628,\n",
       "        0.0926626 , 0.04717948, 0.098585  , 0.16023617, 0.1580891 ,\n",
       "        0.04088522, 0.16560617, 0.03226106, 0.15853769, 0.18072527,\n",
       "        0.10879304, 0.05691234, 0.16001187, 0.01663491, 0.07309499,\n",
       "        0.34755109, 0.06297911, 0.14057301, 0.11013397, 0.21169426,\n",
       "        0.06790066, 0.16301746, 0.15107748, 0.15612496, 0.03404498,\n",
       "        0.0449002 , 0.10777499, 0.22992698, 0.10853763, 0.12245518,\n",
       "        0.01130012, 0.21015007, 0.11881111, 0.03067947, 0.41431058,\n",
       "        0.04527516, 0.13228058, 0.00857527, 0.12666751, 0.02782614,\n",
       "        0.14442396, 0.11720612, 0.18594815, 0.12260315, 0.22610816,\n",
       "        0.07296883, 0.22948961, 0.06984251, 0.20173059, 0.10223585,\n",
       "        0.27003235, 0.07721759, 0.10515285, 0.08722117, 0.12898236,\n",
       "        0.24461028, 0.06808855, 0.21193306, 0.10335482, 0.28245807]),\n",
       " 'mean_score_time': array([0.4224778 , 0.31201148, 0.37163774, 0.32726868, 0.31838799,\n",
       "        0.3455677 , 0.32643302, 0.35905306, 0.37496567, 0.45058425,\n",
       "        0.31750194, 0.3056941 , 0.36380299, 0.32699839, 0.40457082,\n",
       "        0.31241083, 0.38168542, 0.33910783, 0.33694903, 0.37494151,\n",
       "        0.30317648, 0.37368838, 0.34291617, 0.34114432, 0.32564815,\n",
       "        0.343623  , 0.40504114, 0.41888682, 0.32209404, 0.31768139,\n",
       "        0.37207588, 0.31017812, 0.33351771, 0.33331688, 0.38636454,\n",
       "        0.3136456 , 0.35121568, 0.48409311, 0.40321342, 0.4395175 ,\n",
       "        0.32680257, 0.33325529, 0.32708764, 0.35779897, 0.31234996,\n",
       "        0.34921614, 0.32181923, 0.31566906, 0.33309881, 0.30596487,\n",
       "        0.32775664, 0.34397149, 0.32039762, 0.34562731, 0.35107533,\n",
       "        0.37019277, 0.38894335, 0.45483581, 0.36426783, 0.43586604,\n",
       "        0.37181131, 0.4170479 , 0.40046581, 0.32342092, 0.39753008,\n",
       "        0.35189088, 0.34861167, 0.37682748, 0.33096353, 0.36897612,\n",
       "        0.3249081 , 0.35319344, 0.35175721, 0.36447056, 0.32061068,\n",
       "        0.34237552, 0.36605382, 0.3605961 , 0.34697723, 0.36461592,\n",
       "        0.42933957, 0.34662143, 0.78841305, 0.4925789 , 0.57522408,\n",
       "        0.54325318, 0.5116361 , 0.5207173 , 0.54314311, 0.50830738,\n",
       "        0.55224204, 1.15560889, 0.4911073 , 0.87394643, 0.66853897,\n",
       "        0.45956612, 0.48209254, 0.61649013, 0.74305344, 0.48041582,\n",
       "        0.7556293 , 0.69841258, 0.79537884, 0.77418923, 0.50286611,\n",
       "        0.49774035, 0.50625809, 0.37920745, 0.34669884, 0.36560281,\n",
       "        0.40138054, 0.36702394, 0.39591916, 0.52630695, 0.58047279,\n",
       "        0.53079438, 0.56308635, 0.42697183, 0.44344171, 0.40557106,\n",
       "        0.35074155, 0.38106457, 0.35949683, 0.34909423, 0.35378067,\n",
       "        0.37527076, 0.46904405, 0.35130326, 0.37895147, 0.3574837 ,\n",
       "        0.3533802 , 0.41337403, 0.34792161, 0.45722342, 0.36851033,\n",
       "        0.34540383, 0.33970284, 0.47107967, 0.34321721, 0.33236893,\n",
       "        0.320599  , 0.33041835, 0.37509974, 0.29720759, 0.29081543,\n",
       "        0.32490047, 0.40501046, 0.35790626, 0.39768362, 0.35932175,\n",
       "        0.40140168, 0.31041288, 0.31304844, 0.34809462, 0.30019848,\n",
       "        0.29043182, 0.40006375, 0.36627897, 0.32336601, 0.39698156,\n",
       "        0.29439998, 0.45463729, 0.32058652, 0.35286951, 0.34566569,\n",
       "        0.36454248, 0.43803755, 0.50623775, 0.45158537, 0.3321143 ,\n",
       "        0.30081813, 0.35000642, 0.43628701, 0.38375974, 0.64271506,\n",
       "        0.47157884, 0.48968617, 0.44182769, 0.43628486, 0.42697541,\n",
       "        0.58848516, 0.41645845, 0.43070324, 0.57630547, 0.45956333,\n",
       "        0.67231901, 0.52992288, 0.50817585, 0.48264949, 0.63491543,\n",
       "        0.4457492 , 0.46432432, 0.47376831, 0.45031301, 0.48892291,\n",
       "        0.60602323, 0.44466742, 0.4221762 , 0.56053178, 0.43211873,\n",
       "        0.58116674, 0.4277672 , 0.41712681, 0.44829408, 0.58627971,\n",
       "        0.42544468, 0.46575443, 0.78743243, 0.54219453, 0.63181297,\n",
       "        0.67759411, 0.54717541, 0.36620108, 0.60624663, 0.40926131,\n",
       "        0.4538312 , 0.44447009, 0.43010545, 0.44471192, 0.53637242,\n",
       "        0.43215696, 0.43107979, 0.41331816, 0.5726858 , 0.4279387 ,\n",
       "        0.52492189, 0.53149438, 0.44082022, 0.41344659, 0.41431403,\n",
       "        0.44555759, 0.41553116, 0.46413255, 0.42052968, 0.4901669 ,\n",
       "        0.41664354, 0.43515325, 0.42689244, 0.54653223, 0.47913909,\n",
       "        0.71946915, 0.65770531, 0.52591832, 0.62064171, 0.58545041,\n",
       "        0.3058339 , 0.34715796, 0.3206385 , 0.30851436, 0.30090563,\n",
       "        0.3281157 , 0.35237225, 0.36155359, 0.3589224 , 0.4022278 ,\n",
       "        0.39284706, 0.38267398, 0.36191551, 0.36141292, 0.32194964,\n",
       "        0.36608895, 0.35868112, 0.41973122, 0.35169212, 0.48301562,\n",
       "        0.32527057, 0.31257399, 0.36591792, 0.41827544, 0.51848284,\n",
       "        0.39297756, 0.31893007, 0.31002696, 0.38270974, 0.3267897 ,\n",
       "        0.48445002, 0.30464904, 0.51878508, 0.33303539, 0.44767952,\n",
       "        0.26409729, 0.33735681, 0.3481342 , 0.48951276, 0.52634597,\n",
       "        0.59365058, 0.45654011, 0.60396036, 0.66926511, 0.40323289,\n",
       "        0.62419685, 0.428931  , 0.48963841, 0.34099793, 0.50296354,\n",
       "        0.37252355, 0.34702118, 0.37706606, 0.35818982, 0.34439087,\n",
       "        0.52294318, 0.35738428, 0.34394542, 0.36041244, 0.3506813 ,\n",
       "        0.36779722, 0.36990078, 0.35761913, 0.36760712, 0.36394827,\n",
       "        0.36015217, 0.36487381, 0.3559432 , 0.46081106, 0.43529256,\n",
       "        0.47248006, 0.36533141, 0.5486509 , 0.35779317, 0.36727182,\n",
       "        0.36089595, 0.3502322 , 0.35270468, 0.35899154, 0.3720936 ,\n",
       "        0.33637285, 0.48969404, 0.42535774, 0.40997076, 0.35302258,\n",
       "        0.36632617, 0.35782886, 0.34521262, 0.39818835, 0.36186862,\n",
       "        0.3831017 , 0.48795176, 0.37744053, 0.37481483, 0.35570733,\n",
       "        0.36032685, 0.3581051 , 0.37039717, 0.4056627 , 0.45120613,\n",
       "        0.37210035, 0.35263697, 0.35990159, 0.37379742, 0.4237922 ,\n",
       "        0.59970713, 0.43654966, 0.3854599 , 0.38818026, 0.37270363,\n",
       "        0.35614769, 0.33670974, 0.39561741, 0.37119532, 0.3468674 ,\n",
       "        0.36488128, 0.41878438, 0.35645088, 0.39466723, 0.35715381,\n",
       "        0.54402049, 0.35760109, 0.39017733, 0.37796489, 0.41925335,\n",
       "        0.39252035, 0.3492798 , 0.37552643, 0.37045765, 0.37792945,\n",
       "        0.34362833, 0.36491871, 0.36439919, 0.39059035, 0.33977334,\n",
       "        0.39016199, 0.34162418, 0.43697206, 0.35690061, 0.37418914,\n",
       "        0.37962866, 0.38387044, 0.36808578, 0.3667744 , 0.36855149,\n",
       "        0.58494401, 0.37989179, 0.34730736, 0.38597528, 0.33738796,\n",
       "        0.38377682, 0.52044408, 0.4102544 , 0.34199651, 0.37715284,\n",
       "        0.34425354, 0.37953607, 0.33048646, 0.38788462, 0.48095194,\n",
       "        0.45669985, 0.51566656, 0.45111434, 0.47733005, 0.43637371,\n",
       "        0.40835865, 0.43918339, 0.45386998, 0.47981326, 0.42199771,\n",
       "        0.47355572, 0.44305102, 0.46639132, 0.57208451, 0.46254857,\n",
       "        0.61187792, 0.42244585, 0.61890403, 0.40758093, 0.59654148,\n",
       "        0.42139673, 0.44828796, 0.46920983, 0.42732128, 0.43527412,\n",
       "        0.39564371, 0.43397681, 0.41154138, 0.48293726, 0.42577982,\n",
       "        0.52019127, 0.48254363, 0.48878853, 0.47099789, 0.45783575,\n",
       "        0.54177944, 0.78025683, 0.486022  , 0.6549813 , 0.54156446,\n",
       "        0.45811558, 0.50056235, 0.53013301, 0.52589877, 0.52972364,\n",
       "        0.54161382, 0.5404822 , 0.43637037, 0.61117371, 0.53396694,\n",
       "        0.53550029, 0.49821925, 0.70523604, 0.50546527, 0.66932003,\n",
       "        0.58811076, 0.73863339, 0.48008513, 0.58036113, 0.47817095,\n",
       "        0.51252453, 0.51999458, 0.61597538, 0.60839232, 0.60281793,\n",
       "        0.57132427, 0.59540868, 0.59645653, 0.60982339, 0.58290346,\n",
       "        0.62785769, 0.51199961, 0.67234619, 0.5145816 , 0.54729231,\n",
       "        0.42838987, 0.51175523, 0.47321645, 0.53239187, 0.55592887,\n",
       "        0.58891042, 0.66092761, 0.64184936, 0.54997023, 0.51661372,\n",
       "        0.58434971, 0.6619521 , 0.69540652, 0.55996394, 0.53377843,\n",
       "        0.71038747, 0.54790711, 0.55855147, 0.56178363, 0.58515946,\n",
       "        0.60858734, 0.82647427, 0.54280845, 0.72549852, 0.52404984,\n",
       "        0.49438262, 0.55813766, 0.51408418, 0.46648979, 0.78034012,\n",
       "        0.55699444, 0.48479573, 0.55853033, 0.58021498, 0.59566228,\n",
       "        0.64797274, 0.59581614, 0.56301649, 0.53131207, 0.44549823,\n",
       "        0.53043222, 0.64984592, 0.54606223, 0.53405658, 0.63599698,\n",
       "        0.53524629, 0.4762605 , 0.53547963, 0.4676044 , 0.68878134,\n",
       "        0.47372047, 0.64907567, 0.4859217 , 0.63106012, 0.59781051,\n",
       "        0.6829377 , 0.49008052, 0.68470097, 0.47754677, 0.44335294,\n",
       "        0.44245497, 0.51527611, 0.41779129, 0.53885428, 0.4304777 ,\n",
       "        0.37968262, 0.46407755, 0.68522859, 0.39443183, 0.55319945,\n",
       "        0.37148348, 0.43067845, 0.39480766, 0.53063416, 0.37108914,\n",
       "        0.54341602, 0.40985815, 0.39791369, 0.42264684, 0.5454638 ,\n",
       "        0.45173367, 0.60487787, 0.72325516, 0.48758388, 0.50491373,\n",
       "        0.65480304, 0.42147748, 0.39019116, 0.46733952, 0.44464509,\n",
       "        0.40092619, 0.52504834, 0.47002339, 0.50059255, 0.38746246,\n",
       "        0.45284081, 0.46097136, 0.54113817, 0.3982029 , 0.53412429,\n",
       "        0.41327087, 0.41237521, 0.40227111, 0.59948413, 0.38256669,\n",
       "        0.58388837, 0.3851347 , 0.39968785, 0.3964088 , 0.51891979,\n",
       "        0.39939197, 0.55318189, 0.38498274, 0.40342506, 0.39407301,\n",
       "        0.49782729, 0.36425765, 0.6010468 , 0.35634867, 0.35470303,\n",
       "        0.34536004, 0.47839459, 0.34174395, 0.53200428, 0.37050764,\n",
       "        0.36454574, 0.32640314, 0.46408455, 0.45108032, 0.46057097,\n",
       "        0.56472103, 0.50641696, 0.46294816, 0.41015053, 0.35569485,\n",
       "        0.3938307 , 0.34073631, 0.42047254, 0.38522498, 0.43135071,\n",
       "        0.36029355, 0.35569795, 0.39893945, 0.49795167, 0.36941067,\n",
       "        0.4893256 , 0.38316305, 0.3241334 , 0.37736416, 0.31382251,\n",
       "        0.36315521, 0.58802207, 0.35327005, 0.36521729, 0.3326145 ,\n",
       "        0.39669538, 0.37524509, 0.37828819, 0.37977227, 0.37689773,\n",
       "        0.3591493 , 0.37141403, 0.39522529, 0.3832132 , 0.35587056,\n",
       "        0.34005268, 0.35937277, 0.35549307, 0.39841795, 0.36509625,\n",
       "        0.3919367 , 0.49969641, 0.43171668, 0.39800739, 0.38243548,\n",
       "        0.41386445, 0.43387548, 0.39607406, 0.37416649, 0.32322367,\n",
       "        0.31059949, 0.40623267, 0.35080703, 0.41442895, 0.55806955,\n",
       "        0.33846196, 0.37548089, 0.32410685, 0.34945941, 0.4396747 ,\n",
       "        0.61041069, 0.33153041, 0.31550415, 0.30706501, 0.32065789,\n",
       "        0.25319568, 0.4129409 , 0.25015291, 0.30873299, 0.31793507,\n",
       "        0.28540516, 0.31478008, 0.45014373, 0.36886716, 0.31202269,\n",
       "        0.30479821, 0.27322634, 0.3154935 , 0.28341285, 0.30322655,\n",
       "        0.26120575, 0.29996141, 0.32479501, 0.29201404, 0.27626586,\n",
       "        0.32120156, 0.48399568, 0.24325021, 0.24450835, 0.75340962,\n",
       "        0.31513135, 0.28131684, 0.31758984, 0.29681889, 0.30749949,\n",
       "        0.26946942, 0.28930918, 0.28990269, 0.34705838, 0.27250671,\n",
       "        0.29437065, 0.31945459, 0.26405843, 0.26092203, 0.31833871,\n",
       "        0.27791444, 0.28658334, 0.40407117, 0.3504978 , 0.25655683,\n",
       "        0.30155929, 0.37041235, 0.27655276, 0.38585218, 0.30247744,\n",
       "        0.27309306, 0.2664237 , 0.29570516, 0.2582643 , 0.28383803,\n",
       "        0.28587914, 0.32647125, 0.28470167, 0.32183886, 0.30121422,\n",
       "        0.28351959, 0.26344466, 0.29450591, 0.25324313, 0.26528668,\n",
       "        0.32863951, 0.28432107, 0.30554756, 0.2990218 , 0.30026428,\n",
       "        0.24833226, 0.41956941, 0.2589794 , 0.26464224, 0.2591544 ,\n",
       "        0.27757788, 0.26798002, 0.29609561, 0.27360415, 0.2552015 ,\n",
       "        0.28737696, 0.4121991 , 0.26756708, 0.26250545, 0.27778212,\n",
       "        0.26547535, 0.30011193, 0.43360297, 0.28749156, 0.26885358,\n",
       "        0.33529099, 0.29442914, 0.30352378, 0.27730203, 0.3271265 ,\n",
       "        0.28725314, 0.30004382, 0.33245945, 0.30385534, 0.29693071,\n",
       "        0.42968249, 0.30566176, 0.29019268, 0.29937331, 0.3130726 ,\n",
       "        0.27993027, 0.48717419, 0.28285321, 0.31178403, 0.29984021,\n",
       "        0.25991376, 0.33163929, 0.29179788, 0.33225385, 0.29765304,\n",
       "        0.28211919, 0.33688227, 0.27087641, 0.30404083, 0.3110474 ,\n",
       "        0.29564603, 0.4489371 , 0.28347341, 0.31465785, 0.28808777,\n",
       "        0.29927071, 0.29994965, 0.46995735, 0.29128051, 0.28113723,\n",
       "        0.30582643, 0.28176824, 0.27675486, 0.2960933 , 0.30109684]),\n",
       " 'std_score_time': array([1.67700741e-01, 1.36975282e-02, 6.60407996e-02, 1.70400687e-02,\n",
       "        1.25067727e-02, 6.01627151e-02, 2.04274678e-02, 8.37203631e-02,\n",
       "        3.12879012e-02, 8.18637089e-02, 1.05494870e-02, 1.51170598e-02,\n",
       "        5.94528089e-02, 1.50614303e-02, 1.17383277e-01, 1.27877056e-02,\n",
       "        4.57199722e-02, 4.54054291e-02, 4.42770419e-02, 3.34566146e-02,\n",
       "        5.48965380e-03, 6.11480078e-02, 1.76220395e-02, 2.35005531e-02,\n",
       "        3.41460717e-02, 4.09023326e-02, 1.12398366e-01, 1.24752970e-01,\n",
       "        1.76414594e-02, 1.83531404e-02, 8.51625331e-02, 1.45533056e-02,\n",
       "        2.33082332e-02, 1.29382826e-02, 5.34101925e-02, 1.80074846e-02,\n",
       "        2.81433512e-02, 9.53714948e-02, 5.57432204e-02, 1.43796781e-01,\n",
       "        1.90980176e-02, 2.65333518e-02, 1.95499312e-02, 5.47935755e-02,\n",
       "        1.53948353e-02, 4.49820389e-02, 2.01887082e-02, 2.74775489e-02,\n",
       "        1.90619498e-02, 2.21172263e-02, 1.32829807e-02, 2.00959266e-02,\n",
       "        1.39307185e-02, 3.19383772e-02, 3.22256482e-02, 2.02129157e-02,\n",
       "        6.95931081e-02, 8.18842182e-02, 6.83783003e-02, 4.09290206e-02,\n",
       "        5.35920068e-02, 9.51334499e-02, 5.59679851e-02, 1.22691166e-02,\n",
       "        4.73072134e-02, 1.20657534e-02, 5.65271363e-02, 3.79509562e-02,\n",
       "        1.35948445e-02, 5.14458911e-02, 2.67154913e-02, 5.09431062e-02,\n",
       "        3.71475427e-02, 2.41742029e-02, 2.50023986e-02, 6.59700471e-03,\n",
       "        3.25154788e-02, 3.77223512e-02, 2.99226787e-02, 5.31309849e-02,\n",
       "        5.06395760e-02, 1.72380896e-02, 6.00223465e-01, 2.91556612e-02,\n",
       "        1.23394472e-01, 2.57838342e-02, 3.07339877e-02, 6.43029212e-02,\n",
       "        8.94784106e-02, 8.34477906e-02, 5.51272104e-02, 6.82197474e-01,\n",
       "        8.97523444e-02, 2.46347039e-01, 6.45278537e-02, 7.59336099e-03,\n",
       "        3.77200797e-02, 1.23563522e-01, 1.95471636e-01, 5.08331475e-02,\n",
       "        3.43236891e-02, 8.87747307e-02, 2.10243805e-01, 1.58538022e-01,\n",
       "        4.19268908e-02, 2.00081823e-01, 1.60346684e-01, 4.85064620e-02,\n",
       "        1.36062044e-02, 3.21094112e-02, 8.39949287e-02, 3.24168873e-02,\n",
       "        4.15292622e-02, 1.77883751e-01, 7.91381808e-02, 9.10540024e-02,\n",
       "        8.47606610e-02, 7.10681498e-02, 1.00224543e-01, 5.82810171e-02,\n",
       "        1.98013154e-02, 3.91207144e-02, 2.27141670e-02, 3.47717663e-02,\n",
       "        1.88141989e-02, 3.46508395e-02, 1.73668226e-01, 5.15046015e-02,\n",
       "        5.27468629e-02, 4.39735608e-02, 4.33298157e-02, 8.14431628e-02,\n",
       "        1.31294592e-02, 1.62502713e-01, 1.18523853e-02, 3.09450684e-02,\n",
       "        6.36710651e-02, 8.59752692e-02, 2.91068988e-02, 5.64435027e-02,\n",
       "        2.11539290e-02, 4.71143337e-02, 8.82476945e-02, 8.53960438e-03,\n",
       "        8.34767903e-03, 4.74564996e-02, 1.67327406e-01, 8.19967107e-02,\n",
       "        6.53118476e-02, 2.53247966e-02, 1.23883341e-01, 2.97515406e-02,\n",
       "        6.14404253e-03, 4.99113281e-02, 2.44583579e-02, 2.49085764e-02,\n",
       "        9.35726977e-02, 1.13074288e-01, 3.62485715e-02, 9.73859723e-02,\n",
       "        3.07594403e-04, 1.64196401e-01, 6.44589824e-03, 3.25331600e-02,\n",
       "        2.01988388e-02, 4.74054424e-02, 2.22851876e-02, 8.77517412e-02,\n",
       "        1.66559099e-02, 1.77027306e-02, 2.09835900e-02, 4.91349599e-02,\n",
       "        1.40432509e-01, 4.29804845e-02, 1.44207647e-01, 5.07434528e-02,\n",
       "        1.02351457e-01, 3.51561029e-02, 2.35816099e-02, 1.50306017e-02,\n",
       "        2.60553046e-01, 1.54690620e-02, 3.10471841e-02, 1.81626351e-01,\n",
       "        4.54687357e-02, 1.81486597e-01, 4.87240002e-02, 2.97272635e-02,\n",
       "        1.36564499e-03, 2.04050596e-01, 2.71660836e-02, 2.97757544e-02,\n",
       "        8.12316461e-02, 6.52867833e-02, 7.96615943e-02, 2.07943971e-01,\n",
       "        1.68947135e-02, 1.54623036e-02, 1.75357407e-01, 3.60215877e-02,\n",
       "        1.35930880e-01, 3.54818672e-02, 2.37529353e-02, 4.04461877e-02,\n",
       "        1.48879605e-01, 3.15516877e-02, 5.15043620e-02, 3.63876403e-01,\n",
       "        6.60896439e-02, 1.62163420e-01, 2.72671100e-01, 4.31671942e-02,\n",
       "        8.79651623e-02, 1.87005248e-01, 2.05294433e-02, 3.05719180e-02,\n",
       "        2.67728916e-02, 1.78021913e-02, 6.13077411e-02, 1.73241913e-01,\n",
       "        4.35197897e-03, 3.25330297e-02, 3.30432429e-02, 1.98806463e-01,\n",
       "        3.96589417e-02, 8.08296355e-02, 9.72866643e-02, 3.91339184e-03,\n",
       "        5.24551676e-02, 7.85198829e-03, 5.64741018e-02, 2.14388644e-02,\n",
       "        9.30902701e-02, 3.41196479e-02, 7.83562689e-02, 3.29199442e-02,\n",
       "        1.94458146e-02, 2.17285440e-02, 1.22137431e-01, 4.89314915e-02,\n",
       "        2.01077688e-01, 2.06057011e-01, 3.47152401e-02, 6.75114274e-02,\n",
       "        1.49983576e-01, 2.42148444e-02, 8.23662414e-02, 2.07530417e-02,\n",
       "        2.12492634e-02, 2.29508242e-02, 6.17402196e-02, 1.90487576e-02,\n",
       "        6.52161114e-03, 2.56573480e-02, 4.49142935e-02, 6.17566380e-02,\n",
       "        4.44701831e-02, 3.90609929e-02, 6.22588376e-02, 3.75454588e-02,\n",
       "        7.79022296e-02, 7.11377183e-02, 1.76831646e-01, 2.20624758e-02,\n",
       "        1.37033609e-01, 1.29098487e-02, 8.09563876e-03, 4.44522699e-02,\n",
       "        2.54708280e-02, 1.09508010e-01, 1.41683461e-01, 6.57022833e-02,\n",
       "        4.10365618e-02, 1.29782931e-01, 4.92838487e-02, 1.17902590e-01,\n",
       "        4.63226836e-03, 1.70075616e-01, 7.52868914e-02, 1.46053738e-01,\n",
       "        2.83068129e-02, 4.59001533e-02, 5.60864728e-02, 5.36192531e-02,\n",
       "        9.56593350e-02, 1.46864199e-01, 8.64069208e-02, 1.42901236e-01,\n",
       "        2.35466201e-01, 3.09934101e-02, 2.46654064e-01, 8.89648305e-02,\n",
       "        8.09663708e-02, 3.17530080e-02, 1.96793855e-01, 2.95628294e-02,\n",
       "        3.70792175e-02, 4.43177172e-02, 1.53535911e-02, 8.86941749e-03,\n",
       "        1.38672192e-01, 1.13187989e-02, 4.59675671e-02, 3.62377871e-02,\n",
       "        2.76644188e-02, 1.68883908e-02, 3.10628136e-02, 9.47077637e-03,\n",
       "        4.93573054e-02, 7.56639627e-02, 3.86631541e-02, 4.57979162e-02,\n",
       "        1.04759487e-02, 1.80462643e-01, 5.62127363e-02, 1.94276790e-01,\n",
       "        2.58016501e-02, 2.36940597e-01, 4.39497469e-02, 3.23832961e-02,\n",
       "        2.32101719e-02, 2.81325886e-02, 5.91218379e-02, 4.63717509e-02,\n",
       "        3.26460513e-02, 1.70333019e-02, 6.97128790e-02, 8.95789817e-02,\n",
       "        2.08571707e-02, 1.79279514e-02, 3.49414933e-02, 1.66537886e-02,\n",
       "        4.09261361e-02, 4.97714628e-02, 1.94645776e-02, 3.22688302e-02,\n",
       "        1.39842617e-01, 1.67640771e-02, 2.35558719e-02, 3.48192665e-02,\n",
       "        4.06710425e-02, 1.54991013e-02, 1.14253486e-02, 6.83226816e-02,\n",
       "        1.39659887e-01, 2.77378184e-02, 4.42495985e-02, 3.08140634e-02,\n",
       "        5.38220792e-02, 3.49925029e-02, 3.41558706e-01, 5.75412914e-02,\n",
       "        3.20422828e-02, 1.43963084e-02, 7.69142800e-02, 2.14620598e-02,\n",
       "        3.57689781e-02, 3.73277945e-03, 2.98733163e-02, 5.77889636e-02,\n",
       "        4.34844697e-02, 3.84468316e-02, 5.87529370e-02, 4.65197587e-02,\n",
       "        2.32643576e-02, 1.82216631e-01, 2.56071806e-02, 4.31199139e-03,\n",
       "        4.81121170e-02, 3.74071187e-02, 3.80680668e-02, 1.51460787e-02,\n",
       "        3.64819859e-02, 2.99036399e-02, 6.19883417e-02, 1.73431926e-02,\n",
       "        2.14270409e-02, 4.92283713e-02, 3.08876793e-02, 2.52123996e-02,\n",
       "        7.19454971e-02, 3.63811332e-02, 1.04696732e-01, 3.94902137e-02,\n",
       "        2.30717114e-02, 2.98612567e-02, 3.14905268e-02, 4.20594172e-02,\n",
       "        3.97542500e-02, 5.56092266e-02, 1.99040585e-01, 6.18739186e-02,\n",
       "        4.21088924e-02, 7.08240332e-02, 4.19994728e-02, 3.11956700e-02,\n",
       "        1.26192121e-01, 6.96729732e-02, 3.09771441e-02, 3.08060174e-02,\n",
       "        1.11434905e-02, 4.02350109e-02, 1.98672946e-02, 4.90526531e-02,\n",
       "        1.22191512e-01, 4.18112812e-02, 7.38958557e-02, 3.59927444e-03,\n",
       "        4.28452307e-02, 1.23143802e-02, 2.23972816e-02, 2.05236646e-02,\n",
       "        3.02253887e-02, 4.73521230e-02, 6.16291432e-03, 2.60723143e-02,\n",
       "        1.75595914e-02, 6.16364815e-02, 1.16262641e-01, 8.12433228e-02,\n",
       "        2.33311539e-01, 1.60764869e-02, 2.14900246e-01, 1.22043245e-02,\n",
       "        2.13048938e-01, 5.61930501e-03, 6.56115839e-02, 4.24516473e-02,\n",
       "        1.74572709e-02, 1.73929812e-02, 2.53489142e-02, 6.85233961e-02,\n",
       "        3.41729734e-02, 3.68503425e-02, 1.67654524e-02, 7.08208709e-02,\n",
       "        8.88432225e-02, 4.65408874e-02, 3.08695079e-02, 5.38139706e-03,\n",
       "        1.27295519e-01, 2.06496204e-01, 4.46785352e-02, 7.83969895e-02,\n",
       "        7.20588383e-02, 3.36270029e-02, 5.96669507e-02, 5.71494239e-02,\n",
       "        4.02285368e-02, 9.23401189e-02, 1.37106304e-01, 5.93647927e-02,\n",
       "        3.60342703e-02, 1.49872663e-01, 1.35126064e-01, 9.15872495e-02,\n",
       "        3.96081117e-02, 2.55130684e-01, 6.85141924e-02, 1.99891930e-01,\n",
       "        1.06427236e-01, 3.57158969e-01, 4.71654730e-02, 1.03166300e-01,\n",
       "        3.57704300e-02, 6.63807253e-02, 3.68212488e-02, 8.58541824e-02,\n",
       "        6.20609289e-02, 9.70093277e-02, 1.25317802e-01, 1.22157764e-01,\n",
       "        7.60863959e-02, 1.98026236e-01, 1.19674327e-01, 4.11271777e-02,\n",
       "        1.03766502e-02, 2.86727939e-01, 4.09991318e-02, 7.47950216e-02,\n",
       "        4.82987144e-02, 3.19739163e-02, 2.19117411e-02, 7.00807528e-02,\n",
       "        5.66400618e-02, 1.11867637e-01, 2.28998779e-01, 8.12824820e-02,\n",
       "        5.20462695e-02, 1.15385393e-01, 2.11340574e-02, 1.97552141e-01,\n",
       "        1.95290778e-01, 1.50566253e-01, 8.32490166e-02, 2.85521702e-01,\n",
       "        2.32522106e-02, 8.96708193e-02, 3.11796372e-02, 9.88200011e-02,\n",
       "        2.55169619e-02, 4.61746191e-01, 6.34230653e-02, 2.38633139e-01,\n",
       "        5.77874359e-02, 5.30040402e-02, 5.09565051e-02, 5.86121178e-02,\n",
       "        6.00353789e-02, 1.71911334e-01, 7.82614978e-02, 7.41381235e-03,\n",
       "        3.54498981e-02, 4.78448843e-02, 1.11349930e-01, 2.88540584e-01,\n",
       "        9.95330146e-02, 1.15109493e-01, 2.30321755e-02, 2.61807487e-02,\n",
       "        1.18879966e-01, 1.76358784e-01, 8.50579596e-02, 8.62253406e-02,\n",
       "        4.14866852e-02, 3.10535835e-02, 1.83281978e-02, 2.69712645e-02,\n",
       "        3.71819095e-02, 2.82456349e-01, 2.74830019e-03, 2.29357977e-01,\n",
       "        7.78384795e-02, 1.09846431e-01, 2.22080156e-01, 2.21835337e-01,\n",
       "        6.69038467e-02, 2.25146057e-01, 4.37764286e-02, 2.18565477e-02,\n",
       "        7.48484840e-02, 1.47329378e-01, 2.97982730e-02, 2.32891597e-01,\n",
       "        2.58122256e-02, 4.02971652e-02, 4.32666280e-02, 4.08947102e-01,\n",
       "        8.01066697e-03, 1.40530952e-01, 5.15446818e-02, 5.60190185e-02,\n",
       "        6.30509266e-03, 2.11661768e-01, 2.46385694e-03, 2.08627349e-01,\n",
       "        2.38029818e-02, 2.03748600e-02, 3.28648100e-02, 1.65861558e-01,\n",
       "        1.01596244e-01, 2.28351722e-01, 1.52418652e-01, 2.80174677e-02,\n",
       "        3.36029402e-02, 2.54549301e-01, 2.52051527e-02, 5.67773364e-02,\n",
       "        1.48406790e-01, 4.65409617e-02, 2.80017151e-02, 1.83662272e-01,\n",
       "        3.29807972e-02, 1.47465905e-01, 2.97410425e-02, 4.60365390e-02,\n",
       "        2.22616090e-02, 1.90991378e-01, 2.67845393e-02, 2.18431888e-01,\n",
       "        3.15514004e-02, 6.21348930e-02, 2.78175113e-02, 2.84593124e-01,\n",
       "        4.19024283e-02, 2.31418888e-01, 4.09051340e-02, 4.36275439e-02,\n",
       "        3.23055723e-02, 2.18814198e-01, 4.97390998e-02, 2.05244583e-01,\n",
       "        4.72454676e-02, 2.70186025e-02, 8.77490348e-03, 1.73861742e-01,\n",
       "        4.33302768e-02, 1.97976478e-01, 1.55823383e-02, 6.09055716e-02,\n",
       "        3.64843694e-02, 1.57909931e-01, 4.28355097e-03, 2.28005783e-01,\n",
       "        3.28083020e-02, 3.53107009e-02, 7.55523798e-03, 1.69472788e-01,\n",
       "        5.74567497e-02, 6.10405908e-02, 1.36655509e-01, 1.59164164e-01,\n",
       "        1.12971042e-01, 4.01280644e-02, 3.93632251e-02, 5.01973176e-02,\n",
       "        5.16439457e-02, 7.33604799e-02, 2.65705146e-02, 3.40785947e-02,\n",
       "        3.47785225e-02, 2.07249475e-02, 8.39033327e-02, 1.45296708e-01,\n",
       "        3.72753950e-02, 2.12299814e-01, 3.59052575e-02, 5.97909854e-03,\n",
       "        8.41249305e-02, 1.15199908e-02, 4.08578577e-02, 2.89205884e-01,\n",
       "        2.66103309e-02, 2.13141891e-02, 1.12201496e-02, 5.08167276e-02,\n",
       "        9.11981770e-03, 1.99857418e-02, 9.13212469e-02, 4.97700921e-02,\n",
       "        5.20270459e-02, 1.00561341e-02, 4.73352656e-02, 4.93930272e-02,\n",
       "        2.38752107e-02, 3.15869682e-02, 2.57860963e-02, 3.36579078e-02,\n",
       "        2.21014725e-02, 2.45358232e-02, 6.36803816e-02, 1.99174148e-01,\n",
       "        6.83551671e-02, 6.46586871e-02, 3.75267498e-02, 5.30641177e-02,\n",
       "        5.36218489e-02, 6.27320206e-02, 5.29713047e-02, 3.10727820e-02,\n",
       "        8.47403987e-03, 9.32013656e-02, 7.21807340e-02, 1.14096423e-01,\n",
       "        2.44672331e-01, 2.38729803e-02, 3.77053312e-02, 4.80709139e-02,\n",
       "        4.24613013e-02, 1.10142453e-01, 4.14392590e-01, 5.76763746e-02,\n",
       "        2.41358676e-02, 1.85226117e-02, 3.01105055e-02, 1.74463178e-02,\n",
       "        1.43260850e-01, 5.01947372e-03, 1.31868568e-02, 1.09163751e-02,\n",
       "        3.16231441e-02, 1.13043227e-02, 1.54129915e-01, 5.20824341e-02,\n",
       "        1.07011318e-02, 6.29428155e-02, 2.37449899e-02, 1.21845458e-02,\n",
       "        4.47366983e-02, 7.84723077e-02, 2.56119626e-02, 2.71351272e-02,\n",
       "        4.19908971e-02, 3.14543367e-02, 1.80965749e-02, 6.68566190e-02,\n",
       "        3.09710245e-01, 1.65058384e-02, 6.27784134e-03, 3.12075365e-01,\n",
       "        4.36853292e-02, 2.44862192e-02, 1.45020561e-02, 3.17084833e-02,\n",
       "        3.85927383e-02, 2.03084949e-02, 1.56856408e-02, 1.70505348e-02,\n",
       "        9.07627516e-02, 3.71028607e-02, 9.82085806e-03, 3.65164687e-02,\n",
       "        2.26140807e-02, 3.77247865e-02, 3.98482077e-02, 3.70590478e-02,\n",
       "        1.69463989e-02, 1.88792974e-01, 8.13084494e-02, 3.35780794e-02,\n",
       "        1.41292789e-02, 2.95813089e-02, 1.88721807e-02, 1.71697533e-01,\n",
       "        7.46687568e-02, 1.20243510e-02, 6.66801441e-03, 2.79027130e-02,\n",
       "        3.28327918e-02, 2.49793477e-02, 3.69691021e-02, 5.32751840e-02,\n",
       "        1.11096820e-02, 4.48402685e-02, 4.97128420e-02, 1.89721325e-02,\n",
       "        2.39320205e-02, 2.65901639e-02, 1.57746867e-02, 2.25305401e-02,\n",
       "        5.37387428e-02, 2.99639258e-02, 2.18194364e-02, 1.91863908e-02,\n",
       "        1.02634667e-02, 2.20808871e-02, 1.73611540e-01, 2.26323343e-02,\n",
       "        6.55114037e-03, 4.93154168e-02, 1.71598856e-02, 2.44569588e-02,\n",
       "        4.58923548e-02, 2.81495113e-02, 1.44178439e-02, 8.68543707e-03,\n",
       "        1.87059080e-01, 3.28111115e-02, 2.19832823e-02, 2.83220227e-02,\n",
       "        2.92699631e-02, 9.71278888e-03, 1.62569023e-01, 2.25255724e-02,\n",
       "        3.28651994e-02, 3.84941713e-02, 2.55348765e-02, 1.96048104e-02,\n",
       "        1.52763325e-02, 1.98151916e-02, 4.13469031e-02, 1.64076883e-02,\n",
       "        6.12624622e-02, 1.67794487e-02, 3.52093316e-02, 1.86843204e-01,\n",
       "        8.76541532e-03, 3.13220121e-02, 3.26564123e-02, 2.90285444e-02,\n",
       "        1.60683663e-02, 2.19084338e-01, 3.34256785e-02, 1.99903219e-02,\n",
       "        2.97500029e-02, 2.87083041e-02, 5.53136856e-02, 1.13431944e-02,\n",
       "        5.85048982e-02, 8.63409161e-04, 2.55707029e-02, 5.78408200e-02,\n",
       "        2.72603800e-02, 2.25211562e-02, 2.48085145e-02, 7.92174536e-03,\n",
       "        1.96928045e-01, 2.54386574e-02, 8.51786111e-02, 8.62327551e-03,\n",
       "        1.77571199e-02, 1.61992367e-02, 2.76022165e-01, 1.96315340e-02,\n",
       "        3.57823078e-02, 1.59190535e-02, 3.83101458e-02, 2.40583062e-02,\n",
       "        9.05899890e-03, 3.81873490e-02]),\n",
       " 'param_activation': masked_array(data=['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_neurons': masked_array(data=[8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32,\n",
       "                    64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8,\n",
       "                    32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'}],\n",
       " 'split0_test_score': array([0.81554526, 0.80858469, 0.73549885, 0.824826  , 0.824826  ,\n",
       "        0.58352667, 0.82250577, 0.824826  , 0.59512758, 0.8201856 ,\n",
       "        0.82830626, 0.70533645, 0.82134569, 0.81902552, 0.78190255,\n",
       "        0.78074247, 0.824826  , 0.79234338, 0.8027842 , 0.80626452,\n",
       "        0.8201856 , 0.80046403, 0.80626452, 0.79698378, 0.824826  ,\n",
       "        0.78770304, 0.824826  , 0.74245942, 0.81902552, 0.81902552,\n",
       "        0.81902552, 0.70881671, 0.82134569, 0.72737819, 0.81902552,\n",
       "        0.81438518, 0.7436195 , 0.81554526, 0.824826  , 0.78422272,\n",
       "        0.81090486, 0.78538281, 0.75406033, 0.70533645, 0.824826  ,\n",
       "        0.82366592, 0.82134569, 0.66821349, 0.824826  , 0.82714617,\n",
       "        0.61252898, 0.82250577, 0.82598609, 0.64269143, 0.81786543,\n",
       "        0.81902552, 0.81786543, 0.82134569, 0.82366592, 0.81206495,\n",
       "        0.8074246 , 0.81902552, 0.81090486, 0.81322503, 0.82250577,\n",
       "        0.81902552, 0.56612527, 0.77030164, 0.82134569, 0.59512758,\n",
       "        0.78538281, 0.82250577, 0.77958238, 0.72041762, 0.81786543,\n",
       "        0.50348026, 0.79466355, 0.8027842 , 0.4211137 , 0.73433876,\n",
       "        0.82250577, 0.82250577, 0.81438518, 0.81786543, 0.50812066,\n",
       "        0.78886312, 0.80510443, 0.72969836, 0.62180972, 0.824826  ,\n",
       "        0.82714617, 0.82250577, 0.63341069, 0.82830626, 0.824826  ,\n",
       "        0.64849186, 0.82250577, 0.82366592, 0.70069605, 0.81670535,\n",
       "        0.81786543, 0.82598609, 0.82366592, 0.81902552, 0.824826  ,\n",
       "        0.77030164, 0.82598609, 0.81902552, 0.82714617, 0.8074246 ,\n",
       "        0.82134569, 0.80162412, 0.77494198, 0.82134569, 0.8201856 ,\n",
       "        0.79698378, 0.81902552, 0.73781902, 0.81554526, 0.81670535,\n",
       "        0.7737819 , 0.80046403, 0.81090486, 0.65081209, 0.66937357,\n",
       "        0.82134569, 0.80858469, 0.81554526, 0.82366592, 0.77262181,\n",
       "        0.79118329, 0.82134569, 0.75522041, 0.81902552, 0.82134569,\n",
       "        0.78422272, 0.76914155, 0.44895592, 0.8201856 , 0.81786543,\n",
       "        0.57540601, 0.82366592, 0.82598609, 0.56264502, 0.82366592,\n",
       "        0.81902552, 0.70069605, 0.81902552, 0.8201856 , 0.74941993,\n",
       "        0.80394429, 0.81554526, 0.78538281, 0.62529004, 0.82134569,\n",
       "        0.824826  , 0.74941993, 0.80974478, 0.8201856 , 0.78770304,\n",
       "        0.73781902, 0.82598609, 0.79582369, 0.76682132, 0.82366592,\n",
       "        0.40487239, 0.80510443, 0.81786543, 0.59512758, 0.64965194,\n",
       "        0.7610209 , 0.75870067, 0.76566124, 0.81206495, 0.65081209,\n",
       "        0.8201856 , 0.77262181, 0.39675173, 0.77958238, 0.8027842 ,\n",
       "        0.81902552, 0.8027842 , 0.58584684, 0.82946634, 0.82714617,\n",
       "        0.59628773, 0.82598609, 0.82366592, 0.62761021, 0.81554526,\n",
       "        0.82598609, 0.73549885, 0.80858469, 0.81554526, 0.79002321,\n",
       "        0.81670535, 0.824826  , 0.7737819 , 0.8201856 , 0.81902552,\n",
       "        0.82366592, 0.80162412, 0.81670535, 0.8201856 , 0.80510443,\n",
       "        0.79234338, 0.824826  , 0.59512758, 0.81438518, 0.82250577,\n",
       "        0.80974478, 0.80046403, 0.81554526, 0.59512758, 0.64849186,\n",
       "        0.80046403, 0.7436195 , 0.81090486, 0.8201856 , 0.70533645,\n",
       "        0.80626452, 0.78770304, 0.69373548, 0.81206495, 0.82598609,\n",
       "        0.81554526, 0.82250577, 0.5986079 , 0.82830626, 0.82366592,\n",
       "        0.62645012, 0.82366592, 0.824826  , 0.60092807, 0.81786543,\n",
       "        0.82946634, 0.80858469, 0.82830626, 0.82714617, 0.80858469,\n",
       "        0.82250577, 0.82134569, 0.81206495, 0.824826  , 0.80162412,\n",
       "        0.8201856 , 0.79814386, 0.79002321, 0.81786543, 0.66473317,\n",
       "        0.81670535, 0.81670535, 0.81554526, 0.81554526, 0.82134569,\n",
       "        0.80046403, 0.79234338, 0.82250577, 0.62296987, 0.60672855,\n",
       "        0.81902552, 0.74593967, 0.824826  , 0.8201856 , 0.8027842 ,\n",
       "        0.76218098, 0.8074246 , 0.65081209, 0.80046403, 0.82366592,\n",
       "        0.70765662, 0.71113688, 0.59512758, 0.79118329, 0.8074246 ,\n",
       "        0.59512758, 0.8074246 , 0.81206495, 0.69953597, 0.82134569,\n",
       "        0.81902552, 0.6972158 , 0.81902552, 0.81902552, 0.64385152,\n",
       "        0.82134569, 0.824826  , 0.59628773, 0.79118329, 0.82714617,\n",
       "        0.81902552, 0.78422272, 0.82366592, 0.79698378, 0.82134569,\n",
       "        0.82946634, 0.8201856 , 0.79698378, 0.81438518, 0.81554526,\n",
       "        0.62877029, 0.82250577, 0.8201856 , 0.80858469, 0.79350346,\n",
       "        0.81438518, 0.77030164, 0.76218098, 0.82366592, 0.81322503,\n",
       "        0.824826  , 0.79234338, 0.70069605, 0.82250577, 0.81902552,\n",
       "        0.73665893, 0.73085845, 0.57192576, 0.82598609, 0.81670535,\n",
       "        0.52204174, 0.82598609, 0.81902552, 0.61136889, 0.824826  ,\n",
       "        0.8201856 , 0.71925753, 0.82134569, 0.82366592, 0.73317868,\n",
       "        0.824826  , 0.824826  , 0.73201859, 0.80626452, 0.82134569,\n",
       "        0.82250577, 0.80162412, 0.80858469, 0.81902552, 0.82598609,\n",
       "        0.74477959, 0.824826  , 0.78074247, 0.82830626, 0.8201856 ,\n",
       "        0.73549885, 0.81438518, 0.824826  , 0.6972158 , 0.82598609,\n",
       "        0.82366592, 0.79466355, 0.81670535, 0.82714617, 0.73665893,\n",
       "        0.80162412, 0.824826  , 0.76334107, 0.79582369, 0.824826  ,\n",
       "        0.81902552, 0.81670535, 0.73085845, 0.824826  , 0.82250577,\n",
       "        0.78306264, 0.82250577, 0.82714617, 0.71577728, 0.8201856 ,\n",
       "        0.81902552, 0.6972158 , 0.824826  , 0.82366592, 0.80626452,\n",
       "        0.82250577, 0.82134569, 0.75290024, 0.81090486, 0.824826  ,\n",
       "        0.82250577, 0.78190255, 0.81902552, 0.82134569, 0.81786543,\n",
       "        0.81438518, 0.824826  , 0.81670535, 0.81786543, 0.81786543,\n",
       "        0.8074246 , 0.82830626, 0.82598609, 0.7436195 , 0.77726215,\n",
       "        0.82250577, 0.8027842 , 0.77726215, 0.81902552, 0.74129933,\n",
       "        0.80046403, 0.82250577, 0.54640371, 0.7737819 , 0.81902552,\n",
       "        0.80394429, 0.81786543, 0.65313226, 0.81206495, 0.81902552,\n",
       "        0.65313226, 0.81670535, 0.82714617, 0.71693736, 0.82366592,\n",
       "        0.82250577, 0.64965194, 0.7737819 , 0.81786543, 0.79930395,\n",
       "        0.82946634, 0.82714617, 0.78190255, 0.82250577, 0.81902552,\n",
       "        0.82366592, 0.82134569, 0.81090486, 0.82598609, 0.81786543,\n",
       "        0.79234338, 0.824826  , 0.80858469, 0.59512758, 0.82134569,\n",
       "        0.80162412, 0.81786543, 0.82830626, 0.68909514, 0.80974478,\n",
       "        0.79466355, 0.59512758, 0.82830626, 0.78654295, 0.77494198,\n",
       "        0.59512758, 0.82366592, 0.78190255, 0.82598609, 0.78538281,\n",
       "        0.81902552, 0.81554526, 0.62296987, 0.82250577, 0.82830626,\n",
       "        0.64617169, 0.8201856 , 0.82134569, 0.68329465, 0.82598609,\n",
       "        0.824826  , 0.79350346, 0.81090486, 0.82366592, 0.78886312,\n",
       "        0.81902552, 0.82134569, 0.79814386, 0.82830626, 0.81206495,\n",
       "        0.824826  , 0.72273785, 0.82250577, 0.82714617, 0.78886312,\n",
       "        0.82134569, 0.80974478, 0.79234338, 0.61136889, 0.82598609,\n",
       "        0.82946634, 0.81902552, 0.8201856 , 0.82134569, 0.82134569,\n",
       "        0.82714617, 0.81554526, 0.78654295, 0.81554526, 0.67053366,\n",
       "        0.62412995, 0.79814386, 0.68213457, 0.82134569, 0.8201856 ,\n",
       "        0.82714617, 0.82250577, 0.62761021, 0.82714617, 0.82830626,\n",
       "        0.64733177, 0.82134569, 0.8201856 , 0.66125292, 0.81786543,\n",
       "        0.82250577, 0.79582369, 0.82830626, 0.824826  , 0.82134569,\n",
       "        0.81902552, 0.82598609, 0.81786543, 0.81554526, 0.82134569,\n",
       "        0.81322503, 0.82366592, 0.8201856 , 0.8201856 , 0.824826  ,\n",
       "        0.82134569, 0.82250577, 0.40487239, 0.81902552, 0.79466355,\n",
       "        0.78654295, 0.81322503, 0.824826  , 0.74593967, 0.81206495,\n",
       "        0.81902552, 0.77262181, 0.82714617, 0.82250577, 0.8074246 ,\n",
       "        0.74245942, 0.79814386, 0.82134569, 0.76566124, 0.81438518,\n",
       "        0.72041762, 0.79234338, 0.71461719, 0.79582369, 0.81438518,\n",
       "        0.64617169, 0.81090486, 0.82598609, 0.62529004, 0.82830626,\n",
       "        0.82366592, 0.67285383, 0.81438518, 0.8201856 , 0.70997679,\n",
       "        0.83062643, 0.82250577, 0.67053366, 0.80162412, 0.80046403,\n",
       "        0.82946634, 0.82134569, 0.81786543, 0.8201856 , 0.77958238,\n",
       "        0.80046403, 0.82250577, 0.7436195 , 0.81206495, 0.81554526,\n",
       "        0.82250577, 0.81206495, 0.81786543, 0.82366592, 0.78422272,\n",
       "        0.75754058, 0.79002321, 0.76334107, 0.82366592, 0.824826  ,\n",
       "        0.80162412, 0.8201856 , 0.75174016, 0.80046403, 0.8201856 ,\n",
       "        0.80626452, 0.79582369, 0.63573086, 0.81902552, 0.82598609,\n",
       "        0.58004642, 0.82366592, 0.82714617, 0.59512758, 0.82830626,\n",
       "        0.82598609, 0.78654295, 0.82250577, 0.82134569, 0.68329465,\n",
       "        0.80510443, 0.81438518, 0.74013919, 0.78190255, 0.8074246 ,\n",
       "        0.82598609, 0.76218098, 0.81322503, 0.82366592, 0.79466355,\n",
       "        0.82366592, 0.82134569, 0.82598609, 0.81786543, 0.824826  ,\n",
       "        0.82134569, 0.75986081, 0.81206495, 0.82134569, 0.81902552,\n",
       "        0.824826  , 0.75522041, 0.81554526, 0.82250577, 0.59512758,\n",
       "        0.81902552, 0.8201856 , 0.81902552, 0.81786543, 0.8027842 ,\n",
       "        0.81554526, 0.81786543, 0.63225061, 0.81786543, 0.8201856 ,\n",
       "        0.59512758, 0.82598609, 0.82250577, 0.59512758, 0.82598609,\n",
       "        0.82250577, 0.76566124, 0.82250577, 0.82134569, 0.76682132,\n",
       "        0.81786543, 0.824826  , 0.79466355, 0.73549885, 0.80626452,\n",
       "        0.82366592, 0.7737819 , 0.82250577, 0.824826  , 0.79466355,\n",
       "        0.81902552, 0.81902552, 0.73549885, 0.81786543, 0.82714617,\n",
       "        0.77610207, 0.79814386, 0.81902552, 0.82134569, 0.82250577,\n",
       "        0.824826  , 0.68793505, 0.81786543, 0.81902552, 0.70881671,\n",
       "        0.80394429, 0.82366592, 0.82134569, 0.80974478, 0.82366592,\n",
       "        0.67053366, 0.73201859, 0.41183296, 0.79466355, 0.7389791 ,\n",
       "        0.58352667, 0.80510443, 0.79234338, 0.70417631, 0.82598609,\n",
       "        0.82250577, 0.58816707, 0.78770304, 0.83178651, 0.59512758,\n",
       "        0.80626452, 0.82250577, 0.60904872, 0.74593967, 0.82598609,\n",
       "        0.8027842 , 0.8074246 , 0.82250577, 0.79930395, 0.81902552,\n",
       "        0.8074246 , 0.80162412, 0.78538281, 0.82366592, 0.824826  ,\n",
       "        0.78770304, 0.82250577, 0.81786543, 0.78886312, 0.81786543,\n",
       "        0.80974478, 0.76450115, 0.82598609, 0.8201856 , 0.82366592,\n",
       "        0.82134569, 0.81786543, 0.66357309, 0.824826  , 0.78306264,\n",
       "        0.74709976, 0.7737819 , 0.59512758, 0.81554526, 0.82134569,\n",
       "        0.55336428, 0.82366592, 0.81902552, 0.59628773, 0.82598609,\n",
       "        0.82250577, 0.59512758, 0.82134569, 0.82134569, 0.63225061,\n",
       "        0.81206495, 0.82134569, 0.66357309, 0.7436195 , 0.79582369,\n",
       "        0.81206495, 0.75058007, 0.81090486, 0.82366592, 0.82250577,\n",
       "        0.82830626, 0.82714617, 0.80626452, 0.83410674, 0.82366592,\n",
       "        0.76450115, 0.82714617, 0.82598609, 0.82598609, 0.81786543,\n",
       "        0.824826  , 0.82134569, 0.824826  , 0.82366592, 0.78306264,\n",
       "        0.8201856 , 0.8201856 , 0.74129933, 0.824826  , 0.82714617,\n",
       "        0.8027842 , 0.82134569, 0.675174  , 0.82598609, 0.82250577,\n",
       "        0.62761021, 0.8201856 , 0.82134569, 0.68561482, 0.824826  ,\n",
       "        0.82366592, 0.74129933, 0.82714617, 0.82598609, 0.7389791 ,\n",
       "        0.824826  , 0.82366592, 0.74245942, 0.80626452, 0.81438518,\n",
       "        0.81786543, 0.81206495, 0.81438518, 0.82250577, 0.81902552,\n",
       "        0.82250577, 0.824826  , 0.82366592, 0.82134569, 0.82598609,\n",
       "        0.79118329, 0.82250577, 0.82134569, 0.79234338, 0.82134569,\n",
       "        0.8201856 , 0.68909514, 0.81786543, 0.82250577, 0.79814386,\n",
       "        0.8201856 , 0.82366592, 0.82714617, 0.81670535, 0.81902552]),\n",
       " 'split1_test_score': array([0.79350346, 0.78538281, 0.70301622, 0.80162412, 0.8027842 ,\n",
       "        0.60556847, 0.80162412, 0.80162412, 0.68213457, 0.78886312,\n",
       "        0.79582369, 0.74477959, 0.80510443, 0.80510443, 0.77726215,\n",
       "        0.8027842 , 0.80626452, 0.7784223 , 0.78538281, 0.78538281,\n",
       "        0.78886312, 0.80046403, 0.79234338, 0.80510443, 0.79814386,\n",
       "        0.7784223 , 0.79930395, 0.80046403, 0.79582369, 0.79582369,\n",
       "        0.79930395, 0.7784223 , 0.80046403, 0.66705334, 0.66125292,\n",
       "        0.80510443, 0.80974478, 0.64965194, 0.80510443, 0.60440832,\n",
       "        0.75522041, 0.8027842 , 0.79002321, 0.70649654, 0.79350346,\n",
       "        0.79466355, 0.79930395, 0.59976798, 0.80162412, 0.8074246 ,\n",
       "        0.71577728, 0.8027842 , 0.79930395, 0.65661252, 0.80394429,\n",
       "        0.80394429, 0.80162412, 0.79814386, 0.80162412, 0.79698378,\n",
       "        0.78886312, 0.80162412, 0.79930395, 0.76798141, 0.80394429,\n",
       "        0.80162412, 0.7610209 , 0.79930395, 0.81090486, 0.8074246 ,\n",
       "        0.78074247, 0.79118329, 0.76450115, 0.76218098, 0.80162412,\n",
       "        0.80510443, 0.79002321, 0.79350346, 0.79698378, 0.73317868,\n",
       "        0.80510443, 0.59976798, 0.76334107, 0.80510443, 0.67633408,\n",
       "        0.77494198, 0.78306264, 0.70417631, 0.55568445, 0.7436195 ,\n",
       "        0.80626452, 0.80394429, 0.65313226, 0.79582369, 0.8027842 ,\n",
       "        0.70765662, 0.80046403, 0.8027842 , 0.68793505, 0.80626452,\n",
       "        0.79698378, 0.80394429, 0.79582369, 0.79466355, 0.80394429,\n",
       "        0.8027842 , 0.80046403, 0.80510443, 0.78886312, 0.79234338,\n",
       "        0.80162412, 0.81206495, 0.78306264, 0.80162412, 0.78886312,\n",
       "        0.8074246 , 0.80510443, 0.79234338, 0.78654295, 0.8027842 ,\n",
       "        0.6577726 , 0.77030164, 0.80046403, 0.63805103, 0.78422272,\n",
       "        0.79814386, 0.78074247, 0.79582369, 0.8027842 , 0.78770304,\n",
       "        0.79814386, 0.79814386, 0.75870067, 0.75754058, 0.78886312,\n",
       "        0.78654295, 0.78190255, 0.49419954, 0.79582369, 0.79698378,\n",
       "        0.72041762, 0.80046403, 0.8027842 , 0.5986079 , 0.80394429,\n",
       "        0.80046403, 0.68793505, 0.78886312, 0.79466355, 0.71461719,\n",
       "        0.78538281, 0.80046403, 0.70301622, 0.78422272, 0.79814386,\n",
       "        0.79698378, 0.73201859, 0.79466355, 0.80510443, 0.80858469,\n",
       "        0.80394429, 0.80510443, 0.67633408, 0.7610209 , 0.80626452,\n",
       "        0.37935033, 0.80510443, 0.80162412, 0.78654295, 0.73201859,\n",
       "        0.74709976, 0.71345705, 0.78886312, 0.80626452, 0.80394429,\n",
       "        0.79582369, 0.76914155, 0.68793505, 0.79698378, 0.80394429,\n",
       "        0.79118329, 0.79466355, 0.58236659, 0.79930395, 0.79814386,\n",
       "        0.68329465, 0.79698378, 0.80162412, 0.59976798, 0.79814386,\n",
       "        0.8027842 , 0.66473317, 0.80394429, 0.80394429, 0.76798141,\n",
       "        0.80394429, 0.8027842 , 0.8027842 , 0.80162412, 0.8027842 ,\n",
       "        0.8074246 , 0.79814386, 0.8027842 , 0.80394429, 0.77030164,\n",
       "        0.8027842 , 0.8027842 , 0.79582369, 0.79466355, 0.79930395,\n",
       "        0.72389793, 0.76218098, 0.79814386, 0.80046403, 0.79466355,\n",
       "        0.79930395, 0.79118329, 0.79814386, 0.79814386, 0.77030164,\n",
       "        0.76682132, 0.79698378, 0.77958238, 0.5939675 , 0.80162412,\n",
       "        0.80162412, 0.80394429, 0.64733177, 0.80394429, 0.80046403,\n",
       "        0.72273785, 0.80510443, 0.80046403, 0.69605571, 0.80046403,\n",
       "        0.80046403, 0.79234338, 0.8027842 , 0.80162412, 0.79698378,\n",
       "        0.80858469, 0.80162412, 0.79930395, 0.78770304, 0.79350346,\n",
       "        0.8027842 , 0.79118329, 0.78190255, 0.79814386, 0.80162412,\n",
       "        0.77262181, 0.80394429, 0.80626452, 0.79930395, 0.80162412,\n",
       "        0.79466355, 0.80626452, 0.79002321, 0.65661252, 0.70649654,\n",
       "        0.78074247, 0.78190255, 0.79002321, 0.73549885, 0.79466355,\n",
       "        0.68097448, 0.79002321, 0.77494198, 0.64733177, 0.80394429,\n",
       "        0.73781902, 0.72041762, 0.35034803, 0.78074247, 0.76682132,\n",
       "        0.47099769, 0.78074247, 0.79350346, 0.61020881, 0.80162412,\n",
       "        0.80046403, 0.62296987, 0.79814386, 0.80046403, 0.66125292,\n",
       "        0.80162412, 0.8027842 , 0.63341069, 0.78654295, 0.80394429,\n",
       "        0.78190255, 0.80046403, 0.79698378, 0.79582369, 0.75986081,\n",
       "        0.7784223 , 0.80046403, 0.76914155, 0.79002321, 0.79930395,\n",
       "        0.79814386, 0.79002321, 0.80626452, 0.68097448, 0.80858469,\n",
       "        0.80510443, 0.8027842 , 0.79698378, 0.80394429, 0.77030164,\n",
       "        0.8027842 , 0.80046403, 0.67749423, 0.7737819 , 0.79698378,\n",
       "        0.79234338, 0.68793505, 0.59164733, 0.79930395, 0.79698378,\n",
       "        0.57888633, 0.80046403, 0.8027842 , 0.59976798, 0.8074246 ,\n",
       "        0.79930395, 0.60092807, 0.79582369, 0.80394429, 0.69025522,\n",
       "        0.80510443, 0.80046403, 0.71345705, 0.79002321, 0.79234338,\n",
       "        0.8027842 , 0.78074247, 0.8027842 , 0.80046403, 0.71229696,\n",
       "        0.79814386, 0.80046403, 0.76914155, 0.79698378, 0.80046403,\n",
       "        0.76566124, 0.8027842 , 0.80626452, 0.72853827, 0.79814386,\n",
       "        0.79814386, 0.73665893, 0.79814386, 0.80626452, 0.69141531,\n",
       "        0.79234338, 0.80626452, 0.75174016, 0.80510443, 0.80510443,\n",
       "        0.80046403, 0.79466355, 0.62761021, 0.79930395, 0.80046403,\n",
       "        0.59976798, 0.80162412, 0.80394429, 0.64733177, 0.80394429,\n",
       "        0.80394429, 0.76334107, 0.80046403, 0.8074246 , 0.77958238,\n",
       "        0.80394429, 0.79814386, 0.77262181, 0.78538281, 0.79698378,\n",
       "        0.8027842 , 0.79466355, 0.80858469, 0.80046403, 0.79350346,\n",
       "        0.79814386, 0.80394429, 0.69837588, 0.79814386, 0.79930395,\n",
       "        0.76798141, 0.80394429, 0.80626452, 0.7737819 , 0.76682132,\n",
       "        0.80162412, 0.8027842 , 0.80046403, 0.80162412, 0.76334107,\n",
       "        0.78886312, 0.80510443, 0.77610207, 0.79234338, 0.79930395,\n",
       "        0.77958238, 0.77958238, 0.5939675 , 0.79466355, 0.80046403,\n",
       "        0.60788864, 0.79814386, 0.8027842 , 0.59976798, 0.79582369,\n",
       "        0.79582369, 0.75174016, 0.78074247, 0.80162412, 0.75986081,\n",
       "        0.79930395, 0.80394429, 0.74709976, 0.79466355, 0.79350346,\n",
       "        0.79814386, 0.80046403, 0.79002321, 0.78074247, 0.79350346,\n",
       "        0.80510443, 0.80510443, 0.80510443, 0.79698378, 0.80510443,\n",
       "        0.78074247, 0.80162412, 0.80510443, 0.78538281, 0.79930395,\n",
       "        0.80394429, 0.79002321, 0.40023202, 0.78886312, 0.70881671,\n",
       "        0.79582369, 0.78770304, 0.77494198, 0.7610209 , 0.80046403,\n",
       "        0.79350346, 0.8027842 , 0.63457078, 0.80162412, 0.80046403,\n",
       "        0.66937357, 0.80394429, 0.80162412, 0.75522041, 0.79814386,\n",
       "        0.79930395, 0.77958238, 0.80626452, 0.8074246 , 0.79930395,\n",
       "        0.8027842 , 0.8027842 , 0.7737819 , 0.79814386, 0.80046403,\n",
       "        0.79582369, 0.79002321, 0.79466355, 0.79698378, 0.79002321,\n",
       "        0.80046403, 0.8027842 , 0.80162412, 0.80046403, 0.8027842 ,\n",
       "        0.78190255, 0.79002321, 0.80394429, 0.73317868, 0.75522041,\n",
       "        0.79350346, 0.77262181, 0.79698378, 0.80162412, 0.80510443,\n",
       "        0.80394429, 0.80046403, 0.79698378, 0.80394429, 0.79002321,\n",
       "        0.80162412, 0.80046403, 0.62877029, 0.80626452, 0.80626452,\n",
       "        0.60324824, 0.80858469, 0.8074246 , 0.6577726 , 0.80046403,\n",
       "        0.8027842 , 0.80046403, 0.80394429, 0.80046403, 0.80626452,\n",
       "        0.79466355, 0.80394429, 0.79814386, 0.80046403, 0.80510443,\n",
       "        0.8027842 , 0.77494198, 0.79234338, 0.80510443, 0.79814386,\n",
       "        0.80046403, 0.80162412, 0.5684455 , 0.74941993, 0.79930395,\n",
       "        0.80510443, 0.78886312, 0.79350346, 0.79698378, 0.79698378,\n",
       "        0.80626452, 0.78770304, 0.59976798, 0.79234338, 0.76566124,\n",
       "        0.78190255, 0.8027842 , 0.72853827, 0.79930395, 0.78770304,\n",
       "        0.59976798, 0.7784223 , 0.61832947, 0.79466355, 0.79118329,\n",
       "        0.59512758, 0.79698378, 0.8027842 , 0.68097448, 0.80162412,\n",
       "        0.79814386, 0.64849186, 0.77030164, 0.80510443, 0.6577726 ,\n",
       "        0.80046403, 0.80046403, 0.66473317, 0.67285383, 0.80046403,\n",
       "        0.80046403, 0.79234338, 0.79930395, 0.79814386, 0.78770304,\n",
       "        0.75870067, 0.79698378, 0.8074246 , 0.80510443, 0.80510443,\n",
       "        0.79698378, 0.80046403, 0.74013919, 0.80046403, 0.79350346,\n",
       "        0.78074247, 0.80046403, 0.79698378, 0.80394429, 0.43735498,\n",
       "        0.79698378, 0.80046403, 0.80394429, 0.79350346, 0.76566124,\n",
       "        0.78538281, 0.79930395, 0.72853827, 0.79814386, 0.79814386,\n",
       "        0.69373548, 0.80046403, 0.80394429, 0.75290024, 0.79698378,\n",
       "        0.80510443, 0.65429235, 0.80046403, 0.80046403, 0.79466355,\n",
       "        0.79930395, 0.8027842 , 0.73201859, 0.8027842 , 0.80510443,\n",
       "        0.79698378, 0.77030164, 0.79814386, 0.80046403, 0.78538281,\n",
       "        0.79814386, 0.8027842 , 0.8027842 , 0.72737819, 0.79002321,\n",
       "        0.77958238, 0.78886312, 0.80510443, 0.80394429, 0.79814386,\n",
       "        0.79698378, 0.78074247, 0.79234338, 0.79698378, 0.74477959,\n",
       "        0.80626452, 0.80394429, 0.80046403, 0.59976798, 0.8027842 ,\n",
       "        0.79814386, 0.8027842 , 0.72041762, 0.80510443, 0.80626452,\n",
       "        0.71229696, 0.80626452, 0.79698378, 0.67749423, 0.80046403,\n",
       "        0.80162412, 0.74013919, 0.80162412, 0.8027842 , 0.79582369,\n",
       "        0.80162412, 0.80626452, 0.79350346, 0.79002321, 0.80162412,\n",
       "        0.78422272, 0.79698378, 0.80510443, 0.79814386, 0.80626452,\n",
       "        0.79698378, 0.80162412, 0.78538281, 0.79930395, 0.8027842 ,\n",
       "        0.79698378, 0.80162412, 0.80046403, 0.78306264, 0.80394429,\n",
       "        0.80626452, 0.80394429, 0.80510443, 0.80162412, 0.60324824,\n",
       "        0.71345705, 0.79466355, 0.80394429, 0.79350346, 0.79350346,\n",
       "        0.70997679, 0.62180972, 0.44199535, 0.74941993, 0.74593967,\n",
       "        0.59976798, 0.78654295, 0.78422272, 0.63573086, 0.79814386,\n",
       "        0.80162412, 0.61136889, 0.8027842 , 0.79930395, 0.66589326,\n",
       "        0.8074246 , 0.79466355, 0.59976798, 0.80046403, 0.79582369,\n",
       "        0.77610207, 0.78074247, 0.80046403, 0.78538281, 0.79234338,\n",
       "        0.78538281, 0.79698378, 0.80162412, 0.80046403, 0.80046403,\n",
       "        0.75754058, 0.79814386, 0.80510443, 0.78654295, 0.79698378,\n",
       "        0.8074246 , 0.8074246 , 0.80394429, 0.8027842 , 0.80046403,\n",
       "        0.79118329, 0.80626452, 0.79814386, 0.79930395, 0.79350346,\n",
       "        0.69489557, 0.75986081, 0.65893269, 0.78306264, 0.79002321,\n",
       "        0.5986079 , 0.79930395, 0.80162412, 0.59976798, 0.80162412,\n",
       "        0.8027842 , 0.75174016, 0.77726215, 0.80510443, 0.69025522,\n",
       "        0.80510443, 0.80626452, 0.63805103, 0.80394429, 0.80046403,\n",
       "        0.80626452, 0.79118329, 0.79582369, 0.8027842 , 0.79582369,\n",
       "        0.79582369, 0.80046403, 0.79234338, 0.79930395, 0.80394429,\n",
       "        0.79930395, 0.80162412, 0.79698378, 0.79466355, 0.79814386,\n",
       "        0.8027842 , 0.79814386, 0.79118329, 0.80046403, 0.78886312,\n",
       "        0.79814386, 0.80046403, 0.79582369, 0.81438518, 0.77726215,\n",
       "        0.79350346, 0.79350346, 0.59048724, 0.8027842 , 0.8027842 ,\n",
       "        0.58932716, 0.80162412, 0.80162412, 0.70881671, 0.79698378,\n",
       "        0.80510443, 0.77958238, 0.80858469, 0.80046403, 0.75986081,\n",
       "        0.80162412, 0.80046403, 0.7563805 , 0.80046403, 0.79582369,\n",
       "        0.79930395, 0.80162412, 0.80510443, 0.80394429, 0.79466355,\n",
       "        0.79698378, 0.80394429, 0.7610209 , 0.80046403, 0.80394429,\n",
       "        0.80162412, 0.80046403, 0.80162412, 0.79466355, 0.79466355,\n",
       "        0.80510443, 0.8027842 , 0.80394429, 0.80046403, 0.80046403,\n",
       "        0.80394429, 0.79582369, 0.79930395, 0.8027842 , 0.80162412]),\n",
       " 'split2_test_score': array([0.81765389, 0.77816492, 0.57491291, 0.81533098, 0.81184667,\n",
       "        0.6736353 , 0.81881535, 0.82462251, 0.68408829, 0.81881535,\n",
       "        0.82578397, 0.74680603, 0.80603951, 0.8211382 , 0.79442507,\n",
       "        0.81997675, 0.81184667, 0.78861791, 0.81997675, 0.80603951,\n",
       "        0.81649244, 0.81649244, 0.81533098, 0.81649244, 0.76538908,\n",
       "        0.82346112, 0.81881535, 0.80023229, 0.78977931, 0.81765389,\n",
       "        0.7189315 , 0.63066202, 0.79790938, 0.62833911, 0.82462251,\n",
       "        0.81765389, 0.80487806, 0.82694542, 0.8211382 , 0.82578397,\n",
       "        0.67595822, 0.81881535, 0.72357726, 0.63066202, 0.82229966,\n",
       "        0.82346112, 0.81300813, 0.61556327, 0.82346112, 0.82229966,\n",
       "        0.69454122, 0.82462251, 0.81881535, 0.64227641, 0.82346112,\n",
       "        0.82229966, 0.78048778, 0.81649244, 0.8211382 , 0.80836236,\n",
       "        0.81533098, 0.81184667, 0.8211382 , 0.83275259, 0.80836236,\n",
       "        0.82346112, 0.79094076, 0.81068528, 0.81765389, 0.79326367,\n",
       "        0.81997675, 0.81533098, 0.81881535, 0.81416959, 0.81765389,\n",
       "        0.77816492, 0.81068528, 0.79442507, 0.80139375, 0.7224158 ,\n",
       "        0.81765389, 0.79094076, 0.77003485, 0.82229966, 0.68176538,\n",
       "        0.7723577 , 0.8211382 , 0.61440188, 0.74448317, 0.81997675,\n",
       "        0.81997675, 0.82346112, 0.64227641, 0.82462251, 0.81881535,\n",
       "        0.76655054, 0.81997675, 0.81881535, 0.77351916, 0.81068528,\n",
       "        0.81997675, 0.8037166 , 0.83159119, 0.82229966, 0.81416959,\n",
       "        0.81997675, 0.82229966, 0.81881535, 0.79210222, 0.78861791,\n",
       "        0.8211382 , 0.78745645, 0.73170733, 0.82346112, 0.58652729,\n",
       "        0.70847851, 0.81533098, 0.80255514, 0.78745645, 0.82694542,\n",
       "        0.69105691, 0.81533098, 0.80952382, 0.57026714, 0.78745645,\n",
       "        0.81765389, 0.73054588, 0.83159119, 0.81765389, 0.79326367,\n",
       "        0.79907084, 0.81997675, 0.74099886, 0.80487806, 0.81533098,\n",
       "        0.76306617, 0.79558653, 0.6074332 , 0.8037166 , 0.82462251,\n",
       "        0.57258999, 0.8211382 , 0.8211382 , 0.59930313, 0.81765389,\n",
       "        0.82229966, 0.60975611, 0.82229966, 0.81881535, 0.76074332,\n",
       "        0.81649244, 0.82578397, 0.74448317, 0.76190478, 0.80952382,\n",
       "        0.81997675, 0.79558653, 0.81068528, 0.80603951, 0.78048778,\n",
       "        0.81881535, 0.80139375, 0.64692217, 0.83159119, 0.82346112,\n",
       "        0.71312428, 0.76655054, 0.81765389, 0.62601626, 0.77700347,\n",
       "        0.82229966, 0.68060392, 0.8037166 , 0.80603951, 0.76771194,\n",
       "        0.78164923, 0.81765389, 0.81649244, 0.80487806, 0.81533098,\n",
       "        0.8211382 , 0.80603951, 0.66202092, 0.81881535, 0.81765389,\n",
       "        0.60975611, 0.81881535, 0.81649244, 0.66434377, 0.82462251,\n",
       "        0.82346112, 0.77584207, 0.81765389, 0.81997675, 0.78861791,\n",
       "        0.81416959, 0.8211382 , 0.78977931, 0.82346112, 0.81765389,\n",
       "        0.81765389, 0.80952382, 0.8211382 , 0.81649244, 0.64227641,\n",
       "        0.82694542, 0.81881535, 0.81416959, 0.80720091, 0.79094076,\n",
       "        0.62253195, 0.66318232, 0.81649244, 0.6387921 , 0.77816492,\n",
       "        0.81649244, 0.65853661, 0.79210222, 0.82229966, 0.79442507,\n",
       "        0.78164923, 0.82229966, 0.5888502 , 0.77468061, 0.80952382,\n",
       "        0.81765389, 0.8211382 , 0.62369341, 0.81765389, 0.8211382 ,\n",
       "        0.74680603, 0.81997675, 0.81881535, 0.63995355, 0.8037166 ,\n",
       "        0.8211382 , 0.81416959, 0.81997675, 0.81881535, 0.80603951,\n",
       "        0.81765389, 0.80487806, 0.81068528, 0.78513354, 0.83159119,\n",
       "        0.8211382 , 0.81068528, 0.82462251, 0.81997675, 0.80487806,\n",
       "        0.78281069, 0.81765389, 0.76887339, 0.81184667, 0.81997675,\n",
       "        0.78977931, 0.78745645, 0.8211382 , 0.74912894, 0.52148664,\n",
       "        0.81765389, 0.77119631, 0.79210222, 0.81300813, 0.56678283,\n",
       "        0.61207896, 0.81649244, 0.62253195, 0.43437862, 0.79790938,\n",
       "        0.73170733, 0.70034844, 0.55865276, 0.78164923, 0.78048778,\n",
       "        0.64343786, 0.80720091, 0.80023229, 0.61440188, 0.81881535,\n",
       "        0.81765389, 0.58768874, 0.8211382 , 0.8211382 , 0.72706157,\n",
       "        0.8211382 , 0.81765389, 0.78048778, 0.78977931, 0.8211382 ,\n",
       "        0.78745645, 0.65389085, 0.8037166 , 0.79907084, 0.79558653,\n",
       "        0.8211382 , 0.81300813, 0.73867595, 0.82810688, 0.80139375,\n",
       "        0.62369341, 0.786295  , 0.81765389, 0.71544713, 0.81068528,\n",
       "        0.80023229, 0.81300813, 0.81068528, 0.79790938, 0.74680603,\n",
       "        0.79790938, 0.8211382 , 0.77700347, 0.79790938, 0.82229966,\n",
       "        0.78164923, 0.74448317, 0.60859466, 0.82694542, 0.82694542,\n",
       "        0.62253195, 0.82578397, 0.81881535, 0.56329846, 0.82926828,\n",
       "        0.81881535, 0.6562137 , 0.82229966, 0.8211382 , 0.73054588,\n",
       "        0.81765389, 0.81649244, 0.75261325, 0.82694542, 0.81997675,\n",
       "        0.80836236, 0.80139375, 0.79094076, 0.81997675, 0.82926828,\n",
       "        0.82926828, 0.80836236, 0.81997675, 0.82694542, 0.82694542,\n",
       "        0.81184667, 0.81997675, 0.8211382 , 0.77351916, 0.77351916,\n",
       "        0.82578397, 0.78745645, 0.81649244, 0.82346112, 0.78281069,\n",
       "        0.78977931, 0.81881535, 0.79326367, 0.83159119, 0.81765389,\n",
       "        0.81184667, 0.80603951, 0.69802552, 0.82694542, 0.81533098,\n",
       "        0.62601626, 0.8211382 , 0.81649244, 0.61207896, 0.79907084,\n",
       "        0.8211382 , 0.73983741, 0.81997675, 0.81997675, 0.75261325,\n",
       "        0.81765389, 0.81649244, 0.76190478, 0.81997675, 0.81997675,\n",
       "        0.81416959, 0.78397214, 0.82694542, 0.81765389, 0.81881535,\n",
       "        0.82694542, 0.81533098, 0.82462251, 0.83042973, 0.81997675,\n",
       "        0.69802552, 0.77932638, 0.81649244, 0.77468061, 0.80720091,\n",
       "        0.81997675, 0.62020904, 0.80836236, 0.81765389, 0.76190478,\n",
       "        0.82462251, 0.81997675, 0.79907084, 0.81533098, 0.8211382 ,\n",
       "        0.70963997, 0.78048778, 0.59465736, 0.8211382 , 0.8211382 ,\n",
       "        0.61556327, 0.82346112, 0.81416959, 0.62020904, 0.82346112,\n",
       "        0.82578397, 0.66898954, 0.8350755 , 0.80603951, 0.77003485,\n",
       "        0.81184667, 0.82229966, 0.80487806, 0.80836236, 0.81416959,\n",
       "        0.82346112, 0.83275259, 0.81184667, 0.81533098, 0.79907084,\n",
       "        0.82346112, 0.81997675, 0.79907084, 0.78977931, 0.82462251,\n",
       "        0.82229966, 0.82462251, 0.80836236, 0.82346112, 0.80952382,\n",
       "        0.82346112, 0.81533098, 0.8211382 , 0.80720091, 0.77584207,\n",
       "        0.61440188, 0.81300813, 0.73054588, 0.81184667, 0.82694542,\n",
       "        0.82926828, 0.81416959, 0.56445992, 0.82578397, 0.81997675,\n",
       "        0.68176538, 0.82346112, 0.81997675, 0.73867595, 0.82229966,\n",
       "        0.82346112, 0.73983741, 0.82926828, 0.82578397, 0.79674798,\n",
       "        0.82346112, 0.80139375, 0.78281069, 0.76887339, 0.81649244,\n",
       "        0.81997675, 0.81068528, 0.78745645, 0.80952382, 0.80255514,\n",
       "        0.80023229, 0.81997675, 0.62717772, 0.77003485, 0.81068528,\n",
       "        0.76074332, 0.81649244, 0.786295  , 0.80952382, 0.82462251,\n",
       "        0.80952382, 0.82810688, 0.81649244, 0.78048778, 0.786295  ,\n",
       "        0.82229966, 0.81533098, 0.80836236, 0.82810688, 0.81533098,\n",
       "        0.81765389, 0.82346112, 0.62137049, 0.82462251, 0.82229966,\n",
       "        0.72357726, 0.82346112, 0.82346112, 0.68873405, 0.78861791,\n",
       "        0.81533098, 0.82346112, 0.82462251, 0.80603951, 0.80603951,\n",
       "        0.82694542, 0.82346112, 0.81184667, 0.81997675, 0.81649244,\n",
       "        0.81184667, 0.8211382 , 0.81997675, 0.81300813, 0.76771194,\n",
       "        0.79558653, 0.81881535, 0.75842047, 0.78861791, 0.77584207,\n",
       "        0.77003485, 0.80720091, 0.80139375, 0.81068528, 0.80836236,\n",
       "        0.82462251, 0.40534264, 0.81184667, 0.8211382 , 0.81184667,\n",
       "        0.82462251, 0.80836236, 0.82346112, 0.80720091, 0.82578397,\n",
       "        0.76887339, 0.7537747 , 0.61207896, 0.79907084, 0.81416959,\n",
       "        0.58652729, 0.82694542, 0.82346112, 0.60859466, 0.82346112,\n",
       "        0.81997675, 0.7723577 , 0.8037166 , 0.81533098, 0.6387921 ,\n",
       "        0.82229966, 0.80487806, 0.7189315 , 0.78397214, 0.82462251,\n",
       "        0.81881535, 0.81765389, 0.82926828, 0.80836236, 0.79094076,\n",
       "        0.82462251, 0.82810688, 0.82346112, 0.80720091, 0.81416959,\n",
       "        0.81068528, 0.78048778, 0.81997675, 0.82694542, 0.8211382 ,\n",
       "        0.81649244, 0.75609756, 0.7549361 , 0.81881535, 0.61788619,\n",
       "        0.80487806, 0.81300813, 0.786295  , 0.82462251, 0.81881535,\n",
       "        0.80255514, 0.83159119, 0.56910568, 0.82810688, 0.81649244,\n",
       "        0.67944252, 0.81416959, 0.81649244, 0.67944252, 0.8211382 ,\n",
       "        0.81184667, 0.61091751, 0.82462251, 0.83391404, 0.72009289,\n",
       "        0.8350755 , 0.82578397, 0.76306617, 0.78048778, 0.80023229,\n",
       "        0.79790938, 0.80023229, 0.81765389, 0.81765389, 0.82578397,\n",
       "        0.8037166 , 0.81649244, 0.65040648, 0.80603951, 0.76074332,\n",
       "        0.670151  , 0.61440188, 0.81997675, 0.69686413, 0.81881535,\n",
       "        0.81997675, 0.65853661, 0.81649244, 0.79326367, 0.76422763,\n",
       "        0.77351916, 0.80836236, 0.81997675, 0.79210222, 0.81533098,\n",
       "        0.82229966, 0.81997675, 0.5888502 , 0.83159119, 0.81997675,\n",
       "        0.62601626, 0.8211382 , 0.8211382 , 0.61672473, 0.82694542,\n",
       "        0.81997675, 0.7363531 , 0.82346112, 0.81765389, 0.80139375,\n",
       "        0.78513354, 0.80836236, 0.80255514, 0.81765389, 0.81184667,\n",
       "        0.81997675, 0.81997675, 0.82578397, 0.82229966, 0.81533098,\n",
       "        0.80603951, 0.82229966, 0.80836236, 0.81416959, 0.81765389,\n",
       "        0.78977931, 0.786295  , 0.83042973, 0.79674798, 0.80255514,\n",
       "        0.79790938, 0.7549361 , 0.79326367, 0.82694542, 0.82578397,\n",
       "        0.79558653, 0.82578397, 0.75261325, 0.8211382 , 0.82810688,\n",
       "        0.70150989, 0.76422763, 0.39605111, 0.79326367, 0.79790938,\n",
       "        0.63646924, 0.81533098, 0.80720091, 0.46457607, 0.81300813,\n",
       "        0.82578397, 0.71544713, 0.82229966, 0.81997675, 0.72125435,\n",
       "        0.82229966, 0.82229966, 0.61440188, 0.76190478, 0.8211382 ,\n",
       "        0.79907084, 0.8211382 , 0.82229966, 0.79094076, 0.80023229,\n",
       "        0.81997675, 0.78861791, 0.81881535, 0.80487806, 0.81184667,\n",
       "        0.82810688, 0.82578397, 0.80487806, 0.80023229, 0.81300813,\n",
       "        0.81533098, 0.67131245, 0.82462251, 0.79790938, 0.69802552,\n",
       "        0.82462251, 0.81533098, 0.81997675, 0.80603951, 0.81068528,\n",
       "        0.78745645, 0.81184667, 0.44483158, 0.81997675, 0.82229966,\n",
       "        0.66898954, 0.81533098, 0.82346112, 0.73054588, 0.82229966,\n",
       "        0.8211382 , 0.65389085, 0.81765389, 0.82346112, 0.79907084,\n",
       "        0.80487806, 0.82810688, 0.71428573, 0.78397214, 0.82694542,\n",
       "        0.79210222, 0.79094076, 0.786295  , 0.81649244, 0.80023229,\n",
       "        0.82694542, 0.80487806, 0.80603951, 0.81184667, 0.79558653,\n",
       "        0.77700347, 0.81184667, 0.81997675, 0.81881535, 0.80487806,\n",
       "        0.81765389, 0.82229966, 0.82578397, 0.81533098, 0.786295  ,\n",
       "        0.81533098, 0.81881535, 0.79210222, 0.80720091, 0.81765389,\n",
       "        0.80255514, 0.82229966, 0.47619048, 0.8211382 , 0.82578397,\n",
       "        0.67711961, 0.81765389, 0.82346112, 0.61207896, 0.82578397,\n",
       "        0.81649244, 0.70034844, 0.82229966, 0.82810688, 0.76306617,\n",
       "        0.79094076, 0.82694542, 0.76887339, 0.80255514, 0.81416959,\n",
       "        0.81881535, 0.82462251, 0.81068528, 0.81184667, 0.82578397,\n",
       "        0.82810688, 0.81881535, 0.82346112, 0.81649244, 0.81881535,\n",
       "        0.8211382 , 0.83275259, 0.81881535, 0.83159119, 0.81881535,\n",
       "        0.81997675, 0.81300813, 0.81881535, 0.82346112, 0.78164923,\n",
       "        0.78513354, 0.8037166 , 0.81765389, 0.82229966, 0.82346112]),\n",
       " 'mean_test_score': array([0.80890087, 0.79071081, 0.67114266, 0.81392703, 0.81315229,\n",
       "        0.62091015, 0.81431508, 0.81702421, 0.65378348, 0.80928802,\n",
       "        0.81663797, 0.73230735, 0.81082988, 0.81508938, 0.78452992,\n",
       "        0.80116781, 0.8143124 , 0.78646119, 0.80271459, 0.79922895,\n",
       "        0.80851372, 0.80580684, 0.80464629, 0.80619355, 0.79611965,\n",
       "        0.79652882, 0.8143151 , 0.78105191, 0.80154284, 0.81083437,\n",
       "        0.77908699, 0.70596701, 0.80657303, 0.67425688, 0.76830031,\n",
       "        0.81238117, 0.78608078, 0.76404754, 0.81702288, 0.73813834,\n",
       "        0.74736116, 0.80232745, 0.75588693, 0.68083167, 0.81354304,\n",
       "        0.81393019, 0.81121926, 0.62784825, 0.81663708, 0.81895681,\n",
       "        0.67428249, 0.8166375 , 0.8147018 , 0.64719345, 0.81509028,\n",
       "        0.81508982, 0.79999244, 0.811994  , 0.81547608, 0.8058037 ,\n",
       "        0.8038729 , 0.8108321 , 0.810449  , 0.80465301, 0.81160414,\n",
       "        0.81470358, 0.70602898, 0.79343029, 0.81663481, 0.73193862,\n",
       "        0.79536734, 0.80967335, 0.78763296, 0.7655894 , 0.81238115,\n",
       "        0.6955832 , 0.79845734, 0.79690425, 0.67316374, 0.72997775,\n",
       "        0.81508803, 0.73773817, 0.78258703, 0.81508984, 0.62207337,\n",
       "        0.77872094, 0.80310176, 0.68275885, 0.64065911, 0.79614075,\n",
       "        0.81779581, 0.81663706, 0.64293979, 0.81625082, 0.81547519,\n",
       "        0.70756634, 0.81431552, 0.81508849, 0.72071675, 0.81121838,\n",
       "        0.81160865, 0.81121566, 0.81702693, 0.81199624, 0.81431329,\n",
       "        0.79768753, 0.81624993, 0.8143151 , 0.80270384, 0.79612863,\n",
       "        0.81470267, 0.80038184, 0.76323732, 0.81547697, 0.73185867,\n",
       "        0.7709623 , 0.81315364, 0.77757251, 0.79651489, 0.81547832,\n",
       "        0.70753713, 0.79536555, 0.80696424, 0.61971009, 0.74701758,\n",
       "        0.81238115, 0.77329101, 0.81432005, 0.81470134, 0.78452951,\n",
       "        0.79613266, 0.81315543, 0.75163998, 0.79381472, 0.80851326,\n",
       "        0.77794395, 0.78221021, 0.51686289, 0.8065753 , 0.81315724,\n",
       "        0.62280454, 0.81508938, 0.81663616, 0.58685201, 0.81508803,\n",
       "        0.81392974, 0.66612907, 0.81006277, 0.8112215 , 0.74159348,\n",
       "        0.80193985, 0.81393109, 0.74429407, 0.72380584, 0.80967112,\n",
       "        0.81392884, 0.75900835, 0.8050312 , 0.81044318, 0.7922585 ,\n",
       "        0.78685955, 0.81082809, 0.70635998, 0.7864778 , 0.81779718,\n",
       "        0.49911567, 0.79225314, 0.81238115, 0.66922893, 0.719558  ,\n",
       "        0.77680677, 0.71758721, 0.78608032, 0.80812299, 0.74082277,\n",
       "        0.79921951, 0.78647242, 0.63372641, 0.79381474, 0.80735316,\n",
       "        0.810449  , 0.80116242, 0.61007812, 0.81586188, 0.81431464,\n",
       "        0.6297795 , 0.81392841, 0.81392749, 0.63057399, 0.81277055,\n",
       "        0.81741047, 0.72535803, 0.81006096, 0.81315543, 0.78220751,\n",
       "        0.81160641, 0.81624947, 0.7887818 , 0.81509028, 0.81315454,\n",
       "        0.81624814, 0.80309727, 0.81354258, 0.81354078, 0.73922749,\n",
       "        0.80735767, 0.81547519, 0.73504029, 0.80541654, 0.80425016,\n",
       "        0.71872489, 0.74194245, 0.81006052, 0.6781279 , 0.74044011,\n",
       "        0.80542014, 0.73111314, 0.80038365, 0.81354304, 0.75668772,\n",
       "        0.78491169, 0.80232882, 0.68738935, 0.72690435, 0.81237801,\n",
       "        0.81160776, 0.81586275, 0.62321103, 0.81663481, 0.81508938,\n",
       "        0.69866467, 0.81624903, 0.8147018 , 0.64564578, 0.80734869,\n",
       "        0.81702286, 0.80503255, 0.8170224 , 0.81586188, 0.80386933,\n",
       "        0.81624812, 0.80928262, 0.80735139, 0.79922086, 0.80890626,\n",
       "        0.81470267, 0.80000414, 0.79884942, 0.81199535, 0.75707845,\n",
       "        0.79071261, 0.81276784, 0.79689439, 0.80889863, 0.81431552,\n",
       "        0.79496896, 0.79535478, 0.81122239, 0.67623711, 0.61157058,\n",
       "        0.80580729, 0.76634618, 0.80231714, 0.78956419, 0.7214102 ,\n",
       "        0.68507814, 0.80464675, 0.68276201, 0.62739148, 0.80850653,\n",
       "        0.72572766, 0.71063431, 0.50137612, 0.784525  , 0.78491124,\n",
       "        0.56985438, 0.79845599, 0.80193357, 0.64138222, 0.81392839,\n",
       "        0.81238115, 0.63595814, 0.81276919, 0.81354258, 0.67738867,\n",
       "        0.81470267, 0.81508803, 0.67006207, 0.78916852, 0.81740956,\n",
       "        0.79612817, 0.74619253, 0.8081221 , 0.79729277, 0.79226434,\n",
       "        0.80967561, 0.81121926, 0.7682671 , 0.81083842, 0.80541432,\n",
       "        0.68353585, 0.79960799, 0.81470134, 0.7350021 , 0.80425781,\n",
       "        0.80657397, 0.79536466, 0.78995001, 0.80850653, 0.77677757,\n",
       "        0.80850653, 0.80464854, 0.71839792, 0.79806568, 0.81276965,\n",
       "        0.77021718, 0.72109222, 0.59072258, 0.81741182, 0.81354485,\n",
       "        0.57448667, 0.81741136, 0.81354169, 0.59147845, 0.82050629,\n",
       "        0.8127683 , 0.65879977, 0.81315635, 0.81624947, 0.71799326,\n",
       "        0.81586144, 0.81392749, 0.73269629, 0.80774438, 0.81122194,\n",
       "        0.81121745, 0.79458678, 0.80076989, 0.81315543, 0.78918378,\n",
       "        0.79073058, 0.81121747, 0.78995359, 0.81741182, 0.81586502,\n",
       "        0.77100225, 0.81238204, 0.81740957, 0.73309108, 0.79921637,\n",
       "        0.81586458, 0.77292631, 0.81044722, 0.81895727, 0.73696164,\n",
       "        0.79458227, 0.81663529, 0.7694483 , 0.81083977, 0.81586144,\n",
       "        0.81044541, 0.8058028 , 0.68549806, 0.81702513, 0.81276693,\n",
       "        0.66961563, 0.81508936, 0.81586097, 0.65839601, 0.80773358,\n",
       "        0.81470267, 0.73346476, 0.81508893, 0.81702242, 0.77948672,\n",
       "        0.81470132, 0.811994  , 0.76247561, 0.80542147, 0.81392884,\n",
       "        0.81315319, 0.78684608, 0.81818521, 0.81315454, 0.81006142,\n",
       "        0.81315815, 0.81470042, 0.77990125, 0.81547968, 0.81238204,\n",
       "        0.75781051, 0.80385898, 0.81624768, 0.76402734, 0.78376146,\n",
       "        0.81470221, 0.74192582, 0.79536285, 0.81276784, 0.75551506,\n",
       "        0.80464989, 0.81586232, 0.7071922 , 0.79381875, 0.81315589,\n",
       "        0.76438888, 0.7926452 , 0.61391904, 0.8092889 , 0.81354258,\n",
       "        0.62552806, 0.81277011, 0.81469999, 0.64563813, 0.81431691,\n",
       "        0.81470448, 0.69012721, 0.79653329, 0.80850969, 0.77639987,\n",
       "        0.81353899, 0.81779671, 0.77796012, 0.80851056, 0.80889952,\n",
       "        0.8150903 , 0.81818744, 0.80425825, 0.80735318, 0.80347991,\n",
       "        0.80696964, 0.81663573, 0.80425332, 0.72729689, 0.81702421,\n",
       "        0.80155541, 0.81470402, 0.81392435, 0.76597969, 0.80619085,\n",
       "        0.80735632, 0.73349392, 0.68322549, 0.79420233, 0.75320025,\n",
       "        0.66845105, 0.80812569, 0.76246347, 0.79961789, 0.80426409,\n",
       "        0.81393242, 0.81083302, 0.60733352, 0.81663795, 0.81624901,\n",
       "        0.66577021, 0.81586367, 0.81431552, 0.72573034, 0.81547654,\n",
       "        0.81586369, 0.77097442, 0.81547922, 0.81895816, 0.79497168,\n",
       "        0.81509028, 0.80850788, 0.78491215, 0.79844117, 0.80967381,\n",
       "        0.81354215, 0.77448211, 0.80154192, 0.81121792, 0.79381382,\n",
       "        0.80734734, 0.81083524, 0.74038174, 0.72728926, 0.81315186,\n",
       "        0.79070407, 0.80851372, 0.80347496, 0.78801606, 0.8003962 ,\n",
       "        0.81005782, 0.80542465, 0.80000639, 0.79921905, 0.7539777 ,\n",
       "        0.75012463, 0.80464629, 0.76249357, 0.81779895, 0.80851326,\n",
       "        0.81547473, 0.81547697, 0.625917  , 0.8193444 , 0.81895681,\n",
       "        0.65805242, 0.81779716, 0.81702377, 0.66925319, 0.80231579,\n",
       "        0.81354032, 0.80658295, 0.81895769, 0.81044318, 0.81121657,\n",
       "        0.81354483, 0.81779716, 0.80928532, 0.81199535, 0.81431419,\n",
       "        0.8092853 , 0.80658203, 0.81083524, 0.81276606, 0.79689393,\n",
       "        0.80579875, 0.81431508, 0.57724612, 0.78568778, 0.78993652,\n",
       "        0.78722741, 0.80309635, 0.8065744 , 0.78453624, 0.8058037 ,\n",
       "        0.81663752, 0.6552225 , 0.74625361, 0.81199578, 0.79497751,\n",
       "        0.78299483, 0.80309681, 0.79111503, 0.79072203, 0.80929073,\n",
       "        0.696353  , 0.77484679, 0.64834187, 0.79651936, 0.80657935,\n",
       "        0.60927552, 0.81161135, 0.81741047, 0.63828639, 0.81779716,\n",
       "        0.81392884, 0.69790113, 0.79613447, 0.81354034, 0.66884716,\n",
       "        0.81779671, 0.80928262, 0.68473277, 0.7528167 , 0.80851686,\n",
       "        0.81624858, 0.81044765, 0.81547922, 0.80889728, 0.78607539,\n",
       "        0.79459574, 0.81586548, 0.79150174, 0.80812343, 0.81160643,\n",
       "        0.81005828, 0.79767225, 0.79266045, 0.81702513, 0.79962146,\n",
       "        0.78492516, 0.78219493, 0.77175365, 0.81547519, 0.62668906,\n",
       "        0.80116198, 0.81121926, 0.78065981, 0.80619667, 0.80155406,\n",
       "        0.79806749, 0.80890628, 0.64445827, 0.81509209, 0.8135408 ,\n",
       "        0.65107481, 0.81276651, 0.81586097, 0.67582345, 0.81547608,\n",
       "        0.8143124 , 0.6839176 , 0.81586411, 0.81857459, 0.7326837 ,\n",
       "        0.81316129, 0.81431778, 0.74507465, 0.78839151, 0.80425378,\n",
       "        0.80695975, 0.77757164, 0.80967426, 0.81392795, 0.80194344,\n",
       "        0.80850879, 0.81354078, 0.75972559, 0.78376104, 0.79186418,\n",
       "        0.75702635, 0.72104194, 0.81238204, 0.77405137, 0.81199491,\n",
       "        0.81392884, 0.73149983, 0.80812703, 0.80425107, 0.70137827,\n",
       "        0.79960306, 0.81083075, 0.81315543, 0.73657854, 0.80696646,\n",
       "        0.81199626, 0.81354213, 0.64717281, 0.81818702, 0.81547562,\n",
       "        0.64448027, 0.81779627, 0.81354258, 0.62978218, 0.81779852,\n",
       "        0.81470221, 0.74738451, 0.81586367, 0.81392793, 0.78801292,\n",
       "        0.80154103, 0.81315096, 0.79690739, 0.78105865, 0.80657844,\n",
       "        0.80928846, 0.79691414, 0.81779806, 0.81508984, 0.80541968,\n",
       "        0.8073496 , 0.81431643, 0.77641467, 0.81044632, 0.81586142,\n",
       "        0.78762172, 0.79535433, 0.81663976, 0.80038544, 0.8096684 ,\n",
       "        0.80966663, 0.74893848, 0.80541118, 0.81586502, 0.7126163 ,\n",
       "        0.77099595, 0.81470448, 0.79263441, 0.80812881, 0.81509209,\n",
       "        0.69400678, 0.70601865, 0.41662647, 0.77911572, 0.76094272,\n",
       "        0.60658797, 0.80232612, 0.794589  , 0.60149441, 0.81237936,\n",
       "        0.81663795, 0.6383277 , 0.8042623 , 0.8170224 , 0.6607584 ,\n",
       "        0.81199626, 0.81315633, 0.60773953, 0.76943616, 0.81431599,\n",
       "        0.79265237, 0.80310176, 0.81508982, 0.79187584, 0.80386706,\n",
       "        0.80426139, 0.79574194, 0.80194076, 0.80966934, 0.8123789 ,\n",
       "        0.79111683, 0.81547787, 0.80928264, 0.79187946, 0.80928578,\n",
       "        0.81083345, 0.74774607, 0.8181843 , 0.80695973, 0.77405183,\n",
       "        0.81238383, 0.81315364, 0.76056457, 0.81005649, 0.79575046,\n",
       "        0.74315059, 0.78182979, 0.56629728, 0.80619488, 0.81122285,\n",
       "        0.60698724, 0.81276695, 0.81470358, 0.64220053, 0.81663662,\n",
       "        0.81547606, 0.66691953, 0.80542058, 0.81663708, 0.70719222,\n",
       "        0.80734915, 0.81857236, 0.67196995, 0.77717865, 0.80774438,\n",
       "        0.80347723, 0.77756804, 0.79767452, 0.81431419, 0.80618725,\n",
       "        0.81702513, 0.81082942, 0.80154914, 0.81508579, 0.80773224,\n",
       "        0.78026952, 0.81353899, 0.81431554, 0.813155  , 0.80696245,\n",
       "        0.81508803, 0.81392974, 0.81393109, 0.81315364, 0.78607359,\n",
       "        0.81122015, 0.813155  , 0.77640841, 0.8154707 , 0.80735407,\n",
       "        0.79961427, 0.81238294, 0.58061724, 0.81663616, 0.81702465,\n",
       "        0.63135233, 0.81315454, 0.81547697, 0.66883683, 0.81586458,\n",
       "        0.8150876 , 0.74041005, 0.81934351, 0.81818567, 0.7539687 ,\n",
       "        0.80579696, 0.81702513, 0.75590444, 0.80309457, 0.80812615,\n",
       "        0.81199491, 0.81277053, 0.8100583 , 0.81276558, 0.81315768,\n",
       "        0.81586548, 0.81586188, 0.80271598, 0.81276739, 0.81624858,\n",
       "        0.80464854, 0.81857413, 0.81392839, 0.80619937, 0.8116082 ,\n",
       "        0.81508893, 0.76829582, 0.81354169, 0.81547697, 0.79341904,\n",
       "        0.80308781, 0.8077354 , 0.81470134, 0.81392974, 0.81470358]),\n",
       " 'std_test_score': array([0.01092159, 0.0129777 , 0.06932486, 0.00952401, 0.00904576,\n",
       "        0.03835289, 0.00909946, 0.01088983, 0.04148365, 0.01445342,\n",
       "        0.0147539 , 0.01908924, 0.00744559, 0.00711291, 0.00724885,\n",
       "        0.01605806, 0.00777569, 0.00588431, 0.014123  , 0.00979113,\n",
       "        0.01397663, 0.00755586, 0.00945415, 0.00800152, 0.0243072 ,\n",
       "        0.01941725, 0.01089443, 0.02728918, 0.012606  , 0.01062891,\n",
       "        0.04329163, 0.06035652, 0.01049778, 0.04075212, 0.07572842,\n",
       "        0.00531565, 0.03009032, 0.08102368, 0.00856103, 0.09607158,\n",
       "        0.05537132, 0.0136526 , 0.02715718, 0.03547846, 0.01420761,\n",
       "        0.01362383, 0.00908697, 0.02926189, 0.01063038, 0.00839111,\n",
       "        0.04451865, 0.0098338 , 0.01127461, 0.00666244, 0.0082058 ,\n",
       "        0.00799363, 0.01530292, 0.00999193, 0.00984903, 0.00641719,\n",
       "        0.01109348, 0.00714022, 0.00891962, 0.02712853, 0.00791682,\n",
       "        0.00942419, 0.0996781 , 0.01700166, 0.00432293, 0.0969126 ,\n",
       "        0.01750429, 0.01339853, 0.02289275, 0.03834989, 0.00760686,\n",
       "        0.1362818 , 0.00885155, 0.00417475, 0.17823539, 0.00536803,\n",
       "        0.00733209, 0.09840704, 0.02265014, 0.00728912, 0.08060724,\n",
       "        0.0072488 , 0.01560866, 0.04944593, 0.07822069, 0.03719086,\n",
       "        0.00866326, 0.00898361, 0.00806495, 0.01452224, 0.00930332,\n",
       "        0.0481973 , 0.00984875, 0.00892295, 0.03769864, 0.00427909,\n",
       "        0.01037721, 0.01044468, 0.01533809, 0.01232874, 0.00852553,\n",
       "        0.02059751, 0.01126331, 0.00651349, 0.01733385, 0.00813097,\n",
       "        0.00924832, 0.01008471, 0.0225402 , 0.00983344, 0.10355734,\n",
       "        0.04438784, 0.00588811, 0.02841743, 0.01346167, 0.00990186,\n",
       "        0.0487732 , 0.01873333, 0.00463079, 0.03534746, 0.05491848,\n",
       "        0.01017947, 0.03229197, 0.0146277 , 0.00877685, 0.00872067,\n",
       "        0.00352013, 0.01062948, 0.00765737, 0.02629192, 0.01411005,\n",
       "        0.01056273, 0.01079831, 0.06665324, 0.01014905, 0.01176436,\n",
       "        0.06903244, 0.01039304, 0.00999277, 0.01711928, 0.00825322,\n",
       "        0.00961505, 0.04020069, 0.01504989, 0.0117216 , 0.01962727,\n",
       "        0.0127793 , 0.01039965, 0.03362628, 0.07025452, 0.00947268,\n",
       "        0.01214441, 0.02682255, 0.00734108, 0.0068995 , 0.01191423,\n",
       "        0.03520433, 0.01082485, 0.06438986, 0.03198775, 0.00815525,\n",
       "        0.15168522, 0.01817448, 0.00760686, 0.08390654, 0.05273236,\n",
       "        0.03266651, 0.03201634, 0.01566015, 0.0027889 , 0.06534339,\n",
       "        0.0159146 , 0.02209436, 0.17559328, 0.01056724, 0.00566102,\n",
       "        0.01365019, 0.00478371, 0.03675658, 0.01248959, 0.01207329,\n",
       "        0.03823832, 0.0123341 , 0.00917949, 0.02644612, 0.01098648,\n",
       "        0.01039357, 0.0459233 , 0.00569344, 0.00675985, 0.01007572,\n",
       "        0.00551595, 0.00963967, 0.01186113, 0.00961545, 0.00735428,\n",
       "        0.00670458, 0.0047612 , 0.00781962, 0.00695122, 0.07001164,\n",
       "        0.01449167, 0.00930332, 0.09921632, 0.00814959, 0.01335256,\n",
       "        0.0765168 , 0.05784327, 0.00843522, 0.0883223 , 0.06536519,\n",
       "        0.00784361, 0.0548701 , 0.00783783, 0.01092301, 0.03762268,\n",
       "        0.01626702, 0.01462096, 0.07799528, 0.09523148, 0.01014844,\n",
       "        0.00711179, 0.0084461 , 0.01989436, 0.0099718 , 0.01039304,\n",
       "        0.05200016, 0.00802305, 0.01036235, 0.03904372, 0.00755408,\n",
       "        0.0121925 , 0.00925776, 0.01062669, 0.01062657, 0.00497846,\n",
       "        0.00576953, 0.0086327 , 0.00571821, 0.01813593, 0.01637968,\n",
       "        0.0084366 , 0.00806959, 0.01852341, 0.00983233, 0.06531148,\n",
       "        0.01884445, 0.0062512 , 0.02017284, 0.00695046, 0.00899156,\n",
       "        0.00436736, 0.00796816, 0.01500048, 0.05334086, 0.07560754,\n",
       "        0.01773235, 0.01507702, 0.01593878, 0.0383421 , 0.10938831,\n",
       "        0.06134756, 0.01098309, 0.06619568, 0.15011738, 0.0109988 ,\n",
       "        0.01301947, 0.00820091, 0.10782615, 0.00472266, 0.01686874,\n",
       "        0.07263128, 0.01252569, 0.00767259, 0.04115652, 0.00876154,\n",
       "        0.00844526, 0.04564767, 0.01037757, 0.00928806, 0.03583527,\n",
       "        0.00924832, 0.00917961, 0.07953996, 0.00194302, 0.00983222,\n",
       "        0.01634886, 0.06560308, 0.01132962, 0.00134352, 0.02521078,\n",
       "        0.02235944, 0.00815006, 0.0238121 , 0.01574857, 0.00721428,\n",
       "        0.0810666 , 0.01626256, 0.0060546 , 0.05390046, 0.00765267,\n",
       "        0.00587059, 0.01820711, 0.02041686, 0.0109988 , 0.02749939,\n",
       "        0.01170996, 0.0121221 , 0.04250913, 0.01989175, 0.01124204,\n",
       "        0.02412755, 0.02409643, 0.01498429, 0.01281019, 0.01243427,\n",
       "        0.04114275, 0.01198386, 0.00760718, 0.02048136, 0.00942625,\n",
       "        0.00953715, 0.0483424 , 0.01226222, 0.00876206, 0.01964318,\n",
       "        0.00815045, 0.01010975, 0.01599263, 0.01510971, 0.01336085,\n",
       "        0.00830055, 0.00978986, 0.00734258, 0.00898257, 0.0543837 ,\n",
       "        0.03488842, 0.01014857, 0.02175144, 0.01445549, 0.01123437,\n",
       "        0.03139684, 0.00716032, 0.00802326, 0.03131663, 0.02143296,\n",
       "        0.01256024, 0.02581315, 0.00870022, 0.00910034, 0.03731262,\n",
       "        0.00508818, 0.0077329 , 0.01749332, 0.01515474, 0.00815045,\n",
       "        0.0076422 , 0.00900008, 0.04307167, 0.0125606 , 0.00917934,\n",
       "        0.0809317 , 0.00953772, 0.00948265, 0.0430515 , 0.0090269 ,\n",
       "        0.00765606, 0.02736903, 0.01052915, 0.00695179, 0.02190315,\n",
       "        0.00786004, 0.00999193, 0.00806141, 0.0146455 , 0.01214441,\n",
       "        0.00808331, 0.00559198, 0.00751925, 0.00909923, 0.01171466,\n",
       "        0.01179016, 0.00853658, 0.05773768, 0.01328817, 0.00928769,\n",
       "        0.04523734, 0.01999604, 0.00805316, 0.01443518, 0.01711351,\n",
       "        0.00930507, 0.08606676, 0.01319905, 0.00789967, 0.01006913,\n",
       "        0.01489574, 0.00767672, 0.11408066, 0.0169944 , 0.0098327 ,\n",
       "        0.03997047, 0.01783723, 0.02772936, 0.01098504, 0.00928806,\n",
       "        0.01976898, 0.01070375, 0.0099528 , 0.05110215, 0.01307695,\n",
       "        0.01341764, 0.04427642, 0.0274012 , 0.00685669, 0.01671976,\n",
       "        0.01237175, 0.00999297, 0.02375205, 0.01136702, 0.01106568,\n",
       "        0.01198323, 0.01336958, 0.01007303, 0.01931287, 0.01042293,\n",
       "        0.01277204, 0.00839074, 0.00393037, 0.09350408, 0.00853406,\n",
       "        0.01696572, 0.00965151, 0.01025615, 0.05654446, 0.00487061,\n",
       "        0.01200157, 0.09838379, 0.200128  , 0.00924006, 0.03138606,\n",
       "        0.09040913, 0.01508224, 0.02274734, 0.02789595, 0.01717931,\n",
       "        0.01503851, 0.00571901, 0.03068392, 0.01070041, 0.01166817,\n",
       "        0.01475276, 0.0085337 , 0.00899156, 0.03075733, 0.01234811,\n",
       "        0.01172275, 0.02273887, 0.00993267, 0.00820117, 0.00444366,\n",
       "        0.00888813, 0.00909543, 0.01005613, 0.02426428, 0.00675848,\n",
       "        0.01268428, 0.03754847, 0.01511286, 0.01237188, 0.00619916,\n",
       "        0.00989878, 0.00706105, 0.08013695, 0.08290409, 0.00963137,\n",
       "        0.02873805, 0.0131156 , 0.01383976, 0.03907508, 0.03197211,\n",
       "        0.01373977, 0.02375526, 0.01241223, 0.01441284, 0.05950143,\n",
       "        0.08940628, 0.00761436, 0.05701196, 0.01017815, 0.0132238 ,\n",
       "        0.01053266, 0.01062291, 0.00324956, 0.00930608, 0.00930378,\n",
       "        0.04970558, 0.0065712 , 0.00691811, 0.01384813, 0.01201183,\n",
       "        0.00815025, 0.01208408, 0.01072207, 0.01042179, 0.00716295,\n",
       "        0.01373701, 0.00984955, 0.00825249, 0.00835216, 0.00680701,\n",
       "        0.00463128, 0.02239668, 0.013076  , 0.00615924, 0.02333346,\n",
       "        0.01117223, 0.00909946, 0.14446949, 0.0284918 , 0.01014474,\n",
       "        0.01432528, 0.01036054, 0.01330175, 0.02785922, 0.00641719,\n",
       "        0.00768249, 0.17679898, 0.10376913, 0.01390756, 0.02080819,\n",
       "        0.03355183, 0.00417754, 0.04425687, 0.01801153, 0.01595837,\n",
       "        0.07110316, 0.01594729, 0.04693315, 0.0018653 , 0.01088701,\n",
       "        0.02632473, 0.01224199, 0.01039357, 0.03094499, 0.01160587,\n",
       "        0.01126282, 0.05357992, 0.01877864, 0.00628571, 0.03009762,\n",
       "        0.01271875, 0.00952224, 0.02429782, 0.05699967, 0.01138842,\n",
       "        0.01197845, 0.01289007, 0.0123487 , 0.00900645, 0.00477773,\n",
       "        0.0272305 , 0.01354577, 0.03448501, 0.00291553, 0.00463178,\n",
       "        0.01042874, 0.0130416 , 0.03714815, 0.01178675, 0.0156793 ,\n",
       "        0.02424804, 0.01893951, 0.01816738, 0.0083906 , 0.1583068 ,\n",
       "        0.00323935, 0.00815006, 0.02168155, 0.01333532, 0.02538622,\n",
       "        0.00909636, 0.01610346, 0.06537998, 0.01254457, 0.01155657,\n",
       "        0.05056248, 0.00952395, 0.00948265, 0.06446124, 0.01339948,\n",
       "        0.00870137, 0.07469635, 0.01092373, 0.01379577, 0.04632964,\n",
       "        0.01567558, 0.00938974, 0.01314679, 0.01019355, 0.00299723,\n",
       "        0.01345896, 0.01636287, 0.0083513 , 0.00983171, 0.01727833,\n",
       "        0.01095651, 0.00785987, 0.07787846, 0.04015995, 0.02619401,\n",
       "        0.06375233, 0.07632981, 0.00607573, 0.05504001, 0.00979454,\n",
       "        0.01214441, 0.05263438, 0.01116742, 0.01299706, 0.07554894,\n",
       "        0.01916574, 0.00685637, 0.00898257, 0.09730976, 0.00591461,\n",
       "        0.01017586, 0.00765568, 0.05473878, 0.01081556, 0.00651379,\n",
       "        0.04958397, 0.00839093, 0.01172215, 0.03487061, 0.01226358,\n",
       "        0.00930507, 0.0130157 , 0.01007643, 0.00802265, 0.01515628,\n",
       "        0.01336287, 0.00829981, 0.00402155, 0.03413342, 0.00417924,\n",
       "        0.01778803, 0.01885903, 0.00907497, 0.01202692, 0.00845857,\n",
       "        0.00904606, 0.00907381, 0.03041484, 0.00802202, 0.01002617,\n",
       "        0.00866036, 0.00656159, 0.01234921, 0.01583922, 0.00909509,\n",
       "        0.01124891, 0.04755007, 0.01004597, 0.01057619, 0.09088955,\n",
       "        0.04082897, 0.01419743, 0.0291773 , 0.01133955, 0.01537275,\n",
       "        0.01695411, 0.0609793 , 0.01906046, 0.02100587, 0.02629338,\n",
       "        0.02214518, 0.01191573, 0.00951425, 0.10076762, 0.01137523,\n",
       "        0.01070041, 0.05534821, 0.01416263, 0.01342449, 0.05161889,\n",
       "        0.00730098, 0.01307664, 0.00604556, 0.02288767, 0.01322496,\n",
       "        0.01180061, 0.01677238, 0.01034234, 0.00572162, 0.01119204,\n",
       "        0.01429894, 0.00538188, 0.01365061, 0.01005979, 0.00995285,\n",
       "        0.02890953, 0.01232984, 0.00606965, 0.00598182, 0.00892199,\n",
       "        0.00331829, 0.05681654, 0.01008458, 0.00956151, 0.05458682,\n",
       "        0.01505061, 0.00498002, 0.0691601 , 0.01079956, 0.01138828,\n",
       "        0.03789086, 0.02197285, 0.08975229, 0.01645671, 0.01499547,\n",
       "        0.04757422, 0.01010963, 0.00942419, 0.06248575, 0.01072159,\n",
       "        0.00899185, 0.06459713, 0.01996798, 0.00820041, 0.06914908,\n",
       "        0.00333585, 0.00913019, 0.03168399, 0.02509162, 0.01370871,\n",
       "        0.00838468, 0.01908363, 0.01013181, 0.00866295, 0.01167846,\n",
       "        0.01500197, 0.01167756, 0.0065101 , 0.01439161, 0.01177213,\n",
       "        0.01439465, 0.01048783, 0.01249855, 0.01339913, 0.00818509,\n",
       "        0.00917961, 0.01116909, 0.01608987, 0.00959644, 0.00237321,\n",
       "        0.00945635, 0.00899128, 0.02487232, 0.00723624, 0.0216282 ,\n",
       "        0.00432201, 0.01335548, 0.08153393, 0.00999277, 0.01015806,\n",
       "        0.03593866, 0.00821849, 0.00983344, 0.0412365 , 0.01335647,\n",
       "        0.00764253, 0.03235323, 0.00786072, 0.01256096, 0.01067972,\n",
       "        0.01414477, 0.01178675, 0.01078871, 0.00239856, 0.0086996 ,\n",
       "        0.00898224, 0.0094023 , 0.0038147 , 0.0076055 , 0.01336522,\n",
       "        0.01354577, 0.008777  , 0.02948299, 0.00892255, 0.00917974,\n",
       "        0.01241463, 0.01347172, 0.00876154, 0.01797969, 0.01202612,\n",
       "        0.00706062, 0.05615867, 0.00679746, 0.01062291, 0.00837624,\n",
       "        0.01432275, 0.01171638, 0.01155669, 0.00820533, 0.00942419]),\n",
       " 'rank_test_score': array([345, 552, 743, 195, 236, 788, 169,  41, 759, 336,  50, 686, 306,\n",
       "        125, 582, 468, 175, 571, 451, 484, 350, 404, 425, 400, 513, 505,\n",
       "        167, 594, 465, 301, 600, 717, 396, 740, 627, 258, 572, 634,  44,\n",
       "        675, 660, 454, 649, 734, 199, 180, 288, 780,  55,   7, 739,  54,\n",
       "        150, 762, 118, 123, 478, 274, 106, 405, 436, 304, 309, 420, 282,\n",
       "        141, 715, 534,  63, 687, 516, 328, 564, 632, 259, 722, 490, 501,\n",
       "        741, 691, 132, 676, 588, 121, 787, 601, 443, 733, 771, 508,  27,\n",
       "         57, 768,  65, 110, 710, 164, 131, 702, 291, 277, 296,  35, 268,\n",
       "        174, 495,  66, 167, 452, 511, 144, 475, 636, 101, 688, 623, 232,\n",
       "        604, 507,  99, 711, 517, 385, 789, 661, 259, 617, 158, 152, 583,\n",
       "        510, 223, 655, 532, 352, 603, 589, 807, 393, 219, 786, 125,  59,\n",
       "        801, 132, 181, 752, 317, 286, 669, 460, 178, 665, 698, 329, 184,\n",
       "        643, 419, 315, 541, 567, 308, 714, 569,  20, 809, 542, 259, 747,\n",
       "        703, 608, 707, 573, 366, 670, 486, 570, 775, 531, 377, 309, 469,\n",
       "        792,  88, 171, 779, 188, 193, 777, 239,  31, 697, 319, 223, 590,\n",
       "        281,  67, 560, 118, 229,  73, 445, 201, 210, 674, 373, 110, 679,\n",
       "        415, 435, 704, 667, 320, 735, 671, 413, 690, 474, 199, 647, 579,\n",
       "        453, 725, 694, 265, 279,  86, 785,  63, 125, 719,  69, 150, 764,\n",
       "        381,  45, 418,  47,  88, 437,  74, 341, 378, 485, 344, 144, 477,\n",
       "        489, 270, 645, 551, 245, 502, 347, 164, 524, 520, 284, 737, 791,\n",
       "        403, 630, 456, 557, 699, 727, 424, 732, 781, 358, 696, 709, 808,\n",
       "        584, 580, 805, 491, 461, 770, 189, 259, 774, 243, 201, 736, 144,\n",
       "        132, 744, 559,  34, 512, 663, 367, 498, 540, 325, 288, 629, 298,\n",
       "        416, 730, 482, 152, 680, 431, 395, 518, 555, 358, 609, 358, 422,\n",
       "        705, 494, 242, 624, 700, 800,  28, 197, 804,  30, 207, 799,   1,\n",
       "        244, 755, 220,  67, 706,  91, 193, 684, 368, 285, 294, 527, 471,\n",
       "        223, 558, 549, 293, 554,  28,  78, 620, 255,  33, 683, 488,  80,\n",
       "        618, 312,   6, 677, 528,  62, 625, 297,  91, 314, 407, 726,  36,\n",
       "        249, 745, 128,  94, 756, 371, 144, 682, 129,  46, 598, 155, 274,\n",
       "        638, 411, 184, 235, 568,  15, 229, 318, 217, 156, 597,  96, 255,\n",
       "        644, 439,  75, 635, 585, 148, 668, 519, 245, 650, 421,  87, 713,\n",
       "        530, 222, 633, 538, 790, 334, 201, 784, 241, 157, 765, 160, 138,\n",
       "        724, 504, 355, 612, 214,  24, 602, 354, 346, 117,  12, 430, 376,\n",
       "        440, 383,  61, 433, 692,  41, 462, 140, 196, 631, 401, 374, 681,\n",
       "        731, 529, 653, 750, 364, 639, 480, 427, 177, 303, 795,  51,  70,\n",
       "        753,  84, 164, 695, 105,  83, 622,  97,   4, 523, 118, 357, 578,\n",
       "        492, 327, 205, 614, 466, 292, 533, 382, 299, 673, 693, 237, 553,\n",
       "        350, 442, 562, 472, 323, 410, 476, 487, 651, 656, 425, 637,  17,\n",
       "        352, 113, 101, 783,   2,   7, 757,  21,  43, 746, 457, 213, 389,\n",
       "          5, 315, 295, 198,  21, 338, 270, 172, 339, 390, 299, 251, 503,\n",
       "        408, 169, 803, 576, 556, 566, 447, 394, 581, 405,  53, 758, 662,\n",
       "        269, 522, 587, 446, 548, 550, 333, 721, 613, 761, 506, 391, 793,\n",
       "        276,  31, 773,  21, 184, 720, 509, 212, 748,  24, 341, 728, 654,\n",
       "        349,  71, 311,  97, 348, 574, 525,  76, 546, 365, 280, 322, 497,\n",
       "        536,  36, 479, 577, 591, 619, 110, 782, 470, 288, 595, 398, 463,\n",
       "        493, 343, 767, 115, 209, 760, 250,  94, 738, 106, 175, 729,  82,\n",
       "          9, 685, 216, 159, 664, 561, 432, 387, 605, 326, 191, 458, 356,\n",
       "        210, 642, 586, 545, 646, 701, 255, 616, 272, 184, 689, 362, 434,\n",
       "        718, 483, 305, 223, 678, 384, 266, 206, 763,  13, 109, 766,  26,\n",
       "        201, 778,  18, 148, 659,  84, 192, 563, 467, 238, 500, 593, 392,\n",
       "        335, 499,  19, 121, 414, 379, 161, 610, 313,  93, 565, 521,  49,\n",
       "        473, 331, 332, 657, 417,  78, 708, 621, 138, 539, 361, 115, 723,\n",
       "        716, 810, 599, 640, 797, 455, 526, 798, 263,  51, 772, 428,  47,\n",
       "        754, 266, 221, 794, 626, 162, 537, 443, 123, 544, 438, 429, 515,\n",
       "        459, 330, 264, 547, 100, 340, 543, 337, 302, 658,  16, 388, 615,\n",
       "        253, 232, 641, 324, 514, 666, 592, 806, 399, 283, 796, 248, 141,\n",
       "        769,  58, 108, 751, 412,  55, 712, 380,  11, 742, 607, 368, 441,\n",
       "        606, 496, 172, 402,  36, 307, 464, 137, 372, 596, 214, 163, 227,\n",
       "        386, 132, 181, 178, 232, 575, 287, 227, 611, 114, 375, 481, 254,\n",
       "        802,  59,  40, 776, 229, 101, 749,  80, 136, 672,   3,  14, 652,\n",
       "        409,  36, 648, 448, 363, 272, 240, 321, 252, 218,  76,  88, 450,\n",
       "        247,  71, 422,  10, 189, 397, 278, 129, 628, 207, 101, 535, 449,\n",
       "        370, 152, 181, 141])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details in the traininf results\n",
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 80.02163721601154 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1385\n",
      "           1       0.81      0.79      0.80      1388\n",
      "\n",
      "    accuracy                           0.80      2773\n",
      "   macro avg       0.80      0.80      0.80      2773\n",
      "weighted avg       0.80      0.80      0.80      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test data with the best hyperparameters\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print('Accuracy on test data:',accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))#,labels=labels_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#,display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('model/NN_biclass-gridsearch-imbalanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, with the optimised hyperparmaters, the model predicted roughly the same amount of entries as dissimilar and similar, even on imbalanced data. Showing that the tendency to predict entries as 1 as we've seen in with the randomly selected hyperparamters might not be reproducible with other hyperparmeter combinations. With that in mind, we are still repeating the same process with balanced data to see if there's any noticable difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with Balanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check training data label balance:\n",
      "overall\n",
      "0    1026\n",
      "1    1026\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Balanced data\n",
    "balancing = train_df.groupby('overall')\n",
    "balance_train_df = balancing.apply(lambda x: x.sample(balancing.size().min()))\n",
    "balance_train_df = balance_train_df.reset_index(drop=True)\n",
    "print('Check training data label balance:')\n",
    "print(balance_train_df.groupby('overall').size(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced training data\n",
    "target_column = ['overall']\n",
    "predictors = list(set(list(balance_train_df.drop(['pair_id'], axis=1).columns))-set(target_column))\n",
    "\n",
    "X_train = balance_train_df[predictors].values\n",
    "y_train = balance_train_df[target_column].values\n",
    "#X_test = balance_train_df[predictors].values\n",
    "#y_test = balance_train_df[target_column].values\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2052, 5)\n",
      "(2773, 5)\n",
      "(2052, 1)\n",
      "(2773, 1)\n"
     ]
    }
   ],
   "source": [
    "# Imbalanced training data shape : 2585\n",
    "# Balanced training data shape : 2052\n",
    "\n",
    "print(X_train.shape); print(X_test.shape)\n",
    "print(y_train.shape); print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rinrada\\AppData\\Local\\Temp/ipykernel_3908/1808950710.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch_size, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# Initialize model with random hyperparameter\n",
    "hidden_size = 8\n",
    "epoch = 100\n",
    "input_size = X_train.shape[1]\n",
    "learning_rate = 0.01\n",
    "batch_size = 5\n",
    "kfold = 5\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_size, input_dim=input_size, activation='relu'))\n",
    "    #model.add(Dense(hidden_size, input_dim=input_size, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Create a KerasClassfier\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "# Number of folds\n",
    "kfold = KFold(n_splits=kfold, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation in Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time(s) used: 193.39749598503113\n",
      "Baseline: 81.77% (1.77%)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results_binn = cross_val_score(estimator, X_train, y_train, cv=kfold)\n",
    "\n",
    "print('Time(s) used:',time.time() - start)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results_binn.mean()*100, results_binn.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.5160 - accuracy: 0.7485\n",
      "Epoch 2/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.4125 - accuracy: 0.8163\n",
      "Epoch 3/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.4068 - accuracy: 0.8212\n",
      "Epoch 4/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.4051 - accuracy: 0.8192\n",
      "Epoch 5/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.8192\n",
      "Epoch 6/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.4044 - accuracy: 0.8207\n",
      "Epoch 7/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.8138\n",
      "Epoch 8/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8221\n",
      "Epoch 9/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.8197\n",
      "Epoch 10/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8207\n",
      "Epoch 11/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.4016 - accuracy: 0.8143\n",
      "Epoch 12/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8246\n",
      "Epoch 13/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3954 - accuracy: 0.8216\n",
      "Epoch 14/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3986 - accuracy: 0.8231\n",
      "Epoch 15/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8138\n",
      "Epoch 16/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3926 - accuracy: 0.8216\n",
      "Epoch 17/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3923 - accuracy: 0.8173\n",
      "Epoch 18/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8158\n",
      "Epoch 19/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8173\n",
      "Epoch 20/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8134\n",
      "Epoch 21/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3884 - accuracy: 0.8207\n",
      "Epoch 22/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3910 - accuracy: 0.8216\n",
      "Epoch 23/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3904 - accuracy: 0.8255\n",
      "Epoch 24/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8221\n",
      "Epoch 25/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3855 - accuracy: 0.8226\n",
      "Epoch 26/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3890 - accuracy: 0.8153\n",
      "Epoch 27/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3880 - accuracy: 0.8231\n",
      "Epoch 28/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8197\n",
      "Epoch 29/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8168\n",
      "Epoch 30/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3846 - accuracy: 0.8250\n",
      "Epoch 31/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3878 - accuracy: 0.8212\n",
      "Epoch 32/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3890 - accuracy: 0.8226\n",
      "Epoch 33/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3881 - accuracy: 0.8226\n",
      "Epoch 34/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3873 - accuracy: 0.8202\n",
      "Epoch 35/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3854 - accuracy: 0.8216\n",
      "Epoch 36/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3835 - accuracy: 0.8255\n",
      "Epoch 37/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8299\n",
      "Epoch 38/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8246\n",
      "Epoch 39/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3854 - accuracy: 0.8236\n",
      "Epoch 40/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8241\n",
      "Epoch 41/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3848 - accuracy: 0.8265\n",
      "Epoch 42/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8216\n",
      "Epoch 43/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8250\n",
      "Epoch 44/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3843 - accuracy: 0.8226\n",
      "Epoch 45/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3867 - accuracy: 0.8275\n",
      "Epoch 46/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3821 - accuracy: 0.8236\n",
      "Epoch 47/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8226\n",
      "Epoch 48/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3848 - accuracy: 0.8216\n",
      "Epoch 49/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3859 - accuracy: 0.8250\n",
      "Epoch 50/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3834 - accuracy: 0.8270\n",
      "Epoch 51/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3853 - accuracy: 0.8226\n",
      "Epoch 52/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3833 - accuracy: 0.8216\n",
      "Epoch 53/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3849 - accuracy: 0.8231\n",
      "Epoch 54/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8236\n",
      "Epoch 55/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3849 - accuracy: 0.8221\n",
      "Epoch 56/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8221\n",
      "Epoch 57/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3842 - accuracy: 0.8241\n",
      "Epoch 58/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8197\n",
      "Epoch 59/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3849 - accuracy: 0.8280\n",
      "Epoch 60/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3857 - accuracy: 0.8285\n",
      "Epoch 61/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3830 - accuracy: 0.8236\n",
      "Epoch 62/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3833 - accuracy: 0.8270\n",
      "Epoch 63/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3852 - accuracy: 0.8260\n",
      "Epoch 64/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8250\n",
      "Epoch 65/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3825 - accuracy: 0.8260\n",
      "Epoch 66/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3823 - accuracy: 0.8255\n",
      "Epoch 67/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3844 - accuracy: 0.8197\n",
      "Epoch 68/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3826 - accuracy: 0.8236\n",
      "Epoch 69/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8255\n",
      "Epoch 70/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3825 - accuracy: 0.8265\n",
      "Epoch 71/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8241\n",
      "Epoch 72/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3830 - accuracy: 0.8260\n",
      "Epoch 73/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3858 - accuracy: 0.8246\n",
      "Epoch 74/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3819 - accuracy: 0.8250\n",
      "Epoch 75/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3842 - accuracy: 0.8246\n",
      "Epoch 76/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3820 - accuracy: 0.8255\n",
      "Epoch 77/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3822 - accuracy: 0.8250\n",
      "Epoch 78/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3842 - accuracy: 0.8226\n",
      "Epoch 79/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3824 - accuracy: 0.8231\n",
      "Epoch 80/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8231\n",
      "Epoch 81/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8226\n",
      "Epoch 82/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8241\n",
      "Epoch 83/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8275\n",
      "Epoch 84/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3823 - accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3816 - accuracy: 0.8289\n",
      "Epoch 86/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3844 - accuracy: 0.8250\n",
      "Epoch 87/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3801 - accuracy: 0.8260\n",
      "Epoch 88/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3845 - accuracy: 0.8236\n",
      "Epoch 89/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3809 - accuracy: 0.8255\n",
      "Epoch 90/100\n",
      "411/411 [==============================] - 1s 2ms/step - loss: 0.3804 - accuracy: 0.8246\n",
      "Epoch 91/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3806 - accuracy: 0.8236\n",
      "Epoch 92/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3847 - accuracy: 0.8289\n",
      "Epoch 93/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3823 - accuracy: 0.8285\n",
      "Epoch 94/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3829 - accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3819 - accuracy: 0.8260\n",
      "Epoch 96/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8260\n",
      "Epoch 97/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8285\n",
      "Epoch 98/100\n",
      "411/411 [==============================] - 0s 1ms/step - loss: 0.3815 - accuracy: 0.8255\n",
      "Epoch 99/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3841 - accuracy: 0.8177\n",
      "Epoch 100/100\n",
      "411/411 [==============================] - 1s 1ms/step - loss: 0.3827 - accuracy: 0.8221\n"
     ]
    }
   ],
   "source": [
    "# Fit train data\n",
    "train_result = estimator.fit(X_train, y_train, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 76.92030292102416 %\n"
     ]
    }
   ],
   "source": [
    "# Make prediction and get accuracy\n",
    "y_pred = estimator.predict(X_test)\n",
    "dummy_y_test = np_utils.to_categorical(y_test)\n",
    "dummy_y_pred = np_utils.to_categorical(y_pred)\n",
    "print('Accuracy on test data:',accuracy_score(dummy_y_test, dummy_y_pred)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))#,labels=labels_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)#,display_labels=target_names)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.66      0.74      1385\n",
      "           1       0.72      0.88      0.79      1388\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2773\n",
      "   macro avg       0.78      0.77      0.77      2773\n",
      "weighted avg       0.78      0.77      0.77      2773\n",
      " samples avg       0.77      0.77      0.77      2773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dummy_y_test, dummy_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch for Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_grid(neurons = 5 , activation = 'relu', learning_rate = '0.001', optimizer='adam',):\n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Activation functions\n",
    "    if activation=='relu':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='relu'))\n",
    "        #model.add(Dense(neurons, activation='relu'))\n",
    "    if activation=='tanh':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='tanh'))\n",
    "        #model.add(Dense(neurons, activation='tanh'))\n",
    "    if activation=='sigmoid':\n",
    "        model.add(Dense(neurons, input_dim=input_size, activation='sigmoid'))\n",
    "        #model.add(Dense(neurons, activation='sigmoid'))\n",
    "        \n",
    "    # Output layer    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Optimizers\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    if optimizer == 'rmsprop':\n",
    "        opt = tf.keras.optimizers.RMSprop(learning_rate = learning_rate)\n",
    "    if optimizer == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "    \n",
    "    # Compile Model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rinrada\\AppData\\Local\\Temp/ipykernel_12916/685262876.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator_grid = KerasClassifier(build_fn=create_model_grid, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "estimator_grid = KerasClassifier(build_fn=create_model_grid, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hyperparameters to be searched\n",
    "activation_list = ['tanh','relu']\n",
    "optimizer_list = ['rmsprop','adam','sgd']\n",
    "epoch_list = [5,10,20]\n",
    "batch_list = [10,20,50]\n",
    "learning_rate_list = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "neurons_list = [8, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearch\n",
    "param_grid = dict(activation = activation_list,\n",
    "                 optimizer = optimizer_list,\n",
    "                 epochs = epoch_list, \n",
    "                  batch_size = batch_list,\n",
    "                 learning_rate = learning_rate_list,\n",
    "                 neurons = neurons_list)\n",
    "\n",
    "# Search with 3 folds (cross_validation)\n",
    "grid = GridSearchCV(estimator = estimator_grid, param_grid = param_grid, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 810 candidates, totalling 2430 fits\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=  13.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   6.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   7.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=334.1min\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   6.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   8.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   9.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=  16.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   8.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   8.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   6.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   6.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   7.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   7.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   7.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   7.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   6.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   6.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   6.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   6.5s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   6.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   6.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   7.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   6.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   6.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.4s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   6.6s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.8s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.1s\n",
      "[CV] END activation=tanh, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   6.9s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.2s\n",
      "[CV] END activation=tanh, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   5.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=tanh, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   7.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   6.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   6.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   6.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   6.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   6.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   6.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   7.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   6.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   6.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   5.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   6.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   5.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   6.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   5.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   6.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   6.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   6.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   5.3s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   5.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   5.1s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   5.0s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=10, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   4.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   4.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   5.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   4.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   5.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   4.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   4.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   4.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   4.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   4.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   5.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   3.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   4.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   3.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   4.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   2.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.1s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   3.8s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.7s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=20, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   0.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=5, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=adam; total time=   3.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=10, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=rmsprop; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=32, optimizer=sgd; total time=   1.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.001, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=8, optimizer=sgd; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=rmsprop; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=32, optimizer=sgd; total time=   3.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.01, neurons=64, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   2.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=adam; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.4s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   2.3s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.1, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=rmsprop; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=rmsprop; total time=   2.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=32, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   2.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.2, neurons=64, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.6s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=8, optimizer=sgd; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=rmsprop; total time=   1.9s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   2.1s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=adam; total time=   1.7s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.5s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=32, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=rmsprop; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   2.2s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=adam; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.8s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   2.0s\n",
      "[CV] END activation=relu, batch_size=50, epochs=20, learning_rate=0.3, neurons=64, optimizer=sgd; total time=   1.6s\n"
     ]
    }
   ],
   "source": [
    "# Training to get the best hyperparameter combination\n",
    "grid_result = grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.824561 using {'activation': 'relu', 'batch_size': 20, 'epochs': 20, 'learning_rate': 0.01, 'neurons': 32, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Print Best Result\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>neurons</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.008608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.822612</td>\n",
       "      <td>0.008469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>tanh</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.300</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.822125</td>\n",
       "      <td>0.009649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.822125</td>\n",
       "      <td>0.007294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>relu</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010</td>\n",
       "      <td>32</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>0.822125</td>\n",
       "      <td>0.006126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>tanh</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.452729</td>\n",
       "      <td>0.039955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.430799</td>\n",
       "      <td>0.025219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.413255</td>\n",
       "      <td>0.056702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>tanh</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.391813</td>\n",
       "      <td>0.090981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>relu</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>32</td>\n",
       "      <td>sgd</td>\n",
       "      <td>0.391326</td>\n",
       "      <td>0.065320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    activation  batch_size  epochs  learning_rate  neurons optimizer  \\\n",
       "643       relu          20      20          0.010       32      adam   \n",
       "598       relu          20      10          0.010       32      adam   \n",
       "128       tanh          10      20          0.300        8       sgd   \n",
       "511       relu          10      20          0.010       64      adam   \n",
       "507       relu          10      20          0.010       32   rmsprop   \n",
       "..         ...         ...     ...            ...      ...       ...   \n",
       "140       tanh          20       5          0.001       32       sgd   \n",
       "548       relu          20       5          0.001       64       sgd   \n",
       "362       tanh          50      20          0.001        8       sgd   \n",
       "365       tanh          50      20          0.001       32       sgd   \n",
       "545       relu          20       5          0.001       32       sgd   \n",
       "\n",
       "         Mean       Std  \n",
       "643  0.824561  0.008608  \n",
       "598  0.822612  0.008469  \n",
       "128  0.822125  0.009649  \n",
       "511  0.822125  0.007294  \n",
       "507  0.822125  0.006126  \n",
       "..        ...       ...  \n",
       "140  0.452729  0.039955  \n",
       "548  0.430799  0.025219  \n",
       "362  0.413255  0.056702  \n",
       "365  0.391813  0.090981  \n",
       "545  0.391326  0.065320  \n",
       "\n",
       "[810 rows x 8 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Hyperparameter listed out and shown as dataframe\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "df = pd.DataFrame(params)\n",
    "df['Mean'] = means\n",
    "df['Std'] = stds\n",
    "\n",
    "df.sort_values('Mean',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.20488874e+00, 2.15313943e+00, 1.91519825e+00, 2.16574184e+00,\n",
       "        1.81061268e+00, 1.83774201e+00, 2.23642063e+00, 2.31316574e+00,\n",
       "        1.99478165e+00, 2.37340283e+00, 2.16502794e+00, 2.05105042e+00,\n",
       "        2.30550114e+00, 2.14559460e+00, 2.02141062e+00, 2.09948746e+00,\n",
       "        1.82924263e+00, 1.92664417e+00, 2.10251458e+00, 1.95074256e+00,\n",
       "        1.81745474e+00, 2.02912815e+00, 2.12707535e+00, 2.04592021e+00,\n",
       "        2.26646996e+00, 1.82255801e+00, 1.96900296e+00, 1.93671195e+00,\n",
       "        1.95158474e+00, 1.75161282e+00, 2.00580454e+00, 1.97519883e+00,\n",
       "        1.85636878e+00, 2.11757127e+00, 1.90654985e+00, 1.72178944e+00,\n",
       "        1.97099320e+00, 1.87283349e+00, 1.82630165e+00, 2.08797177e+00,\n",
       "        1.98462590e+00, 1.85995690e+00, 1.98989979e+00, 2.01007811e+00,\n",
       "        1.69973858e+00, 7.07548078e+00, 3.61445697e+00, 3.72848185e+00,\n",
       "        3.50127570e+00, 3.12185494e+00, 2.55969000e+00, 3.01928242e+00,\n",
       "        3.42782760e+00, 2.78993964e+00, 3.57898506e+00, 3.15466189e+00,\n",
       "        2.86215941e+00, 3.04563983e+00, 2.99890320e+00, 2.60780374e+00,\n",
       "        2.92255759e+00, 3.16816012e+00, 2.84129763e+00, 2.98730874e+00,\n",
       "        2.72120086e+00, 2.96531471e+00, 2.96713551e+00, 2.93321753e+00,\n",
       "        2.93848697e+00, 3.72543049e+00, 2.96610459e+00, 2.79683614e+00,\n",
       "        2.82523425e+00, 2.92552741e+00, 2.72090594e+00, 2.88409360e+00,\n",
       "        2.81358401e+00, 2.52768652e+00, 2.81685114e+00, 3.07335917e+00,\n",
       "        2.42030843e+00, 2.76613847e+00, 2.60607306e+00, 2.59794577e+00,\n",
       "        2.78564421e+00, 2.74774853e+00, 2.70635525e+00, 2.71898293e+00,\n",
       "        2.87601360e+00, 2.42073075e+00, 4.51411899e+00, 4.42888252e+00,\n",
       "        4.37339203e+00, 4.49277401e+00, 4.34367911e+00, 4.12049405e+00,\n",
       "        4.51889984e+00, 4.44767563e+00, 4.13512182e+00, 4.56247107e+00,\n",
       "        4.77734486e+00, 4.35817480e+00, 4.57491279e+00, 4.65863045e+00,\n",
       "        5.09985964e+00, 4.59893322e+00, 4.69455187e+00, 4.32013392e+00,\n",
       "        6.68495343e+03, 5.23725708e+00, 5.43338315e+00, 4.61958051e+00,\n",
       "        4.19453947e+00, 4.04834175e+00, 4.32045062e+00, 4.53494581e+00,\n",
       "        4.19352253e+00, 5.59131638e+00, 1.00651497e+01, 5.89172220e+00,\n",
       "        6.72426883e+00, 6.41643222e+00, 5.90447934e+00, 5.82523266e+00,\n",
       "        6.02471177e+00, 5.91658942e+00, 5.47621385e+00, 5.48214499e+00,\n",
       "        5.13240314e+00, 5.29131142e+00, 4.97777168e+00, 4.93677624e+00,\n",
       "        5.28792548e+00, 5.26672705e+00, 5.09949080e+00, 1.62595320e+00,\n",
       "        1.78128044e+00, 1.48004627e+00, 1.97769252e+00, 1.90298080e+00,\n",
       "        1.57017716e+00, 2.01870012e+00, 1.63197231e+00, 1.42291983e+00,\n",
       "        2.19173495e+00, 1.49901223e+00, 1.38177133e+00, 1.70163727e+00,\n",
       "        1.34806538e+00, 1.38822142e+00, 1.54160094e+00, 1.56926155e+00,\n",
       "        1.32582148e+00, 1.64956148e+00, 1.36723550e+00, 1.50418631e+00,\n",
       "        1.53218873e+00, 1.53746891e+00, 1.34474277e+00, 1.51138735e+00,\n",
       "        1.52374419e+00, 1.35253779e+00, 1.54274877e+00, 1.34575335e+00,\n",
       "        1.51124652e+00, 1.53507900e+00, 1.54957438e+00, 1.43679746e+00,\n",
       "        1.64734761e+00, 1.40771087e+00, 1.35296122e+00, 1.58518720e+00,\n",
       "        1.34318471e+00, 1.54736129e+00, 1.44167034e+00, 1.55129234e+00,\n",
       "        1.41203046e+00, 1.62060364e+00, 1.42997209e+00, 1.45369943e+00,\n",
       "        1.90676085e+00, 1.90339494e+00, 1.66922458e+00, 2.16707277e+00,\n",
       "        1.86193649e+00, 1.61552223e+00, 2.27641988e+00, 2.15388227e+00,\n",
       "        1.92633899e+00, 2.27089667e+00, 2.16589459e+00, 1.66962473e+00,\n",
       "        1.85747790e+00, 1.89244739e+00, 1.77180370e+00, 2.01393596e+00,\n",
       "        1.79476221e+00, 1.61253333e+00, 1.98974903e+00, 1.80762132e+00,\n",
       "        1.76448003e+00, 2.12442883e+00, 2.01795959e+00, 1.73292732e+00,\n",
       "        1.97070169e+00, 2.13367200e+00, 1.70735113e+00, 2.21781492e+00,\n",
       "        1.78800464e+00, 1.72971479e+00, 2.12739372e+00, 1.82545853e+00,\n",
       "        1.91654976e+00, 1.90412823e+00, 2.08175747e+00, 1.68495901e+00,\n",
       "        2.02999806e+00, 1.82481035e+00, 1.69533714e+00, 2.10847656e+00,\n",
       "        1.82995272e+00, 1.92765427e+00, 2.02015678e+00, 1.97388514e+00,\n",
       "        1.76508919e+00, 2.97939785e+00, 2.84627207e+00, 2.82523147e+00,\n",
       "        2.80431596e+00, 3.04392052e+00, 2.60932144e+00, 2.92227133e+00,\n",
       "        3.04512827e+00, 3.23087716e+00, 3.21819019e+00, 3.01122379e+00,\n",
       "        2.99813430e+00, 3.21179668e+00, 2.88329212e+00, 2.89190499e+00,\n",
       "        3.47880340e+00, 2.97592870e+00, 2.87478654e+00, 3.49862369e+00,\n",
       "        2.69742870e+00, 2.78997755e+00, 3.35918283e+00, 3.07940920e+00,\n",
       "        2.74911626e+00, 3.35357245e+00, 3.61821771e+00, 3.22860630e+00,\n",
       "        3.66071971e+00, 3.18547281e+00, 3.25452073e+00, 3.34036215e+00,\n",
       "        3.33938845e+00, 2.69860721e+00, 2.98832417e+00, 3.18964362e+00,\n",
       "        2.87305800e+00, 3.03284820e+00, 3.04360080e+00, 2.98473175e+00,\n",
       "        5.42979074e+00, 4.27830195e+00, 3.54658294e+00, 3.80802353e+00,\n",
       "        3.37613837e+00, 3.54645729e+00, 1.44480435e+00, 1.58742189e+00,\n",
       "        1.40790852e+00, 1.47854940e+00, 1.66534138e+00, 1.23178633e+00,\n",
       "        2.49770427e+00, 1.69815826e+00, 1.27453732e+00, 1.74788690e+00,\n",
       "        1.47754725e+00, 1.31421383e+00, 1.63816905e+00, 1.34367021e+00,\n",
       "        1.36780294e+00, 1.61393325e+00, 1.20261407e+00, 1.39447594e+00,\n",
       "        1.35953633e+00, 1.36267130e+00, 1.33850392e+00, 1.50694060e+00,\n",
       "        1.15569957e+00, 1.23340933e+00, 1.47708988e+00, 1.32147408e+00,\n",
       "        1.26029801e+00, 1.36483558e+00, 1.46973618e+00, 1.17706966e+00,\n",
       "        1.80721211e+00, 1.25067671e+00, 1.26945710e+00, 2.85541860e+00,\n",
       "        1.59648450e+00, 1.71512930e+00, 1.60424908e+00, 1.40694189e+00,\n",
       "        1.58537634e+00, 1.73193073e+00, 1.37545149e+00, 1.17750669e+00,\n",
       "        1.70890371e+00, 1.35102145e+00, 1.22320056e+00, 1.63449502e+00,\n",
       "        1.74353711e+00, 1.46748042e+00, 1.97731463e+00, 1.64637272e+00,\n",
       "        1.33476496e+00, 1.84762367e+00, 1.68025708e+00, 1.58745567e+00,\n",
       "        1.89696360e+00, 1.59642776e+00, 1.46187782e+00, 2.04678663e+00,\n",
       "        1.43605685e+00, 2.62127773e+00, 2.36544585e+00, 1.90759158e+00,\n",
       "        1.86728660e+00, 2.63737194e+00, 2.04952852e+00, 1.71455518e+00,\n",
       "        2.14789804e+00, 2.11731092e+00, 1.91107043e+00, 2.21462083e+00,\n",
       "        1.60294882e+00, 1.53823892e+00, 1.87401334e+00, 1.83229891e+00,\n",
       "        1.60465447e+00, 1.78574014e+00, 1.49330576e+00, 1.48065019e+00,\n",
       "        1.93457357e+00, 2.34143655e+00, 1.92817012e+00, 1.95762873e+00,\n",
       "        1.97505434e+00, 1.85544801e+00, 1.84266702e+00, 1.87011337e+00,\n",
       "        2.34618600e+00, 1.93935124e+00, 2.09637682e+00, 1.59334580e+00,\n",
       "        2.44153134e+00, 2.20271373e+00, 2.39329878e+00, 2.67184067e+00,\n",
       "        2.44919244e+00, 1.82104087e+00, 2.43615691e+00, 2.01559273e+00,\n",
       "        2.43276342e+00, 2.42581113e+00, 2.55934850e+00, 1.93995214e+00,\n",
       "        2.31568273e+00, 2.03796069e+00, 2.04708902e+00, 3.08970698e+00,\n",
       "        2.35349409e+00, 2.28422999e+00, 2.70332853e+00, 2.31894016e+00,\n",
       "        1.78395375e+00, 1.92817807e+00, 1.98573256e+00, 1.63803832e+00,\n",
       "        2.14404511e+00, 1.74885599e+00, 1.67816917e+00, 2.10568619e+00,\n",
       "        2.01455688e+00, 1.88431780e+00, 2.03289930e+00, 2.22844346e+00,\n",
       "        1.82220896e+00, 2.45795870e+00, 2.22041933e+00, 1.94411826e+00,\n",
       "        2.09945591e+00, 2.08321436e+00, 1.99562780e+00, 2.13505952e+00,\n",
       "        2.04242158e+00, 1.81429370e+00, 2.07778390e+00, 1.91539685e+00,\n",
       "        2.22675896e+00, 2.19292577e+00, 2.32868568e+00, 1.84458852e+00,\n",
       "        2.28172286e+00, 2.22052765e+00, 1.91768074e+00, 2.30642851e+00,\n",
       "        1.92579834e+00, 1.83940474e+00, 2.15412529e+00, 2.42144243e+00,\n",
       "        1.85727064e+00, 2.49091379e+00, 2.51505486e+00, 2.07564092e+00,\n",
       "        2.39518642e+00, 2.27548154e+00, 2.30704204e+00, 2.81048886e+00,\n",
       "        2.59768057e+00, 1.80302914e+00, 2.37184739e+00, 1.75190838e+00,\n",
       "        1.55458593e+00, 2.08823514e+00, 1.67511535e+00, 1.53528746e+00,\n",
       "        2.42149242e+00, 2.84770870e+00, 2.16933688e+00, 2.76121545e+00,\n",
       "        2.21165776e+00, 2.28751381e+00, 2.70604690e+00, 2.36068114e+00,\n",
       "        2.26452351e+00, 2.31503034e+00, 1.72900605e+00, 2.10673046e+00,\n",
       "        2.04221408e+00, 1.70732641e+00, 1.57491231e+00, 2.27857121e+00,\n",
       "        1.73790828e+00, 1.72553396e+00, 2.97969874e+00, 2.54993534e+00,\n",
       "        2.28502266e+00, 2.98661566e+00, 2.23112909e+00, 2.18588583e+00,\n",
       "        2.41921441e+00, 2.69865433e+00, 2.27942753e+00, 2.64174422e+00,\n",
       "        2.42872540e+00, 2.44707712e+00, 2.45199402e+00, 2.58852800e+00,\n",
       "        2.31589031e+00, 2.67570472e+00, 2.68337854e+00, 2.36699454e+00,\n",
       "        4.05572001e+00, 3.61846471e+00, 3.43839478e+00, 3.42725841e+00,\n",
       "        4.10532173e+00, 3.44709428e+00, 3.62646612e+00, 3.14572247e+00,\n",
       "        2.23307546e+00, 2.62935686e+00, 2.60040148e+00, 2.31149054e+00,\n",
       "        2.79888932e+00, 2.97880522e+00, 2.64991681e+00, 4.32499337e+00,\n",
       "        4.02841036e+00, 3.30426017e+00, 3.82983398e+00, 3.12994679e+00,\n",
       "        3.12353539e+00, 3.90870619e+00, 3.07465998e+00, 3.17248027e+00,\n",
       "        4.48649319e+00, 3.47065099e+00, 2.84188708e+00, 5.80589247e+00,\n",
       "        6.01480524e+00, 4.82032760e+00, 5.89402922e+00, 5.28268544e+00,\n",
       "        4.86591244e+00, 5.38490295e+00, 4.99488044e+00, 4.53713187e+00,\n",
       "        5.34990319e+00, 5.39670976e+00, 5.12087456e+00, 5.67327134e+00,\n",
       "        5.37706327e+00, 4.55987573e+00, 4.75591381e+00, 4.64900796e+00,\n",
       "        4.40686448e+00, 4.81097571e+00, 4.56697575e+00, 4.40531309e+00,\n",
       "        4.78879070e+00, 4.60061351e+00, 4.78900385e+00, 4.79665844e+00,\n",
       "        4.54891324e+00, 4.31008204e+00, 4.72829692e+00, 4.50222015e+00,\n",
       "        4.23295172e+00, 4.56260562e+00, 4.48112059e+00, 4.14836812e+00,\n",
       "        5.15824215e+00, 5.07950958e+00, 4.72168763e+00, 5.07720423e+00,\n",
       "        4.76254749e+00, 4.25451342e+00, 4.47663625e+00, 4.46876462e+00,\n",
       "        4.31775030e+00, 4.60496211e+00, 4.56594173e+00, 4.29358681e+00,\n",
       "        1.90578461e+00, 1.43257618e+00, 1.60350569e+00, 1.64577866e+00,\n",
       "        1.50997599e+00, 1.21352569e+00, 1.53096088e+00, 1.58192889e+00,\n",
       "        1.28042873e+00, 1.44434889e+00, 1.51987187e+00, 1.23653650e+00,\n",
       "        1.70766854e+00, 1.59331369e+00, 1.32866549e+00, 1.58130391e+00,\n",
       "        1.54052560e+00, 1.29593158e+00, 1.49042074e+00, 1.45861204e+00,\n",
       "        1.27684585e+00, 1.68537593e+00, 1.55212140e+00, 1.41242758e+00,\n",
       "        1.78949626e+00, 1.69625235e+00, 1.30028995e+00, 2.17171788e+00,\n",
       "        2.53595662e+00, 2.03614267e+00, 2.44316451e+00, 1.75971897e+00,\n",
       "        1.83483601e+00, 2.21244017e+00, 1.54930774e+00, 2.01222960e+00,\n",
       "        1.91645678e+00, 1.76646852e+00, 1.80420367e+00, 2.36350314e+00,\n",
       "        2.44597562e+00, 1.58639034e+00, 1.90690215e+00, 1.51841911e+00,\n",
       "        1.38005161e+00, 2.55755035e+00, 2.28603729e+00, 2.37901664e+00,\n",
       "        2.30669316e+00, 2.22274836e+00, 1.85800401e+00, 2.36405126e+00,\n",
       "        2.08418107e+00, 2.23959072e+00, 2.61673983e+00, 2.37847702e+00,\n",
       "        2.31403875e+00, 2.69937229e+00, 2.32681767e+00, 2.34377400e+00,\n",
       "        2.43474428e+00, 2.57634974e+00, 2.36698985e+00, 2.54369052e+00,\n",
       "        2.41046103e+00, 2.13710992e+00, 2.66319267e+00, 2.37120040e+00,\n",
       "        2.05742391e+00, 2.21054395e+00, 2.26356546e+00, 2.31984687e+00,\n",
       "        2.67767278e+00, 2.29904032e+00, 2.07752736e+00, 2.27890460e+00,\n",
       "        2.13335419e+00, 1.83658806e+00, 2.36808642e+00, 2.06111852e+00,\n",
       "        2.17408196e+00, 2.38409575e+00, 2.25564313e+00, 2.05586878e+00,\n",
       "        2.61741678e+00, 2.47679154e+00, 2.09885240e+00, 2.76433921e+00,\n",
       "        2.47096237e+00, 2.03767586e+00, 3.85234149e+00, 3.42150609e+00,\n",
       "        3.22078848e+00, 3.43764353e+00, 3.59461117e+00, 3.43317763e+00,\n",
       "        3.62035751e+00, 3.32212528e+00, 2.99972693e+00, 3.42643817e+00,\n",
       "        3.38221431e+00, 3.01663907e+00, 3.53808037e+00, 3.02922893e+00,\n",
       "        3.00727574e+00, 4.47406721e+00, 3.71176227e+00, 3.29539442e+00,\n",
       "        3.85546700e+00, 3.41679390e+00, 3.09716908e+00, 3.84074251e+00,\n",
       "        3.47176909e+00, 3.04439680e+00, 3.82345891e+00, 3.33375335e+00,\n",
       "        3.20484964e+00, 3.39081891e+00, 3.45403298e+00, 3.09239213e+00,\n",
       "        3.14945237e+00, 3.17526277e+00, 3.33546710e+00, 3.95337772e+00,\n",
       "        3.57815806e+00, 2.86198004e+00, 3.37374632e+00, 3.11236564e+00,\n",
       "        3.13263369e+00, 3.26596570e+00, 2.67534494e+00, 2.40974991e+00,\n",
       "        2.89301085e+00, 2.49512887e+00, 2.29518867e+00, 1.24030455e+00,\n",
       "        9.47745879e-01, 1.22604259e+00, 1.18226274e+00, 1.10729702e+00,\n",
       "        1.22234567e+00, 1.35558256e+00, 1.25101360e+00, 1.05496144e+00,\n",
       "        1.41229113e+00, 1.06134049e+00, 8.97458712e-01, 1.41019479e+00,\n",
       "        1.27718941e+00, 1.12590591e+00, 1.18745685e+00, 1.11878467e+00,\n",
       "        1.10802301e+00, 1.10586270e+00, 1.15487496e+00, 9.04905796e-01,\n",
       "        1.28638705e+00, 9.58654881e-01, 8.41661930e-01, 1.27562936e+00,\n",
       "        1.03045440e+00, 8.41685216e-01, 1.06684693e+00, 1.05441809e+00,\n",
       "        1.02651072e+00, 1.29171848e+00, 1.19243026e+00, 1.27104394e+00,\n",
       "        1.31007282e+00, 1.02994442e+00, 9.03539817e-01, 1.38449152e+00,\n",
       "        9.63193099e-01, 8.67463986e-01, 1.05294855e+00, 1.05100218e+00,\n",
       "        8.25330178e-01, 1.01045966e+00, 9.32785590e-01, 8.59039307e-01,\n",
       "        1.37848973e+00, 1.09888411e+00, 1.14155245e+00, 1.45643036e+00,\n",
       "        1.08119003e+00, 1.36832698e+00, 1.24104532e+00, 1.47280924e+00,\n",
       "        1.43198975e+00, 1.44595671e+00, 1.24087675e+00, 1.00316159e+00,\n",
       "        1.30219881e+00, 1.59893934e+00, 1.42570893e+00, 1.65854955e+00,\n",
       "        1.42751249e+00, 9.65104898e-01, 1.35919197e+00, 1.37980596e+00,\n",
       "        1.08954803e+00, 1.24464115e+00, 1.84293469e+00, 1.70792174e+00,\n",
       "        1.81844894e+00, 1.33962504e+00, 1.24981952e+00, 1.22372905e+00,\n",
       "        1.13329323e+00, 1.18058817e+00, 1.11756786e+00, 1.04584336e+00,\n",
       "        1.19478456e+00, 1.23190522e+00, 1.22456805e+00, 1.14507246e+00,\n",
       "        1.57395220e+00, 1.05215859e+00, 1.03483446e+00, 1.50588314e+00,\n",
       "        1.10642330e+00, 1.26341573e+00, 1.30373931e+00, 1.26577560e+00,\n",
       "        9.22814449e-01, 1.73327891e+00, 1.54835081e+00, 1.21001895e+00,\n",
       "        1.48468248e+00, 1.68441232e+00, 1.24926893e+00, 1.38798197e+00,\n",
       "        1.58551383e+00, 1.30979085e+00, 1.96728579e+00, 1.53210179e+00,\n",
       "        1.54400984e+00, 1.36684259e+00, 1.66446726e+00, 2.04899033e+00,\n",
       "        2.16963005e+00, 1.85854952e+00, 1.75708334e+00, 1.84359646e+00,\n",
       "        1.77648870e+00, 1.84689172e+00, 2.06751768e+00, 1.96409504e+00,\n",
       "        1.59913532e+00, 2.09988809e+00, 1.72128995e+00, 1.70484885e+00,\n",
       "        1.69618201e+00, 1.76348909e+00, 1.43233538e+00, 1.90718651e+00,\n",
       "        1.52928694e+00, 1.48855042e+00, 2.05930877e+00, 1.55836598e+00,\n",
       "        1.62711573e+00, 1.78548527e+00, 1.57827592e+00, 1.60968820e+00,\n",
       "        1.79408105e+00, 1.57338397e+00, 1.56100456e+00, 1.66016897e+00,\n",
       "        1.71638942e+00, 1.62555679e+00]),\n",
       " 'std_fit_time': array([2.13334008e-01, 3.20915269e-01, 1.60152922e-01, 2.66181950e-01,\n",
       "        1.17436690e-01, 2.47350626e-01, 2.76317789e-01, 3.72432699e-01,\n",
       "        1.18612056e-01, 2.44011896e-01, 4.07129277e-01, 1.81433884e-01,\n",
       "        3.34335863e-01, 2.40117864e-01, 1.95233155e-01, 2.26764685e-01,\n",
       "        1.37244957e-01, 2.84550580e-01, 1.32251736e-01, 1.82234274e-01,\n",
       "        1.04853048e-01, 2.80512774e-02, 2.83177438e-01, 9.83215021e-02,\n",
       "        7.31876090e-02, 1.08915683e-01, 1.29742935e-01, 9.10727279e-02,\n",
       "        2.39825628e-01, 1.05238010e-01, 5.83111837e-02, 1.88346529e-01,\n",
       "        2.52289894e-01, 1.76270982e-01, 1.42734193e-01, 7.75555815e-02,\n",
       "        1.45234359e-01, 4.53255027e-02, 8.07109239e-02, 1.46618726e-01,\n",
       "        1.10797108e-01, 8.02255843e-02, 1.32127303e-01, 2.23311905e-01,\n",
       "        4.64930077e-02, 3.26601563e+00, 1.31810775e-01, 2.50422580e-01,\n",
       "        6.60258425e-01, 2.70043068e-01, 1.40457395e-01, 6.19479862e-02,\n",
       "        5.17029242e-01, 1.54915755e-01, 5.39297276e-01, 4.74067950e-01,\n",
       "        1.63267884e-01, 2.96702987e-01, 1.88001664e-01, 2.79779726e-02,\n",
       "        2.46339472e-01, 2.36457233e-01, 9.13936317e-02, 1.52327714e-01,\n",
       "        2.02881799e-01, 2.29492113e-01, 1.55598527e-01, 3.06910413e-01,\n",
       "        1.60714959e-01, 6.71926504e-01, 1.94494211e-01, 3.60933323e-01,\n",
       "        1.03353252e-01, 2.63093581e-01, 2.48747541e-01, 8.76489918e-02,\n",
       "        1.12064961e-01, 1.83387490e-01, 2.72403048e-01, 4.49998334e-01,\n",
       "        3.08357479e-02, 1.51876438e-01, 5.41772969e-02, 9.18534497e-02,\n",
       "        1.48022424e-01, 1.89866954e-01, 1.16666046e-01, 4.35151039e-02,\n",
       "        3.64109425e-01, 4.51713587e-02, 2.79919864e-01, 6.85855609e-02,\n",
       "        2.08907173e-01, 1.94139696e-01, 1.13831567e-01, 2.10579717e-01,\n",
       "        1.41029226e-01, 6.39315511e-02, 7.96551277e-02, 3.89125881e-01,\n",
       "        4.86640889e-01, 2.11489083e-01, 1.05837214e-01, 4.04495436e-01,\n",
       "        9.36521764e-01, 2.49746052e-01, 2.90538108e-01, 3.43523286e-01,\n",
       "        9.44774801e+03, 1.07607848e+00, 2.36671994e+00, 1.35353840e-01,\n",
       "        1.41238737e-01, 2.52414018e-01, 2.48967835e-01, 8.74445194e-02,\n",
       "        1.29568678e-01, 4.11558789e-01, 2.66440071e+00, 5.21491534e-01,\n",
       "        9.20833463e-02, 4.80971668e-01, 4.48574049e-01, 3.67979940e-01,\n",
       "        1.98974540e-01, 7.23847108e-01, 5.84810813e-01, 1.21667304e-01,\n",
       "        5.02583672e-01, 3.82375752e-01, 2.46776939e-01, 3.83641521e-01,\n",
       "        4.65383433e-01, 4.89203778e-01, 3.16934168e-01, 1.36809753e-01,\n",
       "        1.83885358e-01, 2.60498221e-01, 4.44769547e-01, 3.89837073e-01,\n",
       "        2.41012689e-01, 2.67125635e-01, 3.71059878e-01, 1.57761317e-01,\n",
       "        1.75926618e-01, 5.06019820e-02, 1.53437463e-01, 1.51367841e-01,\n",
       "        1.32239645e-01, 1.83586981e-01, 1.29299803e-01, 1.56045184e-01,\n",
       "        9.77705589e-02, 9.36629184e-02, 1.11218439e-01, 2.97489825e-01,\n",
       "        7.59874940e-02, 2.07827886e-01, 2.67582109e-02, 2.24361301e-02,\n",
       "        3.13644356e-01, 1.56408040e-01, 1.89780593e-01, 6.03654014e-02,\n",
       "        3.11636911e-01, 4.20706580e-02, 1.64058036e-01, 1.65735877e-01,\n",
       "        1.21572864e-01, 8.43250622e-02, 2.02887970e-01, 6.99534525e-02,\n",
       "        1.05847497e-01, 3.66847152e-01, 1.20885492e-01, 2.47361522e-01,\n",
       "        1.64115992e-01, 2.83533501e-01, 6.33701822e-02, 2.62179092e-01,\n",
       "        6.69687283e-02, 1.34911821e-01, 7.96386024e-02, 3.43261648e-01,\n",
       "        7.07224323e-02, 1.09928161e-01, 2.19391883e-01, 1.56101684e-01,\n",
       "        2.27051431e-01, 2.60032193e-01, 2.02048600e-01, 8.39201244e-02,\n",
       "        1.24158057e-01, 1.00389687e-01, 2.23068149e-01, 2.01173512e-01,\n",
       "        5.04273643e-02, 8.40458844e-02, 1.67247042e-01, 1.69056515e-01,\n",
       "        1.74044822e-01, 2.11326754e-01, 2.05561355e-01, 1.92415820e-02,\n",
       "        4.80831455e-02, 2.05806500e-01, 7.85204591e-02, 1.69740174e-01,\n",
       "        1.32590289e-01, 1.48107848e-01, 2.84712881e-01, 3.07579720e-02,\n",
       "        2.51110412e-01, 8.51782565e-02, 3.04813646e-01, 2.83660541e-02,\n",
       "        1.40857408e-01, 1.60367784e-01, 3.61768279e-02, 2.77667432e-01,\n",
       "        2.28940883e-02, 2.40399597e-01, 1.37674477e-02, 1.29713890e-01,\n",
       "        2.01654199e-01, 1.04109951e-01, 2.12432909e-01, 3.52511758e-01,\n",
       "        9.76753986e-02, 1.59385640e-01, 1.36920800e-02, 2.67619563e-01,\n",
       "        2.17719305e-01, 4.88576934e-01, 3.85670539e-01, 1.61294310e-01,\n",
       "        3.18619345e-01, 2.39518459e-01, 1.56034605e-01, 2.82865782e-01,\n",
       "        3.98881181e-01, 2.09141250e-01, 2.10257601e-01, 3.53087990e-01,\n",
       "        1.46864837e-01, 2.33686199e-01, 2.85715726e-01, 3.00944000e-01,\n",
       "        1.68814748e-01, 1.49200087e-01, 7.94510009e-01, 1.10538542e-01,\n",
       "        5.10951380e-01, 5.73673065e-02, 3.89914192e-01, 2.65520007e-01,\n",
       "        3.96552163e-01, 8.22843313e-02, 1.20240898e-01, 3.28734727e-01,\n",
       "        2.94527406e-01, 6.81779514e-02, 2.86944033e-01, 4.76266122e-01,\n",
       "        7.65720752e-01, 1.30377146e-01, 3.26403858e-01, 5.93237099e-01,\n",
       "        1.22915857e-01, 1.08077095e-01, 1.37436549e-01, 2.90713957e-01,\n",
       "        3.59421833e-01, 8.10904894e-02, 6.38427311e-01, 1.92829090e-01,\n",
       "        2.99642208e-01, 1.66851019e-01, 2.14940193e-01, 1.21355283e-01,\n",
       "        3.06166191e-01, 4.99733196e-02, 2.14359576e-01, 1.86166816e-01,\n",
       "        3.66462647e-01, 2.88551950e-01, 4.89395083e-03, 3.30899303e-01,\n",
       "        2.53953231e-01, 3.08029223e-01, 2.89334616e-01, 2.27599275e-01,\n",
       "        5.94270296e-02, 1.83168427e-01, 1.81473588e-01, 1.55488992e-01,\n",
       "        2.79638618e-01, 1.15263282e-01, 2.02239209e-01, 1.06322865e-01,\n",
       "        2.17692039e-01, 4.28456744e-02, 8.14861023e-02, 1.82544815e+00,\n",
       "        1.77892249e-01, 3.83685437e-01, 1.00631343e-01, 2.92938571e-02,\n",
       "        3.78305767e-02, 1.97132987e-01, 1.22811606e-01, 8.43374961e-02,\n",
       "        2.54710798e-01, 1.39853598e-01, 1.00046516e-01, 2.75392872e-02,\n",
       "        4.78347789e-01, 2.43948220e-02, 1.91011340e-01, 1.29518997e-01,\n",
       "        5.73577843e-02, 2.07058581e-01, 7.93236337e-02, 2.06494936e-01,\n",
       "        2.18155081e-02, 1.20973181e-01, 5.13282554e-02, 2.29616760e-01,\n",
       "        9.99307100e-02, 5.34549122e-02, 5.83855839e-01, 3.05220810e-01,\n",
       "        5.49723842e-01, 4.90411112e-01, 9.42936243e-02, 6.48989116e-02,\n",
       "        4.13989922e-02, 1.77052702e-01, 3.75296377e-01, 9.35984721e-02,\n",
       "        3.28328570e-02, 2.68941453e-01, 5.45813450e-02, 2.54531288e-01,\n",
       "        2.14598005e-01, 1.69813640e-01, 1.74469870e-01, 1.66793990e-01,\n",
       "        3.78994049e-01, 6.13479401e-01, 3.82048557e-01, 3.05947459e-01,\n",
       "        5.37107403e-01, 3.10221492e-01, 1.01295560e-01, 1.31591848e-01,\n",
       "        7.05573327e-01, 2.42746599e-01, 3.31430289e-01, 2.16036849e-01,\n",
       "        3.59870744e-01, 3.04241025e-01, 6.10205247e-01, 2.15356782e-01,\n",
       "        2.81948888e-01, 2.23654852e-01, 3.91959133e-01, 2.50232901e-02,\n",
       "        5.55827811e-01, 9.60656918e-02, 5.89675364e-02, 2.24672944e-01,\n",
       "        2.42644520e-01, 1.53015821e-01, 1.75148905e-01, 7.77788195e-01,\n",
       "        3.63101239e-01, 2.32493106e-01, 3.84919000e-02, 2.61116828e-01,\n",
       "        2.74525412e-01, 7.35805867e-02, 2.29110119e-01, 3.22055335e-02,\n",
       "        1.30112025e-01, 1.06601471e-01, 7.91082185e-02, 1.07104791e-01,\n",
       "        1.81973851e-01, 3.09857739e-01, 3.55172074e-02, 2.95545032e-01,\n",
       "        1.80398614e-01, 3.64716627e-01, 1.44542266e-01, 2.89038716e-01,\n",
       "        6.35028708e-02, 2.78366340e-01, 7.94973461e-02, 3.04966132e-01,\n",
       "        2.12721320e-01, 9.34170041e-02, 1.02864573e-01, 9.37576388e-02,\n",
       "        4.59466283e-01, 7.01471111e-02, 4.98398662e-01, 5.77497237e-02,\n",
       "        2.99524663e-01, 2.35108335e-01, 1.66203950e-01, 2.23385568e-01,\n",
       "        1.13492036e-01, 1.11856481e-01, 2.51084349e-02, 2.85531102e-01,\n",
       "        1.33523960e-01, 2.08948093e-01, 3.04649115e-01, 8.99898668e-02,\n",
       "        2.15345433e-01, 2.18152117e-01, 1.45376302e-01, 3.09919184e-01,\n",
       "        1.83380834e-01, 1.31320833e-01, 1.77692410e-01, 2.87846062e-01,\n",
       "        2.14730023e-01, 4.55560131e-01, 4.06645246e-02, 1.76340783e-01,\n",
       "        1.51401174e-01, 5.32577501e-01, 7.21222805e-02, 3.27753874e-01,\n",
       "        1.33307199e-01, 1.38567285e-01, 2.11833887e-01, 1.21920084e-01,\n",
       "        1.54867606e-01, 1.06483498e-01, 1.23956453e-01, 3.87881263e-01,\n",
       "        2.45190052e-01, 1.03259629e-01, 2.67045985e-01, 1.45223342e-01,\n",
       "        1.90794814e-01, 1.24097685e-01, 1.75538924e-01, 2.72942803e-01,\n",
       "        2.23726161e-01, 5.06069932e-01, 1.20517555e-01, 1.02028547e-01,\n",
       "        2.15666525e-01, 1.74287606e-01, 1.16711194e-01, 2.08909442e-01,\n",
       "        8.30010814e-02, 1.47948230e-01, 9.32593770e-02, 2.54992192e-01,\n",
       "        9.60955691e-02, 3.18009930e-01, 7.22805790e-02, 1.48007268e-01,\n",
       "        6.24681753e-01, 1.35153480e-01, 3.06925204e-01, 3.32246576e-02,\n",
       "        3.94457215e-01, 2.33203710e-01, 2.51537299e-01, 5.09255980e-01,\n",
       "        5.60842960e-02, 2.55212901e-01, 3.23472728e-01, 1.05013113e-01,\n",
       "        2.60060691e-01, 4.48021216e-01, 1.73615188e-01, 1.30809755e+00,\n",
       "        2.78220142e-01, 2.26793444e-01, 2.17613299e-01, 1.48884733e-01,\n",
       "        3.64223457e-01, 2.56245017e-01, 8.19661858e-02, 2.97059142e-01,\n",
       "        1.31128963e+00, 2.69370046e-01, 9.11750150e-02, 4.14396758e-01,\n",
       "        3.39281830e-01, 2.72205674e-01, 6.15195936e-01, 2.30992022e-01,\n",
       "        2.13797676e-01, 5.19236180e-01, 1.52178283e-01, 1.29693392e-01,\n",
       "        4.03901936e-01, 1.42624000e-01, 2.05078228e-01, 2.00621464e-01,\n",
       "        1.39535754e-01, 8.66726138e-02, 1.75440492e-01, 8.05232605e-02,\n",
       "        1.43866938e-01, 3.20734806e-01, 2.78435996e-01, 1.73824225e-01,\n",
       "        2.63904054e-01, 2.79760065e-02, 6.32815784e-01, 1.37189620e-01,\n",
       "        1.21878309e-01, 2.37169450e-01, 2.60428324e-01, 1.37279949e-01,\n",
       "        1.73567012e-01, 1.80895481e-01, 1.41796614e-01, 5.05257620e-02,\n",
       "        4.34430983e-01, 1.94973441e-01, 1.40139227e-01, 2.99210384e-01,\n",
       "        1.91951649e-01, 1.69712306e-01, 8.57048098e-02, 1.84710454e-01,\n",
       "        2.40477019e-01, 2.21305607e-01, 1.26834153e-01, 1.01917863e-01,\n",
       "        4.92170571e-01, 1.37673581e-01, 3.06004213e-01, 2.00535306e-01,\n",
       "        2.00186000e-01, 8.95656651e-02, 9.69148928e-02, 2.91570635e-01,\n",
       "        8.34453773e-02, 9.17834630e-02, 1.12848272e-01, 4.01999029e-02,\n",
       "        1.39168640e-01, 1.38873231e-01, 3.75429296e-02, 3.38474861e-02,\n",
       "        1.64827762e-01, 4.35759026e-02, 6.38720103e-02, 3.65494894e-02,\n",
       "        7.64221083e-02, 2.70768246e-01, 1.54350385e-01, 9.36181666e-02,\n",
       "        1.99104303e-01, 1.94336372e-01, 1.05783062e-02, 6.73070164e-01,\n",
       "        5.95763171e-01, 2.62350641e-01, 2.95743368e-01, 3.11588411e-01,\n",
       "        3.84825594e-01, 3.90472565e-01, 4.48080734e-02, 1.23524893e-01,\n",
       "        3.27534779e-01, 2.63888007e-01, 4.02742841e-02, 8.35400071e-02,\n",
       "        1.35255776e-01, 1.36316470e-01, 4.29252939e-01, 6.50393645e-02,\n",
       "        7.78179434e-02, 3.48278524e-01, 1.08425525e-01, 2.43407180e-01,\n",
       "        7.86296797e-02, 2.43887774e-01, 2.93488468e-02, 1.92724887e-01,\n",
       "        1.66783605e-01, 3.12906692e-01, 3.51674801e-01, 1.18071130e-01,\n",
       "        1.96737244e-01, 4.46284581e-01, 1.13792788e-01, 1.21550265e-01,\n",
       "        1.86739025e-01, 2.36732785e-01, 5.40967209e-01, 1.36754145e-01,\n",
       "        2.52554916e-01, 2.50013769e-01, 4.32677498e-01, 8.01924597e-02,\n",
       "        1.27636120e-01, 7.02624670e-02, 1.46416276e-01, 1.67045873e-01,\n",
       "        7.17670889e-02, 2.08882294e-01, 2.31582557e-01, 7.45315152e-02,\n",
       "        1.54265543e-01, 9.63345081e-02, 3.32561421e-01, 5.15036232e-02,\n",
       "        2.33515846e-01, 1.90905625e-01, 3.39091231e-01, 3.08365112e-01,\n",
       "        3.48587092e-01, 9.58666886e-02, 7.60961766e-02, 5.67453542e-01,\n",
       "        1.23090190e-01, 1.32593320e-01, 4.99146989e-01, 2.51484937e-01,\n",
       "        1.71983478e-01, 2.32055904e-01, 1.74050896e-01, 5.97345827e-01,\n",
       "        1.97760858e-01, 2.17482413e-01, 1.27812351e-01, 5.45167680e-01,\n",
       "        1.86908849e-01, 2.94558985e-01, 2.08434433e-01, 9.24510844e-02,\n",
       "        1.88470110e-01, 1.54131033e-01, 5.98875063e-01, 1.15316907e-01,\n",
       "        9.22558869e-02, 2.29222513e-01, 5.29741544e-02, 4.68112755e-01,\n",
       "        1.64175939e-01, 1.11586220e-01, 2.22667829e-01, 2.13069225e-01,\n",
       "        2.46880025e-01, 1.27467475e-01, 4.21685998e-01, 3.52282367e-01,\n",
       "        9.64686931e-02, 1.19876583e-01, 3.33172150e-01, 9.40341237e-01,\n",
       "        3.77876209e-01, 5.29229485e-02, 8.12017502e-02, 2.35495726e-01,\n",
       "        2.74245325e-01, 6.00470621e-01, 2.31009265e-01, 4.70299760e-02,\n",
       "        2.14415539e-01, 1.52204051e-01, 3.12382363e-01, 2.45267665e-01,\n",
       "        2.87211808e-02, 4.52161376e-01, 1.00581530e-01, 3.77950729e-02,\n",
       "        2.81638418e-01, 8.77198437e-02, 2.28025801e-01, 1.83147518e-01,\n",
       "        1.37859883e-01, 6.56756910e-02, 4.42716286e-02, 3.84919812e-01,\n",
       "        5.67936237e-02, 1.36202513e-01, 6.00842053e-02, 1.01201552e-01,\n",
       "        3.26048977e-01, 2.74904407e-02, 2.19546939e-01, 4.33957305e-02,\n",
       "        1.17750556e-01, 2.66861700e-02, 4.61983777e-02, 1.62352392e-01,\n",
       "        1.49658653e-01, 5.76881449e-02, 2.59982442e-02, 9.86308168e-02,\n",
       "        9.86181760e-02, 6.90185825e-02, 2.60299834e-01, 8.42449387e-02,\n",
       "        2.43358377e-01, 5.29560967e-02, 1.94872016e-02, 3.09085458e-01,\n",
       "        5.97602261e-02, 1.67160295e-01, 4.57329362e-02, 1.59403884e-01,\n",
       "        6.20572362e-02, 1.10779950e-02, 6.41833230e-02, 6.05763121e-02,\n",
       "        2.10528181e-01, 2.06567725e-02, 9.16196541e-02, 2.01358477e-01,\n",
       "        5.57343409e-02, 2.68287462e-01, 1.51825689e-01, 2.95770958e-01,\n",
       "        3.80282619e-01, 9.42008952e-02, 1.90758482e-01, 8.13304520e-02,\n",
       "        1.80396865e-01, 3.06963095e-01, 1.54368233e-01, 3.83362008e-01,\n",
       "        1.14695002e-01, 2.13623865e-02, 2.09270299e-02, 2.26306562e-01,\n",
       "        5.94901021e-02, 4.70691547e-02, 5.03095860e-01, 1.13741473e-01,\n",
       "        1.86371736e-01, 2.57746053e-01, 2.74989366e-01, 5.81608243e-02,\n",
       "        1.68305709e-01, 1.64765538e-01, 4.64263399e-02, 1.37870185e-02,\n",
       "        1.06735828e-01, 1.34552670e-01, 1.47231992e-01, 1.09607006e-01,\n",
       "        2.39984209e-01, 6.28225551e-02, 6.06161982e-02, 2.16869174e-01,\n",
       "        5.21894164e-02, 1.46014658e-01, 6.19923943e-02, 1.40792822e-01,\n",
       "        1.67929765e-02, 2.20970424e-01, 1.68822328e-01, 7.13215922e-02,\n",
       "        7.02314152e-02, 1.51498158e-01, 9.95384183e-02, 2.33133091e-02,\n",
       "        2.49701265e-02, 1.01976395e-01, 1.88255984e-01, 3.23007530e-02,\n",
       "        2.47561580e-01, 4.21680782e-02, 3.66190319e-01, 4.94527899e-01,\n",
       "        3.60360460e-01, 1.88153258e-01, 1.00839387e-01, 1.47595009e-01,\n",
       "        1.71708830e-01, 9.03626904e-02, 2.08208378e-01, 1.00717177e-01,\n",
       "        1.24641388e-01, 1.26995130e-01, 1.22489520e-01, 2.77947709e-01,\n",
       "        3.32970015e-02, 1.70814580e-01, 6.96553647e-02, 3.41944715e-01,\n",
       "        3.32717070e-02, 3.02359050e-02, 4.53798365e-01, 1.71135250e-02,\n",
       "        1.93110086e-01, 1.84049276e-01, 5.62115351e-02, 2.21513614e-01,\n",
       "        8.35667467e-02, 2.39230755e-02, 1.83207250e-01, 2.57574354e-02,\n",
       "        1.86209544e-01, 1.72940048e-01]),\n",
       " 'mean_score_time': array([0.40723594, 0.38154968, 0.48738313, 0.37180479, 0.5874579 ,\n",
       "        0.39609385, 0.42503524, 0.36871529, 0.41676784, 0.40124305,\n",
       "        0.350957  , 0.40671627, 0.45210942, 0.41638152, 0.45312182,\n",
       "        0.53485854, 0.36051194, 0.38781921, 0.38963064, 0.36590234,\n",
       "        0.38657006, 0.57662519, 0.38789654, 0.42490904, 0.40354458,\n",
       "        0.39171147, 0.40578238, 0.40916491, 0.41860874, 0.43290861,\n",
       "        0.45553978, 0.38605007, 0.38403169, 0.37973984, 0.4172349 ,\n",
       "        0.38837115, 0.49578206, 0.34455458, 0.36011163, 0.37496241,\n",
       "        0.41468279, 0.37905447, 0.40128787, 0.37149429, 0.33941754,\n",
       "        1.1240991 , 0.54971536, 0.53103375, 0.36776018, 0.38328425,\n",
       "        0.39096355, 0.59269158, 0.428526  , 0.4072419 , 0.40964103,\n",
       "        0.51694091, 0.3553501 , 0.41651408, 0.35561482, 0.33132052,\n",
       "        0.50319735, 0.46989441, 0.33275779, 0.35879207, 0.37961268,\n",
       "        0.39422894, 0.5484755 , 0.48082423, 0.39800374, 0.4564627 ,\n",
       "        0.3451105 , 0.35848061, 0.39023217, 0.33947285, 0.36194714,\n",
       "        0.44753114, 0.38537153, 0.35911854, 0.33816862, 0.31920719,\n",
       "        0.31431135, 0.50810941, 0.33164231, 0.34348909, 0.36167518,\n",
       "        0.37023671, 0.32750424, 0.32708629, 0.35349735, 0.33132641,\n",
       "        0.49199899, 0.35148907, 0.36202343, 0.3212467 , 0.57016285,\n",
       "        0.3419772 , 0.34591405, 0.32772938, 0.34498096, 0.32438827,\n",
       "        0.83291483, 0.39894994, 0.31311615, 0.31472206, 0.77116291,\n",
       "        0.45871298, 0.36238869, 0.35864933, 0.37029568, 1.25945934,\n",
       "        0.32015618, 0.31294966, 0.30800128, 0.30819321, 0.32766358,\n",
       "        0.33776402, 0.51556277, 0.44004003, 1.17859817, 0.47423077,\n",
       "        0.51191966, 0.73523458, 0.50654022, 0.48648469, 0.51276207,\n",
       "        0.45775231, 0.40577928, 0.49776626, 0.45103757, 0.3735683 ,\n",
       "        0.4098018 , 0.37004709, 0.41833146, 0.53092829, 0.4178888 ,\n",
       "        0.37014516, 0.421743  , 0.37901235, 0.38123782, 0.41899538,\n",
       "        0.33281636, 0.41472562, 0.50930365, 0.3494796 , 0.41952252,\n",
       "        0.33566173, 0.36316331, 0.32512983, 0.33709311, 0.51227999,\n",
       "        0.31598759, 0.31231642, 0.33782967, 0.31859867, 0.31629229,\n",
       "        0.32116516, 0.3259635 , 0.33882229, 0.34880781, 0.31411537,\n",
       "        0.30060673, 0.34591516, 0.45342143, 0.30009707, 0.33393184,\n",
       "        0.3005538 , 0.29810882, 0.32752697, 0.30487204, 0.315166  ,\n",
       "        0.45753908, 0.32887419, 0.30883233, 0.30631733, 0.32772112,\n",
       "        0.32303826, 0.32271306, 0.30100457, 0.34856335, 0.31100186,\n",
       "        0.30244335, 0.49163405, 0.30774498, 0.33458893, 0.30433734,\n",
       "        0.32354689, 0.31932465, 0.44127472, 0.48900127, 0.41391524,\n",
       "        0.32896558, 0.29650259, 0.45743155, 0.30323958, 0.30411069,\n",
       "        0.30844426, 0.43480802, 0.31279802, 0.2836113 , 0.27826269,\n",
       "        0.35185456, 0.31344   , 0.32222795, 0.43312112, 0.35052657,\n",
       "        0.30859812, 0.29998342, 0.3253483 , 0.31500276, 0.30060641,\n",
       "        0.29391535, 0.31326509, 0.35826047, 0.30835303, 0.32657003,\n",
       "        0.30180566, 0.47118545, 0.29536613, 0.29645491, 0.35369174,\n",
       "        0.31036758, 0.32350906, 0.29060634, 0.33829888, 0.34818141,\n",
       "        0.35842816, 0.31283712, 0.31255174, 0.3020854 , 0.29977012,\n",
       "        0.31331046, 0.3324004 , 0.31655534, 0.35511192, 0.55520105,\n",
       "        0.30563895, 0.37406389, 0.39799047, 0.5051616 , 0.32108053,\n",
       "        0.36792374, 0.35485021, 0.29418929, 0.33705036, 0.29397289,\n",
       "        0.35499072, 0.36940924, 0.44644825, 0.41854095, 0.34506249,\n",
       "        0.35141468, 0.3471326 , 0.3988169 , 0.38222019, 0.39361366,\n",
       "        0.33405217, 0.38847844, 0.32712555, 0.52426688, 0.34724816,\n",
       "        0.49541545, 0.33024073, 0.34605781, 0.32909894, 0.5754203 ,\n",
       "        0.61196804, 0.42696063, 0.54914292, 0.40730651, 0.65928157,\n",
       "        0.26451278, 0.39596097, 0.34629178, 0.36000268, 0.31666144,\n",
       "        0.38626583, 0.45500191, 0.43177048, 0.30522251, 0.52626808,\n",
       "        0.4447457 , 0.50088573, 0.32096624, 0.33590182, 0.36570207,\n",
       "        0.34781051, 0.31465991, 0.31582228, 0.29672869, 0.39972862,\n",
       "        0.3410058 , 0.42088572, 0.32874719, 0.38792245, 0.54018601,\n",
       "        0.3232789 , 0.2821211 , 0.35648012, 0.3055168 , 0.32551813,\n",
       "        0.33538707, 0.31686163, 0.3840541 , 0.39508692, 0.35627143,\n",
       "        0.41611242, 0.39127541, 0.65635014, 0.44242056, 0.34368245,\n",
       "        0.39541388, 0.34053866, 0.33284227, 0.35065365, 0.30940866,\n",
       "        0.31910427, 0.35694114, 0.35656389, 0.33265003, 0.33776267,\n",
       "        0.35310507, 0.37914348, 0.36329659, 0.37761927, 0.4232645 ,\n",
       "        0.56472715, 0.32923142, 0.54710539, 0.32635474, 0.58396928,\n",
       "        0.40682093, 0.39393902, 0.55531796, 0.53484241, 0.4224929 ,\n",
       "        0.54118927, 0.56173849, 0.40962895, 0.37806519, 0.71737647,\n",
       "        0.33611163, 0.32902352, 0.36718003, 0.37909555, 0.40534019,\n",
       "        0.36883434, 0.30837965, 0.40854104, 0.31820615, 0.62302796,\n",
       "        0.75170231, 0.34133895, 0.40737057, 0.36904438, 0.33644589,\n",
       "        0.51748745, 0.49708867, 0.31336633, 0.40695906, 0.41572769,\n",
       "        0.33588346, 0.3606813 , 0.48059694, 0.43979025, 0.36341278,\n",
       "        0.34878898, 0.58390395, 0.40231752, 0.41670124, 0.33673056,\n",
       "        0.37649441, 0.37821372, 0.53379949, 0.34474587, 0.43405422,\n",
       "        0.43342392, 0.45276157, 0.36136476, 0.35018929, 0.35233307,\n",
       "        0.30297311, 0.49268262, 0.38612318, 0.32018971, 0.4606576 ,\n",
       "        0.30879792, 0.49757759, 0.34341486, 0.29877861, 0.33755596,\n",
       "        0.33317439, 0.45511603, 0.31810435, 0.51233117, 0.29819202,\n",
       "        0.38312372, 0.3313307 , 0.34029595, 0.33989302, 0.59349807,\n",
       "        0.32235289, 0.33996884, 0.54217362, 0.33736881, 0.37627522,\n",
       "        0.34033966, 0.45379313, 0.36638292, 0.58955288, 0.4479719 ,\n",
       "        0.40569687, 0.38746285, 0.40092508, 0.53996086, 0.36800218,\n",
       "        0.53782709, 0.37657205, 0.44364611, 0.47221239, 0.39727767,\n",
       "        0.77387285, 0.39644337, 0.56819399, 0.38549383, 0.52372281,\n",
       "        0.36741678, 0.59131368, 0.30493561, 0.36902984, 0.30359896,\n",
       "        0.27539349, 0.45423516, 0.46150168, 0.75569201, 0.49336775,\n",
       "        0.43400757, 0.63929741, 0.41451422, 0.62083173, 0.48370806,\n",
       "        0.57602501, 0.3764987 , 0.35336598, 0.44041816, 0.37385456,\n",
       "        0.29985189, 0.35581883, 0.35526546, 0.33613451, 0.37776232,\n",
       "        0.35016282, 0.33165042, 0.30560374, 0.34588401, 0.42434033,\n",
       "        0.28822509, 0.28885245, 0.32890097, 0.28600844, 0.35932295,\n",
       "        0.3490262 , 0.27465216, 0.34372576, 0.32379421, 0.33148249,\n",
       "        0.5103213 , 0.32527844, 0.32857084, 0.51466179, 0.563845  ,\n",
       "        0.4591922 , 0.4733719 , 0.51695434, 0.46815801, 0.4569753 ,\n",
       "        0.53186051, 0.36677941, 0.32277306, 0.29278835, 0.5217642 ,\n",
       "        0.27426155, 0.36414846, 0.54743489, 0.43208377, 0.4707106 ,\n",
       "        0.53226733, 0.474521  , 0.37070727, 0.55823294, 0.40272101,\n",
       "        0.38132175, 0.52277184, 0.62032906, 0.47274844, 0.45308042,\n",
       "        0.52934988, 0.46965766, 0.42986123, 0.4305222 , 0.43627739,\n",
       "        0.57416471, 0.41280953, 0.42592072, 0.58896494, 0.43031224,\n",
       "        0.65211519, 0.43135556, 0.70366939, 0.40510956, 0.35183382,\n",
       "        0.55456169, 0.39944434, 0.52282302, 0.34146825, 0.54647422,\n",
       "        0.35597833, 0.39930805, 0.62112808, 0.36604897, 0.36696394,\n",
       "        0.39566501, 0.34019891, 0.31766756, 0.35760689, 0.48934301,\n",
       "        0.32380557, 0.32751664, 0.35146658, 0.49735395, 0.35445229,\n",
       "        0.35228578, 0.34804813, 0.3134013 , 0.50117628, 0.38915086,\n",
       "        0.48678557, 0.34087888, 0.34198332, 0.51621858, 0.31865986,\n",
       "        0.3925906 , 0.35196733, 0.37290597, 0.32422932, 0.31230585,\n",
       "        0.46462194, 0.32170447, 0.35490378, 0.3099939 , 0.47678979,\n",
       "        0.35697707, 0.30380479, 0.35570351, 0.32680972, 0.43702793,\n",
       "        0.29898715, 0.47792776, 0.31044324, 0.31022263, 0.53041267,\n",
       "        0.28642559, 0.32823316, 0.33678516, 0.30935884, 0.35654521,\n",
       "        0.33386453, 0.49575377, 0.40400704, 0.57155077, 0.43261989,\n",
       "        0.62929527, 0.41540233, 0.43203123, 0.4939669 , 0.37556744,\n",
       "        0.47252591, 0.32803043, 0.43605081, 0.41427962, 0.43457341,\n",
       "        0.42029794, 0.39331071, 0.39177791, 0.33788872, 0.35914946,\n",
       "        0.54966116, 0.44870869, 0.59725102, 0.34664814, 0.51254169,\n",
       "        0.32049839, 0.38646785, 0.49844956, 0.4481674 , 0.38349938,\n",
       "        0.39713995, 0.39338168, 0.41389235, 0.39078347, 0.37624828,\n",
       "        0.41005985, 0.46994789, 0.39275972, 0.45734231, 0.46618946,\n",
       "        0.40132252, 0.34560323, 0.4628636 , 0.56852166, 0.37425884,\n",
       "        0.38087773, 0.62629835, 0.44614204, 0.56101791, 0.34610995,\n",
       "        0.56441673, 0.35800378, 0.36285822, 0.35442082, 0.4127233 ,\n",
       "        0.37991103, 0.34614388, 0.40164097, 0.35105054, 0.37978323,\n",
       "        0.57638152, 0.36947354, 0.45844618, 0.3916862 , 0.48004341,\n",
       "        0.3847634 , 0.40396388, 0.36146681, 0.35523812, 0.60396139,\n",
       "        0.39473224, 0.3454299 , 0.38611118, 0.36514918, 0.36057679,\n",
       "        0.38035599, 0.38961323, 0.38231587, 0.35982323, 0.56489269,\n",
       "        0.60719403, 0.56564768, 0.4387002 , 0.45780611, 0.64599435,\n",
       "        0.37093925, 0.42248313, 0.3829608 , 0.35542965, 0.35095533,\n",
       "        0.38596582, 0.35816042, 0.38162001, 0.39519374, 0.35748768,\n",
       "        0.38551513, 0.36639404, 0.40014863, 0.3818775 , 0.37290963,\n",
       "        0.55332828, 0.3952771 , 0.35355814, 0.67496101, 0.32901716,\n",
       "        0.29539458, 0.274834  , 0.46280042, 0.27623423, 0.30358521,\n",
       "        0.2450912 , 0.23009189, 0.30714122, 0.27815445, 0.27342558,\n",
       "        0.28241547, 0.31128208, 0.3296446 , 0.33825962, 0.47073849,\n",
       "        0.27409625, 0.24174484, 0.26377106, 0.34586716, 0.26219861,\n",
       "        0.26633604, 0.26655563, 0.25846275, 0.27133981, 0.24504503,\n",
       "        0.25093246, 0.25385483, 0.24407013, 0.25485969, 0.24443332,\n",
       "        0.2606415 , 0.37864526, 0.23982175, 0.43985367, 0.29274201,\n",
       "        0.27074877, 0.2720538 , 0.28689162, 0.27235095, 0.24336831,\n",
       "        0.26032408, 0.27545023, 0.2477018 , 0.22178245, 0.22323855,\n",
       "        0.39682595, 0.2199324 , 0.22597679, 0.38551847, 0.20809197,\n",
       "        0.24264892, 0.24529568, 0.25498509, 0.23764269, 0.31978949,\n",
       "        0.24069834, 0.2425077 , 0.7370398 , 0.24973909, 0.30803935,\n",
       "        0.22582436, 0.23760605, 0.22971137, 0.33582981, 0.38008984,\n",
       "        0.25014695, 0.28618741, 0.38192121, 0.28256949, 0.42859999,\n",
       "        0.24848564, 0.22177211, 0.35551516, 0.4220988 , 0.30597862,\n",
       "        0.26748157, 0.41234549, 0.40397056, 0.3087852 , 0.2524298 ,\n",
       "        0.24160425, 0.2189676 , 0.26157578, 0.238928  , 0.24863474,\n",
       "        0.26098617, 0.29793922, 0.24196641, 0.3247993 , 0.27609317,\n",
       "        0.27181117, 0.23477387, 0.26552836, 0.24693378, 0.35963853,\n",
       "        0.23542182, 0.27692676, 0.24338706, 0.24577061, 0.26691779,\n",
       "        0.23020625, 0.36814658, 0.26500877, 0.28627165, 0.25944829,\n",
       "        0.27856795, 0.23143291, 0.25564901, 0.23910491, 0.70773149,\n",
       "        0.33992147, 0.26013406, 0.31827521, 0.48985457, 0.39857833,\n",
       "        0.31406728, 0.32956266, 0.30524691, 0.53085915, 0.27821151,\n",
       "        0.31619684, 0.28715698, 0.28934876, 0.28005362, 0.28310275,\n",
       "        0.30839817, 0.26090169, 0.26536258, 0.2482729 , 0.28051392,\n",
       "        0.24873988, 0.28094101, 0.25367244, 0.27965538, 0.26886392,\n",
       "        0.40245366, 0.29937855, 0.26961446, 0.28680595, 0.26272154]),\n",
       " 'std_score_time': array([6.83949768e-02, 4.40548428e-02, 1.55570780e-01, 6.08858984e-02,\n",
       "        2.09326640e-01, 3.32415530e-02, 2.00375626e-02, 9.35878528e-03,\n",
       "        4.02242667e-02, 2.73282157e-02, 5.70317186e-02, 1.35781393e-02,\n",
       "        1.08190334e-01, 4.30719153e-02, 4.53498658e-02, 1.65946545e-01,\n",
       "        1.39372208e-02, 4.18757244e-02, 5.30979196e-02, 3.33402881e-02,\n",
       "        5.84101584e-02, 3.18817796e-01, 1.37309001e-02, 2.18434619e-02,\n",
       "        5.08868164e-02, 3.97990045e-02, 4.03221293e-02, 1.06339557e-02,\n",
       "        2.32497873e-02, 8.43859359e-02, 1.30281194e-01, 6.26281898e-02,\n",
       "        2.33195988e-02, 4.66411708e-02, 1.72432951e-02, 7.90729669e-02,\n",
       "        1.97055442e-01, 3.28854540e-02, 5.27409567e-02, 4.71978318e-02,\n",
       "        4.77945626e-02, 1.72396372e-02, 7.15955524e-02, 1.84002057e-02,\n",
       "        8.86741963e-03, 5.03786100e-01, 1.07681613e-01, 3.58643088e-02,\n",
       "        7.14839823e-02, 2.75285020e-02, 3.60383774e-02, 2.91581896e-01,\n",
       "        3.90150138e-02, 9.62548363e-02, 4.65149996e-02, 1.49681692e-01,\n",
       "        2.05937576e-02, 6.56771531e-02, 3.48625267e-02, 8.57834987e-03,\n",
       "        1.99359072e-01, 6.61136726e-02, 4.29891687e-02, 2.59496868e-02,\n",
       "        9.63303692e-03, 4.48125915e-02, 2.96351808e-01, 7.96541236e-02,\n",
       "        7.09847131e-02, 9.73639406e-02, 3.81003274e-02, 4.95493030e-02,\n",
       "        3.59443889e-02, 2.96462968e-02, 6.58867171e-02, 1.30223434e-01,\n",
       "        3.85586793e-02, 8.98676249e-03, 2.51793951e-02, 1.72728751e-02,\n",
       "        3.79784239e-02, 1.74977051e-01, 3.53722449e-02, 3.39329183e-02,\n",
       "        2.66695405e-02, 3.50415015e-03, 3.26736810e-02, 3.02168541e-02,\n",
       "        2.24215601e-02, 2.62069776e-02, 1.64185270e-01, 1.34934466e-02,\n",
       "        7.60639551e-03, 3.84571836e-02, 1.53755352e-01, 1.82704236e-02,\n",
       "        3.07542720e-02, 6.73395894e-03, 2.92099836e-02, 1.95511949e-02,\n",
       "        7.01127106e-01, 4.04120883e-02, 3.64485136e-02, 3.06948570e-02,\n",
       "        6.16125988e-01, 2.02287267e-01, 2.24571336e-02, 3.05136482e-02,\n",
       "        1.27736115e-02, 1.37315160e+00, 4.91275641e-02, 1.15377535e-02,\n",
       "        2.79318108e-02, 1.42869814e-02, 3.25093383e-02, 2.08306729e-02,\n",
       "        2.24410993e-01, 7.38982649e-02, 7.50928959e-01, 3.31983114e-02,\n",
       "        2.23266718e-02, 1.47630859e-01, 9.47645126e-02, 1.09968673e-01,\n",
       "        4.58524403e-02, 7.33281340e-02, 4.71835174e-03, 5.87492120e-02,\n",
       "        8.90437371e-02, 3.67691402e-02, 6.59400681e-02, 1.42877222e-02,\n",
       "        7.08547415e-02, 1.72973082e-01, 4.82469531e-02, 8.06664772e-02,\n",
       "        7.22800652e-02, 6.79497843e-02, 1.01729700e-01, 7.52378229e-02,\n",
       "        1.10483183e-02, 2.91781875e-02, 2.04944328e-01, 2.25455140e-02,\n",
       "        3.26784453e-02, 1.76997530e-02, 4.91567277e-02, 8.22120522e-03,\n",
       "        4.69653922e-03, 1.21678693e-01, 1.90492535e-02, 2.49645999e-02,\n",
       "        3.40105382e-02, 1.69137292e-02, 1.54827077e-02, 4.48156200e-02,\n",
       "        1.64273006e-02, 4.48572175e-02, 2.31638256e-02, 1.75627472e-02,\n",
       "        2.84115987e-02, 2.34057020e-02, 2.20642954e-01, 4.03585580e-02,\n",
       "        2.62422963e-02, 4.16567740e-02, 3.19747533e-03, 5.75295699e-02,\n",
       "        1.21829917e-02, 9.79868420e-03, 1.89822575e-01, 2.49692535e-02,\n",
       "        3.00662586e-02, 1.72772113e-02, 1.81560572e-02, 9.26946502e-03,\n",
       "        3.97233512e-02, 2.10389925e-02, 5.04220565e-02, 3.68960063e-02,\n",
       "        7.99259708e-03, 2.51911927e-01, 1.10844558e-02, 3.39938837e-02,\n",
       "        1.91489001e-02, 1.45651413e-02, 6.31393072e-02, 6.30862462e-02,\n",
       "        1.53143603e-01, 2.04140130e-02, 1.16030348e-02, 2.14393259e-02,\n",
       "        1.71437981e-01, 1.83819464e-02, 3.63775559e-03, 1.66295076e-02,\n",
       "        1.88271310e-01, 5.73686285e-02, 3.06951577e-03, 1.23170731e-02,\n",
       "        6.80335559e-02, 3.35067151e-02, 6.90883467e-03, 2.02827970e-01,\n",
       "        2.16124033e-02, 8.51054630e-03, 2.68941077e-02, 7.09881911e-02,\n",
       "        4.19016092e-03, 1.30272365e-02, 2.80490605e-02, 1.03190626e-02,\n",
       "        2.58918448e-02, 3.07615686e-02, 2.34351020e-02, 3.37390581e-02,\n",
       "        2.02860845e-01, 3.18984407e-02, 1.73292560e-02, 3.21306569e-02,\n",
       "        1.76813362e-02, 5.01623904e-02, 2.38286373e-02, 8.73739087e-03,\n",
       "        2.24384228e-02, 1.47667226e-02, 5.16758020e-03, 7.84545442e-03,\n",
       "        1.99114268e-02, 4.65694905e-02, 7.73529742e-03, 3.25841561e-02,\n",
       "        2.30905409e-03, 7.29856979e-02, 2.92559777e-01, 6.78290234e-03,\n",
       "        8.60069948e-02, 1.61665265e-02, 1.66261860e-01, 2.04550235e-02,\n",
       "        3.44572994e-02, 5.28027336e-02, 1.77533075e-02, 3.73795286e-02,\n",
       "        6.15305102e-03, 9.42397070e-02, 4.71234989e-02, 2.32713281e-01,\n",
       "        8.39218332e-02, 7.85081903e-02, 3.06911416e-02, 1.62965349e-02,\n",
       "        4.32754564e-02, 9.93475334e-02, 6.93582797e-02, 4.56570657e-02,\n",
       "        9.22407189e-02, 2.99311667e-02, 2.61425849e-01, 1.12872117e-02,\n",
       "        2.17192599e-01, 4.92053659e-02, 2.03548998e-02, 2.17537017e-02,\n",
       "        3.47558041e-02, 2.50581675e-01, 1.26342770e-01, 1.01940468e-01,\n",
       "        5.80336785e-02, 1.25940578e-01, 2.74355154e-02, 4.93736974e-02,\n",
       "        1.58312574e-02, 6.03630088e-02, 1.54243409e-02, 7.16681036e-02,\n",
       "        4.93230440e-02, 1.23405959e-01, 3.58490930e-02, 4.61326526e-02,\n",
       "        4.25113059e-02, 2.24217235e-01, 3.92280379e-02, 9.27909640e-03,\n",
       "        3.99091704e-02, 2.98241421e-02, 2.55755743e-02, 3.46100341e-02,\n",
       "        4.12643020e-02, 1.09067043e-01, 6.68904205e-02, 2.18371853e-01,\n",
       "        2.87888530e-02, 5.64811602e-02, 2.98773347e-01, 3.47542664e-02,\n",
       "        3.58558649e-02, 7.08536375e-02, 4.43962617e-02, 1.40002902e-02,\n",
       "        2.70692341e-02, 1.02402698e-02, 5.83273376e-02, 4.43474770e-03,\n",
       "        1.78719906e-02, 4.13436997e-02, 1.83260427e-02, 3.70363987e-01,\n",
       "        1.36623386e-02, 5.58078765e-02, 4.68487971e-02, 2.60336097e-02,\n",
       "        6.26705686e-03, 4.10544388e-02, 1.96637518e-02, 1.63622860e-02,\n",
       "        1.64327588e-02, 3.05384100e-02, 1.64495285e-02, 1.34379332e-02,\n",
       "        1.34586744e-02, 7.54975533e-02, 3.49992830e-02, 5.14016075e-02,\n",
       "        4.43537454e-02, 2.75600301e-01, 5.45783700e-03, 1.83783070e-01,\n",
       "        2.65176519e-02, 1.22787329e-01, 7.49598095e-02, 7.87482692e-02,\n",
       "        1.44397059e-01, 9.92507250e-02, 1.22688018e-01, 2.23853356e-01,\n",
       "        2.10096837e-01, 5.65789776e-02, 1.62925413e-03, 3.13968894e-01,\n",
       "        3.00374388e-02, 1.35937697e-02, 4.50967563e-02, 2.78102358e-02,\n",
       "        6.32463509e-02, 8.49382534e-03, 1.74287485e-02, 7.92776233e-02,\n",
       "        3.03480788e-02, 1.74791470e-01, 4.85401763e-01, 6.27812638e-02,\n",
       "        7.42723418e-02, 6.56402788e-02, 4.20060618e-02, 1.35780485e-01,\n",
       "        2.28931626e-01, 4.76499360e-02, 4.19235318e-02, 9.48194388e-02,\n",
       "        3.77223363e-02, 5.01633995e-02, 6.23206556e-02, 9.79878079e-02,\n",
       "        3.63870951e-02, 3.96332335e-02, 2.95091145e-01, 3.30877584e-02,\n",
       "        8.00008469e-02, 4.94462403e-02, 1.03218827e-01, 2.77617543e-02,\n",
       "        2.48629896e-01, 2.49709159e-02, 5.65979375e-02, 1.31604464e-01,\n",
       "        1.11432696e-01, 4.17337764e-02, 5.94217702e-02, 4.24069105e-02,\n",
       "        2.73189407e-02, 2.39129065e-01, 5.78968138e-02, 3.52118178e-02,\n",
       "        1.80386753e-01, 4.40863577e-02, 2.04271233e-01, 4.78053581e-02,\n",
       "        3.06368042e-02, 4.89952665e-02, 4.27633748e-02, 6.50966218e-02,\n",
       "        3.81675722e-02, 2.71257960e-01, 2.75371234e-02, 1.86657493e-02,\n",
       "        3.92331465e-02, 4.84759360e-02, 6.86012067e-02, 2.49354203e-01,\n",
       "        3.88188641e-03, 4.58278111e-02, 2.35411008e-01, 5.55584994e-02,\n",
       "        2.54456952e-02, 1.87195011e-02, 4.37609680e-02, 2.42184852e-02,\n",
       "        2.39997725e-01, 5.85234318e-02, 5.48703423e-02, 4.86760849e-03,\n",
       "        4.63233684e-02, 2.25725811e-01, 2.96182152e-02, 1.06956614e-01,\n",
       "        1.52812594e-02, 2.31158697e-02, 1.03825029e-01, 4.11786668e-02,\n",
       "        9.26494548e-02, 3.05091726e-02, 1.63517384e-01, 5.38651200e-02,\n",
       "        1.24129788e-01, 4.51581109e-02, 2.00229702e-01, 1.14684611e-03,\n",
       "        1.37785865e-01, 2.25852303e-02, 2.64030271e-02, 1.86310129e-01,\n",
       "        3.37332903e-02, 2.95346782e-01, 1.80653757e-02, 1.77300886e-02,\n",
       "        2.35797416e-01, 7.03376536e-03, 2.57192217e-01, 5.39530143e-02,\n",
       "        2.32141165e-01, 4.00315687e-02, 9.45243528e-03, 1.94644309e-01,\n",
       "        4.20884066e-02, 2.15576610e-02, 4.82987645e-02, 4.79283443e-02,\n",
       "        3.74639984e-02, 5.00141330e-03, 9.44842041e-02, 4.77305704e-02,\n",
       "        6.29260537e-03, 6.53181104e-02, 1.90654850e-01, 3.57091219e-02,\n",
       "        2.48454765e-02, 1.26930807e-02, 2.68995888e-02, 8.51458704e-02,\n",
       "        4.56144546e-02, 1.47588192e-02, 2.13656749e-02, 1.63853210e-02,\n",
       "        6.87697797e-02, 2.87575578e-01, 1.15928564e-02, 8.97572931e-02,\n",
       "        1.37302979e-02, 9.99710685e-02, 8.29854558e-02, 3.82504205e-02,\n",
       "        2.14854938e-02, 1.24138263e-02, 1.97832425e-02, 3.22016600e-01,\n",
       "        6.57231931e-02, 1.92897629e-02, 2.16353153e-02, 2.18691612e-01,\n",
       "        2.98018218e-02, 7.31901182e-02, 2.34962351e-01, 4.57126148e-02,\n",
       "        4.84952053e-02, 9.74597903e-02, 6.18112218e-02, 8.93252235e-03,\n",
       "        1.73878404e-01, 3.73117132e-02, 5.59208109e-03, 4.87854570e-02,\n",
       "        3.32816040e-01, 8.54083999e-02, 3.09279445e-02, 1.33308042e-01,\n",
       "        4.93241656e-02, 2.52001851e-02, 2.99547856e-02, 8.14700404e-02,\n",
       "        2.08431095e-01, 5.74315270e-02, 3.78228879e-02, 3.36061527e-01,\n",
       "        2.87616838e-02, 1.82948161e-01, 2.29841055e-02, 3.65997322e-01,\n",
       "        3.83024199e-02, 1.29876829e-02, 2.22042946e-01, 3.42731704e-02,\n",
       "        1.64578259e-01, 1.64305212e-02, 2.24836007e-01, 1.46554101e-02,\n",
       "        4.84500652e-02, 2.49044666e-01, 1.05212745e-02, 1.72249099e-02,\n",
       "        3.68870491e-02, 5.00500698e-03, 2.36636915e-03, 3.67279134e-02,\n",
       "        2.09373665e-01, 2.25216648e-02, 3.78076131e-02, 3.90189216e-03,\n",
       "        1.97200004e-01, 2.59133345e-02, 2.98832964e-02, 3.76336055e-02,\n",
       "        1.12294268e-02, 2.01345832e-01, 8.26114122e-02, 1.41760563e-01,\n",
       "        2.96790386e-02, 4.64834138e-02, 2.29930590e-01, 3.41765820e-02,\n",
       "        1.37549683e-01, 3.99677892e-02, 3.62317695e-02, 1.46836745e-02,\n",
       "        1.35663045e-02, 2.24143632e-01, 2.82633948e-02, 2.10584009e-02,\n",
       "        1.75494457e-02, 2.09366658e-01, 7.68802796e-02, 3.42270711e-02,\n",
       "        2.29385688e-02, 1.11555396e-02, 2.39626147e-01, 2.55491031e-02,\n",
       "        2.27329265e-01, 7.34480313e-03, 3.84759531e-02, 2.96198679e-01,\n",
       "        2.53985009e-02, 1.98207973e-02, 4.62601200e-02, 1.56974457e-02,\n",
       "        2.10710230e-02, 3.78661511e-02, 2.20394014e-01, 2.20533346e-02,\n",
       "        1.32764287e-01, 9.05474961e-02, 2.34865301e-01, 5.29176644e-02,\n",
       "        2.28752489e-02, 7.14307994e-02, 7.33269673e-02, 1.05653314e-01,\n",
       "        1.83844713e-02, 2.74131762e-02, 5.40247152e-02, 9.14471356e-02,\n",
       "        5.78179177e-02, 6.79901984e-02, 4.29520463e-02, 4.17777091e-03,\n",
       "        2.64576965e-02, 2.69156089e-01, 6.10304730e-02, 2.58504285e-01,\n",
       "        3.22064141e-02, 2.33232874e-01, 2.67061579e-02, 8.12381046e-02,\n",
       "        2.50938882e-01, 1.33539584e-01, 2.40266495e-02, 6.44323210e-02,\n",
       "        3.91789998e-02, 6.99829039e-02, 7.15443697e-02, 7.03646768e-02,\n",
       "        4.43594167e-02, 1.22552546e-01, 5.31247412e-02, 1.00435467e-01,\n",
       "        1.61657637e-01, 4.17928726e-02, 2.13217120e-02, 1.89489510e-02,\n",
       "        2.32768288e-01, 5.67136471e-03, 1.99373876e-02, 2.91556292e-01,\n",
       "        6.80289731e-02, 1.89758722e-01, 1.63489138e-02, 3.01224432e-01,\n",
       "        2.70992990e-02, 1.41472148e-02, 7.05617661e-02, 2.22637948e-02,\n",
       "        1.30495401e-02, 3.10745682e-02, 1.16456544e-01, 5.04914814e-03,\n",
       "        5.29249117e-02, 2.61916576e-01, 4.64686196e-02, 8.80252451e-02,\n",
       "        2.75321642e-02, 8.46056418e-02, 2.92466004e-02, 4.52746682e-02,\n",
       "        5.57125368e-02, 2.99184457e-02, 2.42920212e-01, 3.60785920e-02,\n",
       "        3.75455559e-02, 2.82684991e-02, 5.08843527e-02, 1.84754317e-02,\n",
       "        1.62059778e-02, 4.87319370e-02, 2.86027185e-02, 1.86731019e-02,\n",
       "        2.10432717e-01, 1.05225993e-01, 2.68289969e-01, 6.44234534e-02,\n",
       "        6.80067056e-02, 3.82603898e-01, 4.26851080e-02, 5.34577067e-02,\n",
       "        8.46913693e-03, 1.64698239e-02, 3.08575695e-02, 5.42202814e-02,\n",
       "        2.66867709e-02, 2.98535376e-02, 1.52818910e-02, 1.63306105e-02,\n",
       "        6.70139498e-02, 3.81278453e-02, 4.07558750e-02, 2.86034951e-02,\n",
       "        2.12415960e-02, 2.18441160e-01, 4.23517301e-02, 6.27354519e-02,\n",
       "        4.07325030e-01, 4.85249281e-02, 3.63486037e-02, 9.35683805e-03,\n",
       "        2.00046447e-01, 1.20822514e-02, 2.66603642e-02, 1.52308828e-02,\n",
       "        2.59855583e-02, 3.71673367e-02, 2.70283374e-02, 2.73939121e-02,\n",
       "        2.02827669e-02, 2.93985848e-02, 1.11031966e-01, 1.02581313e-01,\n",
       "        1.71981889e-01, 3.20302028e-02, 2.10008411e-02, 2.84441293e-02,\n",
       "        2.35813767e-02, 2.90735026e-02, 2.40858798e-02, 2.68183684e-02,\n",
       "        3.87713903e-03, 1.71814155e-02, 1.08163959e-02, 4.30260656e-02,\n",
       "        3.37305991e-03, 1.07784198e-02, 3.47575562e-03, 3.54811945e-02,\n",
       "        1.24103930e-02, 1.71402539e-01, 2.15767574e-02, 2.46442930e-01,\n",
       "        7.94857847e-03, 2.93418906e-02, 4.01491632e-02, 1.12018201e-02,\n",
       "        1.97721798e-02, 2.16872122e-02, 1.26618956e-02, 6.07083774e-02,\n",
       "        1.49677191e-02, 1.31570536e-02, 8.47641201e-03, 1.63592425e-01,\n",
       "        1.78605486e-02, 1.75313683e-02, 1.95431877e-01, 1.93024200e-02,\n",
       "        8.49451143e-03, 1.91888643e-02, 2.25876090e-02, 1.49962500e-02,\n",
       "        2.80078188e-02, 1.84333952e-02, 1.49738021e-02, 6.20247382e-01,\n",
       "        2.57505627e-03, 5.28028756e-02, 6.30526257e-03, 6.08296687e-03,\n",
       "        5.20443552e-03, 5.59298410e-02, 1.35776202e-01, 1.82661326e-02,\n",
       "        4.74435072e-02, 2.01093572e-01, 6.87820835e-02, 2.28336901e-01,\n",
       "        1.34381477e-03, 5.36897162e-03, 7.44822851e-02, 8.76754778e-02,\n",
       "        3.61673663e-02, 4.64715450e-02, 1.84814909e-01, 2.19768836e-01,\n",
       "        4.89636314e-02, 3.07293491e-02, 2.79178516e-02, 5.96813148e-03,\n",
       "        4.11129421e-02, 1.20525176e-02, 3.60537438e-02, 3.84679106e-02,\n",
       "        4.60655062e-02, 9.32261563e-03, 1.43863007e-01, 9.75903121e-03,\n",
       "        1.92311425e-02, 2.62575118e-02, 2.55267553e-03, 4.57163272e-03,\n",
       "        1.65071916e-01, 1.70127772e-02, 6.86869501e-02, 5.11362132e-03,\n",
       "        2.73109065e-02, 4.44444015e-02, 1.50565222e-02, 1.89907377e-01,\n",
       "        3.85644652e-02, 5.84590522e-02, 3.70646881e-02, 3.80268852e-02,\n",
       "        8.17011251e-03, 5.84065455e-03, 2.18193605e-02, 1.92677766e-01,\n",
       "        1.05947572e-01, 1.77940163e-02, 6.70557327e-02, 2.12669479e-01,\n",
       "        1.29373491e-01, 1.52710395e-02, 1.12503913e-02, 1.93974366e-02,\n",
       "        3.36644124e-01, 3.21478356e-02, 1.22124071e-02, 2.92927842e-02,\n",
       "        5.45942167e-02, 3.05455064e-02, 2.26660467e-02, 3.32200060e-02,\n",
       "        1.41085307e-02, 1.74230743e-02, 7.20612670e-03, 2.18228100e-02,\n",
       "        7.90307821e-03, 4.26858248e-03, 2.34788329e-02, 3.99430480e-02,\n",
       "        2.42474519e-02, 2.04584894e-01, 5.37948472e-02, 7.36076071e-03,\n",
       "        2.12184618e-02, 1.51759774e-02]),\n",
       " 'param_activation': masked_array(data=['tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_epochs': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_neurons': masked_array(data=[8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32,\n",
       "                    64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8,\n",
       "                    32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32,\n",
       "                    32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64, 64, 8, 8,\n",
       "                    8, 32, 32, 32, 64, 64, 64, 8, 8, 8, 32, 32, 32, 64, 64,\n",
       "                    64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_optimizer': masked_array(data=['rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd',\n",
       "                    'rmsprop', 'adam', 'sgd', 'rmsprop', 'adam', 'sgd'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'tanh',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 10,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 20,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 5,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 10,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.001,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.01,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.1,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.2,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 8,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 32,\n",
       "   'optimizer': 'sgd'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'rmsprop'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'adam'},\n",
       "  {'activation': 'relu',\n",
       "   'batch_size': 50,\n",
       "   'epochs': 20,\n",
       "   'learning_rate': 0.3,\n",
       "   'neurons': 64,\n",
       "   'optimizer': 'sgd'}],\n",
       " 'split0_test_score': array([0.78362572, 0.77339178, 0.61842108, 0.80409354, 0.82163745,\n",
       "        0.46052632, 0.82017541, 0.81140351, 0.66812867, 0.8347953 ,\n",
       "        0.81725144, 0.71052629, 0.81578946, 0.82894737, 0.76754385,\n",
       "        0.80263156, 0.8128655 , 0.76754385, 0.81725144, 0.82748538,\n",
       "        0.80994153, 0.80994153, 0.77923977, 0.81725144, 0.61257309,\n",
       "        0.7631579 , 0.8260234 , 0.63742691, 0.8260234 , 0.81140351,\n",
       "        0.75584793, 0.79970759, 0.81578946, 0.69152045, 0.68128657,\n",
       "        0.80409354, 0.79239768, 0.80555558, 0.82748538, 0.82163745,\n",
       "        0.75730991, 0.81725144, 0.58771932, 0.80555558, 0.81578946,\n",
       "        0.80994153, 0.8128655 , 0.50146198, 0.82309943, 0.83187133,\n",
       "        0.69883043, 0.83187133, 0.82894737, 0.66666669, 0.80994153,\n",
       "        0.8260234 , 0.7909357 , 0.82894737, 0.82894737, 0.7909357 ,\n",
       "        0.8128655 , 0.81725144, 0.79532164, 0.82748538, 0.81725144,\n",
       "        0.82748538, 0.8128655 , 0.8128655 , 0.82894737, 0.80701756,\n",
       "        0.75584793, 0.82456142, 0.74122804, 0.8391813 , 0.83040935,\n",
       "        0.82456142, 0.7850877 , 0.83187133, 0.76023394, 0.8128655 ,\n",
       "        0.82309943, 0.83771932, 0.7631579 , 0.83040935, 0.79239768,\n",
       "        0.81725144, 0.81871343, 0.60087717, 0.68859649, 0.8260234 ,\n",
       "        0.81578946, 0.8260234 , 0.61403507, 0.83040935, 0.82748538,\n",
       "        0.70614034, 0.83187133, 0.82163745, 0.70321637, 0.81432748,\n",
       "        0.82017541, 0.80263156, 0.80409354, 0.82163745, 0.80116957,\n",
       "        0.82894737, 0.82163745, 0.80994153, 0.79970759, 0.80847955,\n",
       "        0.82163745, 0.81578946, 0.81432748, 0.82163745, 0.78654969,\n",
       "        0.8128655 , 0.82163745, 0.80263156, 0.82894737, 0.8128655 ,\n",
       "        0.77485383, 0.81871343, 0.82894737, 0.76461989, 0.80555558,\n",
       "        0.82456142, 0.8260234 , 0.76608187, 0.82894737, 0.78216374,\n",
       "        0.6608187 , 0.82017541, 0.81140351, 0.65350878, 0.82017541,\n",
       "        0.73976606, 0.80994153, 0.49269006, 0.80701756, 0.78362572,\n",
       "        0.49122807, 0.80994153, 0.79824561, 0.51169592, 0.82163745,\n",
       "        0.81432748, 0.66812867, 0.82163745, 0.81578946, 0.75146198,\n",
       "        0.8260234 , 0.8260234 , 0.73245615, 0.81432748, 0.83040935,\n",
       "        0.81140351, 0.83771932, 0.80701756, 0.80994153, 0.70760232,\n",
       "        0.80555558, 0.80555558, 0.74853802, 0.83625734, 0.81140351,\n",
       "        0.76754385, 0.7719298 , 0.81578946, 0.83771932, 0.78216374,\n",
       "        0.82163745, 0.7850877 , 0.8347953 , 0.79970759, 0.75584793,\n",
       "        0.71052629, 0.81871343, 0.61695904, 0.75730991, 0.82309943,\n",
       "        0.78654969, 0.81725144, 0.64181286, 0.81140351, 0.82309943,\n",
       "        0.57748538, 0.82748538, 0.8260234 , 0.55555558, 0.81725144,\n",
       "        0.83040935, 0.73245615, 0.82748538, 0.83040935, 0.77046782,\n",
       "        0.81871343, 0.82309943, 0.7719298 , 0.81871343, 0.82456142,\n",
       "        0.81140351, 0.80701756, 0.82017541, 0.82894737, 0.82456142,\n",
       "        0.82309943, 0.82309943, 0.78947371, 0.8128655 , 0.81578946,\n",
       "        0.70467836, 0.80555558, 0.8260234 , 0.79239768, 0.75146198,\n",
       "        0.83040935, 0.71929824, 0.77777779, 0.80555558, 0.68421054,\n",
       "        0.78801167, 0.82309943, 0.70614034, 0.82309943, 0.8260234 ,\n",
       "        0.81725144, 0.81725144, 0.74707603, 0.82163745, 0.83333331,\n",
       "        0.64181286, 0.82748538, 0.81725144, 0.66228068, 0.82748538,\n",
       "        0.81725144, 0.80555558, 0.81578946, 0.82748538, 0.78070176,\n",
       "        0.8260234 , 0.82017541, 0.79970759, 0.82456142, 0.80847955,\n",
       "        0.82894737, 0.80116957, 0.81871343, 0.82309943, 0.83187133,\n",
       "        0.8128655 , 0.83040935, 0.80994153, 0.81725144, 0.82748538,\n",
       "        0.80994153, 0.75438595, 0.82017541, 0.64473683, 0.81432748,\n",
       "        0.82456142, 0.7631579 , 0.81432748, 0.82309943, 0.62719297,\n",
       "        0.67982459, 0.82894737, 0.67836255, 0.83187133, 0.82309943,\n",
       "        0.70029241, 0.67105263, 0.6111111 , 0.74707603, 0.70760232,\n",
       "        0.59649122, 0.80263156, 0.74707603, 0.48099416, 0.81432748,\n",
       "        0.81432748, 0.21491228, 0.83040935, 0.82894737, 0.5350877 ,\n",
       "        0.82456142, 0.82748538, 0.57894737, 0.80116957, 0.81578946,\n",
       "        0.77923977, 0.82894737, 0.81725144, 0.79385966, 0.72076023,\n",
       "        0.81578946, 0.77923977, 0.6739766 , 0.80994153, 0.80701756,\n",
       "        0.71783626, 0.80116957, 0.80409354, 0.64766079, 0.82309943,\n",
       "        0.80847955, 0.72222221, 0.79678363, 0.78216374, 0.62426901,\n",
       "        0.82309943, 0.80555558, 0.70467836, 0.80116957, 0.81871343,\n",
       "        0.80116957, 0.47953215, 0.50584793, 0.78216374, 0.80701756,\n",
       "        0.50584793, 0.80701756, 0.79678363, 0.45029241, 0.82309943,\n",
       "        0.83187133, 0.77631581, 0.81578946, 0.8260234 , 0.72076023,\n",
       "        0.79678363, 0.82748538, 0.60087717, 0.79824561, 0.8260234 ,\n",
       "        0.79678363, 0.81432748, 0.83040935, 0.80847955, 0.80994153,\n",
       "        0.80847955, 0.80994153, 0.80701756, 0.81871343, 0.81725144,\n",
       "        0.58187133, 0.82017541, 0.8260234 , 0.79678363, 0.80116957,\n",
       "        0.8260234 , 0.74415207, 0.80701756, 0.80263156, 0.36257309,\n",
       "        0.77046782, 0.82017541, 0.6520468 , 0.79678363, 0.81725144,\n",
       "        0.78216374, 0.78801167, 0.41374269, 0.80701756, 0.81725144,\n",
       "        0.43859649, 0.81871343, 0.83040935, 0.54970759, 0.82309943,\n",
       "        0.83187133, 0.69444442, 0.81578946, 0.82894737, 0.75438595,\n",
       "        0.83040935, 0.8260234 , 0.75584793, 0.82017541, 0.81871343,\n",
       "        0.82163745, 0.79824561, 0.82456142, 0.81725144, 0.7631579 ,\n",
       "        0.82017541, 0.82309943, 0.81140351, 0.80701756, 0.82163745,\n",
       "        0.75877196, 0.81578946, 0.82894737, 0.79970759, 0.82894737,\n",
       "        0.82309943, 0.81140351, 0.82163745, 0.82309943, 0.7368421 ,\n",
       "        0.7850877 , 0.80263156, 0.81432748, 0.76169592, 0.8260234 ,\n",
       "        0.80555558, 0.76900584, 0.51754385, 0.79970759, 0.80701756,\n",
       "        0.46345028, 0.80116957, 0.8128655 , 0.49561402, 0.82163745,\n",
       "        0.81725144, 0.67982459, 0.8347953 , 0.81871343, 0.7149123 ,\n",
       "        0.81725144, 0.81578946, 0.76900584, 0.8260234 , 0.81725144,\n",
       "        0.83040935, 0.81725144, 0.79970759, 0.81578946, 0.80994153,\n",
       "        0.78801167, 0.81432748, 0.75730991, 0.74561405, 0.83187133,\n",
       "        0.61257309, 0.81871343, 0.80409354, 0.76023394, 0.8128655 ,\n",
       "        0.8260234 , 0.81725144, 0.81871343, 0.82748538, 0.80994153,\n",
       "        0.78947371, 0.82748538, 0.81871343, 0.82163745, 0.82017541,\n",
       "        0.79824561, 0.80994153, 0.71929824, 0.82456142, 0.81725144,\n",
       "        0.71052629, 0.82748538, 0.82748538, 0.68421054, 0.82894737,\n",
       "        0.82456142, 0.75584793, 0.82163745, 0.83187133, 0.7850877 ,\n",
       "        0.8260234 , 0.82456142, 0.76754385, 0.79824561, 0.82894737,\n",
       "        0.8260234 , 0.82894737, 0.78801167, 0.81725144, 0.79678363,\n",
       "        0.80701756, 0.8260234 , 0.82309943, 0.82017541, 0.79385966,\n",
       "        0.81725144, 0.8260234 , 0.80263156, 0.83187133, 0.79678363,\n",
       "        0.80555558, 0.8260234 , 0.83040935, 0.82456142, 0.76608187,\n",
       "        0.80994153, 0.83040935, 0.75584793, 0.82309943, 0.81871343,\n",
       "        0.81578946, 0.82017541, 0.65935671, 0.82748538, 0.81725144,\n",
       "        0.68567252, 0.83040935, 0.8260234 , 0.57894737, 0.82163745,\n",
       "        0.82309943, 0.77485383, 0.83040935, 0.8128655 , 0.79970759,\n",
       "        0.83771932, 0.83187133, 0.80555558, 0.80847955, 0.82163745,\n",
       "        0.81871343, 0.80116957, 0.81871343, 0.82163745, 0.79385966,\n",
       "        0.79385966, 0.83333331, 0.81578946, 0.83040935, 0.8260234 ,\n",
       "        0.81725144, 0.81871343, 0.82163745, 0.80701756, 0.81578946,\n",
       "        0.82456142, 0.76900584, 0.79824561, 0.81432748, 0.73099416,\n",
       "        0.8128655 , 0.8128655 , 0.72953218, 0.79532164, 0.83187133,\n",
       "        0.74561405, 0.74269009, 0.51608187, 0.77777779, 0.7850877 ,\n",
       "        0.4269006 , 0.80555558, 0.8128655 , 0.40204677, 0.80701756,\n",
       "        0.82163745, 0.68128657, 0.82748538, 0.82456142, 0.63596493,\n",
       "        0.80409354, 0.81432748, 0.7090643 , 0.80116957, 0.82748538,\n",
       "        0.80994153, 0.82163745, 0.79678363, 0.80409354, 0.73830408,\n",
       "        0.84064329, 0.80263156, 0.81140351, 0.82309943, 0.82748538,\n",
       "        0.79239768, 0.80555558, 0.82748538, 0.80263156, 0.8128655 ,\n",
       "        0.82017541, 0.78362572, 0.80701756, 0.81725144, 0.8347953 ,\n",
       "        0.82456142, 0.8128655 , 0.80994153, 0.83333331, 0.80263156,\n",
       "        0.75584793, 0.80994153, 0.50877196, 0.80555558, 0.80847955,\n",
       "        0.49415204, 0.82017541, 0.8260234 , 0.50438595, 0.82163745,\n",
       "        0.8260234 , 0.72076023, 0.81871343, 0.83187133, 0.74853802,\n",
       "        0.82163745, 0.83040935, 0.73976606, 0.77777779, 0.81140351,\n",
       "        0.81578946, 0.80555558, 0.81871343, 0.82309943, 0.80263156,\n",
       "        0.83040935, 0.83187133, 0.75730991, 0.8128655 , 0.82456142,\n",
       "        0.74707603, 0.79678363, 0.8260234 , 0.81140351, 0.68274856,\n",
       "        0.82309943, 0.82309943, 0.83040935, 0.80263156, 0.80701756,\n",
       "        0.81578946, 0.81871343, 0.64619881, 0.81140351, 0.78216374,\n",
       "        0.80409354, 0.79824561, 0.72368419, 0.82017541, 0.8260234 ,\n",
       "        0.69736844, 0.83040935, 0.83333331, 0.59356725, 0.83625734,\n",
       "        0.8347953 , 0.72514617, 0.82017541, 0.83625734, 0.7909357 ,\n",
       "        0.81725144, 0.82163745, 0.77777779, 0.80994153, 0.80409354,\n",
       "        0.82017541, 0.76461989, 0.78362572, 0.82456142, 0.80263156,\n",
       "        0.81871343, 0.81578946, 0.82163745, 0.79824561, 0.82456142,\n",
       "        0.80701756, 0.74707603, 0.82163745, 0.80263156, 0.77339178,\n",
       "        0.82163745, 0.74415207, 0.81140351, 0.82017541, 0.63157892,\n",
       "        0.80263156, 0.80701756, 0.82894737, 0.81432748, 0.82017541,\n",
       "        0.61403507, 0.59064329, 0.50584793, 0.73245615, 0.74269009,\n",
       "        0.50877196, 0.74415207, 0.76754385, 0.48245615, 0.80263156,\n",
       "        0.81725144, 0.44590643, 0.83040935, 0.82309943, 0.40789473,\n",
       "        0.82309943, 0.8260234 , 0.51169592, 0.82894737, 0.81578946,\n",
       "        0.77339178, 0.83040935, 0.82309943, 0.77923977, 0.82894737,\n",
       "        0.81578946, 0.79824561, 0.82163745, 0.81725144, 0.80263156,\n",
       "        0.79385966, 0.8260234 , 0.80409354, 0.65350878, 0.79532164,\n",
       "        0.79678363, 0.80555558, 0.81432748, 0.8128655 , 0.74853802,\n",
       "        0.79532164, 0.80116957, 0.81578946, 0.81140351, 0.80555558,\n",
       "        0.70175439, 0.79239768, 0.69444442, 0.79532164, 0.7850877 ,\n",
       "        0.58040935, 0.79385966, 0.8128655 , 0.48538011, 0.82309943,\n",
       "        0.81871343, 0.73245615, 0.82163745, 0.83187133, 0.68859649,\n",
       "        0.82748538, 0.82748538, 0.67105263, 0.82748538, 0.80701756,\n",
       "        0.78362572, 0.83187133, 0.81725144, 0.79824561, 0.8260234 ,\n",
       "        0.82748538, 0.80555558, 0.64766079, 0.82748538, 0.8128655 ,\n",
       "        0.79239768, 0.82456142, 0.81871343, 0.77631581, 0.82163745,\n",
       "        0.82017541, 0.81140351, 0.8128655 , 0.79678363, 0.72222221,\n",
       "        0.80847955, 0.81725144, 0.82748538, 0.79385966, 0.79532164,\n",
       "        0.78362572, 0.77485383, 0.5350877 , 0.79824561, 0.81578946,\n",
       "        0.4649123 , 0.81725144, 0.8260234 , 0.5979532 , 0.80701756,\n",
       "        0.82163745, 0.48391813, 0.8260234 , 0.82163745, 0.70614034,\n",
       "        0.84356725, 0.81871343, 0.73245615, 0.82017541, 0.82163745,\n",
       "        0.80701756, 0.8260234 , 0.80701756, 0.82456142, 0.82309943,\n",
       "        0.82456142, 0.81725144, 0.81578946, 0.82163745, 0.79385966,\n",
       "        0.70467836, 0.80847955, 0.82163745, 0.79532164, 0.82456142,\n",
       "        0.81871343, 0.81140351, 0.82163745, 0.82748538, 0.75877196,\n",
       "        0.83040935, 0.8128655 , 0.80555558, 0.82309943, 0.81725144]),\n",
       " 'split1_test_score': array([0.77046782, 0.80847955, 0.7280702 , 0.81871343, 0.81578946,\n",
       "        0.6739766 , 0.82163745, 0.82163745, 0.7368421 , 0.82163745,\n",
       "        0.8260234 , 0.77485383, 0.81140351, 0.78947371, 0.78801167,\n",
       "        0.8128655 , 0.8128655 , 0.77339178, 0.80116957, 0.82017541,\n",
       "        0.80409354, 0.8128655 , 0.80701756, 0.81871343, 0.78654969,\n",
       "        0.78216374, 0.81725144, 0.70029241, 0.82309943, 0.81871343,\n",
       "        0.79532164, 0.80409354, 0.80409354, 0.6608187 , 0.6520468 ,\n",
       "        0.82309943, 0.79239768, 0.82017541, 0.81140351, 0.28070176,\n",
       "        0.80701756, 0.81432748, 0.79239768, 0.77777779, 0.8128655 ,\n",
       "        0.82017541, 0.82017541, 0.68421054, 0.81725144, 0.81871343,\n",
       "        0.50730991, 0.81725144, 0.8260234 , 0.72076023, 0.80701756,\n",
       "        0.82748538, 0.78947371, 0.82163745, 0.81578946, 0.80116957,\n",
       "        0.78654969, 0.82163745, 0.79824561, 0.82456142, 0.80555558,\n",
       "        0.80847955, 0.7909357 , 0.79824561, 0.80994153, 0.81140351,\n",
       "        0.77777779, 0.81871343, 0.81725144, 0.80409354, 0.81140351,\n",
       "        0.79239768, 0.79970759, 0.79678363, 0.78362572, 0.80555558,\n",
       "        0.8128655 , 0.78654969, 0.78947371, 0.81432748, 0.78362572,\n",
       "        0.52046782, 0.79532164, 0.74415207, 0.6608187 , 0.8128655 ,\n",
       "        0.81725144, 0.81725144, 0.45321637, 0.82163745, 0.81578946,\n",
       "        0.75584793, 0.8128655 , 0.81140351, 0.74853802, 0.8260234 ,\n",
       "        0.80409354, 0.81140351, 0.80847955, 0.82309943, 0.80847955,\n",
       "        0.82309943, 0.82309943, 0.81140351, 0.81725144, 0.81725144,\n",
       "        0.80994153, 0.80263156, 0.78070176, 0.82894737, 0.77046782,\n",
       "        0.75438595, 0.81871343, 0.81140351, 0.82309943, 0.82748538,\n",
       "        0.63304096, 0.57748538, 0.8260234 , 0.55994153, 0.80701756,\n",
       "        0.82309943, 0.49707603, 0.81140351, 0.82894737, 0.68567252,\n",
       "        0.80555558, 0.81140351, 0.80701756, 0.62719297, 0.81140351,\n",
       "        0.80555558, 0.80701756, 0.66959065, 0.7909357 , 0.79532164,\n",
       "        0.39766082, 0.81871343, 0.80847955, 0.52339178, 0.82456142,\n",
       "        0.82163745, 0.77777779, 0.81871343, 0.81725144, 0.72514617,\n",
       "        0.82309943, 0.81871343, 0.74269009, 0.79678363, 0.81725144,\n",
       "        0.81871343, 0.81432748, 0.75      , 0.81578946, 0.78070176,\n",
       "        0.80701756, 0.80994153, 0.7850877 , 0.77339178, 0.8128655 ,\n",
       "        0.80409354, 0.7909357 , 0.81432748, 0.7368421 , 0.78070176,\n",
       "        0.81725144, 0.80263156, 0.80263156, 0.82456142, 0.74707603,\n",
       "        0.77046782, 0.81871343, 0.80116957, 0.80555558, 0.80847955,\n",
       "        0.76169592, 0.82309943, 0.54385966, 0.82163745, 0.82017541,\n",
       "        0.43128654, 0.81725144, 0.82748538, 0.73976606, 0.82309943,\n",
       "        0.80847955, 0.7850877 , 0.80116957, 0.82456142, 0.75438595,\n",
       "        0.81432748, 0.81725144, 0.79678363, 0.80847955, 0.82748538,\n",
       "        0.8128655 , 0.78654969, 0.7631579 , 0.8128655 , 0.80555558,\n",
       "        0.82309943, 0.80847955, 0.81432748, 0.79385966, 0.81140351,\n",
       "        0.74415207, 0.79678363, 0.82748538, 0.76900584, 0.74707603,\n",
       "        0.79532164, 0.81140351, 0.81578946, 0.82163745, 0.80555558,\n",
       "        0.79385966, 0.80263156, 0.80116957, 0.72660822, 0.81578946,\n",
       "        0.82456142, 0.82163745, 0.73245615, 0.8260234 , 0.81578946,\n",
       "        0.70467836, 0.82017541, 0.81871343, 0.62426901, 0.82163745,\n",
       "        0.81432748, 0.81432748, 0.81725144, 0.81432748, 0.79678363,\n",
       "        0.79824561, 0.81432748, 0.80116957, 0.81871343, 0.82456142,\n",
       "        0.8260234 , 0.8128655 , 0.81578946, 0.82748538, 0.79824561,\n",
       "        0.80409354, 0.81578946, 0.79678363, 0.77339178, 0.81871343,\n",
       "        0.70175439, 0.81578946, 0.80701756, 0.74853802, 0.78070176,\n",
       "        0.81140351, 0.78362572, 0.82017541, 0.82163745, 0.65643275,\n",
       "        0.79532164, 0.79532164, 0.80409354, 0.79385966, 0.78947371,\n",
       "        0.76900584, 0.68421054, 0.62280703, 0.78801167, 0.77339178,\n",
       "        0.6520468 , 0.7909357 , 0.77339178, 0.49561402, 0.82017541,\n",
       "        0.81140351, 0.57894737, 0.82309943, 0.79970759, 0.74707603,\n",
       "        0.80994153, 0.81140351, 0.66666669, 0.7909357 , 0.8260234 ,\n",
       "        0.77923977, 0.80994153, 0.77923977, 0.7850877 , 0.81432748,\n",
       "        0.81432748, 0.79385966, 0.80555558, 0.82309943, 0.80555558,\n",
       "        0.48976609, 0.81578946, 0.80555558, 0.69298244, 0.81871343,\n",
       "        0.80994153, 0.56578946, 0.80701756, 0.81140351, 0.80409354,\n",
       "        0.80847955, 0.81871343, 0.64766079, 0.81871343, 0.80994153,\n",
       "        0.76023394, 0.76023394, 0.43128654, 0.79239768, 0.79970759,\n",
       "        0.66228068, 0.80994153, 0.8128655 , 0.44005847, 0.81871343,\n",
       "        0.81725144, 0.67690057, 0.8128655 , 0.82456142, 0.71929824,\n",
       "        0.80847955, 0.80847955, 0.72953218, 0.81578946, 0.81140351,\n",
       "        0.80701756, 0.80555558, 0.81871343, 0.80263156, 0.79970759,\n",
       "        0.82748538, 0.81140351, 0.81140351, 0.80409354, 0.80701756,\n",
       "        0.80701756, 0.81578946, 0.80701756, 0.6871345 , 0.69736844,\n",
       "        0.81871343, 0.68567252, 0.80409354, 0.82309943, 0.71783626,\n",
       "        0.74707603, 0.80555558, 0.80847955, 0.79970759, 0.80555558,\n",
       "        0.77046782, 0.79385966, 0.48245615, 0.81725144, 0.82017541,\n",
       "        0.26461989, 0.81871343, 0.81871343, 0.6608187 , 0.82456142,\n",
       "        0.81871343, 0.7631579 , 0.82894737, 0.81871343, 0.77777779,\n",
       "        0.8128655 , 0.80994153, 0.78070176, 0.79678363, 0.81725144,\n",
       "        0.81871343, 0.79678363, 0.81871343, 0.82017541, 0.74561405,\n",
       "        0.80994153, 0.80555558, 0.79532164, 0.81432748, 0.81725144,\n",
       "        0.80847955, 0.80263156, 0.82017541, 0.67836255, 0.71052629,\n",
       "        0.8128655 , 0.82748538, 0.80555558, 0.8260234 , 0.80263156,\n",
       "        0.82017541, 0.80847955, 0.78216374, 0.72660822, 0.82456142,\n",
       "        0.76461989, 0.7719298 , 0.39619884, 0.78947371, 0.81725144,\n",
       "        0.3859649 , 0.82017541, 0.82163745, 0.6608187 , 0.80116957,\n",
       "        0.80409354, 0.74707603, 0.80263156, 0.81140351, 0.77777779,\n",
       "        0.80555558, 0.8260234 , 0.76461989, 0.80263156, 0.79970759,\n",
       "        0.80116957, 0.81432748, 0.81871343, 0.80701756, 0.80409354,\n",
       "        0.80263156, 0.77923977, 0.81140351, 0.80409354, 0.79532164,\n",
       "        0.73976606, 0.79970759, 0.82017541, 0.79970759, 0.79970759,\n",
       "        0.79970759, 0.62719297, 0.79678363, 0.7909357 , 0.78947371,\n",
       "        0.74415207, 0.80847955, 0.75730991, 0.82163745, 0.81725144,\n",
       "        0.75584793, 0.82309943, 0.73830408, 0.82163745, 0.81871343,\n",
       "        0.56871343, 0.82309943, 0.81432748, 0.71345031, 0.82309943,\n",
       "        0.80409354, 0.77485383, 0.78947371, 0.80701756, 0.79678363,\n",
       "        0.82456142, 0.82163745, 0.80116957, 0.80994153, 0.79532164,\n",
       "        0.82309943, 0.81140351, 0.82309943, 0.82456142, 0.81725144,\n",
       "        0.79385966, 0.82163745, 0.77339178, 0.48976609, 0.82017541,\n",
       "        0.78801167, 0.79239768, 0.8260234 , 0.78947371, 0.80847955,\n",
       "        0.80847955, 0.81432748, 0.75877196, 0.82163745, 0.81140351,\n",
       "        0.80847955, 0.81578946, 0.79385966, 0.81140351, 0.79678363,\n",
       "        0.81578946, 0.81725144, 0.42982456, 0.82163745, 0.82309943,\n",
       "        0.70614034, 0.81871343, 0.8260234 , 0.65497077, 0.8260234 ,\n",
       "        0.82456142, 0.78947371, 0.82017541, 0.80847955, 0.80555558,\n",
       "        0.79532164, 0.82017541, 0.8128655 , 0.82456142, 0.83040935,\n",
       "        0.81871343, 0.8128655 , 0.82017541, 0.82748538, 0.80847955,\n",
       "        0.82017541, 0.82309943, 0.82456142, 0.77046782, 0.80701756,\n",
       "        0.80994153, 0.8128655 , 0.82163745, 0.76900584, 0.7909357 ,\n",
       "        0.81432748, 0.82163745, 0.82456142, 0.79824561, 0.80116957,\n",
       "        0.63450295, 0.81140351, 0.81578946, 0.81871343, 0.82017541,\n",
       "        0.73538011, 0.77339178, 0.59941518, 0.78362572, 0.79239768,\n",
       "        0.44736841, 0.80994153, 0.82163745, 0.46345028, 0.82456142,\n",
       "        0.8128655 , 0.74561405, 0.82163745, 0.82456142, 0.6871345 ,\n",
       "        0.80994153, 0.82894737, 0.7280702 , 0.80409354, 0.80555558,\n",
       "        0.78654969, 0.79970759, 0.82309943, 0.81432748, 0.75584793,\n",
       "        0.81871343, 0.80701756, 0.81871343, 0.76754385, 0.82163745,\n",
       "        0.79532164, 0.81432748, 0.81578946, 0.68567252, 0.80409354,\n",
       "        0.81432748, 0.54678363, 0.79532164, 0.77485383, 0.80409354,\n",
       "        0.82163745, 0.80847955, 0.7719298 , 0.79824561, 0.79824561,\n",
       "        0.77631581, 0.77777779, 0.70614034, 0.8128655 , 0.81432748,\n",
       "        0.64327484, 0.82163745, 0.82017541, 0.53801167, 0.80994153,\n",
       "        0.81140351, 0.82017541, 0.82017541, 0.82456142, 0.77485383,\n",
       "        0.80701756, 0.82456142, 0.7850877 , 0.80847955, 0.7909357 ,\n",
       "        0.82017541, 0.76461989, 0.81140351, 0.81871343, 0.82309943,\n",
       "        0.80701756, 0.80701756, 0.7090643 , 0.80701756, 0.79532164,\n",
       "        0.76900584, 0.80847955, 0.82017541, 0.80701756, 0.79385966,\n",
       "        0.81432748, 0.75730991, 0.81140351, 0.81432748, 0.82894737,\n",
       "        0.80994153, 0.80409354, 0.80116957, 0.80994153, 0.81140351,\n",
       "        0.81871343, 0.81432748, 0.67690057, 0.81871343, 0.82456142,\n",
       "        0.62573099, 0.82309943, 0.82163745, 0.63011694, 0.81871343,\n",
       "        0.82456142, 0.76608187, 0.81725144, 0.81578946, 0.79385966,\n",
       "        0.82456142, 0.82017541, 0.79239768, 0.78947371, 0.81578946,\n",
       "        0.81578946, 0.82017541, 0.82309943, 0.81871343, 0.82163745,\n",
       "        0.78654969, 0.8128655 , 0.80701756, 0.80847955, 0.80555558,\n",
       "        0.77777779, 0.82163745, 0.82309943, 0.80555558, 0.80409354,\n",
       "        0.82309943, 0.81725144, 0.80847955, 0.76754385, 0.81432748,\n",
       "        0.82309943, 0.82163745, 0.78070176, 0.79239768, 0.82163745,\n",
       "        0.78216374, 0.77631581, 0.52046782, 0.76900584, 0.76023394,\n",
       "        0.51023394, 0.78070176, 0.77046782, 0.60818714, 0.81578946,\n",
       "        0.81432748, 0.49122807, 0.81871343, 0.82017541, 0.64327484,\n",
       "        0.78947371, 0.8128655 , 0.60818714, 0.78947371, 0.82894737,\n",
       "        0.76754385, 0.79532164, 0.81432748, 0.80263156, 0.80847955,\n",
       "        0.80847955, 0.7850877 , 0.82163745, 0.81725144, 0.80409354,\n",
       "        0.60526317, 0.80409354, 0.80409354, 0.81140351, 0.80701756,\n",
       "        0.80994153, 0.8260234 , 0.82163745, 0.79678363, 0.80847955,\n",
       "        0.80701756, 0.80994153, 0.79532164, 0.79532164, 0.80409354,\n",
       "        0.72222221, 0.74415207, 0.4868421 , 0.78801167, 0.79678363,\n",
       "        0.51169592, 0.79678363, 0.80116957, 0.51169592, 0.80847955,\n",
       "        0.82309943, 0.71052629, 0.79532164, 0.81725144, 0.73391813,\n",
       "        0.81432748, 0.80994153, 0.74707603, 0.80409354, 0.82309943,\n",
       "        0.80847955, 0.74707603, 0.82163745, 0.81432748, 0.80701756,\n",
       "        0.80701756, 0.80409354, 0.73830408, 0.79239768, 0.81140351,\n",
       "        0.75146198, 0.81871343, 0.80555558, 0.80263156, 0.82748538,\n",
       "        0.8128655 , 0.80116957, 0.82456142, 0.81871343, 0.71052629,\n",
       "        0.79678363, 0.82017541, 0.79239768, 0.80701756, 0.82017541,\n",
       "        0.76900584, 0.7631579 , 0.49853802, 0.81725144, 0.81578946,\n",
       "        0.71345031, 0.82017541, 0.82309943, 0.51754385, 0.80847955,\n",
       "        0.81140351, 0.77339178, 0.80555558, 0.82748538, 0.78216374,\n",
       "        0.79824561, 0.81578946, 0.78947371, 0.78362572, 0.81725144,\n",
       "        0.8128655 , 0.79970759, 0.7909357 , 0.81725144, 0.80116957,\n",
       "        0.80994153, 0.8128655 , 0.69444442, 0.82456142, 0.77923977,\n",
       "        0.76023394, 0.81432748, 0.7909357 , 0.81871343, 0.82309943,\n",
       "        0.80994153, 0.75292397, 0.80555558, 0.82748538, 0.7631579 ,\n",
       "        0.82163745, 0.8260234 , 0.7909357 , 0.81578946, 0.80409354]),\n",
       " 'split2_test_score': array([0.78947371, 0.78070176, 0.49707603, 0.80116957, 0.79824561,\n",
       "        0.44298247, 0.80555558, 0.80263156, 0.67543858, 0.80409354,\n",
       "        0.80555558, 0.73976606, 0.80701756, 0.80847955, 0.78216374,\n",
       "        0.79970759, 0.81140351, 0.78801167, 0.79532164, 0.80994153,\n",
       "        0.79385966, 0.77923977, 0.80847955, 0.80263156, 0.79532164,\n",
       "        0.81871343, 0.80701756, 0.79532164, 0.79678363, 0.80847955,\n",
       "        0.77485383, 0.80555558, 0.80994153, 0.73830408, 0.77777779,\n",
       "        0.80847955, 0.81725144, 0.80555558, 0.80555558, 0.73245615,\n",
       "        0.79970759, 0.79970759, 0.75730991, 0.77485383, 0.79970759,\n",
       "        0.79239768, 0.79824561, 0.3508772 , 0.80847955, 0.80701756,\n",
       "        0.65643275, 0.80701756, 0.80847955, 0.67836255, 0.8128655 ,\n",
       "        0.81140351, 0.79678363, 0.80994153, 0.80847955, 0.78362572,\n",
       "        0.80116957, 0.80701756, 0.7850877 , 0.80701756, 0.79970759,\n",
       "        0.80409354, 0.76169592, 0.80701756, 0.80994153, 0.80409354,\n",
       "        0.7850877 , 0.80847955, 0.79970759, 0.78947371, 0.80555558,\n",
       "        0.76900584, 0.73391813, 0.79970759, 0.73391813, 0.81578946,\n",
       "        0.79970759, 0.73830408, 0.79385966, 0.80409354, 0.76900584,\n",
       "        0.77485383, 0.80409354, 0.76900584, 0.80847955, 0.80555558,\n",
       "        0.80701756, 0.80994153, 0.69590646, 0.80409354, 0.80847955,\n",
       "        0.74853802, 0.80555558, 0.80701756, 0.72514617, 0.80409354,\n",
       "        0.8128655 , 0.79385966, 0.80701756, 0.80701756, 0.80994153,\n",
       "        0.80555558, 0.80847955, 0.80701756, 0.80263156, 0.8128655 ,\n",
       "        0.80263156, 0.78947371, 0.79970759, 0.80701756, 0.79970759,\n",
       "        0.80116957, 0.80994153, 0.80263156, 0.80409354, 0.80409354,\n",
       "        0.61988306, 0.80994153, 0.80555558, 0.80555558, 0.69152045,\n",
       "        0.79824561, 0.80555558, 0.77046782, 0.80847955, 0.72660822,\n",
       "        0.77923977, 0.79385966, 0.5350877 , 0.81578946, 0.80701756,\n",
       "        0.75438595, 0.78070176, 0.54970759, 0.79385966, 0.78801167,\n",
       "        0.46929824, 0.79678363, 0.80409354, 0.69444442, 0.80701756,\n",
       "        0.80701756, 0.76169592, 0.79385966, 0.80409354, 0.75      ,\n",
       "        0.80409354, 0.80847955, 0.77485383, 0.78947371, 0.79678363,\n",
       "        0.78654969, 0.77631581, 0.79970759, 0.80263156, 0.80116957,\n",
       "        0.81140351, 0.80555558, 0.80994153, 0.79239768, 0.80555558,\n",
       "        0.73538011, 0.80263156, 0.79385966, 0.79824561, 0.71637428,\n",
       "        0.80409354, 0.79678363, 0.80847955, 0.79532164, 0.68128657,\n",
       "        0.78947371, 0.78801167, 0.75292397, 0.78362572, 0.79678363,\n",
       "        0.79824561, 0.78070176, 0.45614034, 0.79678363, 0.80847955,\n",
       "        0.45906433, 0.80994153, 0.80847955, 0.72953218, 0.80994153,\n",
       "        0.79678363, 0.76900584, 0.80994153, 0.80555558, 0.78216374,\n",
       "        0.79239768, 0.80409354, 0.78070176, 0.80994153, 0.79824561,\n",
       "        0.80847955, 0.58040935, 0.80701756, 0.80994153, 0.81578946,\n",
       "        0.80116957, 0.80263156, 0.73830408, 0.81871343, 0.79970759,\n",
       "        0.66374266, 0.78070176, 0.79385966, 0.78362572, 0.7149123 ,\n",
       "        0.80409354, 0.79532164, 0.79532164, 0.78801167, 0.75730991,\n",
       "        0.77339178, 0.8128655 , 0.75438595, 0.80994153, 0.80116957,\n",
       "        0.80555558, 0.80116957, 0.57017541, 0.81432748, 0.80555558,\n",
       "        0.70175439, 0.80409354, 0.80555558, 0.70175439, 0.8128655 ,\n",
       "        0.80555558, 0.78947371, 0.80701756, 0.80263156, 0.78362572,\n",
       "        0.80994153, 0.80116957, 0.79385966, 0.79970759, 0.80701756,\n",
       "        0.80555558, 0.80701756, 0.80555558, 0.79678363, 0.8128655 ,\n",
       "        0.79385966, 0.80555558, 0.75730991, 0.80555558, 0.80409354,\n",
       "        0.79532164, 0.80847955, 0.79824561, 0.71052629, 0.77046782,\n",
       "        0.79970759, 0.78362572, 0.79824561, 0.80263156, 0.69298244,\n",
       "        0.7850877 , 0.80555558, 0.61257309, 0.78070176, 0.80116957,\n",
       "        0.71929824, 0.71345031, 0.44444445, 0.7909357 , 0.79385966,\n",
       "        0.51754385, 0.78654969, 0.79239768, 0.5219298 , 0.81140351,\n",
       "        0.79678363, 0.67251462, 0.80555558, 0.80555558, 0.5409357 ,\n",
       "        0.80555558, 0.81140351, 0.72368419, 0.80701756, 0.80555558,\n",
       "        0.78362572, 0.79532164, 0.80994153, 0.78216374, 0.73976606,\n",
       "        0.80409354, 0.78947371, 0.77485383, 0.80116957, 0.80263156,\n",
       "        0.48976609, 0.81140351, 0.79532164, 0.72660822, 0.76754385,\n",
       "        0.79532164, 0.77777779, 0.80116957, 0.79970759, 0.7719298 ,\n",
       "        0.80847955, 0.80555558, 0.80994153, 0.80263156, 0.79970759,\n",
       "        0.78070176, 0.77046782, 0.51608187, 0.78654969, 0.78801167,\n",
       "        0.49707603, 0.7909357 , 0.80116957, 0.63742691, 0.80116957,\n",
       "        0.80263156, 0.72953218, 0.79385966, 0.80555558, 0.68421054,\n",
       "        0.8128655 , 0.80263156, 0.75730991, 0.79678363, 0.80409354,\n",
       "        0.80555558, 0.79970759, 0.80555558, 0.80263156, 0.70760232,\n",
       "        0.79532164, 0.80116957, 0.79385966, 0.79239768, 0.80409354,\n",
       "        0.48976609, 0.75292397, 0.79824561, 0.70467836, 0.78216374,\n",
       "        0.80701756, 0.78947371, 0.81140351, 0.81140351, 0.78947371,\n",
       "        0.80263156, 0.80847955, 0.74853802, 0.78801167, 0.80263156,\n",
       "        0.79385966, 0.78362572, 0.34356725, 0.80847955, 0.80701756,\n",
       "        0.47222221, 0.80701756, 0.80555558, 0.68859649, 0.80116957,\n",
       "        0.80409354, 0.73391813, 0.80116957, 0.80701756, 0.78216374,\n",
       "        0.79532164, 0.80701756, 0.79824561, 0.79678363, 0.80847955,\n",
       "        0.81140351, 0.79239768, 0.81432748, 0.80263156, 0.74269009,\n",
       "        0.80116957, 0.80116957, 0.74561405, 0.80994153, 0.80847955,\n",
       "        0.79824561, 0.80701756, 0.80847955, 0.69298244, 0.81432748,\n",
       "        0.80847955, 0.6388889 , 0.81725144, 0.80555558, 0.7719298 ,\n",
       "        0.81432748, 0.8128655 , 0.74853802, 0.73099416, 0.80701756,\n",
       "        0.7368421 , 0.77339178, 0.53801167, 0.79824561, 0.79970759,\n",
       "        0.66959065, 0.80555558, 0.80116957, 0.40350878, 0.81140351,\n",
       "        0.80847955, 0.68128657, 0.80116957, 0.79824561, 0.79532164,\n",
       "        0.81140351, 0.80701756, 0.75292397, 0.81578946, 0.79970759,\n",
       "        0.81140351, 0.78070176, 0.78654969, 0.8128655 , 0.76900584,\n",
       "        0.79678363, 0.80847955, 0.80994153, 0.79532164, 0.80409354,\n",
       "        0.78654969, 0.80994153, 0.80994153, 0.80409354, 0.79970759,\n",
       "        0.80116957, 0.79970759, 0.79532164, 0.8128655 , 0.77339178,\n",
       "        0.76169592, 0.80116957, 0.79970759, 0.55263156, 0.79532164,\n",
       "        0.79532164, 0.80116957, 0.64181286, 0.80116957, 0.80994153,\n",
       "        0.6739766 , 0.80847955, 0.80701756, 0.69444442, 0.80701756,\n",
       "        0.80555558, 0.73099416, 0.80409354, 0.8128655 , 0.78947371,\n",
       "        0.81140351, 0.8128655 , 0.78070176, 0.80555558, 0.78654969,\n",
       "        0.80994153, 0.80994153, 0.79824561, 0.80701756, 0.80847955,\n",
       "        0.80116957, 0.80847955, 0.80701756, 0.81432748, 0.80116957,\n",
       "        0.80994153, 0.78362572, 0.80555558, 0.79678363, 0.79239768,\n",
       "        0.80263156, 0.81432748, 0.7149123 , 0.79824561, 0.80409354,\n",
       "        0.79678363, 0.80409354, 0.72222221, 0.80994153, 0.80701756,\n",
       "        0.80555558, 0.80847955, 0.70614034, 0.80409354, 0.80555558,\n",
       "        0.7149123 , 0.81432748, 0.80994153, 0.69005847, 0.80701756,\n",
       "        0.80994153, 0.79385966, 0.81578946, 0.7909357 , 0.79824561,\n",
       "        0.81578946, 0.81432748, 0.80263156, 0.80263156, 0.80701756,\n",
       "        0.80847955, 0.80701756, 0.80409354, 0.80994153, 0.78070176,\n",
       "        0.79532164, 0.80701756, 0.81871343, 0.80994153, 0.80116957,\n",
       "        0.80701756, 0.79970759, 0.80847955, 0.81140351, 0.80263156,\n",
       "        0.81725144, 0.80555558, 0.51023394, 0.81578946, 0.78216374,\n",
       "        0.80116957, 0.81140351, 0.80116957, 0.80701756, 0.80409354,\n",
       "        0.70175439, 0.78801167, 0.5131579 , 0.7909357 , 0.7850877 ,\n",
       "        0.29970759, 0.79678363, 0.79824561, 0.4269006 , 0.80555558,\n",
       "        0.80847955, 0.68567252, 0.79678363, 0.80409354, 0.76900584,\n",
       "        0.80994153, 0.80994153, 0.7149123 , 0.79239768, 0.80994153,\n",
       "        0.79239768, 0.79824561, 0.79970759, 0.80116957, 0.73099416,\n",
       "        0.79970759, 0.80116957, 0.80116957, 0.81725144, 0.80116957,\n",
       "        0.79385966, 0.80409354, 0.79970759, 0.7850877 , 0.79678363,\n",
       "        0.80994153, 0.79824561, 0.79678363, 0.81432748, 0.79239768,\n",
       "        0.81140351, 0.77485383, 0.7909357 , 0.75438595, 0.80116957,\n",
       "        0.78947371, 0.7909357 , 0.55994153, 0.80994153, 0.80994153,\n",
       "        0.34356725, 0.80263156, 0.80994153, 0.54385966, 0.80116957,\n",
       "        0.80555558, 0.74122804, 0.8128655 , 0.81140351, 0.77339178,\n",
       "        0.80409354, 0.80847955, 0.77923977, 0.79385966, 0.79824561,\n",
       "        0.80263156, 0.80409354, 0.80701756, 0.8128655 , 0.80116957,\n",
       "        0.80555558, 0.80555558, 0.80263156, 0.79385966, 0.80116957,\n",
       "        0.80555558, 0.79678363, 0.80555558, 0.78801167, 0.79970759,\n",
       "        0.8128655 , 0.78216374, 0.81140351, 0.80263156, 0.78216374,\n",
       "        0.80994153, 0.79532164, 0.80263156, 0.81432748, 0.7909357 ,\n",
       "        0.80409354, 0.80409354, 0.63742691, 0.80701756, 0.80116957,\n",
       "        0.52046782, 0.80847955, 0.80555558, 0.55994153, 0.80701756,\n",
       "        0.80555558, 0.7631579 , 0.80409354, 0.82163745, 0.7909357 ,\n",
       "        0.80847955, 0.80994153, 0.78654969, 0.80263156, 0.80701756,\n",
       "        0.80263156, 0.78947371, 0.80116957, 0.80994153, 0.79970759,\n",
       "        0.80701756, 0.81140351, 0.7909357 , 0.78801167, 0.79970759,\n",
       "        0.80847955, 0.80555558, 0.79970759, 0.80701756, 0.80555558,\n",
       "        0.80701756, 0.80116957, 0.78070176, 0.80116957, 0.79678363,\n",
       "        0.81140351, 0.80994153, 0.80701756, 0.80994153, 0.78362572,\n",
       "        0.65350878, 0.74122804, 0.4649123 , 0.74269009, 0.73830408,\n",
       "        0.60672516, 0.76608187, 0.79532164, 0.45614034, 0.80847955,\n",
       "        0.79532164, 0.67836255, 0.80409354, 0.80994153, 0.75292397,\n",
       "        0.80409354, 0.8128655 , 0.58333331, 0.78947371, 0.80409354,\n",
       "        0.78362572, 0.77485383, 0.8128655 , 0.7850877 , 0.80116957,\n",
       "        0.78362572, 0.79385966, 0.76169592, 0.80994153, 0.78654969,\n",
       "        0.80555558, 0.80409354, 0.80116957, 0.79824561, 0.74707603,\n",
       "        0.78801167, 0.79532164, 0.80263156, 0.78362572, 0.79678363,\n",
       "        0.81140351, 0.80409354, 0.79970759, 0.79532164, 0.79824561,\n",
       "        0.79970759, 0.74122804, 0.41812867, 0.78947371, 0.79532164,\n",
       "        0.55263156, 0.79532164, 0.80555558, 0.62719297, 0.81432748,\n",
       "        0.81432748, 0.76169592, 0.78216374, 0.79824561, 0.70614034,\n",
       "        0.80555558, 0.80555558, 0.71929824, 0.79678363, 0.80263156,\n",
       "        0.78801167, 0.79970759, 0.80701756, 0.80116957, 0.78070176,\n",
       "        0.80701756, 0.80555558, 0.81578946, 0.80116957, 0.79970759,\n",
       "        0.79678363, 0.8128655 , 0.79824561, 0.75877196, 0.81140351,\n",
       "        0.80116957, 0.79824561, 0.79532164, 0.80701756, 0.79824561,\n",
       "        0.79239768, 0.80116957, 0.80847955, 0.80994153, 0.81140351,\n",
       "        0.79824561, 0.80555558, 0.47953215, 0.80994153, 0.80994153,\n",
       "        0.44590643, 0.81140351, 0.80701756, 0.53654969, 0.80263156,\n",
       "        0.80263156, 0.71783626, 0.80263156, 0.81432748, 0.73538011,\n",
       "        0.80701756, 0.80263156, 0.73099416, 0.79970759, 0.80701756,\n",
       "        0.81140351, 0.79824561, 0.81140351, 0.79824561, 0.80263156,\n",
       "        0.81140351, 0.80847955, 0.80555558, 0.80409354, 0.80847955,\n",
       "        0.76169592, 0.80116957, 0.80994153, 0.73245615, 0.80263156,\n",
       "        0.80847955, 0.65058482, 0.80847955, 0.80701756, 0.80994153,\n",
       "        0.79824561, 0.80263156, 0.81140351, 0.80701756, 0.79385966]),\n",
       " 'mean_test_score': array([0.78118908, 0.78752436, 0.61452244, 0.80799218, 0.81189084,\n",
       "        0.52582846, 0.81578948, 0.81189084, 0.69346978, 0.82017543,\n",
       "        0.81627681, 0.74171539, 0.81140351, 0.80896688, 0.77923975,\n",
       "        0.80506821, 0.81237817, 0.77631577, 0.80458089, 0.81920077,\n",
       "        0.80263158, 0.80068227, 0.79824563, 0.81286548, 0.73148147,\n",
       "        0.78801169, 0.81676414, 0.71101365, 0.81530215, 0.8128655 ,\n",
       "        0.77534113, 0.8031189 , 0.80994151, 0.69688108, 0.70370372,\n",
       "        0.81189084, 0.80068227, 0.81042886, 0.81481483, 0.61159845,\n",
       "        0.78801169, 0.81042884, 0.71247564, 0.7860624 , 0.80945418,\n",
       "        0.80750487, 0.81042884, 0.51218324, 0.81627681, 0.81920077,\n",
       "        0.6208577 , 0.81871345, 0.8211501 , 0.68859649, 0.80994153,\n",
       "        0.82163743, 0.79239768, 0.82017545, 0.81773879, 0.79191033,\n",
       "        0.80019492, 0.81530215, 0.79288499, 0.81968812, 0.80750487,\n",
       "        0.81335282, 0.78849904, 0.80604289, 0.81627681, 0.80750487,\n",
       "        0.77290448, 0.81725146, 0.78606236, 0.81091619, 0.81578948,\n",
       "        0.79532164, 0.77290448, 0.80945418, 0.75925926, 0.81140351,\n",
       "        0.81189084, 0.78752436, 0.78216376, 0.81627679, 0.78167641,\n",
       "        0.70419103, 0.80604287, 0.70467836, 0.71929824, 0.81481483,\n",
       "        0.81335282, 0.81773879, 0.5877193 , 0.81871345, 0.81725146,\n",
       "        0.7368421 , 0.81676414, 0.81335284, 0.72563352, 0.81481481,\n",
       "        0.81237815, 0.80263158, 0.80653022, 0.81725148, 0.80653022,\n",
       "        0.81920079, 0.81773881, 0.8094542 , 0.8065302 , 0.8128655 ,\n",
       "        0.81140351, 0.80263158, 0.79824561, 0.81920079, 0.78557503,\n",
       "        0.78947367, 0.81676414, 0.80555554, 0.81871345, 0.81481481,\n",
       "        0.67592595, 0.73538011, 0.82017545, 0.710039  , 0.7680312 ,\n",
       "        0.81530215, 0.70955167, 0.78265107, 0.82212476, 0.73148149,\n",
       "        0.74853802, 0.80847953, 0.71783626, 0.69883041, 0.8128655 ,\n",
       "        0.7665692 , 0.79922028, 0.57066277, 0.79727097, 0.78898635,\n",
       "        0.45272905, 0.80847953, 0.80360623, 0.57651071, 0.81773881,\n",
       "        0.8143275 , 0.73586746, 0.81140351, 0.81237815, 0.74220272,\n",
       "        0.81773879, 0.81773879, 0.75000002, 0.80019494, 0.81481481,\n",
       "        0.80555554, 0.8094542 , 0.78557505, 0.80945418, 0.76315788,\n",
       "        0.80799222, 0.80701756, 0.78118908, 0.80068227, 0.80994153,\n",
       "        0.76900584, 0.78849902, 0.8079922 , 0.79093568, 0.75974659,\n",
       "        0.81432748, 0.7948343 , 0.81530213, 0.80653022, 0.72807018,\n",
       "        0.75682261, 0.80847951, 0.72368419, 0.78216374, 0.8094542 ,\n",
       "        0.78216374, 0.80701754, 0.54727095, 0.80994153, 0.81725146,\n",
       "        0.48927875, 0.81822612, 0.82066278, 0.67495128, 0.81676414,\n",
       "        0.81189084, 0.76218323, 0.8128655 , 0.82017545, 0.76900584,\n",
       "        0.80847953, 0.81481481, 0.78313839, 0.81237817, 0.81676414,\n",
       "        0.81091619, 0.72465887, 0.79678363, 0.81725146, 0.81530215,\n",
       "        0.81578948, 0.81140351, 0.78070176, 0.80847953, 0.80896686,\n",
       "        0.70419103, 0.79434699, 0.81578948, 0.78167641, 0.73781677,\n",
       "        0.80994151, 0.77534113, 0.7962963 , 0.80506823, 0.74902534,\n",
       "        0.7850877 , 0.8128655 , 0.75389862, 0.78654973, 0.81432748,\n",
       "        0.81578948, 0.81335282, 0.68323586, 0.82066278, 0.81822612,\n",
       "        0.68274854, 0.81725144, 0.81384015, 0.66276803, 0.82066278,\n",
       "        0.81237817, 0.80311892, 0.81335282, 0.81481481, 0.78703703,\n",
       "        0.81140351, 0.81189082, 0.79824561, 0.81432748, 0.81335284,\n",
       "        0.82017545, 0.80701754, 0.81335282, 0.81578948, 0.81432748,\n",
       "        0.80360623, 0.81725146, 0.78801169, 0.79873294, 0.81676412,\n",
       "        0.76900585, 0.79288499, 0.80847953, 0.70126704, 0.78849902,\n",
       "        0.81189084, 0.77680312, 0.81091617, 0.81578948, 0.65886939,\n",
       "        0.75341131, 0.80994153, 0.69834306, 0.80214425, 0.80458091,\n",
       "        0.72953216, 0.68957116, 0.55945419, 0.77534113, 0.75828459,\n",
       "        0.58869396, 0.79337231, 0.77095517, 0.49951266, 0.81530213,\n",
       "        0.80750487, 0.48879142, 0.81968812, 0.81140351, 0.60769981,\n",
       "        0.81335284, 0.81676414, 0.65643275, 0.79970761, 0.81578948,\n",
       "        0.78070176, 0.81140351, 0.80214425, 0.78703703, 0.75828459,\n",
       "        0.81140349, 0.78752438, 0.751462  , 0.81140351, 0.80506823,\n",
       "        0.56578948, 0.80945418, 0.80165692, 0.68908381, 0.8031189 ,\n",
       "        0.80458091, 0.68859649, 0.80165692, 0.79775828, 0.73343078,\n",
       "        0.81335284, 0.80994153, 0.72076023, 0.80750485, 0.80945418,\n",
       "        0.78070176, 0.67007797, 0.48440545, 0.78703703, 0.79824561,\n",
       "        0.55506821, 0.8026316 , 0.80360623, 0.50925926, 0.81432748,\n",
       "        0.81725144, 0.72758285, 0.80750487, 0.81871347, 0.70808967,\n",
       "        0.80604289, 0.8128655 , 0.69590642, 0.80360623, 0.81384015,\n",
       "        0.80311892, 0.80653022, 0.81822612, 0.80458089, 0.77241715,\n",
       "        0.81042886, 0.80750487, 0.80409358, 0.80506821, 0.80945418,\n",
       "        0.62621833, 0.79629628, 0.81042886, 0.72953216, 0.76023392,\n",
       "        0.81725146, 0.7397661 , 0.80750487, 0.81237817, 0.62329435,\n",
       "        0.7733918 , 0.81140351, 0.73635479, 0.7948343 , 0.80847953,\n",
       "        0.78216374, 0.78849902, 0.41325536, 0.81091619, 0.81481481,\n",
       "        0.39181286, 0.81481481, 0.81822612, 0.63304092, 0.81627681,\n",
       "        0.8182261 , 0.73050682, 0.81530213, 0.81822612, 0.77144249,\n",
       "        0.8128655 , 0.8143275 , 0.7782651 , 0.80458089, 0.81481481,\n",
       "        0.81725146, 0.79580897, 0.81920077, 0.8133528 , 0.75048735,\n",
       "        0.81042884, 0.80994153, 0.78411307, 0.81042886, 0.81578948,\n",
       "        0.78849904, 0.80847953, 0.81920077, 0.72368419, 0.78460038,\n",
       "        0.81481483, 0.75925926, 0.81481483, 0.81822614, 0.77046782,\n",
       "        0.8065302 , 0.8079922 , 0.78167641, 0.7397661 , 0.81920079,\n",
       "        0.76900585, 0.77144247, 0.48391812, 0.79580897, 0.8079922 ,\n",
       "        0.50633528, 0.80896686, 0.81189084, 0.5199805 , 0.81140351,\n",
       "        0.80994151, 0.70272907, 0.81286548, 0.80945418, 0.76267058,\n",
       "        0.81140351, 0.81627681, 0.76218323, 0.81481481, 0.80555554,\n",
       "        0.81432748, 0.80409356, 0.8016569 , 0.81189084, 0.79434697,\n",
       "        0.79580895, 0.80068227, 0.79288499, 0.78167641, 0.81042884,\n",
       "        0.71296295, 0.80945418, 0.81140349, 0.78801169, 0.80409356,\n",
       "        0.80896686, 0.74805067, 0.80360623, 0.81042886, 0.79093568,\n",
       "        0.76510723, 0.81237817, 0.79191031, 0.73196882, 0.81091617,\n",
       "        0.78313839, 0.81140351, 0.69980506, 0.81578948, 0.81530213,\n",
       "        0.6510721 , 0.81968812, 0.81627681, 0.69736842, 0.81968812,\n",
       "        0.81140351, 0.75389864, 0.80506823, 0.81725146, 0.79044835,\n",
       "        0.82066278, 0.81968812, 0.78313839, 0.80458091, 0.80360623,\n",
       "        0.81968812, 0.81676414, 0.8031189 , 0.81627681, 0.80750487,\n",
       "        0.80068227, 0.81871347, 0.80116959, 0.70808966, 0.80506821,\n",
       "        0.80506821, 0.80068227, 0.81140351, 0.80604289, 0.79922028,\n",
       "        0.80555556, 0.81822612, 0.7680312 , 0.81481483, 0.79385964,\n",
       "        0.80506823, 0.81676412, 0.75730993, 0.81481483, 0.80750487,\n",
       "        0.81237817, 0.81530213, 0.59844054, 0.81773879, 0.81530215,\n",
       "        0.70224172, 0.82115008, 0.82066278, 0.64132553, 0.81822614,\n",
       "        0.81920079, 0.7860624 , 0.82212474, 0.80409358, 0.80116959,\n",
       "        0.81627681, 0.82212474, 0.80701754, 0.81189084, 0.81968812,\n",
       "        0.81530213, 0.80701754, 0.81432746, 0.81968812, 0.79434699,\n",
       "        0.8031189 , 0.8211501 , 0.8196881 , 0.80360623, 0.81140351,\n",
       "        0.81140351, 0.81042884, 0.81725148, 0.79580897, 0.8031189 ,\n",
       "        0.81871345, 0.79873296, 0.71101365, 0.80945418, 0.77144249,\n",
       "        0.74951267, 0.81189084, 0.78216374, 0.80701754, 0.81871343,\n",
       "        0.72758285, 0.76803118, 0.54288499, 0.78411307, 0.78752436,\n",
       "        0.39132553, 0.80409358, 0.81091619, 0.43079922, 0.81237819,\n",
       "        0.8143275 , 0.70419105, 0.81530215, 0.81773879, 0.69736842,\n",
       "        0.8079922 , 0.81773879, 0.71734893, 0.79922026, 0.8143275 ,\n",
       "        0.7962963 , 0.80653022, 0.80653022, 0.8065302 , 0.74171539,\n",
       "        0.8196881 , 0.80360623, 0.81042884, 0.80263158, 0.81676414,\n",
       "        0.79385966, 0.8079922 , 0.81432748, 0.75779726, 0.80458089,\n",
       "        0.81481481, 0.70955165, 0.79970761, 0.80214425, 0.81042884,\n",
       "        0.81920079, 0.79873296, 0.79093568, 0.79532162, 0.80068225,\n",
       "        0.77387915, 0.79288501, 0.59161794, 0.8094542 , 0.81091619,\n",
       "        0.49366471, 0.81481481, 0.81871345, 0.52875243, 0.81091619,\n",
       "        0.8143275 , 0.76072123, 0.81725144, 0.82261209, 0.76559454,\n",
       "        0.81091619, 0.8211501 , 0.76803118, 0.79337233, 0.80019494,\n",
       "        0.81286548, 0.791423  , 0.81237817, 0.81822612, 0.80896686,\n",
       "        0.8143275 , 0.81481483, 0.75633526, 0.80458091, 0.80701754,\n",
       "        0.77387915, 0.80068227, 0.81725146, 0.80214425, 0.75877194,\n",
       "        0.81676414, 0.78752436, 0.81773879, 0.8065302 , 0.80604289,\n",
       "        0.81189084, 0.80604287, 0.74999998, 0.81189084, 0.79483432,\n",
       "        0.80896684, 0.80555554, 0.67933722, 0.81530213, 0.81725146,\n",
       "        0.61452242, 0.82066278, 0.82017545, 0.59454191, 0.82066278,\n",
       "        0.82163743, 0.75146198, 0.81384013, 0.82456142, 0.79191035,\n",
       "        0.81676414, 0.81725146, 0.78557505, 0.80068227, 0.80896686,\n",
       "        0.81286548, 0.791423  , 0.80263158, 0.81773879, 0.8079922 ,\n",
       "        0.80409356, 0.81335282, 0.80653024, 0.79824561, 0.80994153,\n",
       "        0.7977583 , 0.79142302, 0.81481483, 0.80506823, 0.79434697,\n",
       "        0.81725148, 0.78752436, 0.80019494, 0.79629628, 0.74756334,\n",
       "        0.81237817, 0.81286552, 0.80555556, 0.80555556, 0.80847953,\n",
       "        0.68323586, 0.70272905, 0.49707601, 0.74805069, 0.74707603,\n",
       "        0.54191035, 0.76364523, 0.77777777, 0.51559454, 0.80896686,\n",
       "        0.80896686, 0.53849902, 0.81773877, 0.81773879, 0.60136451,\n",
       "        0.80555556, 0.81725146, 0.56773879, 0.8026316 , 0.81627679,\n",
       "        0.77485379, 0.80019494, 0.81676414, 0.78898635, 0.8128655 ,\n",
       "        0.80263158, 0.79239766, 0.80165694, 0.81481481, 0.79775826,\n",
       "        0.73489281, 0.81140349, 0.80311888, 0.75438597, 0.78313841,\n",
       "        0.79824561, 0.80896688, 0.8128655 , 0.79775828, 0.7846004 ,\n",
       "        0.80458091, 0.80506821, 0.80360623, 0.80068227, 0.80263158,\n",
       "        0.74122806, 0.75925926, 0.53313839, 0.79093568, 0.79239766,\n",
       "        0.54824561, 0.79532164, 0.80653022, 0.541423  , 0.81530215,\n",
       "        0.81871345, 0.73489279, 0.79970761, 0.81578946, 0.70955165,\n",
       "        0.81578948, 0.8143275 , 0.71247564, 0.80945418, 0.81091619,\n",
       "        0.79337231, 0.79288499, 0.81530215, 0.80458089, 0.80458091,\n",
       "        0.81384017, 0.80506823, 0.73391811, 0.80701754, 0.8079922 ,\n",
       "        0.78021443, 0.81871345, 0.80750487, 0.77923977, 0.82017545,\n",
       "        0.81140349, 0.80360623, 0.81091619, 0.80750487, 0.7436647 ,\n",
       "        0.79922028, 0.81286548, 0.8094542 , 0.80360625, 0.80896686,\n",
       "        0.78362572, 0.7811891 , 0.50438596, 0.80847953, 0.81384015,\n",
       "        0.54142301, 0.81627679, 0.81871347, 0.55068225, 0.80604289,\n",
       "        0.81189084, 0.65838206, 0.81140351, 0.8211501 , 0.74122806,\n",
       "        0.81627681, 0.81237815, 0.75097468, 0.80116957, 0.81530215,\n",
       "        0.81042886, 0.8079922 , 0.80311892, 0.81335282, 0.80896686,\n",
       "        0.81530215, 0.8128655 , 0.77192982, 0.81676414, 0.79385966,\n",
       "        0.74220274, 0.8079922 , 0.80750489, 0.78216374, 0.81676414,\n",
       "        0.81237817, 0.7383041 , 0.81189086, 0.82066278, 0.77729046,\n",
       "        0.81676414, 0.81384015, 0.8026316 , 0.81530215, 0.80506821]),\n",
       " 'std_test_score': array([0.00794812, 0.01511509, 0.09434326, 0.00767447, 0.00993962,\n",
       "        0.10500111, 0.00726103, 0.00776677, 0.03081371, 0.0125765 ,\n",
       "        0.00838432, 0.02629776, 0.00358111, 0.01611874, 0.00860795,\n",
       "        0.00564125, 0.00068919, 0.00860795, 0.00927207, 0.00719533,\n",
       "        0.00664628, 0.01520905, 0.01345242, 0.00726105, 0.08415715,\n",
       "        0.02305433, 0.00776675, 0.06490452, 0.01314887, 0.00430396,\n",
       "        0.01611876, 0.00248491, 0.00477484, 0.03185957, 0.0537213 ,\n",
       "        0.00812542, 0.01171618, 0.00689185, 0.00927207, 0.23679498,\n",
       "        0.02191359, 0.00767447, 0.08937148, 0.01383535, 0.00699449,\n",
       "        0.01147036, 0.00911709, 0.13629377, 0.0060082 , 0.01015236,\n",
       "        0.08213491, 0.01019904, 0.00903861, 0.02323902, 0.00238741,\n",
       "        0.00726105, 0.00315824, 0.00782767, 0.00846888, 0.00719533,\n",
       "        0.01076547, 0.00612563, 0.00564125, 0.00903861, 0.00729367,\n",
       "        0.01015238, 0.02096083, 0.0060082 , 0.00895944, 0.00300411,\n",
       "        0.01242452, 0.00664628, 0.03250163, 0.02085861, 0.0106099 ,\n",
       "        0.02277452, 0.02820622, 0.0158962 , 0.02030474, 0.00430396,\n",
       "        0.00957452, 0.04059195, 0.01355793, 0.01083144, 0.00964864,\n",
       "        0.13105992, 0.00964862, 0.07409653, 0.06407225, 0.00846888,\n",
       "        0.00451929, 0.00657443, 0.10081008, 0.01094053, 0.00782767,\n",
       "        0.02191357, 0.01109141, 0.00612564, 0.01850569, 0.00895946,\n",
       "        0.00657443, 0.00716225, 0.00182344, 0.00726105, 0.00383725,\n",
       "        0.0099396 , 0.00657444, 0.00182341, 0.00767447, 0.00358111,\n",
       "        0.00782769, 0.01074336, 0.01376651, 0.00911709, 0.01195697,\n",
       "        0.02526605, 0.00496981, 0.00413514, 0.01060993, 0.00964864,\n",
       "        0.07015852, 0.11170585, 0.0104065 , 0.10744261, 0.05410456,\n",
       "        0.01207556, 0.15047515, 0.02040974, 0.00964862, 0.03954281,\n",
       "        0.06295046, 0.0109405 , 0.12923515, 0.08339743, 0.00547024,\n",
       "        0.02820625, 0.01314887, 0.07372378, 0.00699449, 0.00482432,\n",
       "        0.03995507, 0.00901229, 0.00419217, 0.08352831, 0.00767447,\n",
       "        0.00596854, 0.04834642, 0.01246268, 0.00588843, 0.01207556,\n",
       "        0.00972221, 0.00719533, 0.01806409, 0.01042929, 0.01383535,\n",
       "        0.01376652, 0.02530362, 0.02533176, 0.00538273, 0.04016257,\n",
       "        0.00248489, 0.00206756, 0.025219  , 0.02632483, 0.00315824,\n",
       "        0.02807118, 0.01265181, 0.01001102, 0.04150606, 0.03067466,\n",
       "        0.00745473, 0.00729368, 0.01398898, 0.0128751 , 0.03327427,\n",
       "        0.0336434 , 0.01447295, 0.07799403, 0.01972332, 0.01076547,\n",
       "        0.01524024, 0.0187606 , 0.07583886, 0.01019906, 0.00631651,\n",
       "        0.06339405, 0.00719533, 0.00863549, 0.08452882, 0.00538273,\n",
       "        0.01393796, 0.02202167, 0.01094052, 0.0106099 , 0.01138726,\n",
       "        0.01151169, 0.00794812, 0.01029178, 0.00451929, 0.01314887,\n",
       "        0.00182341, 0.10234151, 0.02437621, 0.00835596, 0.00776675,\n",
       "        0.01033784, 0.00860797, 0.03165017, 0.0106099 , 0.00678771,\n",
       "        0.03282881, 0.01029178, 0.01551821, 0.00964864, 0.01629459,\n",
       "        0.01490941, 0.04016848, 0.0155335 , 0.01373199, 0.04988407,\n",
       "        0.00860797, 0.00835598, 0.03879705, 0.04272408, 0.01019906,\n",
       "        0.00782766, 0.00879897, 0.0801683 , 0.00482432, 0.01147036,\n",
       "        0.0289705 , 0.00977094, 0.0058884 , 0.03163515, 0.0060082 ,\n",
       "        0.00496979, 0.01029176, 0.00451929, 0.01015238, 0.00699449,\n",
       "        0.01138726, 0.0079481 , 0.00315824, 0.01060992, 0.0079481 ,\n",
       "        0.0104065 , 0.00477484, 0.00564122, 0.01355793, 0.01376651,\n",
       "        0.00776675, 0.01019904, 0.02236414, 0.01854416, 0.00964864,\n",
       "        0.04792706, 0.02738601, 0.00901229, 0.04287946, 0.01873527,\n",
       "        0.01015238, 0.00964862, 0.00927207, 0.00932318, 0.02691364,\n",
       "        0.05220113, 0.01407361, 0.07945412, 0.02169573, 0.01393796,\n",
       "        0.02897049, 0.01771897, 0.08146422, 0.02002206, 0.03679903,\n",
       "        0.05518671, 0.00678771, 0.01858253, 0.01693775, 0.00364683,\n",
       "        0.00767447, 0.19739309, 0.01042929, 0.01263302, 0.09858279,\n",
       "        0.0081254 , 0.00758107, 0.05953003, 0.00664628, 0.00835595,\n",
       "        0.00206756, 0.01376651, 0.01646856, 0.00496981, 0.04038077,\n",
       "        0.00520326, 0.00612564, 0.05620581, 0.00901232, 0.00182344,\n",
       "        0.10751331, 0.00612564, 0.00451931, 0.03234783, 0.02521901,\n",
       "        0.00657444, 0.08975069, 0.00419218, 0.0120164 , 0.07829792,\n",
       "        0.00689188, 0.00620267, 0.06721969, 0.0079481 , 0.00776675,\n",
       "        0.0167119 , 0.134801  , 0.03779239, 0.00419218, 0.00782769,\n",
       "        0.07589519, 0.00835596, 0.00678771, 0.09072447, 0.00947478,\n",
       "        0.01193709, 0.0406095 , 0.00972218, 0.00932315, 0.01689564,\n",
       "        0.00678771, 0.01060992, 0.06814602, 0.00863549, 0.00911711,\n",
       "        0.00451932, 0.0060082 , 0.01015236, 0.00275677, 0.04602104,\n",
       "        0.01320294, 0.00451932, 0.00745471, 0.01076544, 0.00564124,\n",
       "        0.13325944, 0.03072108, 0.01159394, 0.04809031, 0.04512469,\n",
       "        0.00782766, 0.04248999, 0.00300411, 0.00838435, 0.18666309,\n",
       "        0.02277449, 0.00631649, 0.06444183, 0.00496981, 0.00631651,\n",
       "        0.00954968, 0.00419218, 0.0567022 , 0.00451929, 0.00564122,\n",
       "        0.09098063, 0.00551348, 0.01015236, 0.06000686, 0.01069909,\n",
       "        0.01134547, 0.02815568, 0.01134547, 0.00895943, 0.01219299,\n",
       "        0.0143245 , 0.00835596, 0.01739432, 0.01102699, 0.00451929,\n",
       "        0.00430398, 0.00248489, 0.00419218, 0.00767447, 0.00903861,\n",
       "        0.00776675, 0.00947478, 0.02800342, 0.00300409, 0.00547026,\n",
       "        0.02143141, 0.00547026, 0.00838432, 0.05408699, 0.05271725,\n",
       "        0.00612564, 0.08536754, 0.00678771, 0.00903861, 0.02687832,\n",
       "        0.01534894, 0.00419218, 0.02686065, 0.01560976, 0.00863549,\n",
       "        0.02822308, 0.00182341, 0.0625872 , 0.00451929, 0.00719533,\n",
       "        0.11969471, 0.00812539, 0.00838435, 0.10644996, 0.00835598,\n",
       "        0.00547026, 0.03136372, 0.01551821, 0.00846888, 0.03452136,\n",
       "        0.00477482, 0.00776675, 0.00678771, 0.00957452, 0.00827025,\n",
       "        0.01211482, 0.01658352, 0.01320294, 0.00364683, 0.01807723,\n",
       "        0.0060082 , 0.01534894, 0.02516245, 0.02575017, 0.0155793 ,\n",
       "        0.07351086, 0.00776675, 0.00664628, 0.01972328, 0.0062027 ,\n",
       "        0.01207556, 0.0857589 , 0.01069906, 0.01502049, 0.01495714,\n",
       "        0.01865906, 0.01109143, 0.02566705, 0.12681059, 0.01109142,\n",
       "        0.01933416, 0.00901232, 0.04173429, 0.01040653, 0.00383722,\n",
       "        0.06011757, 0.0081254 , 0.00846888, 0.01211482, 0.00927207,\n",
       "        0.00932317, 0.01795861, 0.01314887, 0.0106099 , 0.00482432,\n",
       "        0.00657444, 0.00496981, 0.01383535, 0.00482432, 0.01827323,\n",
       "        0.00699449, 0.00863549, 0.01473317, 0.00719533, 0.00838433,\n",
       "        0.00538273, 0.00745471, 0.02071009, 0.15439653, 0.01109141,\n",
       "        0.01242452, 0.01827323, 0.01040651, 0.01850567, 0.00678771,\n",
       "        0.00238743, 0.00551351, 0.04760387, 0.01177686, 0.01986727,\n",
       "        0.00588843, 0.01076547, 0.02926413, 0.00588843, 0.00895943,\n",
       "        0.0048243 , 0.00496979, 0.12074957, 0.00993963, 0.00729367,\n",
       "        0.01225127, 0.00678771, 0.00758107, 0.04637574, 0.0081254 ,\n",
       "        0.00657444, 0.0081254 , 0.00612564, 0.00947476, 0.00315827,\n",
       "        0.01731221, 0.00729368, 0.00430398, 0.00927209, 0.00964862,\n",
       "        0.0048243 , 0.00477484, 0.00726105, 0.00729368, 0.01134547,\n",
       "        0.01207553, 0.01083142, 0.00364685, 0.02487768, 0.01060992,\n",
       "        0.00430396, 0.0079481 , 0.0062027 , 0.01903707, 0.01015236,\n",
       "        0.00430399, 0.0220217 , 0.14237861, 0.0079481 , 0.02963507,\n",
       "        0.08146421, 0.00068919, 0.0376917 , 0.00954966, 0.01138726,\n",
       "        0.01873527, 0.01888674, 0.03999071, 0.00538273, 0.00344595,\n",
       "        0.06532033, 0.00547027, 0.00964864, 0.025219  , 0.00863549,\n",
       "        0.00547027, 0.02934516, 0.01331043, 0.00964865, 0.05479368,\n",
       "        0.00275677, 0.0081254 , 0.00794812, 0.00496979, 0.00947476,\n",
       "        0.00993962, 0.01069909, 0.01177686, 0.00564125, 0.01042929,\n",
       "        0.01672613, 0.00248492, 0.00719533, 0.02492537, 0.0112825 ,\n",
       "        0.0011937 , 0.00451931, 0.01138726, 0.05150036, 0.00657443,\n",
       "        0.00419215, 0.11524903, 0.00520326, 0.01933413, 0.01787907,\n",
       "        0.00564125, 0.01697977, 0.01551822, 0.03229638, 0.00182341,\n",
       "        0.01383537, 0.01320294, 0.0836306 , 0.00300409, 0.00248489,\n",
       "        0.1223556 , 0.00863551, 0.00664628, 0.01739432, 0.00838435,\n",
       "        0.00860795, 0.04286283, 0.00315824, 0.00846888, 0.01207554,\n",
       "        0.00767449, 0.00927207, 0.02012854, 0.01253868, 0.00846888,\n",
       "        0.00745471, 0.01896206, 0.0048243 , 0.00419217, 0.01001105,\n",
       "        0.01138724, 0.01207553, 0.03820489, 0.0079481 , 0.01263303,\n",
       "        0.02412158, 0.00551351, 0.00860794, 0.01015239, 0.05380964,\n",
       "        0.00451932, 0.02712462, 0.00895944, 0.00551351, 0.01911177,\n",
       "        0.00275674, 0.00964862, 0.07340094, 0.00182341, 0.01225127,\n",
       "        0.00689188, 0.00664629, 0.03525651, 0.0058884 , 0.01138727,\n",
       "        0.07265297, 0.00911709, 0.01138723, 0.02865728, 0.01201641,\n",
       "        0.0121148 , 0.01864634, 0.00699449, 0.00860797, 0.00137837,\n",
       "        0.00657443, 0.00520325, 0.0060082 , 0.00846887, 0.00496981,\n",
       "        0.00745471, 0.02272229, 0.0161482 , 0.0060082 , 0.00972221,\n",
       "        0.01329258, 0.00182341, 0.01253868, 0.00835598, 0.01060992,\n",
       "        0.01414096, 0.03203798, 0.01069909, 0.00182344, 0.01482957,\n",
       "        0.00726105, 0.03136371, 0.01383535, 0.02176131, 0.08232552,\n",
       "        0.00838435, 0.00631651, 0.0197233 , 0.00947476, 0.01758443,\n",
       "        0.0717848 , 0.08054068, 0.02351331, 0.01539528, 0.00947478,\n",
       "        0.04583488, 0.01502049, 0.01246269, 0.06634843, 0.00538273,\n",
       "        0.00972218, 0.10061434, 0.01076547, 0.00564124, 0.14394131,\n",
       "        0.01376652, 0.0062027 , 0.04090665, 0.01860806, 0.01015238,\n",
       "        0.00664629, 0.02294073, 0.00451932, 0.0099396 , 0.01175667,\n",
       "        0.01376652, 0.00547027, 0.02825671, 0.00344593, 0.0079481 ,\n",
       "        0.09178627, 0.01033784, 0.00137837, 0.07153292, 0.02594314,\n",
       "        0.00901232, 0.01276394, 0.00782769, 0.01195697, 0.02594314,\n",
       "        0.00678771, 0.00364685, 0.00879896, 0.00758107, 0.00315826,\n",
       "        0.04218708, 0.02346278, 0.11745952, 0.00315826, 0.00520326,\n",
       "        0.02822305, 0.0011937 , 0.00482432, 0.06159273, 0.0060082 ,\n",
       "        0.00358114, 0.02096085, 0.01641079, 0.01376651, 0.01865906,\n",
       "        0.00901229, 0.00947476, 0.03140913, 0.01309457, 0.00879897,\n",
       "        0.01083145, 0.03495208, 0.00612563, 0.00699449, 0.01858253,\n",
       "        0.00964862, 0.00068921, 0.06870827, 0.01490941, 0.00588843,\n",
       "        0.02040974, 0.00477484, 0.00846887, 0.01802458, 0.00664629,\n",
       "        0.00782767, 0.00564125, 0.0120164 , 0.00895943, 0.03888877,\n",
       "        0.00678771, 0.00835596, 0.01434107, 0.00699449, 0.01029176,\n",
       "        0.01193709, 0.01787909, 0.02305434, 0.00782767, 0.00275674,\n",
       "        0.12188888, 0.00364683, 0.00835596, 0.03431436, 0.00248492,\n",
       "        0.00776677, 0.12543219, 0.01040651, 0.00538273, 0.03131068,\n",
       "        0.01962673, 0.00699449, 0.02722947, 0.01495712, 0.00612563,\n",
       "        0.00248489, 0.01276395, 0.00879896, 0.01109143, 0.01001105,\n",
       "        0.00657444, 0.00358111, 0.05494951, 0.00903864, 0.01193709,\n",
       "        0.02654046, 0.00538273, 0.01265181, 0.03642277, 0.01001105,\n",
       "        0.00451929, 0.06646286, 0.00699449, 0.00964862, 0.02315712,\n",
       "        0.01357543, 0.00957452, 0.00860795, 0.00657443, 0.00957449]),\n",
       " 'rank_test_score': array([606, 569, 766, 357, 240, 792, 127, 240, 744,  27, 115, 684, 254,\n",
       "        325, 613, 412, 227, 618, 424,  43, 458, 476, 501, 221, 702, 564,\n",
       "         99, 720, 139, 211, 619, 449, 307, 742, 732, 240, 476, 287, 157,\n",
       "        768, 564, 293, 718, 578, 315, 359, 293, 795, 115,  43, 765,  50,\n",
       "          8, 747, 300,   6, 542,  21,  70, 546, 490, 139, 538,  28, 359,\n",
       "        202, 559, 391, 115, 359, 626,  84, 580, 276, 127, 521, 626, 315,\n",
       "        654, 254, 240, 569, 595, 124, 601, 730, 396, 728, 714, 157, 202,\n",
       "         70, 775,  50,  84, 692,  99, 198, 709, 165, 236, 458, 380,  81,\n",
       "        380,  38,  68, 310, 387, 211, 254, 458, 502,  38, 583, 556,  99,\n",
       "        402,  50, 165, 753, 695,  21, 722, 639, 139, 723, 594,   3, 701,\n",
       "        676, 337, 715, 738, 211, 643, 494, 777, 511, 557, 806, 337, 436,\n",
       "        776,  68, 177, 694, 254, 236, 683,  70,  70, 672, 486, 165, 402,\n",
       "        310, 581, 315, 647, 347, 371, 606, 476, 300, 637, 561, 348, 551,\n",
       "        653, 184, 525, 150, 380, 706, 662, 346, 711, 596, 310, 596, 372,\n",
       "        784, 300,  84, 802,  60,  13, 754,  99, 240, 649, 211,  21, 637,\n",
       "        337, 165, 591, 227,  99, 276, 710, 512,  84, 139, 127, 254, 608,\n",
       "        337, 327, 730, 527, 127, 601, 691, 307, 619, 513, 406, 675, 584,\n",
       "        211, 666, 577, 184, 127, 202, 749,  13,  60, 751,  96, 193, 756,\n",
       "         13, 227, 446, 202, 165, 574, 254, 253, 502, 184, 198,  21, 372,\n",
       "        202, 127, 184, 436,  84, 564, 500, 113, 635, 538, 337, 736, 561,\n",
       "        240, 617, 285, 127, 757, 667, 300, 739, 465, 418, 704, 745, 780,\n",
       "        619, 658, 774, 535, 633, 799, 150, 359, 803,  28, 254, 769, 198,\n",
       "         99, 759, 491, 127, 608, 254, 465, 574, 658, 272, 568, 668, 254,\n",
       "        406, 779, 315, 470, 746, 449, 418, 747, 470, 508, 699, 198, 300,\n",
       "        713, 370, 315, 608, 755, 804, 574, 502, 781, 455, 436, 796, 184,\n",
       "         96, 707, 359,  47, 726, 391, 211, 743, 436, 193, 446, 380,  60,\n",
       "        424, 628, 287, 359, 429, 412, 315, 763, 515, 287, 704, 652,  84,\n",
       "        688, 359, 227, 764, 625, 254, 693, 525, 337, 596, 561, 808, 276,\n",
       "        165, 809, 165,  60, 762, 115,  67, 703, 150,  60, 630, 211, 177,\n",
       "        614, 424, 165,  84, 517,  43, 209, 671, 293, 300, 587, 287, 127,\n",
       "        559, 337,  43, 711, 586, 157, 654, 157,  58, 634, 387, 348, 601,\n",
       "        688,  38, 635, 632, 805, 517, 348, 797, 327, 240, 793, 254, 307,\n",
       "        733, 221, 315, 648, 254, 115, 649, 165, 402, 184, 432, 472, 240,\n",
       "        529, 520, 476, 538, 601, 293, 717, 315, 272, 564, 432, 327, 678,\n",
       "        436, 287, 551, 645, 227, 547, 700, 285, 591, 254, 737, 127, 150,\n",
       "        760,  28, 115, 740,  28, 254, 665, 406,  84, 555,  13,  28, 591,\n",
       "        418, 436,  28,  99, 449, 115, 359, 476,  47, 473, 727, 412, 412,\n",
       "        476, 254, 391, 494, 398,  60, 639, 157, 533, 406, 113, 661, 157,\n",
       "        359, 227, 150, 771,  70, 139, 735,  12,  13, 761,  58,  38, 578,\n",
       "          4, 429, 473, 115,   4, 372, 240,  28, 150, 372, 191,  28, 527,\n",
       "        449,   8,  36, 436, 254, 254, 293,  81, 517, 449,  50, 498, 720,\n",
       "        315, 630, 674, 240, 596, 372,  57, 707, 641, 785, 587, 569, 810,\n",
       "        429, 276, 807, 226, 177, 729, 139,  70, 740, 348,  70, 716, 497,\n",
       "        177, 513, 380, 380, 387, 684,  36, 436, 293, 458,  99, 531, 348,\n",
       "        184, 660, 424, 165, 724, 491, 465, 293,  38, 498, 551, 523, 485,\n",
       "        623, 537, 773, 310, 276, 801, 165,  50, 791, 276, 177, 651,  96,\n",
       "          2, 644, 276,   8, 641, 534, 486, 221, 549, 227,  60, 327, 177,\n",
       "        157, 663, 418, 372, 623, 476,  84, 465, 657,  99, 569,  70, 387,\n",
       "        391, 240, 396, 673, 240, 524, 336, 402, 752, 150,  84, 767,  13,\n",
       "         21, 772,  13,   6, 669, 197,   1, 545,  99,  84, 581, 476, 327,\n",
       "        221, 549, 458,  70, 348, 432, 202, 379, 502, 300, 507, 548, 157,\n",
       "        406, 529,  81, 569, 486, 515, 679, 227, 210, 398, 398, 337, 749,\n",
       "        734, 800, 677, 680, 786, 646, 615, 794, 327, 327, 789,  80,  70,\n",
       "        770, 398,  84, 778, 455, 124, 622, 486,  99, 557, 211, 458, 543,\n",
       "        469, 165, 510, 696, 272, 454, 664, 590, 502, 325, 211, 508, 585,\n",
       "        418, 412, 436, 476, 458, 686, 654, 790, 551, 543, 783, 521, 380,\n",
       "        788, 139,  50, 697, 491, 138, 724, 127, 177, 718, 315, 276, 535,\n",
       "        538, 139, 424, 418, 192, 406, 698, 372, 348, 611,  50, 359, 612,\n",
       "         21, 272, 436, 276, 359, 681, 494, 221, 310, 435, 327, 589, 605,\n",
       "        798, 337, 193, 787, 124,  47, 782, 391, 240, 758, 254,   8, 686,\n",
       "        115, 236, 670, 475, 139, 287, 348, 446, 202, 327, 139, 211, 629,\n",
       "         99, 531, 682, 348, 358, 596,  99, 227, 690, 239,  13, 616,  99,\n",
       "        193, 455, 139, 412])}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Details in the traininf results\n",
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 82.89473684210526 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1026\n",
      "           1       0.85      0.80      0.82      1026\n",
      "\n",
      "    accuracy                           0.83      2052\n",
      "   macro avg       0.83      0.83      0.83      2052\n",
      "weighted avg       0.83      0.83      0.83      2052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make prediction on test data with the best hyperparameters\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "print('Accuracy on test data:',accuracy_score(y_test, y_pred)*100,'%')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEGCAYAAADxD4m3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdj0lEQVR4nO3debxWVd338c/3HJRBmRQlQhQHcsgBERWjnFADrSBzbJCnMJzS5tLb7kyf6rGnntRM7Ta1MHMeEo0cwpFSFJxBTRwQkHlyRAN/zx97HbwkzjnXhnNxXdfm+/a1X2fvtddeex14+WOtvfZeSxGBmVkRNVS7AmZmleIAZ2aF5QBnZoXlAGdmheUAZ2aF1a7aFSildh1DG3audjUsh9133LLaVbAcpk9/hQULFmhtymjsslXE8nfKyhvvzL8zIoauzf3WRm0FuA070377o6pdDcvhHxN/W+0qWA6D9x641mXE8mW03+GYsvIue/zCHmt9w7VQUwHOzOqAAK1VI3CdcYAzs/xUH4/vHeDMLD+34MysmAQNjdWuRFkc4MwsH+EuqpkVldxFNbMCcwvOzArLLTgzKya5BWdmBSU8impmReUWnJkVWYOfwZlZEfk9ODMrNI+imlkx+VMtMysyd1HNrJDkT7XMrMjqpAVXH7U0s9rS1IprbWu1GH1b0hRJz0i6RlIHSVtLmihpmqTrJG2Y8rZPx9PS+b6tle8AZ2Y5pRd9y9laKkXqDZwGDIyInYFG4BjgF8B5EbEdsBgYlS4ZBSxO6eelfC1ygDOzfJo+1Spna107oKOkdkAnYDZwIHBjOj8GGJH2h6dj0vkhUsvNRAc4M8spVwuuh6RJJdvoplIiYhbwK+BVssC2FJgMLImI5SnbTKB32u8NzEjXLk/5N22pph5kMLP8yh9FXRARq12rUFJ3slbZ1sAS4AagTddQdQvOzPJrg2dwwEHAyxExPyL+DdwMDAa6pS4rwBbArLQ/C+gDkM53BRa2dAMHODPLr21GUV8FBknqlJ6lDQGmAvcCR6Q8I4Fb0/7YdEw6f09EREs3cBfVzPJR20yXFBETJd0IPAYsBx4HLgX+Clwr6acp7fJ0yeXAnyRNAxaRjbi2yAHOzHJTQ9t0/iLiLOCsVZJfAvZaTd5lwJF5yneAM7NcBLTydkbNcIAzs3yUtjrgAGdmOcktODMrLgc4MyushjYaZKg0Bzgzy8fP4MysqORncGZWZA5wZlZYDnBmVlgOcGZWTAJ5ZXszKyIPMphZoTnAmVlx1Ud8c4Azs5zkFpyZFZgDnJkVkpC/RTWzAquPBpwDnJnl5GdwZlZkDnBmVlj1EuDq40mhmdUUNaisrcUypO0lPVGyvS7pW5I2kXS3pBfSz+4pvyT9RtI0SU9JGtBaPd2CawMnHXsAXxnxCYhg6rTXOOWcq7jlt99g4406ANCje2cem/IKX/7+7wEYPKAf/+e7X6Bdu0YWLXmTz5xwQTWrv975xjlXceeEZ+jRvTMPXXcmAOde+leu/Ms/2bTbxgD89ymf45DBHwfg13+4k6vGPkRjQwPnfu8IhuyzU9XqXguktvlUKyKeB/qnMhvJVq6/BTgdGB8R50o6PR3/EBgG9Evb3sAl6WezKhrgJA0FLgAagcsi4txK3q8aem3WlROO3o9BR/+MZe/+myt+/jUOP2QPDh19/so8Y35xPOPufwqALht35Fc/PIojT7uYmXMX06P7xlWq+frr2M8M4utH7ceJZ135ofSTjj2AU79y0IfSnntpNjff/RgPXXcmc+YvZcQpv2XSTT+msXH97vxUoIs6BHgxIqZLGg7sn9LHAPeRBbjhwJVpNfuHJXWT1CsiZjdXaMX+llJEvogs6u4EHCupkP/0tWvXSIf2G9DY2ECnDhsyZ/7Slec6b9SBfQd+bGWAO3LoQG6/90lmzl0MwILFb1alzuuzwQO2o3uXTmXlHXf/Uxx+8ADab7gBW/XuwTZ9ejB5yiuVrWAdaGrFtbYBPSRNKtlGN1PkMcA1ab9nSdCaA/RM+72BGSXXzExpzapkC24vYFpEvAQg6VqyCDy1gvdc52bPX8qFV43n6dv+N8vefY97Jz7HvROfW3n+0P125f5Hn+eNt5YBsO2Wm7NBu0Zu+9032bhTe3537X1cN+6RalXfSvz+hge4dtwj7L7jlvz0W4fTrUsnZs9fysCd+67M89HNuzO75B+w9Vb5DbgFETGwxaKkDYHPAWesei4iQlLkrl9SyXZ2WdFW0uim6B7L36lgdSqja+eOHLrvLvQffhY7DjuTTh025Khhe648f8Sn9+CmOyevPG7X2MBuO/Th6G9dwhdOvYjvjxrKtltuXo2qW4mvfeFTPH7LT3jwz6fTs0cXfnT+zdWuUk3L0YIrxzDgsYiYm47nSuqV7tMLmJfSZwF9Sq7bIqU1q+oPEiLi0ogYGBED1a5jtauT2/577cD01xaycMmbLF/xPrfd+yR77bo1AJt03YgBO/Xlrn88szL/a/OWcM/Dz/L2svdYtPQt/vn4NHbu12Ir29aBzTftQmNjAw0NDYwcMZjJU6YD2TPWWelxAsBr8xbTa7Ou1apmTZCgoUFlbWU6lg+6pwBjgZFpfyRwa0n6cWk0dRCwtKXnb1DZAJc72tajmXMWMXCXrenYfgMA9ttze55/OfuHaPiQ3blzwjO8+97ylfnH3f8Ug/pvS2NjAx3bb8DAnfvyr1fmVKXu9oE5Cz7odt5+35PsuG0vAIbtuys33/0Y7773b6bPWsCLr85nj4/3rVIta0V5rbdyWnCSNgIOBkqbzOcCB0t6ATgoHQOMA14CpgG/B05urfxKPoN7FOgnaWuywHYM8MUK3q8qJk+Zztjxj3PfVT9kxYr3eer5mYy55R8AHH7IHpw/5q4P5f/XK3MZ/8+pTLj6DCKCK2/9J8++2OI/QtbGRp35B/4x+QUWLnmTjx/2I04ffSgTJr/A0/+aiSS27LUJ5/3XsQDsuG0vRhy0O4OO+hntGhv45Q+OWu9HUCFrxbWFiHgL2HSVtIVko6qr5g3glDzlK7umMiQdCpxP9prIFRHxs5byN3TaPNpvf1TF6mNtb/Gjv612FSyHwXsPZPLkSWsVnjp85GOx1cgLy8r7r/87dHJrgwyVVNH34CJiHFmz0syKQm3Xgqs0f8lgZrkI8gwgVJUDnJnl5gBnZsXkLqqZFZWon+mSHODMLCcv/GxmBVYn8c0BzsxykgcZzKyg/AzOzAqtTuKbA5yZ5ecWnJkVVp3ENwc4M8vJCz+bWVGJXJNZVpUDnJnlVicNOAc4M8vPXVQzKyZ/bG9mReUXfc2s0BzgzKyw6mUU1csDmVk+6RlcOVurRUndJN0o6TlJz0raR9Imku6W9EL62T3llaTfSJom6SlJA1or3wHOzHJRG66LClwA3BEROwC7Ac8CpwPjI6IfMD4dAwwD+qVtNHBJa4U7wJlZbm3RgpPUFdgXuBwgIt6LiCXAcGBMyjYGGJH2hwNXRuZhoJukXi3dwwHOzHJrkMragB6SJpVso0uK2RqYD/xB0uOSLksr3feMiKbV0OcAPdN+b2BGyfUzU1qzPMhgZrko34SXC1pY+LkdMAA4NSImSrqAD7qjQLaavaQ1Xp3eLTgzy61B5W2tmAnMjIiJ6fhGsoA3t6nrmX7OS+dnAX1Krt8ipTVfz3y/lpkZbTLIEBFzgBmStk9JQ4CpwFhgZEobCdya9scCx6XR1EHA0pKu7Go120WVdCHQbNMwIk5rsfZmVlht+J7vqcCfJW0IvAR8lazhdb2kUcB04KiUdxxwKDANeDvlbVFLz+AmrUWlzaygRPaqSFuIiCeA1T2jG7KavAGckqf8ZgNcRIwpPZbUKSLezlO4mRVTnXzI0PozuPRm8VTguXS8m6SLK14zM6tNyia8LGertnIGGc4HPg0sBIiIJ8lezjOz9ZDI9R5cVZX1HlxEzFhlRGRFZapjZvWgBmJXWcoJcDMkfQIISRsA3yT7XszM1lP1Ml1SOV3UE8lGLnoDrwH9yTmSYWbFUe53qLUQA1ttwUXEAuBL66AuZlYnGmshepWhnFHUbSTdJmm+pHmSbpW0zbqonJnVpjacLqmiyumiXg1cD/QCPgrcAFxTyUqZWe3KRlHb5FvUiisnwHWKiD9FxPK0XQV0qHTFzKxGldl6q4UWXEvfom6Sdv8m6XTgWrJvU48m+ybMzNZTNRC7ytLSIMNksoDW9KucUHIugDMqVSkzq2210DorR0vfom69LitiZvVBQGMtPGArQ1lfMkjaGdiJkmdvEXFlpSplZrWtPsJbGQFO0lnA/mQBbhzZyjYTAAc4s/WQRE18Z1qOckZRjyCbm2lORHyVbGmvrhWtlZnVtMJ8yQC8ExHvS1ouqQvZ/Oh9WrvIzIqr7gcZSkyS1A34PdnI6pvAQ5WslJnVtjqJb2V9i3py2v2dpDuALhHxVGWrZWa1SlL9j6JKGtDSuYh4rDJVMrNaV4Qu6v9r4VwAB7ZxXdh1hz7cdf95bV2sVVD3Q35e7SpYDu++0OIqe2Wrl/VGW3rR94B1WREzqw+i7Vpwkl4B3iCbJXx5RAxMn4leB/QFXgGOiojFym56AdnSgW8D/6u1nmS9BGIzqyFtPJvIARHRPyKalg88HRgfEf2A8ekYsndw+6VtNHBJq/XM80uZmUnZp1rlbGtoONC0bOkYYERJ+pWReRjoJqlXSwU5wJlZbjlacD0kTSrZRq9SVAB3SZpccq5nRDQ9LJwD9Ez7vYEZJdfOTGnNKudTLZFNWb5NRJwjaUvgIxHxSGvXmlkx5XgEt6Ck67k6n4yIWZI2B+6W9FzpyYgISbGG1SyrBXcxsA9wbDp+A7hoTW9oZvWtLddFjYhZ6ec84BZgL2BuU9cz/ZyXss/iw19RbZHSmlVOgNs7Ik4BlqWKLAY2LOM6MyuohjK3lkjaSFLnpn3gEOAZYCwwMmUbCdya9scCxykzCFha0pVdrXI+1fq3pEayvjKSNgPeL+M6MyuoNnpLpCdwS3rlpB1wdUTcIelR4HpJo4DpwFEp/ziyV0Smkb0m8tXWblBOgPsNWdNxc0k/I5td5Ec5fxEzK4i2+lQrIl4im51o1fSFZDMYrZoe5FyTuZxvUf8saXK6oYAREeGV7c3WY3XyKWpZo6hbkjUHbytNi4hXK1kxM6tNTYMM9aCcLupf+WDxmQ7A1sDzwMcrWC8zq2F1Et/K6qLuUnqcZhk5uZnsZlZ0NbKocznKWnSmVEQ8JmnvSlTGzOqD6mTZmXKewX2n5LABGAC8VrEamVlNE9CuTj7yLKcF17lkfznZM7mbKlMdM6sHRZjwkvSCb+eI+N46qo+Z1bhsFLXatShPS1OWt4uI5ZIGr8sKmVmNq5ElAcvRUgvuEbLnbU9IGgvcALzVdDIibq5w3cysRhXpPbgOwEKyNRia3ocLwAHObD0koLEAgwybpxHUZ/ggsDVZ4/mZzKzeiYYCvCbSCGwMq/1NHODM1lPZojPVrkV5WgpwsyPinHVWEzOrDwX5kqFOfgUzW9eKMMjwH/MxmZkVoosaEYvWZUXMrH60xYSX60Luj+3NbP0m6me9UQc4M8tHBfkW1cxsdeojvDnAmVlO9TRleb10pc2shqjMrayypEZJj0u6PR1vLWmipGmSrpO0YUpvn46npfN9WyvbAc7MchINDeVtZfomULpS3y+A8yJiO2AxMCqljwIWp/TzUr4WOcCZWS5No6hru7I9gKQtgMOAy9KxyCb2uDFlGQOMSPvD0zHp/BC1MtrhZ3BmlluOUdQekiaVHF8aEZeWHJ8P/IAPZg7fFFgSEcvT8Uygd9rvDcwASHNVLk35FzR3cwc4M8stxxDDgogYuNoypM8A8yJisqT926Riq3CAM7N82u49uMHA5yQdSjbvZBfgAqBb04ziwBbArJR/FtAHmCmpHdCVbK7KZvkZnJnlIqBRKmtrSUScERFbRERf4Bjgnoj4EnAvcETKNhK4Ne2PTcek8/dERItTtznAmVlubfmayGr8EPiOpGlkz9guT+mXA5um9O8Ap7dWkLuoZpZbW7/nGxH3Afel/ZeAvVaTZxlwZJ5yHeDMLJfsNZH6+JLBAc7McquTL7Uc4MwsLyG34MysiJpGUeuBA5yZ5VOQle3NzFbLAc7MCsvP4MyskLIJL6tdi/I4wJlZbvUyo68DnJnl5i7qeuK1uYv59s+vZsGiN5Dgi5/dh68duR9LXn+LU35yJTNnL2KLXptw8dkj6dq5E9Omz+V7517DlH/N5HvHH8YJxx5Q7V9hvXTS4XvylaH9AZj68jxO+dXtXPjdw+jfrxfLV7zP5Ode49sX/I3lK95n8K5bcvXZRzB9zlIAbpvwPL/884Qq1r663EUFJF0BNM33tHOl7lNtjY0N/Ojkz7HL9n148+1lfOb4X/PJPbfnxr89wuAB/Tj5ywdx8VV/5+KrxnPGSZ+lW5dOnH3a4dw54elqV3291WvTjTlhxJ4MOv5Slr23nCvO/DyH778TN4yfwuhzxwJw2RnDOW5Yf664/TEAHnp6Bsf8+IZqVruG1M+LvpWcTeSPwNAKll8Tevboyi7b9wFg404d2G6rnsydv5S7JzzDF4buCcAXhu7JXSmg9ejemd123JINGhurVmeDdo0NdGjfjsYG0al9O+YsepO7H31x5fnJz7/GR3t0bqGE9Vh6D66crdoqFuAi4gFgUaXKr0UzZi9iygsz6b/TVixY/AY9e3QFYPNNu7Bg8RtVrp01mb3wTS68YSJPX/UNnrv2m7z+9rvcO/nllefbNTZw9JBdGD/ppZVpe+7UmwcvGcUNPzuaHbbqUY1q15QKT5fUZqo+H5yk0ZImSZq0cEGzU6vXvLfefpcT//sP/PjUz9N5ow4fOpfNfloLf90G0HXjDhz6iX70P+5idjz2N3TqsAFHDfn4yvO/OvXT/PPpV3nomRkAPDVtDrt++SI+ddLlXPqXSVz1kyOaK3q90FYTXq4LVQ9wEXFpRAyMiIGb9qjPfxn/vXwFJ/73Hxhx8B4M229XIOuKzl2QPZSeu2ApPbpvXM0qWon9d+/L9DlLWLj0bZaveJ/bJjzPXjttAcAPvvxJenTrxJn/8/eV+d94+z3eWvZvAO5+9EU2aGxgky4dq1L3mlEnTbiqB7h6FxH84BfXst1WPfn60fuvTD9o8M7cdMejANx0x6Mc/MnCjrPUnZnzX2fgDr3p2D4bY9tv9748/+pCvjJ0N4bssQ3H//xWSifC3rz7Riv3B2zfi4YGsej1d9Z1tWuKyvyv2vyayFqa9PTL3HznJHbYphfDvvZLAL7/9cM4+UtDOPmsMVz314n0/kh3Lj47m0p+3sLX+ezoX/PmW8toaBBX3Hg/f7/y9P/o1lrlTH7uNcY++Bz3XTyKFSve56lpcxgz7nFmjf0+M+Yu5a4Lsr+rptdBhn9qB776mQGsWPE+77y3nFE//0t1f4EaUAO9z7KolTUb1rxg6Rpgf6AHMBc4KyIub+ma/gP2iLvuf7gi9bHK2Gr4L6tdBcvh3UkX8f7rs9YqPO24y+5x5a33lZV3r227TW5u2cB1oWItuIg4tlJlm1mV1UkLzl1UM8tFqp9vUT3IYGa5tcUgqqQOkh6R9KSkKZLOTulbS5ooaZqk6yRtmNLbp+Np6Xzf1urpAGdm+bXNayLvAgdGxG5Af2CopEHAL4DzImI7YDEwKuUfBSxO6eelfC1ygDOznMp9SaTVle0jIt5MhxukLYADgRtT+hhgRNofno5J54dILfeVHeDMLLcc36L2aPpSKW2jP1yOGiU9AcwD7gZeBJZExPKUZSbQO+33BmYApPNLgU1bqqcHGcwsF5HrPbgFLb0mEhErgP6SugG3ADusbf1KuQVnZrm19ZcMEbEEuBfYB+gmqanxtQUwK+3PAvoApPNdgYUtlesAZ2a5tcV0SZI2Sy03JHUEDgaeJQt0TTMajARuTftj0zHp/D3RypcK7qKaWW5t9BZcL2CMpEayxtb1EXG7pKnAtZJ+CjwONH0BdTnwJ0nTyKZiO6a1GzjAmVk+bTRTSEQ8Bey+mvSXgL1Wk74MODLPPRzgzCy3WpgppBwOcGaWixedMbNic4Azs6JyF9XMCqtOJhNxgDOz/OokvjnAmdkaqJMI5wBnZrnU04SXDnBmllt9hDcHODNbE3US4RzgzCyn2ljztBwOcGaWW508gnOAM7N8ck54WVUOcGaWm7uoZlZYbsGZWWHVSXxzgDOznMqYjrxWOMCZ2RqojwjnAGdmuXjCSzMrNHdRzayw6uU1Ea+Lamb5qcytpSKkPpLulTRV0hRJ30zpm0i6W9IL6Wf3lC5Jv5E0TdJTkga0Vk0HODPLrQ3iG8By4LsRsRMwCDhF0k7A6cD4iOgHjE/HAMOAfmkbDVzS2g0c4Mwsl3JXtW/tOV1EzI6Ix9L+G2Sr2vcGhgNjUrYxwIi0Pxy4MjIPA90k9WrpHn4GZ2a5qfxRhh6SJpUcXxoRl66mvL5ki0BPBHpGxOx0ag7QM+33BmaUXDYzpc2mGQ5wZpZbjiGGBRExsMWypI2Bm4BvRcTrpcEzIkJSrGE13UU1s/zaooualaMNyILbnyPi5pQ8t6nrmX7OS+mzgD4ll2+R0prlAGdmOans/1osJWuqXQ48GxG/Ljk1FhiZ9kcCt5akH5dGUwcBS0u6sqvlLqqZ5dKG88ENBr4CPC3piZT2X8C5wPWSRgHTgaPSuXHAocA04G3gq63dwAHOzHJriwAXERNo/nHekNXkD+CUPPdwgDOz3OrlSwYHODPLx9MlmVlRlfmVQk1wgDOz/OokwjnAmVlufgZnZoXlCS/NrLgc4MysqNxFNbNCqqeV7ZW9HFwbJM0n+zSjaHoAC6pdCculqH9nW0XEZmtTgKQ7yP58yrEgIoauzf3WRk0FuKKSNKm1KWOstvjvrBg8m4iZFZYDnJkVlgPcuvEfUzRbzfPfWQH4GZyZFZZbcGZWWA5wZlZYDnAVJGmopOfTStynt36FVZukKyTNk/RMtetia88BrkIkNQIXka3GvRNwbFq122rbH4GqvZhqbcsBrnL2AqZFxEsR8R5wLdnK3FbDIuIBYFG162FtwwGucppbhdvM1hEHODMrLAe4ysm9CreZtS0HuMp5FOgnaWtJGwLHkK3MbWbriANchUTEcuAbwJ3As8D1ETGlurWy1ki6BngI2F7SzLS6utUpf6plZoXlFpyZFZYDnJkVlgOcmRWWA5yZFZYDnJkVlgNcHZG0QtITkp6RdIOkTmtR1h8lHZH2L2tpIgBJ+0v6xBrc4xVJ/7H6UnPpq+R5M+e9fiLpe3nraMXmAFdf3omI/hGxM/AecGLpSUlrtM5tRBwfEVNbyLI/kDvAmVWbA1z9ehDYLrWuHpQ0FpgqqVHSLyU9KukpSScAKPPbND/d34HNmwqSdJ+kgWl/qKTHJD0pabykvmSB9Nup9fgpSZtJuind41FJg9O1m0q6S9IUSZdB68ufS/qLpMnpmtGrnDsvpY+XtFlK21bSHemaByXt0CZ/mlZIXtm+DqWW2jDgjpQ0ANg5Il5OQWJpROwpqT3wD0l3AbsD25PNTdcTmApcsUq5mwG/B/ZNZW0SEYsk/Q54MyJ+lfJdDZwXERMkbUn2tcaOwFnAhIg4R9JhQDlfAXwt3aMj8KikmyJiIbARMCkivi3px6nsb5AtBnNiRLwgaW/gYuDANfhjtPWAA1x96SjpibT/IHA5WdfxkYh4OaUfAuza9HwN6Ar0A/YFromIFcBrku5ZTfmDgAeayoqI5uZFOwjYSVrZQOsiaeN0j8PTtX+VtLiM3+k0SZ9P+31SXRcC7wPXpfSrgJvTPT4B3FBy7/Zl3MPWUw5w9eWdiOhfmpD+R3+rNAk4NSLuXCXfoW1YjwZgUEQsW01dyiZpf7JguU9EvC3pPqBDM9kj3XfJqn8GZs3xM7jiuRM4SdIGAJI+Jmkj4AHg6PSMrhdwwGqufRjYV9LW6dpNUvobQOeSfHcBpzYdSOqfdh8AvpjShgHdW6lrV2BxCm47kLUgmzQATa3QL5J1fV8HXpZ0ZLqHJO3Wyj1sPeYAVzyXkT1feywtnPI/ZC31W4AX0rkryWbM+JCImA+MJusOPskHXcTbgM83DTIApwED0yDGVD4YzT2bLEBOIeuqvtpKXe8A2kl6FjiXLMA2eQvYK/0OBwLnpPQvAaNS/abgaeCtBZ5NxMwKyy04MyssBzgzKywHODMrLAc4MyssBzgzKywHODMrLAc4Myus/w+inbvwiFLPrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(list(y_test), list(y_pred))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('model/NN_biclass-gridsearch-balanced.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our observation\n",
    "\n",
    "Compared to performing binary classification on imbalanced data, while there was no noticable tendency for the imbalancedly fitted model to predict more test set entries as group 0, we did see an improvement on performance metrics like accuracy (80 to 82%), precision, and recall when fitted with balanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
